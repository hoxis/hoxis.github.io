<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Windows环境查看端口占用情况、相应进程、杀死进程]]></title>
    <url>%2Fwindows-kill-pid.html</url>
    <content type="text"><![CDATA[本地调试启动程序时经常遇到端口占用的情况，比如： 1234错误: 代理抛出异常错误: &lt;u&gt;java.rmi.server.ExportException&lt;/u&gt;: Port already in use: 54530; nested exception is: &lt;u&gt;java.net.BindException&lt;/u&gt;: Address already in use: JVM_Bind 下面来看下 Windows 下如何查看端口占用情况，以及如何杀死端口占用的进程。 1、查看端口占用情况netstat –ano|findstr &quot;指定端口号&quot;，比如，查看 54530 的占用情况： 1234C:\WINDOWS\system32&gt;netstat -ano|findstr "54530" TCP 127.0.0.1:49643 127.0.0.1:54530 ESTABLISHED 4388 TCP 127.0.0.1:54530 0.0.0.0:0 LISTENING 11320 TCP 127.0.0.1:54530 127.0.0.1:49643 ESTABLISHED 11320 最右边的数字就是进程号。 2、查看进程名可以使用 tasklist|findstr &quot;进程号&quot; 来查看进程名称，比如： 12C:\WINDOWS\system32&gt;tasklist|findstr "4388"xxx.exe 4388 Services 0 13,276 K 可以看出，是 xxx.exe 这个进程占用了端口号，这时可以使用 Windows 任务管理器将服务停掉。 或者使用命令。 3、杀死进程可以使用 tskill 进程号来杀死指定进程。 123456C:\WINDOWS\system32&gt;tasklist|findstr "4388"xxx.exe 4388 Services 0 13,276 KC:\WINDOWS\system32&gt;tskill 4388C:\WINDOWS\system32&gt;tasklist|findstr "4388" 可以看出，进程已被杀死。 若提示没有权限杀死进程，请以管理员身份运行 cmd。 win10 环境下开启方法，按下 win+S：]]></content>
      <categories>
        <category>绊脚石</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次服务器宕机后数据库恢复的过程]]></title>
    <url>%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%95%E6%9C%BA%E5%90%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E6%81%A2%E5%A4%8D%E7%9A%84%E8%BF%87%E7%A8%8B.html</url>
    <content type="text"><![CDATA[现象现象很简单，数据库服务器被宕机，当然是在没有停数据库服务的情况下。 机器重启后，试图重启MySQL服务，无果，查看错误日志： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556170920 0:30:17 InnoDB: Assertion failure in thread 140107687212800 in file /export/home/pb2/build/sb_0-2629600-1291399482.5/mysql-5.5.10/storage/innobase/include/fut0lst.ic line 83InnoDB: Failing assertion: addr.page == FIL_NULL || addr.boffset &gt;= FIL_PAGE_DATAInnoDB: We intentionally generate a memory trap.InnoDB: Submit a detailed bug report to http://bugs.mysql.com.InnoDB: If you get repeated assertion failures or crashes, evenInnoDB: immediately after the mysqld startup, there may beInnoDB: corruption in the InnoDB tablespace. Please refer toInnoDB: http://dev.mysql.com/doc/refman/5.1/en/forcing-recovery.htmlInnoDB: about forcing recovery.170920 0:30:17 - mysqld got signal 6 ;This could be because you hit a bug. It is also possible that this binaryor one of the libraries it was linked against is corrupt, improperly built,or misconfigured. This error can also be caused by malfunctioning hardware.We will try our best to scrape up some info that will hopefully help diagnosethe problem, but since we have already crashed, something is definitely wrongand this may fail.key_buffer_size=16777216read_buffer_size=262144max_used_connections=0max_threads=500thread_count=0connection_count=0It is possible that mysqld could use up to key_buffer_size + (read_buffer_size + sort_buffer_size)*max_threads = 406067 Kbytes of memoryHope that's ok; if not, decrease some variables in the equation.thd: 0x0Attempting backtrace. You can use the following information to find outwhere mysqld died. If you see no messages after this, something wentterribly wrong...stack_bottom = (nil) thread_stack 0x40000/usr/local/mysql/bin/mysqld(my_print_stacktrace+0x39)[0x916839]/usr/local/mysql/bin/mysqld(handle_segfault+0x359)[0x4fc0d9]/lib64/libpthread.so.0(+0xf4a0)[0x7f6d5ca9f4a0]/lib64/libc.so.6(gsignal+0x35)[0x7f6d5be4a885]/lib64/libc.so.6(abort+0x175)[0x7f6d5be4c065]/usr/local/mysql/bin/mysqld[0x7d5601]/usr/local/mysql/bin/mysqld[0x7ca012]/usr/local/mysql/bin/mysqld[0x7ca357]/usr/local/mysql/bin/mysqld[0x7cce1a]/usr/local/mysql/bin/mysqld[0x7b89e8]/usr/local/mysql/bin/mysqld[0x78d97d]/usr/local/mysql/bin/mysqld(_Z24ha_initialize_handlertonP13st_plugin_int+0x48)[0x6683a8]/usr/local/mysql/bin/mysqld[0x57ddba]/usr/local/mysql/bin/mysqld(_Z11plugin_initPiPPci+0xb5d)[0x581cbd]/usr/local/mysql/bin/mysqld[0x50212c]/usr/local/mysql/bin/mysqld(_Z11mysqld_mainiPPc+0x3c2)[0x504742]/lib64/libc.so.6(__libc_start_main+0xfd)[0x7f6d5be36cdd]/usr/local/mysql/bin/mysqld[0x4fa3fa]The manual page at http://dev.mysql.com/doc/mysql/en/crashing.html containsinformation that should help you find out what is causing the crash.170920 00:30:17 mysqld_safe mysqld from pid file /usr/local/mysql/data/localhost.localdomain.pid ended170920 01:04:55 mysqld_safe Starting mysqld daemon with databases from /usr/local/mysql/data170920 1:04:55 [Warning] Ignoring user change to 'ser=mysql' because the user was set to 'mysql' earlier on the command line 解决过程刚开始的重点放在了这段日志上：1234It is possible that mysqld could use up to key_buffer_size + (read_buffer_size + sort_buffer_size)*max_threads = 406067 Kbytes of memoryHope that's ok; if not, decrease some variables in the equation. 以为是MySQL的一些参数设置有问题，结合Google结果，对/etc/my.cnf进行了修改，仍无果。问题解决之后想来，因为之前MySQL是运行正常的，因此配置一般不会有问题，当时也是“病急乱投医”了。 1. Forcing InnoDB Recovery设置恢复模式启动mysql，在 /etc/my.cnf中添加如下配置：12[mysqld]innodb_force_recovery = 1 其中后面的值设置为1、如果1不能恢复，再逐步增加为2/3/4等。直到能启动mysql为止！！！ Forcing InnoDB Recovery提供了6个等级的修复模式，需要注意的是值大于3的时候，会对数据文件造成永久的破坏，不可恢复。六个等级的介绍摘抄如下： SRV_FORCE_IGNORE_CORRUPTLets the server run even if it detects a corrupt page. Tries to make SELECT * FROM tbl_name jump over corrupt index records and pages, which helps in dumping tables. SRV_FORCE_NO_BACKGROUNDPrevents the master thread and any purge threads from running. If a crash would occur during the purge operation, this recovery value prevents it. SRV_FORCE_NO_TRX_UNDODoes not run transaction rollbacks after crash recovery. SRV_FORCE_NO_IBUF_MERGEPrevents insert buffer merge operations. If they would cause a crash, does not do them. Does not calculate table statistics. This value can permanently corrupt data files. After using this value, be prepared to drop and recreate all secondary indexes. SRV_FORCE_NO_UNDO_LOG_SCANDoes not look at undo logs when starting the database: InnoDB treats even incomplete transactions as committed. This value can permanently corrupt data files. SRV_FORCE_NO_LOG_REDODoes not do the redo log roll-forward in connection with recovery. This value can permanently corrupt data files. Leaves database pages in an obsolete state, which in turn may introduce more corruption into B-trees and other database structures. 恢复模式下启动MySQL1/usr/local/mysql/bin/mysqld_safe -user=mysql&amp; 重启成功后，测试数据库是否可以正常连接：mysql -uroot -p123456 数据备份恢复模式数据库是只读的，当然和恢复级别相关。现在需要做的是将数据库数据备份，然后清除之前的错误数据，最后再从备份数据中进行恢复。1mysqldump -uroot -p123456 --all-databases &gt; all_mysql_backup.sql 原数据清理或备份清理数据前需要先将数据库服务停止。将数据库的data目录进行备份，相当于恢复到数据库刚安装完成时的状态。123mkdir data-bakcd datamv * ../data-bak/ 数据恢复数据库初始化因为所有的数据都已删除掉，因此需要进行MySQL的初始化。12cd /usr/local/mysql ./scripts/mysql_install_db --user=mysql&amp; 备份数据恢复登录MySQL：1mysql -u root -p123456 登录后，在数据库中执行下列语句，即可恢复数据：1source /app/all_mysql_backup.sql 恢复后对数据进行检查。]]></content>
      <categories>
        <category>绊脚石</category>
      </categories>
      <tags>
        <tag>错误处理</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我学设计模式：适配器（Adapter）模式]]></title>
    <url>%2F%E6%88%91%E5%AD%A6%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E9%80%82%E9%85%8D%E5%99%A8%EF%BC%88Adapter%EF%BC%89%E6%A8%A1%E5%BC%8F.html</url>
    <content type="text"><![CDATA[定义：将一个类的接口转化成客户端希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 主要功能是进行转换匹配，从而可以复用已有的功能。通过给适配器对象组合被适配的对象，然后当客户端调用Target时，适配器会将相应的功能委托给被适配的对象去完成。生活中的适配器模式很常见，比如电压转换器、翻译等。 适配器模式中的3个角色 Target 目标角色该角色定义把其他类转换为何种接口，也就是期望接口。 123public interface Target&#123; public void request();&#125; 目标角色的实现类： 12345public class ConcreteTarget implements Target&#123; public void request()&#123; System.out.println("ConcreteTarget doing..."); &#125;&#125; Adaptee 源角色想把谁转换成目标角色，这个“谁”就是源角色。它是已经存在的、运行良好的类或对象，经过适配器的包装，成为一个新的角色。 12345public class Adaptee&#123; public void doSomething()&#123; System.out.println("Adaptee doing..."); &#125;&#125; Adapter 适配器角色核心角色，其他两个角色都是已经存在的，而适配器角色是需要新建的。它的职责就是把源角色转换为目标角色。 12345public class Adapter extends Adaptee implements Target&#123; public void request()&#123; super.doSomething(); &#125;&#125; 场景类 12345678910public class Client&#123; public static void main(String[] args)&#123; //原有的业务逻辑 Target target = new ConcreteTarget(); target.request(); //现在增加了适配器角色后的业务逻辑 Target target2 = new Adapter(); target2.request(); &#125;&#125; 适配器的实现适配器通常是一个类，一般或让其去实现Target接口，然后再其具体实现里面调用Adaptee。 类的适配器模式当希望将一个类转换成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类Adaptee，实现新的接口即可。 对象的适配器模式当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Adapter类，持有原类Adaptee的一个实例，在Adapter类的方法中，调用实例的方法就行。 接口的适配器模式当不希望实现一个接口中所有的方法时，可以创建一个抽象类Adapter，实现所有方法，我们写别的类的时候，继承抽象类即可。 适配器模式的调用顺序 优缺点优点 更好的复用性 刚好的可扩展性 缺点 过多地使用会让系统非常混乱，很难从整体进行把握。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 何时使用适配器适配器模式的本质是：转换匹配，复用功能。通过转换已有的功能实现，从而可以将其匹配成所需的接口。转换匹配是手段，复用功能是目的。 想使用一个已存在的类，但它的接口不符合需求时。或者是它不能对每一个子类都进行适配，这种情况下可以使用对象适配器，直接适配这些子类的父类。 想创建一个可复用的类，但是这个类可能会与一些类不兼容时 本文是《研磨设计模式》的读书笔记。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>适配器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我学设计模式：外观（Facade）模式]]></title>
    <url>%2F%E6%88%91%E5%AD%A6%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%A4%96%E8%A7%82%EF%BC%88Facade%EF%BC%89%E6%A8%A1%E5%BC%8F.html</url>
    <content type="text"><![CDATA[定义：为子系统中的一组接口提供一个一致的界面，Facade模式定义了一个高层接口，这个接口使得这一子系统更加易用。 外观模式比较简单，两个字：封装！外观模式是为了解决类与类之间的依赖关系的，将类与类之间（比如A、B、C）的关系放在一个Facade类中，从外部看来只要调用Facade类中的方法，就可以自动调用A、B、C的功能，从而降低了类之间的耦合度。 认识外观模式：封装交互，简化调用 如图所示，外观模式减少了外部与子系统内多个模块的交互，松散耦合，从而让外部可以更简单地使用子系统。一个直观的例子就是电脑，外部来看我们面对的是电脑，只要对电脑上的按钮操作即可，但是电脑内部有很多子系统，如CPU、Memory、Disk等。当我们启动或关闭电脑时，只要对封装好的Computer操作即可，而不需对每个子系统启动。 外观模式的调用顺序 何时使用外观模式 希望为一个复杂的子系统提供一个简单的接口 想让客户端和抽象类的实现部分松散耦合 构建多层结构系统时，可以使用外观作为每层的入口 本文是《研磨设计模式》的读书笔记。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>外观模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我学设计模式：简单工厂模式]]></title>
    <url>%2F%E6%88%91%E5%AD%A6%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F.html</url>
    <content type="text"><![CDATA[提供一个创建对象实例的功能，而无需关心其具体实现。被创建实例的类型可以是接口、抽象类，也可以是具体的类。 认识简单工厂示例： 一个简单接口： 123456package com.liuhao.designpattern.factory;public interface Api &#123; public void operation(String s);&#125; 接口的两个实现类： 12345678910package com.liuhao.designpattern.factory;public class ImplA implements Api &#123; @Override public void operation(String s) &#123; System.out.println("ImplA s=" + s); &#125;&#125; 12345678910package com.liuhao.designpattern.factory;public class ImplB implements Api &#123; @Override public void operation(String s) &#123; System.out.println("ImplB s=" + s); &#125;&#125; 工厂： 1234567891011121314151617181920212223package com.liuhao.designpattern.factory;public class Factory &#123; /** * 具体创建Api对象的方法 * * @param condition 外部传入的选择条件 * @return 创建好的Api对象 */ public static Api createApi(int condition) &#123; Api api = null; if (condition == 1) &#123; api = new ImplA(); &#125; else if (condition == 2) &#123; api = new ImplB(); &#125; return api; &#125;&#125; 客户端调用： 12345678package com.liuhao.designpattern.factory;public class Client &#123; public static void main(String[] args) &#123; Api api = Factory.createApi(1); api.operation("正在使用简单工厂"); &#125;&#125; 要点： 简单工厂的功能通常用来创造接口，但也可以用来创造抽象类或普通类的实例。 静态工厂简单工厂的方法通常是静态的，也被称为静态工厂。 万能工厂一个简单工厂可以创建不同的接口、抽象了或者是实例。 简单工厂的创建范围通常不要太大，建议控制在一个独立的组件级别或者模块级别。 简单工厂的调用顺序 简单工厂的命名建议 类名：模块名称+Factory，如用户模块的工厂就称为UserFactory 方法名：get+接口名称或者create+接口名称，比如getUser 简单工厂中方法的写法主要实现的功能是选择合适的实现类来创建实例对象。选择条件或者参数主要有： 源自客户端，有Client传入参数 源于配置文件，从中获取用于判断的值 源于运行期间的某个值 可配置的简单工厂如上述的工厂代码实例，创建对象时根据传入的参数值来判断创建的实现类，这种情况下每次新增一个实现类都要来修改该工厂类，这种做法明显不太好。 解决的方法可以使用配置文件，当有新的实现类时，只需在配置文件中配置即可。然后使用反射的方式来实现类。 思考简单工厂本质：选择实现简单工厂的重点在于选择，实现是已经做好了的，目的在于为客户端选择相应的实现，从而使得客户端和具体实现之间解耦。 何时选用简单工厂 想完全封装隔离具体实现，让外部只能通过接口来操作封装体 想对创建对象的职责集中管理和控制 相关模式 简单工厂 和 抽象工厂模式简单工厂是用来选择实现的，可以选择任意接口的实现。 抽象工厂是用来选择产品簇的实现的，也就是说抽象工厂里有多个用于选择并创建对象的方法，并且这些对象之间是有关系的，它们通常是构成一个产品簇所需要的部件对象。 简单工厂 和 工厂方法模式工厂方法的本质也是用来选择实现的，区别在于它是把选择具体实现的功能延迟到子类实现。 本文是《研磨设计模式》的读书笔记。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>简单工厂</tag>
        <tag>工厂模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我学设计模式：单例（Singleton）模式]]></title>
    <url>%2F%E6%88%91%E5%AD%A6%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%8D%95%E4%BE%8B%EF%BC%88Singleton%EF%BC%89%E6%A8%A1%E5%BC%8F.html</url>
    <content type="text"><![CDATA[保证一个类仅有一个实例，并提供一个访问它的全局访问点。 要想控制一个类只被创建一个实例，那么首要的问题就是把创建实例的权限收回来，让类自己来负责创建自己类的实例，然后由这个类来提供外部可以访问这个类实例的方法，这就是单例模式的实现方法。 单例模式的结构和实现 Singleton:负责创建Singleton类自己的唯一实例，并提供一个getInstance的方法，来外部来访问这个类的唯一实例。 私有化构造方法 提供静态的获取实例的方法 定义存储实例的属性，因为要在静态方法中使用，因此要加上static修饰 实现控制实例的创建 示例代码懒汉模式所谓懒汉模式，既然懒，那么在创建对象实例时就不要着急，在马上要使用对象实例时才会创建，在装载对象时不会创建对象实例。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.liuhao.designpattern.singleton;/** * 单例模式懒汉模式 * * @author liuhao * * 2015年7月17日 */public class SingletonLazy &#123; // 4. 定义一个变量来存储创建好的类实例 // 5. 因为要在静态方法中使用，因此要加上static修饰 private static SingletonLazy instance = null; // 1. 构造方法私有化，好在内部控制创建实例的数目 private SingletonLazy() &#123; &#125; // 2. 定义一个方法为客户端提供类实例 // 3. 这个方法需要定义成类方法，也就是 public static SingletonLazy getInstance() &#123; // 6. 判断存储实例的变量是否有值 if (instance == null) &#123; instance = new SingletonLazy(); &#125; return instance; &#125; private String singletonData;// 单例可以有自己的属性 /** * 获取属性的值 * * @return 属性的值 */ public String getSingletonData() &#123; return singletonData; &#125; /** * 单例可以有自己的操作方法 */ public void singletonOperation() &#123; &#125;&#125; 饿汉模式所谓饿汉模式，就是在创建对象实例时比较急，在装载类的时候就会创建对象实例。123456789101112131415161718192021222324252627282930313233343536373839404142package com.liuhao.designpattern.singleton;/** * 单例模式饿汉模式 * * @author liuhao * * 2015年7月17日 */public class SingletonHungry &#123; // 4. 直装载类的时候就会创建对象实例，只创建一次 private static SingletonHungry instance = new SingletonHungry(); // 1. 构造方法私有化，好在内部控制创建实例的数目 private SingletonHungry() &#123; &#125; // 2. 定义一个方法为客户端提供类实例 // 3. 这个方法需要定义成类方法，也就是 public static SingletonHungry getInstance() &#123; // 5. 直接使用以及创建好的实例 return instance; &#125; private String singletonData;// 单例可以有自己的属性 /** * 获取属性的值 * * @return 属性的值 */ public String getSingletonData() &#123; return singletonData; &#125; /** * 单例可以有自己的操作方法 */ public void singletonOperation() &#123; &#125;&#125; 其他单例模式的范围目前Java实现的单例是一个虚拟机范围的，因为装载类的功能是虚拟机的，所以一个虚拟机在通过自己的ClassLoader装载饿汉模式实现单例时就会创建一个类的实例。 因此如果一个虚拟机里面有很多个ClassLoader，而这些ClassLoader都装载某个类的话，就会产生多个实例。 单例模式的调用顺序 懒汉模式 饿汉模式 体现的一些思想 延迟加载懒汉模式中，一开始没有加载所需的资源或者数据，一直等到马上就要使用了才加载，即所谓的“延迟加载”。 缓存当某些资源或数据被频繁的使用，而且它们是存储在系统外部的（如数据库、硬盘），那么每次操作都要从数据库获取，速度会很慢，操作性能问题。 一个简单的方法就是把这些数据缓存到内存中，每次操作的时候先到内存里找，若有则直接使用；若果没有再获取它并设置到缓存中。 缓存是一种典型的空间换取时间的方案。 线程安全 不加同步的懒汉模式是线程不安全的。比如，有线程A、B同时调用getInstance方法，那就可能导致并发问题，如图。 如何实现懒汉模式的线程安全 加上关键字synchronized，如下 1public static synchronized SingletonLazy getInstance() &#123;&#125; 双重检查加锁。不是在每次进入getInstance时都需要同步，而是先不同步，进入方法后，先检查实例是否存在。如果不存在才进入下面的同步块，这是第一重检查。进入同步块后，再次检查实例是否存在，如果不存在，就在同步的情况下创建一个实例，这是第二重检查。双重检查加锁机制的实现需要使用volatile关键字，被它修饰的变量的值将不会被本地线程缓存，所有对该变量的读写都是直接操作共享内存，从而确保多个线程能够正确的处理该变量。具体实现： 12345678910111213public static SingletonVolatile getInstance() &#123; // 检查实例是否存在，不存在则进入到同步块 if (instance == null) &#123; // 同步块，线程安全地创建实例 synchronized (SingletonVolatile.class) &#123; // 再次检查实例是否存在，不存在则真正的创建实例 if (instance == null) &#123; instance = new SingletonVolatile(); &#125; &#125; &#125; return instance;&#125; 这种实现方式既可以实现线程安全，同时也不会对性能造成太大的影响。 饿汉模式是线程安全的。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>单例模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于maven的Spring+ActiveMQ整合Demo]]></title>
    <url>%2F%E5%9F%BA%E4%BA%8Emaven%E7%9A%84Spring%2BActiveMQ%E6%95%B4%E5%90%88Demo.html</url>
    <content type="text"><![CDATA[本文主要是示范基于Maven的ActiveMQ+Spring的简单使用，基于ActiveMQ消息代理的Spring JMS消息配置，以及定时任务的使用。 JMS简介JMS提供了应用之间的异步通信机制，当异步发送消息时，客户端不需要等待服务端处理消息结果。 构建JMS两个主要概念：消息代理（message broker）和目的地（destination）。 当一个应用发送消息时，会把消息交给一个消息代理。消息代理实际上是JMS版的邮局。消息代理可以确保消息被投递到指定的目的地，同时释放发送者，使其能够继续其他的业务。 目的地就像一个邮箱，可以将消息放入邮箱，直至有人将其取走。JMS中有两种类型的目的地：队列和主题。，分别应用于队列的点对点模型和主题的发布/订阅模型。 点对点消息模型每一个消息都有一个发送者和一个接收者。当消息代理得到消息后，会将消息放入到消息队列中，接收者请求队列中的下一条消息时，该消息就会从队列中取出，投递给接收者。因为消息投递后会从队列中删除，因此可以保证消息只投递给一个接收者。 可以使用多个接收者来处理队列中的消息，不过每个接收者都会处理自己接收到的消息，需要多个接收者监听队列。 发布-订阅消息模型消息会发送给一个主题，多个接收者可以监听一个主题。与队列不同的是，消息不再是只投递给一个接收者，所有主题的订阅者都可以接收到此消息。 JMS的优点 无需等待 面向消息和解耦 位置独立 确保投递 在Spring中搭建消息代理安装ActiveMQActiveMQ是一个开源的消息代理， 也是使用JMS进行异步消息传递的最佳选择。在官方网站下载后，解压缩安装包，点击apache-activemq-5.12.1\bin\activemq.bat运行即可（64位操作系统可能需要点击apache-activemq-5.12.1\bin\win64\activemq.bat运行）。运行后进入http://localhost:8161/表明安装成功， 这时就可以使用它进行消息代理了。 maven配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.springframework.samples.service.service&lt;/groupId&gt; &lt;artifactId&gt;activemq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;properties&gt; &lt;!-- Generic properties --&gt; &lt;java.version&gt;1.6&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Web --&gt; &lt;jsp.version&gt;2.2&lt;/jsp.version&gt; &lt;jstl.version&gt;1.2&lt;/jstl.version&gt; &lt;servlet.version&gt;2.5&lt;/servlet.version&gt; &lt;!-- Spring --&gt; &lt;spring-framework.version&gt;3.2.3.RELEASE&lt;/spring-framework.version&gt; &lt;!-- Logging --&gt; &lt;logback.version&gt;1.0.13&lt;/logback.version&gt; &lt;slf4j.version&gt;1.7.5&lt;/slf4j.version&gt; &lt;!-- Test --&gt; &lt;junit.version&gt;4.11&lt;/junit.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;1.8.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring MVC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Other Web dependencies --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;$&#123;jstl.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;$&#123;servlet.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;$&#123;jsp.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring and Transactions --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.annotation&lt;/groupId&gt; &lt;artifactId&gt;jsr250-api&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt; &lt;version&gt;5.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-framework.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; Spring配置使用JMS连接工厂通过消息代理发送消息，因为选择了ActiveMQ作为消息代理，因此需要配置JMS连接工厂，让它知道如何连接到ActiveMQ。ActiveMQConnectionFactory是ActiveMQ自带的连接工厂，可以在Spring中进行配置。 使用JmsTemplate可以创建连接、获得会话以及发送和接收消息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://activemq.apache.org/schema/core http://activemq.apache.org/schema/core/activemq-core-5.8.0.xsd"&gt; &lt;!-- Activemq 连接工厂 --&gt; &lt;bean id="activeMQConnectionFactory" class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;constructor-arg value="system1" /&gt; &lt;constructor-arg value="manager1" /&gt; &lt;constructor-arg value="failover:(tcp://localhost:61616)?timeout=2000" /&gt; &lt;/bean&gt; &lt;!-- ConnectionFactory Definition --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.CachingConnectionFactory"&gt; &lt;constructor-arg ref="activeMQConnectionFactory" /&gt; &lt;/bean&gt; &lt;!-- Default Destination Queue Definition --&gt; &lt;!-- 测试配置多个Destination --&gt; &lt;bean id="destination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg index="0" value="test.activemq.queue" /&gt; &lt;/bean&gt; &lt;!-- JmsTemplate Definition --&gt; &lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="defaultDestination" ref="destination" /&gt; &lt;/bean&gt; &lt;!-- Message Sender Definition --&gt; &lt;bean id="messageSender" class="activemq.publisher.MessageSender"&gt; &lt;constructor-arg index="0" ref="jmsTemplate" /&gt; &lt;constructor-arg index="1" ref="destination" /&gt; &lt;/bean&gt; &lt;!-- 消息监听器，主要监听的目的地址 Message Receiver Definition --&gt; &lt;bean id="messageReceiver" class="activemq.consumer.MessageReceiver"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.jms.listener.SimpleMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destinationName" value="test.activemq.queue" /&gt; &lt;property name="messageListener" ref="messageReceiver" /&gt; &lt;/bean&gt;&lt;/beans&gt; 发送消息当调用JmsTemplate的send()方法，JmsTemplate将负责JMS连接、会话并代表发送者发送消息。这里使用了默认的消息目的地。 12345678910111213141516171819202122232425package activemq.publisher;import javax.jms.Destination;import org.springframework.jms.core.JmsTemplate;public class MessageSender &#123; private final JmsTemplate jmsTemplate; private final Destination destination; public MessageSender(final JmsTemplate jmsTemplate, final Destination destination) &#123; this.jmsTemplate = jmsTemplate; this.destination = destination; &#125; public void send(final String text) &#123; try &#123; jmsTemplate.setDefaultDestination(destination); jmsTemplate.convertAndSend(text); System.out.println("发送消息 : " + text); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 接收消息监听器12345678910111213141516171819202122package activemq.consumer;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;public class MessageReceiver implements MessageListener &#123; public void onMessage(Message message) &#123; if (message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; String text = textMessage.getText(); System.out.println("接收到消息: " + text); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 测试使用Spring的定时任务定时发送消息。定时任务配置：12345678910111213141516171819202122232425262728293031323334&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd"&gt; &lt;context:annotation-config /&gt; &lt;bean id="QuartzFactoryBean" class="org.springframework.scheduling.quartz.SchedulerFactoryBean"&gt; &lt;property name="triggers"&gt; &lt;list&gt; &lt;ref bean="capacityDataPublisherJobTrigger" /&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="capacityDataPublisherJob" class="activemq.TestSenderService" init-method="run"&gt; &lt;/bean&gt; &lt;bean id="capacityDataPublisherJobTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean"&gt; &lt;property name="jobDetail" ref="capacityDataPublisherJobDetail" /&gt; &lt;property name="cronExpression"&gt; &lt;value&gt;0 0/5 * * * ?&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="capacityDataPublisherJobDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean"&gt; &lt;property name="targetObject" ref="capacityDataPublisherJob" /&gt; &lt;property name="targetMethod" value="run" /&gt; &lt;property name="concurrent" value="false" /&gt; &lt;/bean&gt;&lt;/beans&gt; 定时任务123456789101112131415package activemq;import org.springframework.beans.factory.annotation.Autowired;import activemq.publisher.MessageSender;public class TestSenderService &#123; @Autowired private MessageSender messageSender; public void run() &#123; messageSender.send("message"); &#125;&#125; 测试结果在tomcat中运行项目。运行后发送了两条消息，消息队列中显示： 重启项目时，接收消息监听器会处理队列中所有的消息，项目运行时，每次发送消息成功后都会触发接收消息监听器： 入列和出列： 代码获取地址：https://github.com/hoxis/JavaWeb/tree/master/activemq]]></content>
      <categories>
        <category>JavaWeb</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Maven</tag>
        <tag>ActiveMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用org.w3c.dom.Element的setTextContent()、getTextContent()方法时出现编译错误]]></title>
    <url>%2F%E4%BD%BF%E7%94%A8org.w3c.dom.Element%E7%9A%84setTextContent()%E3%80%81getTextContent()%E6%96%B9%E6%B3%95%E6%97%B6%E5%87%BA%E7%8E%B0%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF.html</url>
    <content type="text"><![CDATA[今天在更新项目后进行编译时，出现如下错误一堆： Google之，在stackoverflow上看到如下的解决方法： I came here with the same problem. Even worse: I had two projects side by side, both targetting the same JRE (1.6), and one was able to resolve Node.getTextContent() while the other wasn’t. I resolved it sort of by accident; I went to project properties | Java Build Path | Order and Export tab, selected the JRE (which was at the bottom of the list) and clicked the “Top” button to move it to the top. My problem went away. It appears that the Node I wanted was hidden by another one. :-\ Maybe this will help with your problem. 大体解决方法就是：在项目的Java Build Path | Order and Export选项卡中，将JRE System Library选中，并Top置顶。然后再进行编译即可。如图： 但是上面并没有给出原因。 其实顺着问题的解决思路想想，肯定是jar出现了冲突所致。于是我就在项目的jar包中找可能含有org.w3c.dom.Element这个类的jar包。既然将JRE的lib进行了置顶，那么就有理由猜测JRE-lib里存在这个类的相关方法。 最终，在rt.jar和xml-apis.jar和中找到了。应该就是这两个jar冲突所致，由于引用优先级的不同导致引用了xml-apis.jar中的方法。 其实在pom.xml中并没有这个jar的直接引用，在Dependency Hierarchy视图中搜索xml-apis可以发现，它其实是由于dom4j的依赖而引入的。如图： 解决方法：右击该jar，选择exclude maven artifact，确认并保存，重新编译即可： 最终的pom.xml中只是在dom4j的&lt;dependency&gt;中多了这么一段&lt;exclusions&gt;：1234567891011&lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;xml-apis&lt;/artifactId&gt; &lt;groupId&gt;xml-apis&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 参考：http://stackoverflow.com/questions/5534864/compilation-error-in-node-gettextcontent-for-jdk-6http://www.educity.cn/wenda/364108.html]]></content>
      <categories>
        <category>绊脚石</category>
      </categories>
      <tags>
        <tag>错误处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring实战》学习笔记-第四章：面向切面的Spring]]></title>
    <url>%2F%E3%80%8ASpring%E5%AE%9E%E6%88%98%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E9%9D%A2%E5%90%91%E5%88%87%E9%9D%A2%E7%9A%84Spring.html</url>
    <content type="text"><![CDATA[分布于应用中多处的功能称为横切关注点，通过这些横切关注点在概念上是与应用的业务逻辑相分离的，但其代码往往直接嵌入在应用的业务逻辑之中。将这些横切关注点与业务逻辑相分离正是面向切面编程（AOP）所要解决的。 什么是面向切面编程 面向切面编程中，通过声明的方式定义通用功能（安全、事务等）以何种方式在何处应用，而无需修改受影响的类（CourseService、StudentService等）。 AOP术语通知（Advice）：何种功能、何时切面的工作被称为通知，同时通知还要解决何时执行这个工作的问题。Spring切面可以应用5种类型的通知： Before：在方法被调用之前调用通知； After：在方法调用之后调用通知； After-returning：在方法成功执行后； After-throwing：在方法抛出异常后； Around：在方法调用之前和之后都会调用通知； 连接点（Joinpoint）：能够应用通知的点连接点是在应用执行过程中能够插入切面的一个点，这个点可以是调用方法时、抛出异常时、甚至修改一个字段时。切面代码可以利用这些点插入到应用的正常流程中。 切点（Pointcut）：何处，应用通知的连接点的集合切点的定义会匹配通知所要织入的一个或多个连接点。我们通常使用明确的类和方法名称来指定这些切点，或是利用正则表达式定义匹配来指定这些切点。 切面（Aspect）切面是通知和切点的结合，即何时在何处完成何种功能。 引入（Introduction）引入允许我们向现有的类添加新方法或属性，从而可以在无需修改现有类的情况下，让它们具有新的行为和状态。 织入（Weaving）将切面应用到目标对象来创建新的代理对象的过程。切面在指定的连接点被织入到目标对象中，在目标对象的生命周期里有多个点可以进行织入： 编译期：需要特殊的编译器，AspectJ的织入编译器就是这种方式； 类加载期：在目标类加载到JVM时被织入，需要特殊的类加载器。 运行期：在应用运行的某个时刻被织入，一般情况下，在织入切面时，AOP容器会为目标对象动态地创建一个代理对象。Spring AOP就是这种方式。 Spring对AOP的支持 基于代理的经典AOP； @AspectJ注解驱动的切面； 纯POJO切面； 注入式AspectJ切面（适合Spring个版本）； Spring是在运行期将切面织入到所管理的Bean中的，如图所示，代理类封装了目标类，当拦截到方法调用时，在调用目标Bean的方法之前，代理会执行切面逻辑。真正应用需要被代理的Bean时，Spring才会创建代理对象。Spring的切面由包裹了目标对象的代理类实现，代理类处理方法的调用，执行额外的切面逻辑，并调用目标方法。 Spring只支持方法连接点，缺少对字段连接点的支持，例如拦截对象字段的修改。也不支持构造器连接点，也就无法在Bean创建时应用通知。 使用切点选择连接点Spring AOP中，需要使用AspectJ的切点表达式来定义切点。 AspectJ指示器 描述 arg() 限制连接点匹配参数为指定类型的执行方法 @args() 限制连接点匹配参数由指定注解标注的执行方法 execution() 用于匹配是连接点的执行方法 this() 限制连接点匹配AOP代理的Bean引用为指定类型的类 target() 限制连接点匹配目标对象为执行类型的类 @target() 限制连接点匹配特定的执行对象，这些对象对应的类要具备指定类型的注解 within() 限制连接点匹配指定的类型 @within() 限制连接点匹配指定注解所标注的类型 @annotation() 限制匹配带有指定注解连接点 编写切点 这里使用了execution()指示器来选择Instrument的play()方法。表达式以*开头表示不关心返回值的类型，然后指定了全限定类名和方法名，使用..作为方法的参数列表，表示可以是任意的入参。 使用&amp;&amp;将execution()和within()进行连接，那么也就可以使用||（或）和!（非）。 使用Spring的bean()指示器bean()使用Bean id来作为参数，从而限制切点只匹配特定的Bean，如： execution(* com.springinaction.springidol.Instrument.play()) and bean(eddie) 这里，表示在执行Instrument的play()方法时应用通知，但限定Bean的id为eddie。 在XML中声明切面 AOP配置元素 描述 &lt;aop:advisor&gt; 定义AOP通知器 &lt;aop:after&gt; 定义AOP后置通知（不管该方法是否执行成功） &lt;aop:after-returning&gt; 在方法成功执行后调用通知 &lt;aop:after-throwing&gt; 在方法抛出异常后调用通知 &lt;aop:around&gt; 定义AOP环绕通知 &lt;aop:aspect&gt; 定义切面 &lt;aop:aspect-autoproxy&gt; 定义@AspectJ注解驱动的切面 &lt;aop:before&gt; 定义AOP前置通知 &lt;aop:config&gt; 顶层的AOP配置元素，大多数的&lt;aop:*&gt;包含在&lt;aop:config&gt;元素内 &lt;aop:declare-parent&gt; 为被通知的对象引入额外的接口，并透明的实现 &lt;aop:pointcut&gt; 定义切点 下面定义一个观众类：123456789101112131415161718192021222324package com.springinaction.springidol;public class Audience &#123; // 表演之前 public void takeSeats() &#123; System.out.println("The audience is taking their seats."); &#125; // 表演之前 public void turnOffCellPhones() &#123; System.out.println("The audience is turning off their cellphones"); &#125; // 表演之后 public void applaud() &#123; System.out.println("CLAP CLAP CLAP CLAP CLAP"); &#125; // 表演失败之后 public void demandRefund() &#123; System.out.println("Boo! We want our money back!"); &#125;&#125; 声明前置和后置通知12345678910111213141516171819202122232425262728293031323334&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;bean id="eddie" class="com.springinaction.springidol.Instrumentalist"&gt; &lt;property name="instrument"&gt; &lt;bean class="com.springinaction.springidol.Guitar" /&gt; &lt;/property&gt; &lt;property name="song" value="my love" /&gt; &lt;/bean&gt; &lt;bean id="audience" class="com.springinaction.springidol.Audience" /&gt; &lt;aop:config&gt; &lt;aop:aspect ref="audience"&gt;&lt;!-- 引用audience Bean --&gt; &lt;!-- 声明切入点 --&gt; &lt;aop:pointcut id="performance" expression="execution(* com.springinaction.springidol.Performer.perform(..))" /&gt; &lt;!-- 表演之前 --&gt; &lt;aop:before pointcut-ref="performance" method="takeSeats" /&gt; &lt;aop:before pointcut-ref="performance" method="turnOffCellPhones" /&gt; &lt;!-- 表演之后 --&gt; &lt;aop:after-returning pointcut-ref="performance" method="applaud" /&gt; &lt;!-- 表演失败之后 --&gt; &lt;aop:after-throwing pointcut-ref="performance" method="demandRefund" /&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; 在&lt;aop:config&gt;中，可以声明一个或多个通知器、切面或者切点。pointcut属性定义了通知所引用的切点。最终的通知逻辑如何织入到业务逻辑中： 测试代码：123456@Testpublic void testBeforeAndAfter() throws PerformanceException&#123; ApplicationContext context = new ClassPathXmlApplicationContext("spring-idol.xml"); Performer performer = (Performer) context.getBean("eddie"); performer.perform();&#125; 测试结果： The audience is taking their seats.The audience is turning off their cellphonesPlaying my love : Guitar Guitar GuitarCLAP CLAP CLAP CLAP CLAP 声明环绕通知前置通知和后置通知之间共享消息需要使用成员变量，而Audience是单例，使用成员变量有可能存在线程安全问题。使用环绕通知可以完成之前前置和后置所实现的相同功能，而且只需一个方法。 12345678910111213141516171819202122232425package com.springinaction.springidol;import org.aspectj.lang.ProceedingJoinPoint;public class AroundAudience &#123; public void watchPerformance(ProceedingJoinPoint joinpoint) &#123; try &#123; // 表演之前 System.out.println("The audience is taking their seats."); System.out.println("The audience is turning off their cellphones"); long start = System.currentTimeMillis(); // 执行被通知的方法 joinpoint.proceed(); // 表演之后 long end = System.currentTimeMillis(); System.out.println("CLAP CLAP CLAP CLAP CLAP"); System.out.println("The performance took " + (end - start) + " milliseconds."); &#125; catch (Throwable t) &#123; // 表演失败之后 System.out.println("Boo! We want our money back!"); &#125; &#125;&#125; ProceedingJoinPoint作为入参，从而可以在通知里调用被通知的方法。 XML配置：12345678910&lt;bean id="audience" class="com.springinaction.springidol.AroundAudience" /&gt;&lt;aop:config&gt; &lt;aop:aspect ref="audience"&gt;&lt;!-- 引用audience Bean --&gt; &lt;!-- 声明切入点 --&gt; &lt;aop:pointcut id="performance" expression="execution(* com.springinaction.springidol.Performer.perform(..))" /&gt; &lt;aop:around method="watchPerformance" pointcut-ref="performance" /&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 为通知传递参数读心者：1234567package com.springinaction.springidol;public interface MindReader &#123; void interceptThoughts(String thoughts); String getThoughts();&#125; Magician是MindReader 接口的一个简单实现：1234567891011121314151617package com.springinaction.springidol;public class Magician implements MindReader &#123; private String thoughts; @Override public void interceptThoughts(String thoughts) &#123; System.out.println("Intercepting volunteer's thoughts"); this.thoughts = thoughts; &#125; @Override public String getThoughts() &#123; return thoughts; &#125;&#125; 下面是一个志愿者，供读心者去截取他的内心感应：12345package com.springinaction.springidol;public interface Thinker &#123; void thinkOfSomething(String thoughts);&#125; 123456789101112131415package com.springinaction.springidol;public class Volunteer implements Thinker &#123; private String thoughts; @Override public void thinkOfSomething(String thoughts) &#123; System.out.println("Thinker: " + thoughts); this.thoughts = thoughts; &#125; public String getThoughts() &#123; return thoughts; &#125;&#125; 通过配置实现将被通知方法的参数传递给通知：123456789101112&lt;bean id="volunteer" class="com.springinaction.springidol.Volunteer" /&gt;&lt;bean id="magician" class="com.springinaction.springidol.Magician" /&gt;&lt;aop:config&gt; &lt;aop:aspect ref="magician"&gt;&lt;!-- 引用magician Bean --&gt; &lt;!-- 声明切入点 --&gt; &lt;aop:pointcut id="thinking" expression="execution(* com.springinaction.springidol.Thinker.thinkOfSomething(String)) and args(thoughts) " /&gt; &lt;aop:before method="interceptThoughts" pointcut-ref="thinking" arg-names="thoughts" /&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 切入点指定了Thinker的thinkOfSomething()方法，指定了String参数，然后在args参数中标识了将thoughts作为参数。 同时，引用了thoughts参数，标识该参数必须传递给magician的interceptThoughts()方法。 注意： 引用的thoughts参数和pointcut标识的thoughts参数，二者名称必须一致！ 测试：12345678@Testpublic void testBeforeArgs() throws PerformanceException &#123; ApplicationContext context = new ClassPathXmlApplicationContext("spring-magician.xml"); Thinker thinker = (Thinker) context.getBean("volunteer"); MindReader mindReader = (MindReader) context.getBean("magician"); thinker.thinkOfSomething("晚上吃啥呢？"); System.out.println("MindReader: " + mindReader.getThoughts());&#125; 测试结果： Intercepting volunteer’s thoughtsThinker: 晚上吃啥呢？MindReader: 晚上吃啥呢？ 通过切面引入新功能切面可以为SpringBean添加新方法：12345&lt;aop:aspect&gt; &lt;aop:declare-parents types-matching="com.springinaction.springidol.Performer+" implement-interface="com.springinaction.springidol.Contestant" default-impl="com.springinaction.springidol.GraciousContestant" /&gt;&lt;/aop:aspect&gt; 声明了此切面所通知的Bean在它的对象层次结构中拥有新的父类，即类型匹配Performer接口（由types-matching指定）的Bean会实现Contestant接口（由implement-interface指定），同时可以指定Contestant的实现（default-impl，也可以用delegate-ref指定一个Spring Bean来实现）。 注解切面：@Aspect、@Pointcut、采用注解的方式将之前的Audience标注为一个切面：123456789101112131415161718192021222324252627282930313233343536373839404142package com.springinaction.springidol;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;@Aspectpublic class AspectJAudience &#123; // 定义切点 @Pointcut("execution(* com.springinaction.springidol.Performer.perform(..))") public void performance() &#123; &#125; // 表演之前 @Before("performance()") public void takeSeats() &#123; System.out.println("The audience is taking their seats."); &#125; // 表演之前 @Before("performance()") public void turnOffCellPhones() &#123; System.out.println("The audience is turning off their cellphones"); &#125; // 表演之后 @AfterReturning("performance()") public void applaud() &#123; System.out.println("CLAP CLAP CLAP CLAP CLAP"); &#125; // 表演失败之后 @AfterThrowing("performance()") public void demandRefund() &#123; System.out.println("Boo! We want our money back!"); &#125;&#125; @Pointcut注解用于定义一个在@AspectJ切面内可重用的切点，其值是一个AspectJ切点表达式，这里标识该切点必须匹配Performer接口的perform()方法。performance()切点的名称作为参数赋值给了所有的通知注解，从而可以标识每一个通知方法应该应用在哪里。 **AfterReturning 和After 的区别： AfterReturning 增强处理处理只有在目标方法成功完成后才会被织入。 After 增强处理不管目标方法如何结束（保存成功完成和遇到异常中止两种情况），它都会被织入。 使用配置注解，首先我们要将切面在spring上下文中声明成自动代理bean，即&lt;aop:aspectj-autoproxy /&gt;。 测试代码：123456@Testpublic void testAspectJBeforeAndAfter() throws PerformanceException &#123; ApplicationContext context = new ClassPathXmlApplicationContext("spring-idol.xml"); Performer performer = (Performer) context.getBean("eddie"); performer.perform();&#125; 测试结果： The audience is taking their seats.The audience is turning off their cellphonesPlaying my love : Guitar Guitar GuitarCLAP CLAP CLAP CLAP CLAP 运行测试程序时可能会出错，形如： org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘eddie’ defined in class path resource [spring-idol.xml]: Cannot create inner bean ‘com.springinaction.springidol.Guitar#365d15c6’ of type [com.springinaction.springidol.Guitar] while setting bean property ‘instrument’; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘com.springinaction.springidol.Guitar#365d15c6’ defined in class path resource [spring-idol.xml]: Initialization of bean failed; nested exception is java.lang.IllegalArgumentException: error at ::0 can’t find referenced pointcut performance 上网搜了一下，发现是JDK不匹配。我原来用的JDK1.7匹配的是aspectjrt.1.6.2和aspectjweaver.1.6.2，因此会报错。 如果要使用AspectJ完成注解切面需要注意下面的JDK与AspectJ的匹配：JDK1.6 —— aspectJ1.6JDK1.7 —— aspectJ1.7.3+ 注解环绕通知：@Around12345678910111213141516171819202122232425262728293031323334353637package com.springinaction.springidol;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;@Aspectpublic class AspectJAroundAudience &#123; // 定义切点 @Pointcut("execution(* com.springinaction.springidol.Performer.perform(..))") public void performance() &#123; &#125; @Around("performance()") public void watchPerformance(ProceedingJoinPoint joinpoint) &#123; try &#123; // 表演之前 System.out.println("The audience is taking their seats."); System.out.println("The audience is turning off their cellphones"); long start = System.currentTimeMillis(); // 执行被通知的方法 joinpoint.proceed(); // 表演之后 long end = System.currentTimeMillis(); System.out.println("CLAP CLAP CLAP CLAP CLAP"); System.out.println("The performance took " + (end - start) + " milliseconds."); &#125; catch (Throwable t) &#123; // 表演失败之后 System.out.println("Boo! We want our money back!"); &#125; &#125;&#125; 不要忘了配置：@Aspect和测试代码：123456@Testpublic void testAspectJAround() throws PerformanceException &#123; ApplicationContext context = new ClassPathXmlApplicationContext("spring-idol-around.xml"); Performer performer = (Performer) context.getBean("eddie"); performer.perform();&#125; 传递参数给所标注的通知12345678910111213141516171819202122232425262728package com.springinaction.springidol;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;@Aspectpublic class AspectJMagician implements MindReader &#123; private String thoughts; @Pointcut("execution(* com.springinaction.springidol.Thinker.thinkOfSomething(String)) &amp;&amp; args(thoughts))") public void thinking(String thoughts)&#123; &#125; @Override @Before("thinking(thoughts)") public void interceptThoughts(String thoughts) &#123; System.out.println("Intercepting volunteer's thoughts"); this.thoughts = thoughts; &#125; @Override public String getThoughts() &#123; return thoughts; &#125;&#125; 变为@Pointcut，变为@Before，注解里不需要arg-names属性所对应的注解。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring实战》学习笔记-第六章：web视图解析]]></title>
    <url>%2F%E3%80%8ASpring%E5%AE%9E%E6%88%98%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9Aweb%E8%A7%86%E5%9B%BE%E8%A7%A3%E6%9E%90.html</url>
    <content type="text"><![CDATA[本章主要内容包括： 将model数据展现为HTML JSP视图的使用 在前面的章节中，我们主要关注点在于编写控制来处理web请求，同时也创建了一些简单的视图来展现请求返回的model数据，本章我们将主要讨论在控制器完成请求处理之后和将返回结果展示到用户的浏览器之前，这个过程之间发生了什么。 理解视图解析在之前章节中所编写的控制器中并没有直接生成HTML的方法，它只是将数据填充到model中，然后将model传送到视图中进行展现。 Spring MVC中定义了一个ViewResolver接口：12345public interface ViewResolver &#123; View resolveViewName(String viewName, Locale locale) throws Exception;&#125; 方法resolveViewName()，当给定一个视图名称和一个Locale时就会返回一个View实例，View是另外一个接口：12345public interface View &#123; String getContentType(); void render(Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception;&#125; View接口的工作是对model、servlet请求、响应对象进行处理，并将结果输出到response中。 看起来很简单啊，我们所需要做的仅仅是编写ViewResolver和View的实现类来将内容输出到response中，并在用户浏览器中进行展示即可，但真的是这样吗？ 虽然可以编写自定义的实现类，而且有些时候会需要一些特殊的处理，Spring提供了一些现成的实现类： 视图解析器 描述 BeanNameViewResolver 在Spring的application context中的bean中查找与视图名称相同id ContentNegotiatingViewResolver 委托给一个或多个人视图解析器，而选择哪一个取决于请求的内容类型 FreeMarkerViewResolver 查找一个基于FreeMarker的模版 InternalResourceViewResolver 在web应用程序的war文件中查找视图 JasperReportsViewResolver 解析为JasperReport报表文件 ResourceBundleViewResolver 根据属性文件(properties file)查找View实现 TilesViewResolver 通过Tiles模版定义的模版解析，模版的名称与视图名称相同 UrlBasedViewResolver 根据视图名称直接解析，当视图名称与物理视图名称匹配时 VelocityLayoutViewResolver 解析为从不同的Velocity模版组成的Velocity布局 VelocityViewResolver 解析为Velocity模版 XmlViewResolver 根据XML文件（/WEB_INF/views.xml）中声明的View实现进行解析，与BeanNameViewResolver类似 XsltViewResolver 基于XSLT视图解析 我们没有足够的时间和篇幅来讨论所有的解析器，上面的每个解析器都对应着一个特定的视图技术。InternalResourceViewResolver主要用于JSP，TilesViewResolver用于 Apache Tiles视图，FreeMarkerViewResolver和VelocityViewResolver分别用于FreeMarker和Velocity模版。 创建JSP视图Spring对JSP视图有两种支持方式： InternalResourceViewResolver：可以将视图名称解析到JSP文件。另外，对JSP中使用的JSTL（JavaServer Pages Standard Tag Library）标签也提供了支持。 Spring提供了两种JSP标签库，一种是form-to-model绑定，另外一种则提供基本的功能。 InternalResourceViewResolver是最简单也是最常用的一个解析器，下面我们来看一下它是如何使用它来完成任务。 配置JSP视图解析器一些视图解析器（如ResourceBundleViewResolver）是直接的将逻辑视图名称映射到一个特定的View接口实现类上，而InternalResourceViewResolver则采用了另外的比较间接的方式。它采用了一种约定，通过给逻辑视图名称添加前缀和后缀来确定web应用中对应的物理路径。 假设有一个逻辑视图名称为home，如果将所有的JSP文件都存放在/WEB-INF/views/目录下，并且主页的JSP名为home.jsp，那么可以通过为home添加前缀/WEB-INF/views/和后缀.jsp来找到对应的物理视图路径，如图所示。 可以在使用@Bean注解的类进行设置：123456789// 配置一个JSP视图解析器@Beanpublic ViewResolver viewResolver() &#123; InternalResourceViewResolver resolver = new InternalResourceViewResolver(); resolver.setPrefix("/WEB-INF/views/"); resolver.setSuffix(".jsp"); resolver.setExposeContextBeansAsAttributes(true); return resolver;&#125; 另外，如果采用基于XML的Spring配置，也可以通过如下方式进行配置：1234&lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver" p:prefix="/WEB-INF/views/" p:suffix=".jsp" /&gt; 探索JSTL视图当JSP页面使用JSTL标签时，就需要配置InternalResourceViewResolver来解析JstlView了。 JSTL格式化标签需要一个Locale来正确地格式化一些特定语言环境的值，如日期和币种。消息标签可以使用Spring消息源和Locale来正确地选中消息并解析到HTML。 要解析JstlView，需要在InternalResourceViewResolver中设置viewClass属性：1resolver.setViewClass(JstlView.class); 同样的，xml配置中也需要进行配置：1p:viewClass="org.springframework.web.servlet.view.JstlView" 使用Spring的JSP库Spring提供了两种JSP标签库，一种用于将绑定了model属性的HTML标签进行渲染，其他的一些标签在不同场合下可以用到。 将表单绑定到modelSpring的表单绑定JSP标签库共有14种，与原生HTML标签不同的是，它们可以将一个对象绑定在model，并且可以从model对象的属性中获取填充值。标签库同时可以用来与用户交互错误信息。 要使用表单绑定标签库，需要在JSP页面中进行声明：1&lt;%@ taglib uri="http://www.springframework.org/tags/form" prefix="sf" %&gt; 注意，这里使用了sf作为前缀。 JSP标签 描述 &lt;sf:checkbox&gt; 生成一个checkbox类型的HTML input标签 &lt;sf:checkboxes&gt; 生成一组checkbox类型的HTML input标签 &lt;sf:errors&gt; 通过一个HTML &lt;span&gt;标签展现字段的错误 &lt;sf:form&gt; 生成一个HTML的&lt;form&gt;标签，同时为内部标签的绑定暴露了一个绑定路径（binding path） &lt;sf:hidden&gt; 生成一个type为hidden的Html input标签 &lt;sf:input&gt; 生成一个type为text的Html input标签 &lt;sf:label&gt; 生成一个HTML &lt;label&gt;标签 &lt;sf:option&gt; 生成一个HTML的&lt;option&gt;标签，根据绑定的值来设置selected属性 &lt;sf:options&gt; 根据绑定的集合、数组或者map，生成一个option标签列表 &lt;sf:password&gt; 生成password类型的input标签 &lt;sf:radiobutton&gt; 生成radio类型的input标签 &lt;sf:radiobuttons&gt; 生成一组radio类型的input标签 &lt;sf:select&gt; 生成&lt;select&gt;标签 &lt;sf:textarea&gt; 生成&lt;textarea&gt;标签 现在就可以在之前的用户注册界面进行使用：12345678&lt;sf:form method="POST" commandName="spitter"&gt; First Name: &lt;sf:input path="firstName" /&gt;&lt;br/&gt; Last Name: &lt;sf:input path="lastName" /&gt;&lt;br/&gt; Email: &lt;sf:input path="email" /&gt;&lt;br/&gt; Username: &lt;sf:input path="username" /&gt;&lt;br/&gt; Password: &lt;sf:password path="password" /&gt;&lt;br/&gt; &lt;input type="submit" value="Register" /&gt;&lt;/sf:form&gt; 使用Spring的form标签主要有两个作用，第一是它会自动的绑定来自Model中的一个属性值到当前form对应的实体对象，默认是command属性，这样我们就可以在form表单体里面方便的使用该对象的属性了；第二是它支持我们在提交表单的时候使用除GET和POST之外的其他方法进行提交，包括DELETE和PUT等。 这个时候如果Model中存在一个属性名称为command的javaBean，在渲染上面的代码时就会取command的对应属性值赋给对应标签的值。 我们指定form默认自动绑定的是Model的command属性值，那么当我的form对象对应的属性名称不是command的时候，应该怎么办呢？对于这种情况，Spring给我们提供了一个commandName属性，我们可以通过该属性来指定我们将使用Model中的哪个属性作为form需要绑定的command对象。除了commandName属性外，指定modelAttribute属性也可以达到相同的效果。 这里将commandName设置为spitter，因此model中必然存在一个key为spitter的对象，否则表单将不能渲染。这意味着需要对SpitterController进行简单的改动，以保证model中存在一个Spitter的对象：123456// 处理来自/spitter/register的get请求@RequestMapping(value = "/register", method = RequestMethod.GET)public String showRegistrationForm(Model model) &#123; model.addAttribute(new Spitter()); return "registerForm";&#125; 回到表单代码中，使用&lt;sf:input&gt;代替了&lt;input&gt;标签，这个标签会生成一个HTML的&lt;input&gt;标签，并且将它的attribute属性设为text，它的value属性会根据&lt;sf:input&gt;标签的path属性设置的值去model对象中对应的属性值进行设置。如model中的Spitter对象有一个firstName属性为Jack，那么&lt;sf:input path=&quot;firstName&quot; /&gt;会被解析为含有value=&quot;Jack&quot;的input标签。 为了更好的理解，在一次注册失败后，会重定向到注册页面，对应的HTML的form标签如下所示：12345678910111213&lt;form id="spitter" action="/spitter/spitter/register" method="POST"&gt; First Name: &lt;input id="firstName" name="firstName" type="text" value="J"/&gt;&lt;br/&gt; Last Name: &lt;input id="lastName" name="lastName" type="text" value="B"/&gt;&lt;br/&gt; Email: &lt;input id="email" name="email" type="text" value="jack"/&gt;&lt;br/&gt; Username: &lt;input id="username" name="username" type="text" value="jack"/&gt;&lt;br/&gt; Password: &lt;input id="password" name="password" type="password" value=""/&gt;&lt;br/&gt; &lt;input type="submit" value="Register" /&gt;&lt;/form&gt; 值得注意的是，从Spring3.1开始，&lt;sf:input&gt;标签允许使用type属性来声明一些特殊的HTML5类型，如data、range和email等，例如，可以这样来声明email：Email: &lt;sf:input path=&quot;email&quot; type=&quot;email&quot; /&gt;&lt;br/&gt; 这样就会解析为：Email: &lt;input id=&quot;email&quot; name=&quot;email&quot; type=&quot;email&quot; value=&quot;jack&quot;/&gt;&lt;br/&gt; 错误信息展示当存在验证错误时，错误的详细信息会被存放model数据中并被request携带，所要做的就是对model中的错误信息进行展示，使用&lt;sf:errors&gt;标签即可。 例如：12345678First Name: &lt;sf:input path="firstName" /&gt; &lt;sf:errors path="firstName" cssClass="error"/&gt;&lt;br/&gt;``` 这里将`&lt;sf:errors&gt;`的path属性设置为firstName，那么就会展示Spitter model对象的firstName的验证错误信息，如果没有错误，那么就不会对其进行解析。如果有，会将其解析为`&lt;span&gt;`标签。```htmlFirst Name: &lt;input id="firstName" name="firstName" type="text" value="J"/&gt;&lt;span id="firstName.errors"&gt;size must be between 2 and 30&lt;/span&gt; 另外一种展示错误信息的方式是将它们放在一起进行展示，如：1234&lt;sf:form method="POST" commandName="spitter"&gt; &lt;sf:errors path="*" element="div" cssClass="errors" /&gt; ...&lt;/sf:form&gt; 这里的path属性使用了*，这表明&lt;sf:errors&gt;标签会解析所有属性的错误信息。需要注意的是，这里设置了属性element为div，默认情况下errors会被解析为&lt;span&gt;标签，适用于只有一条错误信息时。但是当有多条错误信息时，就需要使用&lt;div&gt;，这样错误信息就会解析为&lt;div&gt;标签。 现在还需要对需要更正的属性进行高亮显示，可以通过使用&lt;sf:label&gt;标签以及它的cssErroeClass属性来实现：123456&lt;sf:form method="POST" commandName="spitter"&gt; &lt;sf:errors path="*" element="div" cssClass="errors" /&gt; &lt;sf:label path="firstName" cssErrorClass="error"&gt;First Name&lt;/sf:label&gt;： &lt;sf:input path="firstName" cssErrorClass="error"/&gt;&lt;br/&gt;...&lt;/sf:form&gt; &lt;sf:label&gt;标签也有一个path属性，用来显示对于的model对象中的属性，如果没有验证错误，那么会将其解析为&lt;label&gt;标签：&lt;label for=&quot;firstName&quot;&gt;First Name&lt;/label&gt; 如果出现了验证错误消息，那么就会解析成：&lt;label for=&quot;firstName&quot; class=&quot;error&quot;&gt;First Name&lt;/label&gt; 类似的，&lt;sf:input&gt;将其cssErrorClass属性设置为error，如果出现验证错误，那么解析后的&lt;input&gt;标签的class属性会被设置为error。可以自定义属性信息：12345678910111213141516span.error &#123; color: red;&#125;label.error &#123; color: red;&#125;input.error &#123; background-color: #ffcccc;&#125;div.errors &#123; background-color: #ffcccc; border: 2px solid red;&#125; 现在可以为用户展示一个比较美观的验证错误信息，另外还可以在Spitter类中为验证信息设置message属性，从而可以得到比较友好的验证信息：12345678910111213141516171819@NotNull@Size(min = 5, max = 16, message = "&#123;username.size&#125;")private String username;@NotNull@Size(min = 5, max = 25, message = "&#123;password.size&#125;")private String password;@NotNull@Size(min = 2, max = 30, message = "&#123;firstName.size&#125;")private String firstName;@NotNull@Size(min = 2, max = 30, message = "&#123;lastName.size&#125;")private String lastName;@NotNull@Email(message = "&#123;email.valid&#125;")private String email; 对于每一个属性，为@Size标注的message设置了一个字符串，其中的值使用了大括号包括，那么大括号之间的值对应的真实内容可以通过properties文件进行设置：12345firstName.size=First name must be between &#123;min&#125; and &#123;max&#125; characters long.lastName.size=Last name must be between &#123;min&#125; and &#123;max&#125; characters long.username.size=Username must be between &#123;min&#125; and &#123;max&#125; characters long.password.size=Password must be between &#123;min&#125; and &#123;max&#125; characters long.email.valid=The email address must be valid. 其中的min和max是@Size标注中设置的。 当用户提交了一个不合法的注册信息时，可以得到如下图这样的错误提示信息： Spring基础标签库处理表单绑定标签库之外，Spring还提供了一个跟基本的JSP标签库。要使用该标签库，需要在页面中做以下声明：&lt;%@ taglib uri=&quot;http://www.springframework.org/tags&quot; prefix=&quot;s&quot; %&gt; 声明了之后，就可以在页面中使用如下的JSP标签了： JSP标签 描述 &lt;s:bind&gt; 通常和form一起用，用以指明表单要提交到哪个类或类的属性中去 &lt;spring:escapeBody&gt; 对标签中的内容进行转义处理 &lt;spring:hasBindErrors&gt; 用于将特定对象（request属性中）中绑定的的errors解析出来 &lt;spring:htmlEscape&gt; 设置当前页面的默认的HTML转义值 &lt;spring:message&gt; 根据code取得消息资源，并将其解析为一个page、request、session或者application范围的变量（由var或者scope属性指定） &lt;spring:nestedpath&gt; 为&lt;spring:bind&gt;配置嵌套路径 &lt;s:theme&gt; 与&lt;spring:message&gt;相同，只不过处理的是theme消息 &lt;spring:transform&gt; 来转换表单中不与bean中的属性一一对应的那些属性 &lt;s:url&gt; 与&lt;spring:message&gt;相同，只不过处理的是URI模版变量 &lt;s:eval&gt; 与&lt;spring:message&gt;相同，只不过处理的是SpEL表达式 展示消息的国际化支持使用&lt;s:message&gt;标签可以对引用外部属性文件的文件进行完美地解析，如：&lt;h1&gt;&lt;s:message code=&quot;spittr.welcome&quot; /&gt;&lt;/h1&gt;。 这里&lt;s:message&gt;标签会从某个属性文件中根据key值spittr.welcome读取对应的文本并解析到页面中，在这之前需要对这个key-value进行配置。 Spring有一些实现自MessageSource接口的消息源类，其中一个比较常用的就是ResourceBundleMessageSource，它可以从properties文件中加载消息，下面的@Bean方法对该类进行了配置：123456@Beanpublic MessageSource messageSource() &#123; ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); messageSource.setBasename("messages"); return messageSource;&#125; 其中的关键在于设置了basename属性，之后ResourceBundleMessageSource就可以对classpath根路径下相对应的的properties文件进行解析。 另外，还可以使用ReloadableResourceBundleMessageSource，它可以在不重新编译或者重启项目的情况下重新加载消息属性：1234567@Beanpublic MessageSource messageSource() &#123; ReloadableResourceBundleMessageSource messageSource = new ReloadableResourceBundleMessageSource(); messageSource.setBasename("file:///etc/spittr/messages"); messageSource.setCacheSeconds(10); return messageSource;&#125; 与ResourceBundleMessageSource主要的区别在于basename的设置，这里可以将其设置为classpath（需要前缀classpath:）、文件系统（file:）或者项目的根目录（不加任何前缀）。上面代码中设置的就是在文件系统中的/etc/spittr目录中查找文件名称为messages的文件。 下面创建一个名为messages.properties的文件，并添加如下内容：spittr.welcome=Welcome to Spittr! 构建URL：&lt;s:url&gt;标签的主要功能就是创建URL，并将其分配给一个变量或者解析到响应中。作为JSTL的&lt;c:url&gt;标签的简单替换，它也有这一些新功能。 &lt;s:url&gt;标签需要一个servlet上下文相关的URL，并对其进行解析。例如：&lt;a href=&quot;&lt;s:url href=&quot;/spitter/register&quot; /&gt;&quot;&gt;Register&lt;/a&gt; 如果servlet上下文是spittr，那么上面的链接将会被解析为：&lt;a href=&quot;/spittr/spitter/register&quot;&gt;Register&lt;/a&gt; 将servlet上下文作为链接前缀添加到目标链接中。 另外也可以使用&lt;s:url&gt;标签构建URL并分配到变量中：12&lt;s:url href="/spitter/register" var="registerUrl" /&gt;&lt;a href="$&#123;registerUrl&#125;"&gt;Register&lt;/a&gt; 默认情况下，URL变量是page范围内的。但是也可以通过设置scope属性将其设置为application、session或者request范围内的：&lt;s:url href=&quot;/spitter/register&quot; var=&quot;registerUrl&quot; scope=&quot;request&quot; /&gt; 如果想为URL添加参数，可以通过&lt;s:param&gt;标签进行添加。例如，下面的&lt;s:url&gt;标签通过&lt;s:param&gt;为/spittles设置了max和count属性：1234&lt;s:url href="/spittles" var="spittlesUrl"&gt; &lt;s:param name="max" value="60" /&gt; &lt;s:param name="count" value="20" /&gt;&lt;/s:url&gt; 现在看起来&lt;s:url&gt;和&lt;c:url&gt;没有什么区别嘛。但是如果需要创建一个含有路径参数的URL时怎么处理？如何让一个href中有一个可以替换的path参数？ 使用&lt;s:param&gt;就可以处理：123&lt;s:url href="/spitter/&#123;username&#125;" var="spitterUrl"&gt; &lt;s:param name="username" value="jbauer" /&gt;&lt;/s:url&gt; href中有一个占位符，通过来指定这个占位符的值。 另外，&lt;s:url&gt;也可以实现URL的转义，通过设置htmlEscape属性可以完成URL中的HTML转义：1234&lt;s:url value="/spittles" htmlEscape="true"&gt; &lt;s:param name="max" value="60" /&gt; &lt;s:param name="count" value="20" /&gt;&lt;/s:url&gt; 上面的标签将会被解析为：/spitter/spittles?max=60&amp;amp;count=20 另一方面，如果想在JavaScript代码中使用URL，那么可以设置javaScriptEscape属性为true。12345678&lt;s:url value="/spittles" var="spittlesJSUrl" javaScriptEscape="true"&gt; &lt;s:param name="max" value="60" /&gt; &lt;s:param name="count" value="20" /&gt;&lt;/s:url&gt;&lt;script&gt; var spittlesUrl = "$&#123;spittlesJSUrl&#125;"&lt;/script&gt; 上述代码会被解析为： 123&lt;script&gt; var spittlesUrl = "\/spitter\/spittles?max=60&amp;count=20"&lt;/script&gt; 内容转义：有时想在页面展示一段HTML代码，一般的要在页面显示字符&lt;和&gt;需要用&amp;lt;和&amp;gt;代替，但是这种做法明显的很笨重而且难读。这种情况下可以使用&lt;s:escapeBody&gt;标签：123&lt;s:escapeBody htmlEscape="true"&gt;&lt;h1&gt;Hello&lt;/h1&gt;&lt;/s:escapeBody&gt; 上述代码会被解析为：&amp;lt;h1&amp;gt;Hello&amp;lt;/h1&amp;gt; 当然，该标签页支持JavaScript代码，只需将其javaScriptEscape属性设为true即可：123&lt;s:escapeBody javaScriptEscape="true"&gt;&lt;h1&gt;Hello&lt;/h1&gt;&lt;/s:escapeBody&gt; 使用Apache Tiles视图假设要为所有页面添加一个通用的页首和页尾，一般的做法是为每个JSP页面添加HTML代码，显然这种方法在后期不方便进行维护。 刚好的方法是使用排版引擎，例如Apache Tiles，来定义所有页面中的通用页面排版。 配置Tiles视图解析器为了在Spring中使用Tiles，必须配置一些bean。需要一个TilesConfigurer，它主要用来定位以及加载tile定义。另外还需要TilesViewResolver来解析tile定义中的逻辑视图。 对于这两个组件，Apache Tiles 2和3中使用了不同的包：org.springframework.web.servlet.view.tiles2和org.springframework.web.servlet.view.tiles3，这里我们使用3版本。 下面添加TilesConfigurer的bean定义：123456789@Beanpublic TilesConfigurer tilesConfigurer() &#123; TilesConfigurer tiles = new TilesConfigurer(); // 指定tile定义的位置 tiles.setDefinitions(new String[] &#123; "/WEB-INF/layout/tiles.xml" &#125;); // 开启刷新 tiles.setCheckRefresh(true); return tiles;&#125; 在配置TilesConfigurer时，最重要的属性就是definitions，该属性使用一个String数组作为参数，用来指定tile定义文件的位置。可以指定多个位置，还可以使用通配符。例如可以使用如下的配置来指定TilesConfigurer寻找/WEB-INF目录下的任意名为tiles.xml的文件：123tiles.setDefinitions(new String[] &#123; "/WEB-INF/**/tiles.xml"&#125;); Ant风格的**模式表明要在/WEB-INF/下的所有目录查找名为tiles.xml的文件。 下面来配置TilesViewResolver：1234567891011121314151617@Beanpublic ViewResolver tilesViewResolver()&#123; return new TilesViewResolver();&#125;``` 另外，也可以使用XML的方式配置：```xml&lt;bean id="tilesConfigurer" class="org.springframework.web.servlet.view.tiles3.TilesConfigurer"&gt; &lt;property name="definitions"&gt; &lt;list&gt; &lt;value&gt;/WEB-INF/layout/tiles.xml.xml&lt;/value&gt; &lt;value&gt;/WEB-INF/views/**/tiles.xml&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="viewResolver" class="org.springframework.web.servlet.view.tiles3.TilesViewResolver" /&gt; 定义tile配置文件Apache Tiles提供了一个DTD（document type definition）用来指定XML中tile的定义。每个定义由&lt;definition&gt;元素组成，该元素又有一个或多个&lt;put-attribute&gt;，如：1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE tiles-definitions PUBLIC "-//Apache Software Foundation//DTD Tiles Configuration 3.0//EN" "http://tiles.apache.org/dtds/tiles-config_3_0.dtd"&gt;&lt;tiles-definitions&gt; &lt;!-- 定义一个基础tile --&gt; &lt;definition name="base" template="/WEB-INF/layout/page.jsp"&gt; &lt;put-attribute name="header" value="/WEB-INF/layout/header.jsp" /&gt; &lt;put-attribute name="footer" value="/WEB-INF/layout/footer.jsp" /&gt; &lt;/definition&gt; &lt;definition name="home" extends="base"&gt; &lt;put-attribute name="body" value="/WEB-INF/views/home.jsp" /&gt; &lt;/definition&gt; &lt;definition name="registerForm" extends="base"&gt; &lt;put-attribute name="body" value="/WEB-INF/views/registerForm.jsp" /&gt; &lt;/definition&gt; &lt;definition name="profile" extends="base"&gt; &lt;put-attribute name="body" value="/WEB-INF/views/profile.jsp" /&gt; &lt;/definition&gt; &lt;definition name="spittles" extends="base"&gt; &lt;put-attribute name="body" value="/WEB-INF/views/spittles.jsp" /&gt; &lt;/definition&gt; &lt;definition name="spittle" extends="base"&gt; &lt;put-attribute name="body" value="/WEB-INF/views/spittle.jsp" /&gt; &lt;/definition&gt;&lt;/tiles-definitions&gt; 每个&lt;definition&gt;元素定义了一个tile，代表着一个JSP模版。一个tile同时也可以代表其他在主模版中被嵌入的模版。对应base tile，它表示一个header JSP模版和footer JSP模版。 下面是page.jsp：12345678910111213141516171819202122232425262728&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ taglib uri="http://www.springframework.org/tags" prefix="s"%&gt;&lt;%@ taglib uri="http://tiles.apache.org/tags-tiles" prefix="t"%&gt;&lt;%@ page session="false"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;Spittr&lt;/title&gt;&lt;link rel="stylesheet" type="text/css" href="&lt;s:url value="/resources/style.css" /&gt;"&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- 头部 --&gt; &lt;div id="header"&gt; &lt;t:insertAttribute name="header" /&gt; &lt;/div&gt; &lt;!-- 正文 --&gt; &lt;div id="content"&gt; &lt;t:insertAttribute name="body" /&gt; &lt;/div&gt; &lt;!-- 尾部 --&gt; &lt;div id="footer"&gt; &lt;t:insertAttribute name="footer" /&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 其中的关键在于如何使用&lt;t:insertAttribute&gt;标签从Tile标签库插入到其他模版中。使用该标签来引入header、body、footer属性，最终的布局如下图所示： 其中，header和footer属性在tile定义文件中分别指明了，但是body属性呢？它在哪里设置呢？ base tile的主要作用是作为一个基础模版用来作为其他tile定义扩展使用的。那么扩展了base的tile就继承了base的header和footer属性（也可以进行重写）。它们自己也设置了一个body属性用来引用一个JSP模版。 如home tile，它继承自base，所以它继承了base的所有属性。即使home tile的定义非常简单，但是它相当于如下定义：12345&lt;definition name="home" template="/WEB-INF/layout/page.jsp"&gt; &lt;put-attribute name="header" value="/WEB-INF/layout/header.jsp" /&gt; &lt;put-attribute name="footer" value="/WEB-INF/layout/footer.jsp" /&gt; &lt;put-attribute name="body" value="/WEB-INF/views/home.jsp" /&gt;&lt;/definition&gt; hsader.jsp12345&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ taglib uri="http://www.springframework.org/tags" prefix="s"%&gt;&lt;a href="&lt;s:url value="/" /&gt;"&gt;&lt;img src="&lt;s:url value="/resources" /&gt;/images/spittr_logo_50.png" border="0" /&gt;&lt;/a&gt; footer.jsp：1Copyright &amp;copy; Craig Walls 每一个继承自base的tile都定义了自己的body模版： home.jsp：12345&lt;%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c" %&gt;&lt;%@ page session="false" %&gt;&lt;h1&gt;Welcome to Spittr&lt;/h1&gt;&lt;a href="&lt;c:url value="/spittles" /&gt;"&gt;Spittles&lt;/a&gt; |&lt;a href="&lt;c:url value="/spitter/register" /&gt;"&gt;Register&lt;/a&gt; 这里的关键在于一个页面的公共部分已经在page.jsp、header.jsp、footer.jsp中捕获，这样就可以在所有页面里进行重复利用，简化后期的维护工作。 如下图所示，页面中包含一些样式和图片，但是这些与Tiles是没有关联的，因此这里就不再进行详细的阐述。但是，从这个页面可以看出页面是如何通过各个不同的tile组件组成的。 使用Thymeleaf虽然JSP已经使用了较长的时间，并且在Java web中使用的也很广泛，但是它也有自身的一些缺陷。明显的就是JSP是以HTML或者XML的形式展现的。大多数的JSP模版都使用HTML的格式，并使用各种JSP标签库。虽然这些标签库可以在JSP中进行动态的解析，但是却很难有一个格式良好的页面。比如，可以在HTML中使用下面的JSP标签：&lt;input type=&quot;text&quot; value=&quot;&lt;c:out value=&quot;${thing.name}&quot;/&gt;&quot; /&gt; 当阅读一个没有解析的JSP页面时，常常很难读懂，简直就是一场视觉灾难！因为JSP并不是真正的HTML，很多web浏览器和编辑器很难对JSP进行解析。 另外，JSP与servlet规范是紧密耦合的，这就意味着它只能使用在以servlet为基础的web应用中。 近年内有涌现出很多要替代JSP作为java应用的视图技术，其中一个有力的竞争者就是：Thymeleaf。Thymeleaf不需要依赖标签库，并且是可编辑的、可以解析到HTML中。另外，它与servlet规范是没有耦合的，因此它可以在JSP不能使用的环境进行使用。下面，我们来看一下如何在Spring MVC中使用Thymeleaf。 配置Thymeleaf视图解析器为了在Spring中使用Thymeleaf，需要配置3个bean： ThymeleafViewResolver：用来从逻辑视图中解析出Thymeleaf模版； SpringTemplateEngine：对模版进行处理，并给出结果； TemplateResolver：用来加载Thymeleaf模版； 下面使用Java类的方式进行声明：12345678910111213141516171819202122232425// Thymeleaf视图解析器@Beanpublic ViewResolver viewResolver(SpringTemplateEngine templateEngine) &#123; ThymeleafViewResolver viewResolver = new ThymeleafViewResolver(); viewResolver.setTemplateEngine(templateEngine); return viewResolver();&#125;// Thymeleaf驱动@Beanpublic TemplateEngine templateEngine(TemplateResolver templateResolver) &#123; SpringTemplateEngine templateEngine = new SpringTemplateEngine(); templateEngine.setTemplateResolver(templateResolver); return templateEngine;&#125;// 模版解析器@Beanpublic TemplateResolver templateResolver() &#123; TemplateResolver templateResolver = new ServletContextTemplateResolver(); templateResolver.setPrefix("/WEB-INF/templates/"); templateResolver.setSuffix(".html"); templateResolver.setTemplateMode("HTML5"); return templateResolver;&#125; 也可以使用XML配置文件的方式进行配置：1234567&lt;bean id="viewResolver" class="org.thymeleaf.spring3.view.ThymeleafViewResolver" p:templateEngine-ref="templateEngine" /&gt;&lt;bean id="templateEngine" class="org.thymeleaf.spring3.SpringTemplateEngine" p:templateResolver-ref="templateResolver" /&gt;&lt;bean id="templateResolver" class="org.thymeleaf.templateresolver.ServletContextTemplateResolver" p:prefix="/WEB-INF/templates/" p:suffix=".html" p:templateMode="HTML5" /&gt; ThymeleafViewResolver是Spring MVC视图解析器ViewResolver的一个实现，和其他视图解析器一样，它会对一个逻辑视图名称进行解析，此时最终的视图会是一个Thymeleaf模版。 注意，ThymeleafViewResolver中注入了一个SpringTemplateEngine的bean类，SpringTemplateEngine可以用来对模版进行转换和解析。 TemplateResolver用来定位最终的模版。 定义Thymeleaf模版Thymeleaf模版主要是HTML文件，并没有一些特殊的标签或者标签库。它是通过自定义命名空间的方式来向标准HTML中添加Thymeleaf属性的。比如下面的例子：12345678910111213&lt;!DOCTYPE html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt;&lt;title&gt;Spittr&lt;/title&gt;&lt;link rel="stylesheet" type="text/css" th:href="@&#123;/resources/style.css&#125;"&gt;&lt;/link&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Welcome to Spittr&lt;/h1&gt; &lt;a th:href="@&#123;/spittles&#125;"&gt;Spittles&lt;/a&gt; | &lt;a th:href="@&#123;/spitter/register&#125;"&gt;Register&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 主页模版非常简单，只使用了th:href属性。该属性就像HTML的href属性，使用起来也是一样的。它的特别之处在于它可以包含Thymeleaf表达式。它会对href属性进行解析，这就是Thymeleaf表达式的工作原理：它们对应着标准的HTML属性，并且会解析一些计算值。这种情况下，所有的th:href属性会使用@{}表达式来得出相关的上下文URL路径（类似于JSTL中的标签）。 Thymeleaf模版不像JSP，它是可以编辑甚至可以自然的解析，不需要准备其他任何处理过程。当然，需要Thymeleaf对模版进行处理从而获取到预想的输出。但是不需要做其他特殊的处理，home.html就可以装载到浏览器中，如图所示： 如上图所示，JSP文件的标签库声明也会显示出来，并且在超链接前面会有一些奇怪的标记。 相反，Thymeleaf模版解析得比较完美，唯一的不足就是超链接的解析。浏览器没有将th:href解析为href，所有link没有解析为超链接的样式。 Spring的JSP标签擅长使用绑定，如果摒弃使用JSP，那么该如何使用属性绑定呢？ 使用Thymeleaf进行绑定表单绑定是Spring MVC的一个重要特性，没有正确的表单绑定，你就必须保证HTML的表单字段是正确命名的，并且是和后台的对象属性是一一映射的。同时还要保证当验证失败对表单进行展示时属性值可以正确地set到相应的对象属性中去。 比如registration.jsp中的First Name属性：123&lt;sf:label path="firstName" cssErrorClass="error"&gt;First Name&lt;/sf:label&gt;： &lt;sf:input path="firstName" cssErrorClass="error" /&gt;&lt;br /&gt; 这里&lt;sf:input&gt;标签会被解析为HTML的&lt;input&gt;标签，并且其value属性会根据后台对象的firstName属性进行设置。同时使用了&lt;sf:label&gt;和cssErrorClass属性用来在出现验证错误时解析该标签。 但是本节中我们要讨论的是如何在Thymeleaf中使用动态绑定，而不是JSP，比如下面的代码：1234&lt;label th:class="$&#123;#fields.hasErrors('firstName')&#125;? 'error'"&gt; First Name&lt;/label&gt;:&lt;input type="text" th:field="*&#123;firstName&#125;" th:class="$&#123;#fields.hasErrors('firstName')&#125;? 'error'" /&gt;&lt;br/&gt; 这里使用了th:class属性，该属性会被解析为一个class属性，并且其值是使用给定的表达式计算而来。该属性会对firstName值进行检查是否存在校验错误，如果存在，那么class属性解析后就会包含error，如果没有错误，那么class属性就不会进行解析。 &lt;input&gt;标签使用了th:field属性来从后台对象中解析出firstName属性。这里使用了th:field属性与后台对象的firstName属性进行了绑定，这样可以同时得到为firstName设置的value属性和name属性。 下面的代码中验证了Thymeleaf的数据绑定：1234567891011121314151617181920212223242526272829&lt;form method="POST" th:object="$&#123;spitter&#125;"&gt; &lt;div class="errors" th:if="$&#123;#fields.hasErrors('*')&#125;"&gt; &lt;ul&gt; &lt;li th:each="err : $&#123;#fields.errors('*')&#125;" th:text="$&#123;err&#125;"&gt;Input is incorrect&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;label th:class="$&#123;#fields.hasErrors('firstName')&#125;? 'error'"&gt;First Name&lt;/label&gt;: &lt;input type="text" th:field="*&#123;firstName&#125;" th:class="$&#123;#fields.hasErrors('firstName')&#125;? 'error'" /&gt;&lt;br/&gt; &lt;label th:class="$&#123;#fields.hasErrors('lastName')&#125;? 'error'"&gt;Last Name&lt;/label&gt;: &lt;input type="text" th:field="*&#123;lastName&#125;" th:class="$&#123;#fields.hasErrors('lastName')&#125;? 'error'" /&gt;&lt;br/&gt; &lt;label th:class="$&#123;#fields.hasErrors('email')&#125;? 'error'"&gt;Email&lt;/label&gt;: &lt;input type="text" th:field="*&#123;email&#125;" th:class="$&#123;#fields.hasErrors('email')&#125;? 'error'" /&gt;&lt;br/&gt; &lt;label th:class="$&#123;#fields.hasErrors('username')&#125;? 'error'"&gt;Username&lt;/label&gt;: &lt;input type="text" th:field="*&#123;username&#125;" th:class="$&#123;#fields.hasErrors('username')&#125;? 'error'" /&gt;&lt;br/&gt; &lt;label th:class="$&#123;#fields.hasErrors('password')&#125;? 'error'"&gt;Password&lt;/label&gt;: &lt;input type="password" th:field="*&#123;password&#125;" th:class="$&#123;#fields.hasErrors('password')&#125;? 'error'" /&gt;&lt;br/&gt; &lt;input type="submit" value="Register" /&gt;&lt;/form&gt; 上述代码使用了相同的Thymeleaf属性和*{}表达式来对后台对象进行绑定。值得注意的是，我们在form的顶部使用Thymeleaf来解析所有的异常。&lt;div&gt;元素使用了th:if属性来对是否存在错误进行校验，如果有错误，那么就会对&lt;div&gt;进行解析，否则就不解析。 &lt;div&gt;中的列表是无序的，针对变量err中的每一个error，每个&lt;li&gt;中的th:each会解析为一个&lt;li&gt;标签。&lt;li&gt;标签也有一个th:text属性，该属性会对表达式的值进行计算，并将结果解析到对应的&lt;li&gt;标签中。最终，针对每个error，都会有一个&lt;li&gt;进行展示。 你也许会对${}和*{}包含的表达式有疑惑。${}表达式是变量表达式，如${spitter}。一般的，都是一些OGNL(Object-Graph Navigation Language，对象图导航语言)表达式，但是当使用Spring时，它们就是SpEL表达式。比如${spitter}会解析为key是spitter的model对象。 而*{}表达式则是选择表达式，变量表达式根据整个的SpEL上下文进行计算，而选择表达式则是根据指定的对象进行计算。在上述表单中，选中的对象是在&lt;form&gt;标签中根据th:object属性指定的，即来自model的spitter对象，因此，*{password}表达式会被解析为spitter对象的password属性。 总结对请求的处理仅仅是Spring MVC的一半内容，如果来自控制器的结果准备进行展示，那么所产生的model数据需要解析到views中并在用户的浏览器中进行展示。Spring在试图解析方面是非常灵活的，并且可以提供一些创造性的选项，包括传统的JSP和较为高级的Apache Tile页面引擎。 本章大致介绍了视图以及Spring提供的视图解析，同时对如何使用JSP和Apache Tile进行了研究，另外还有Thymeleaf。 不知道是我见识少还是我没怎么关注前端技术，好像还没有见人使用过Tile和Thymeleaf，因此本文翻译过程中显得很单薄，代码也不完善，读完之后只能有一个大体的了解，请见谅。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring实战》学习笔记-第八章：使用Spring Web Flow]]></title>
    <url>%2F%E3%80%8ASpring%E5%AE%9E%E6%88%98%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E4%BD%BF%E7%94%A8Spring%20Web%20Flow.html</url>
    <content type="text"><![CDATA[第四版的第八章内容与第三版基本一致。 本章内容： 创建会话式web应用程序 定义流程状态和行为 保护web流程 互联网的一个奇特之处就在于它很容易让人迷失。有如此多的内容可以查看和阅读，而超链接是其强大魔力的核心所在。 有时候，web应用程序需要控制web冲浪者的导向，引导他们一步步地访问应用。比如电子商务网站的付款流程，从购物车开始，应用程序会引导你依次经过配送详情、账单信息以及最终的订单确认。 Spring Web Flow是一个web框架，它适用于元素规定流程运行的程序。本章中，我们将会探索它是如何用于Spring Web框架平台的。 其实我们可以使用任何的Web框架编写流程化的应用程序，比如使用Struts构建特定的流程。但是这样没有办法将流程与实现分开，你会发现流程的定义分散在组成流程的各个元素中，没有特定的地方能够完整地描述整个流程。 Spring Web Flow是Spring MVC的扩展，它支持开发基于流程的应用程序，可以将流程的定义和实现流程行为的类和视图分离开来。 在介绍Spring Web Flow的时候，我们会暂且放下Spittr样例，而使用生产披萨订单的web程序。 使用的第一步是在项目中进行安装，那么就从安装开始吧。 在Spring中配置Spring Web FlowSpring Web Flow是基于Spring MVC构建的，这就意味着所有的流程请求都需要经过Spring MVC的DispatcherServlet。我们需要在Spring应用上下文中配置一些Bean来处理流程请求并执行流程。 现在还没有支持使用Java来配置Spring Web Flow，所以没得选，只能在XML中进行配置。有一些Bean会使用Spring Web Flow的Spring配置文件命名空间来进行声明，因此我们需要在上下文定义XML文件中添加相应的命名空间：12345678910&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:flow="http://www.springframework.org/schema/webflow-config" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/webflow-config http://www.springframework.org/schema/webflow-config/spring-webflow-config-2.3.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd"&gt; 声明了命名空间后，就可以准备装配Web Flow的Bean了。 编写流程执行器顾名思义，流程执行器（flow executor ）就是用来驱动流程的执行。当用户进入到一个流程时，流程执行器会为该用户创建并启动一个流程执行器的实例。当流程暂停时（例如为用户展示视图时），流程执行器会在用户执行操作后恢复流程。 在Spring中，&lt;flow:flow-executor&gt;元素可以创建一个流程执行器：&lt;flow:flow-executor id=&quot;flowExecutor&quot; /&gt; 尽管流程执行器负责创建和执行流程，但它并不负责加载流程定义。这个要由流程注册表（flow registry）负责，下面会创建它。 配置流程注册表流程注册表的工作就是加载流程定义，并让流程执行器可以使用它们。可以在Spring中使用&lt;flow:flow-registry&gt;进行配置：123&lt;flow:flow-registry id="flowRegistry" base-path="/WEB-INF/flows"&gt; &lt;flow:flow-location-pattern value="/**/*-flow.xml" /&gt;&lt;/flow:flow-registry&gt; 正如这里声明的，流程注册表会在/WEB-INF/flows目录下寻找流程定义，这个路径是由base-path属性指明的。根据&lt;flow:flow-location-pattern&gt;元素，任何以-flow.xml结尾的XML文件都会被视为流程定义。 所有的流程都是通过其ID来进行引用的。使用&lt;flow:flow-location-pattern&gt;元素，流程的ID就是相对于base-path的路径，或者是双星号所代表的路径，如下图展示了流程ID是如何计算的： 另外，你也可以不使用base-path属性，直接显式地声明流程定义文件的位置：123&lt;flow:flow-registry id="flowRegistry"&gt; &lt;flow:flow-location path="/WEB-INF/flows/springpizza.xml" /&gt;&lt;/flow:flow-registry&gt; 这里使用了&lt;flow:flow-location&gt;而不是&lt;flow:flow-location-pattern&gt;，path属性直接指定了/WEB-INF/flows/springpizza.xml为流程定义文件。当这样定义时，流程的ID是从流程定义文件的文件名中获取的，这就是springpizza。 如果你希望更显示地指定流程ID，那么可以通过&lt;flow:flow-location&gt;元素的id属性来进行设置。例如，要设定pizza作为流程ID，可以这样进行配置：1234&lt;flow:flow-registry id="flowRegistry"&gt; &lt;flow:flow-location id="pizza" path="/WEB-INF/flows/springpizza.xml" /&gt;&lt;/flow:flow-registry&gt; 处理流程请求正如前面的章节中提到的，DispatcherServlet会将请求分发给控制器，但是对于流程而言，你需要FlowHandlerMapping来帮助DispatcherServlet将流程请求发送给Spring Web Flow。FlowHandlerMapping的配置如下：123&lt;bean class="org.springframework.webflow.mvc.servlet.FlowHandlerMapping"&gt; &lt;property name="flowRegistry" ref="flowRegistry" /&gt;&lt;/bean&gt; FlowHandlerMapping装配了注册表的引用，这样它就知道如何将请求的URL匹配到流程上。例如，如果有一个ID为pizza的流程，FlowHandlerMapping就会知道如果请求的URL是/pizza的话，就会将其匹配到这个流程上。 然而，FlowHandlerMapping的工作仅仅是将流程请求定向到Spring Web Flow，响应请求的是FlowHandlerAdapter，它等同于Spring MVC的控制器，会对流程请求进行响应并处理。FlowHandlerAdapter可以像下面这样装配成一个Spring Bean：123&lt;bean class="org.springframework.webflow.mvc.servlet.FlowHandlerAdapter"&gt; &lt;property name="flowExecutor" ref="flowExecutor" /&gt;&lt;/bean&gt; 这个处理适配器就是DispatcherServlet和Spring Web Flow之间的桥梁。它会处理流程请求并管理基于这些请求的流程。在这里，它装配了流程执行器的引用，而后者是为请求执行流程的。 现在已经配置了Spring Web Flow所需的Bean和组件，下面所需的就是真正的定义流程了。首先了解下流程的组成元素。 流程组件在Spring Web Flow中，流程是由3个主要元素组成的：状态（state）、转移（transition）和流程数据（flow data）。状态是流程中事件发生的地点。如果将流程想象成公路旅行，那么状态就是路途上的城镇、路边饭店以及风景点等。流程中的状态是业务逻辑执行、做出决策或将页面展示给用户的地方，而不是在公路旅行中买薯片或者可乐这些行为。 如果说流程状态是公路上停下来的地点，那么转移就是连接这些点的公路。在流程上，需要通过转移从一个状态到达另一个状态。 在城镇间旅行的时候，可能需要购买一些纪念品、留下一下回忆。类似的，在流程处理过程中，它要收集一些数据：流程当前状况等。也许你很想将其称为流程的状态，但是我们定义的状态已经有了另外的含义。 状态Spring Web Flow定义了5种不同的状态，如下表所示。通过选择Spring Web Flow的状态几乎可以把任意的安排功能构造成会话式的Web应用程序。尽管并不是所有的流程都需要下表中的状态，但最终你可能会经常使用其中几个。 状态类型 作用 行为（Action） 流程逻辑发生的地方 决策（Decision） 决策状态将流程分为两个方向，它会基于流程数据的评估结果确定流程方向 结束（End） 结束状态是流程的最后一站，进入End状态，流程就会终止 子流程（Subflow） 子流程状态会在当前正在运行的流程上下文中启动一个新的流程 视图（View） 视图状态会暂停流程并邀请用户参与流程 首先了解下这些流程元素在Spring Web Flow定义中是如何表现的。 视图状态视图状态用来为用户展现信息并使用户在流程中发挥作用。实际的视图实现可以是Spring支持的任意视图类型，但通常是用JSP来实现的。 在流程定义文件中，&lt;view-state&gt;用来定义视图状态：1&lt;view-state id="welcome" /&gt; 在这个简单的示例中，id属性有两个含义。其一，它定义了流程中的状态。其二，因为这里没有其他地方指定视图，那么它就指定了流程到达这个状态时要展现的逻辑视图名称为welcome。 如果要显示地指定另外一个视图名称，那么就可以使用view属性：1&lt;view-state id="welcome" view="greeting" /&gt; 如果流程为用户展现了一个表单，你希望指定表单所绑定的对象，可以使用model属性：1&lt;view-state id="takePayment" model="flowScope.paymentDetails"/&gt; 这里指定了takePayment视图将绑定流程范围内的paymentDetails对象。 行为状态视图状态包括流程应用的用户，而行为状态则是应用程序自身在执行任务。行为状态一般会触发Spring所管理Bean的一些方法，并跟你讲方法调用的执行结果转移到另一个状态。 在流程定义文件中，行为状态使用&lt;action-state&gt;元素来声明：1234&lt;action-state id="saveOrder"&gt; &lt;evaluate expression="pizzaFlowActions.saveOrder(order)" /&gt; &lt;transition to="thankYou" /&gt;&lt;/action-state&gt; 尽管没有严格要求，但是&lt;action-state&gt;元素一般都有一个&lt;evaluate&gt;子元素，该元素给出了行为状态要做的事情，expression属性指定了进入这个状态时要评估的表达式。本例中，给出的是SpEL表达式，这表明它将会找到ID为pizzaFlowActions的Bean，并调用其saveOrder()方法。 决策状态流程有可能会按照线性执行下去，从一个状态到另一个状态，没有其他的替代路线。但是更常见的是流程在某一个点根据流程当前情况进入不同的分支。 决策状态能够使得在流程执行时产生两个分支，它会评估一个Boolean表达式，根据结果是true还是false在两个状态转移中选择一个。在流程定义文件中，使用&lt;decision-state&gt;元素来定义决策状态：12345&lt;decision-state id="checkDeliveryArea"&gt; &lt;if test="pizzaFlowActions.checkDeliveryArea(customer.zipCode)" then="addCustomer" else="deliveryWarning" /&gt;&lt;/decision-state&gt; &lt;decision-state&gt;并不是单独工作的，&lt;if&gt;元素是其核心，它是进行表达式评估的地方，如果表达式结果为true，流程会转向then属性指定的状态，为false会转向else指定的状态中。 子流程状态也许你不会将应用程序的所有逻辑都写在一个方法里，而是将其分散到多个类、方法一起其他结构中。 同样的，将流程分成独立的部分也是个不错的主意。&lt;subflow-state&gt;元素允许在一个正在执行的流程中调用另一个流程：1234&lt;subflow-state id="order" subflow="pizza/order"&gt; &lt;input name="order" value="order"/&gt; &lt;transition on="orderCreated" to="payment" /&gt;&lt;/subflow-state&gt; 这里，&lt;input&gt;元素作为子流程的输入被用于传递订单对象。如果子流程结束的&lt;end-state&gt;状态ID为orderCreated，那么本流程就会转移到ID为payment的状态。 结束状态最后，所有的流程都要结束。这就是流程转移到结束状态时所做的。&lt;end-state&gt;元素指定了流程的结束：1&lt;end-state id="customerReady" /&gt; 当流程到达&lt;end-state&gt;时，流程就会结束。接下来发生什么要取决于以下几个因素： 如果结束的流程是个子流程，那么调用它的流程将会从&lt;subflow-state&gt;处继续执行。&lt;end-state&gt;的ID将会用作时间触发从&lt;subflow-state&gt;开始的转移。 如果&lt;end-state&gt;设置了view属性，那么就会渲染指定的视图。视图可以是相对于流程的路径，也可以是流程模板，使用externalRedirect:前缀的会重定向到流程外部的页面，而使用flowRedirect:前缀的则会重定向到另外一个流程。 如果结束的流程不是子流程也没有配置view属性，那么这个流程就会结束。浏览器最后将会加载流程的基本URL地址，同时，因为没有活动的流程，所以会开始一个新的流程实例。 需要注意的是一个流程可能有多个结束状态。因为子流程的结束状态ID确定了激活的事件，所以也许你会希望以多种结束状态来结束子流程，从而能够在调用流程中触发不同的事件，即使不是在子流程中，也有可能在结束流程后，根据流程的执行情况有多个显示页面供选择。 下面看一下流程是如何在状态间迁移的，如何在流程中通过定义转移来完成道路铺设。 转移如前文所述，转移连接了流程中的状态。流程中除结束状态外的每个状态，至少需要一个转移，这样就知道在状态完成时的走向。一个状态也许有多个转移，分别表示当前状态结束时可以执行的不同路径。 转移是通过&lt;transition&gt;元素来定义的，作为其他状态元素（&lt;action-state&gt;、&lt;view-state&gt;和&lt;subflow-state&gt;）的子元素。最简单的形式就是&lt;transition&gt;元素在流程中指定下一个状态：1&lt;transition to="customerReady" /&gt; 属性to用于指定流程中的下一个状态。如果&lt;transition&gt;元素只使用了to属性，那么这个转移就会是当前状态的默认转移选项，如果没有其他可用转移的话，就会使用它。 更为常见的转移定义是基于事件的触发来进行的。在视图状态，事件通常会是用户采取的动作。在行为状态，事件是评估表达式得到的结果。而在子流程状态，事件取决于子流程结束状态的ID。在任意事件中，你可以使用on属性来指定触发转移的事件：1&lt;transition on="phoneEntered" to="lookupCustomer"/&gt; 在示例中，如果触发了phoneEntered事件流程，就会进入lookupCustomer状态。 在抛出异常时，流程也可能进入另一种状态。例如，如果没有找到顾客的记录，你可能希望流程转移到一个显示注册表单的视图状态，如下面：12&lt;transition on-exception="com.springinaction.pizza.service.CustomerNotFoundException" to="registrationForm" /&gt; 属性on-exception和属性on十分类似，它是指定了要发生转移的异常而不是一个事件。 全局转移在创建完流程后，也许你会发现有些状态使用了一些通用的转移。例如在整个流程中到处都有如下转移：1&lt;transition on="cancel" to="endState" /&gt; 与其在多个流程状态中重复通用的转移，不如将其作为&lt;globaltransitions&gt;的子元素，从而作为全局转移。123&lt;global-transitions&gt; &lt;transition on="cancel" to="endState" /&gt;&lt;/global-transitions&gt; 定义完全局转移，流程中所有的状态都会默认拥有这个cancel转移。 流程数据当流程从一个状态到达另一个状态时，它会带走一些数据。有时这些数据很快就会被使用，比如直接展示给用户，有时这些数据需要在整个流程中传递并在流程结束时使用。 声明变量流程数据是保存在变量中的，而变量可以在流程的任意位置进行引用，并且可以以多种方式进行创建。其中最简单的方式就是使用&lt;var&gt;元素：1&lt;var name="customer" class="com.springinaction.pizza.domain.Customer"/&gt; 这里创建了一个新的Customer实例并将其放在customer变量中，这个变量可以在流程的任意状态下进行访问使用。 作为行为状态的一部分或者说作为视图状态的入口，也可以使用&lt;evaluate&gt;元素来创建变量：12&lt;evaluate result="viewScope.toppingsList" expression="T(com.springinaction.pizza.domain.Topping).asList()" /&gt; 这里&lt;evaluate&gt;元素计算了一个SpEL表达式，并将结果放到toppingsList变量中，这个变量是视图作用域的。 类似的，&lt;set&gt;元素也可以设置变量的值：12&lt;set name="flowScope.pizza" value="new com.springinaction.pizza.domain.Pizza()" /&gt; &lt;set&gt;元素与&lt;evaluate&gt;元素类似，都是讲变量设置为表达式计算的结果。这里我们设置了一个流程范围的pizza变量，它的值为Pizza对象的新实例。 流程数据的作用域流程中所携带的数据都有其各自的生命周期，这取决于保存数据的变量本身的作用域，如下表： 范围 生命周期 Conversation 最高层级的流程开始时创建，在最高层级的流程结束时销毁。由最高层级的流程和其所有的子流程所共享 Flow 当流程开始时创建，在流程结束时销毁。只在创建它的流程中是可见的 Request 当一个请求进入流程时创建，流程返回时销毁 Flash 流程开始时创建，流程结束时销毁。在视图状态解析后，才会被清除 View 进入视图状态时创建，退出这个状态时销毁，只在视图状态内可见 当使用&lt;var&gt;元素声明变量时，变量始终是流程作用域的，也就是在流程作用域内定义变量。当使用&lt;set&gt;或&lt;evaluate&gt;时，作用域通过name或result属性的前缀指定。例如，将一个值赋给流程作用域的theAnswer变量：1&lt;set name="flowScope.theAnswer" value="42"/&gt; 到目前为止，我们已经看到了Web流程的所有原材料，下面要将其进行整合了，完成一个完整的流程。 组合起来：披萨流程首先从构建一个高层次的流程开始，它定义了订购披萨的整体流程，然后将其拆分为多个子流程。 定义基本流程当顾客访问Spizza网站时，他们需要进行用户识别、选择一个或多个披萨添加到订单、提供支付信息，然后提交订单，等待披萨上来，如下图： 下面展示Spring Web Flow的XML流程定义来实现披萨订单的整体流程：123456789101112131415161718192021222324252627282930313233343536&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;flow xmlns="http://www.springframework.org/schema/webflow" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/webflowhttp://www.springframework.org/schema/webflow/spring-webflow-2.3.xsd"&gt; &lt;var name="order" class="com.springinaction.pizza.domain.Order" /&gt; &lt;!-- 调用顾客子流程 --&gt; &lt;subflow-state id="identifyCustomer" subflow="pizza/customer"&gt; &lt;output name="customer" value="order.customer" /&gt; &lt;transition on="customerReady" to="buildOrder" /&gt; &lt;/subflow-state&gt; &lt;!-- 调用订单子流程 --&gt; &lt;subflow-state id="buildOrder" subflow="pizza/order"&gt; &lt;input name="order" value="order" /&gt; &lt;transition on="orderCreated" to="takePayment" /&gt; &lt;/subflow-state&gt; &lt;!-- 调用支付子流程 --&gt; &lt;subflow-state id="takePayment" subflow="pizza/payment"&gt; &lt;input name="order" value="order" /&gt; &lt;transition on="paymentTaken" to="saveOrder" /&gt; &lt;/subflow-state&gt; &lt;!-- 保存订单 --&gt; &lt;action-state id="saveOrder"&gt; &lt;evaluate expression="pizzaFlowActions.saveOrder(order)" /&gt; &lt;transition to="thankCustomer" /&gt; &lt;/action-state&gt; &lt;!-- 感谢顾客 --&gt; &lt;view-state id="thankCustomer"&gt; &lt;transition to="endState" /&gt; &lt;/view-state&gt; &lt;end-state id="endState" /&gt; &lt;!-- 全局取消转移 --&gt; &lt;global-transitions&gt; &lt;transition on="cancel" to="endState" /&gt; &lt;/global-transitions&gt;&lt;/flow&gt; 流程定义中的第一件事就是声明order变量。每次流程开始的时候都会创建一个Order实例。Order类会包含关于订单的所有信息、顾客信息、订购的披萨以及支付信息等。123456789101112131415161718192021222324252627282930313233package com.springinaction.pizza.domain;import java.io.Serializable;import java.util.ArrayList;import java.util.List;import org.springframework.beans.factory.annotation.Configurable;@Configurable("order")public class Order implements Serializable &#123; private static final long serialVersionUID = 1L; private Customer customer; private List&lt;Pizza&gt; pizzas; private Payment payment; public Order() &#123; pizzas = new ArrayList&lt;Pizza&gt;(); customer = new Customer(); &#125; //getters and setters&#125; ``` 流程定义的主要组成部分是流程的状态，默认情况下，流程定义文件中的第一个状态会是流程访问的第一个状态。本例中就是identifyCustomer状态（一个子流程）。也可以通过`&lt;flow&gt;`元素的`start-state`属性来指定任意状态为开始状态：```xml&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;flow xmlns="http://www.springframework.org/schema/webflow" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/webflow http://www.springframework.org/schema/webflow/spring-webflow-2.3.xsd" start-state="identifyCustomer"&gt; ...&lt;/flow&gt; 识别顾客、构建披萨订单和支付这样的活动比较复杂，并不适合将其直接放在一个状态，而是以&lt;subflow-state&gt;元素展现的。 流程变量order将在前3个状态中进行填充并在第4个状态中进行保存。identifyCustomer子流程使用了&lt;output&gt;元素来填充order的customer属性，将其设置为调用顾客子流程收到的输出。buildOrder和takePayment状态使用了不同的方式，它们使用&lt;input&gt;将order流程变量作为输入，这些子流程就能在其内部填充order对象。 在订单得到顾客、披萨以及支付信息后，就可以对其进行保存。saveOrder是处理这个任务的行为状态。它使用&lt;evaluate&gt;来调用ID为pizzaFlowActions的Bean的saveOrder()方法，并将保存的订单对象传递进来。订单完成保存后会转移到thankCustomer。 thankCustomer状态是一个简单的视图状态，后台使用了/WEB-INF/flows/pizza/thankCustomer.jsp文件进行展示：1234567891011&lt;html xmlns:jsp="http://java.sun.com/JSP/Page"&gt; &lt;jsp:output omit-xml-declaration="yes" /&gt; &lt;jsp:directive.page contentType="text/html;charset=UTF-8" /&gt; &lt;head&gt;&lt;title&gt;Spizza&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h2&gt;Thank you for your order!&lt;/h2&gt; &lt;![CDATA[ &lt;a href='$&#123;flowExecutionUrl&#125;&amp;_eventId=finished'&gt;Finish&lt;/a&gt; ]]&gt; &lt;/body&gt;&lt;/html&gt; 该页面提供了一个完成流程的链接，它展示了用户与流程交互的唯一办法。 Spring Web Flow为视图的用户提供了一个flowExecutionUrl变量，它包含了流程的URL。结束链接将一个_eventId参数关联到URL上，以便返回到Web流程时触发finished事件。这个事件将会使流程到达结束状态。 流程将会在结束状态完成。由于在流程结束后没有下一步做什么具体信息，流程将会重新从identifyCustomer状态开始，以准备接受下一个订单。 下面还要定义identifyCustomer、buildOrder、takePayment这些子流程。 收集顾客信息对于一个顾客，需要收集其电话、住址等信息，如下面的流程图： 这个流程不再是线性的，而是有了分支。例如在查找顾客后，流程可能结束，也可能转到注册表单。同样的，在checkDeliveryArea状态，顾客可能会被告警，也可能是不被告警。 程序清单：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;flow xmlns="http://www.springframework.org/schema/webflow" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/webflow http://www.springframework.org/schema/webflow/spring-webflow-2.0.xsd"&gt; &lt;input name="order" required="true" /&gt; &lt;!-- Customer --&gt; &lt;view-state id="welcome"&gt; &lt;transition on="phoneEntered" to="lookupCustomer" /&gt; &lt;transition on="cancel" to="cancel" /&gt; &lt;/view-state&gt; &lt;action-state id="lookupCustomer"&gt; &lt;evaluate result="order.customer" expression="pizzaFlowActions.lookupCustomer(requestParameters.phoneNumber)" /&gt; &lt;transition to="registrationForm" on-exception="com.springinaction.pizza.service.CustomerNotFoundException" /&gt; &lt;transition to="customerReady" /&gt; &lt;/action-state&gt; &lt;view-state id="registrationForm" model="order" popup="true"&gt; &lt;on-entry&gt; &lt;evaluate expression="order.customer.phoneNumber = requestParameters.phoneNumber" /&gt; &lt;/on-entry&gt; &lt;transition on="submit" to="checkDeliveryArea" /&gt; &lt;transition on="cancel" to="cancel" /&gt; &lt;/view-state&gt; &lt;decision-state id="checkDeliveryArea"&gt; &lt;if test="pizzaFlowActions.checkDeliveryArea(order.customer.zipCode)" then="addCustomer" else="deliveryWarning" /&gt; &lt;/decision-state&gt; &lt;view-state id="deliveryWarning"&gt; &lt;transition on="accept" to="addCustomer" /&gt; &lt;transition on="cancel" to="cancel" /&gt; &lt;/view-state&gt; &lt;action-state id="addCustomer"&gt; &lt;evaluate expression="pizzaFlowActions.addCustomer(order.customer)" /&gt; &lt;transition to="customerReady" /&gt; &lt;/action-state&gt; &lt;!-- End state --&gt; &lt;end-state id="cancel" /&gt; &lt;end-state id="customerReady" /&gt;&lt;/flow&gt; 下面将这个流程定义分解成一个个的状态。 询问电话号码welcome状态是一个很简单的视图状态，它欢迎访问Spizza网站的顾客并要求输入电话。它有两个转移：如果从视图触发phoneEntered事件，就会定向到lookupCustomer，另外一个就是在全局转移中定义用来响应cancel事件的cancel转移。 页面代码：123456789101112131415161718192021&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core"%&gt;&lt;%@ taglib prefix="form" uri="http://www.springframework.org/tags/form"%&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Spring Pizza&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h2&gt;Welcome to Spring Pizza!!!&lt;/h2&gt; &lt;form:form&gt; &lt;input type="hidden" name="_flowExecutionKey" value="$&#123;flowExecutionKey&#125;" /&gt; &lt;input type="text" name="phoneNumber" /&gt; &lt;br /&gt; &lt;input type="submit" name="_eventId_phoneEntered" value="Lookup Customer" /&gt; &lt;/form:form&gt;&lt;/body&gt;&lt;/html&gt; 这个简单的表单用来让用户输入电话号码，有两个特殊的部分，首先是隐藏的_flowExecutionKey输入。当进入视图状态时，流程暂停并等待用户采取一些行为。当用户提交表单时，流程执行键会在_flowExecutionKey输入域中返回，并在流程暂停的位置进行恢复。 还需要注意提交按钮的名称_eventId_部分是Spring Web Flow的一个线索，它表明了接下来要触发事件。当点击这个按钮提交表单时，就会触发phoneEntered事件，进而转移到lookupCustomer。 查找顾客当欢迎顾客的表单提交后，顾客的电话号码将包含在请求参数中，并用于查询顾客。lookupCustomer状态的&lt;evaluate&gt;元素是查找发生的位置。它将电话号码从请求参数中抽取出来，并传递到pizzaFlowActions Bean的lookupCustomer()方法中。该方法要么返回Customer对象，要么抛出CustomerNotFoundException异常。 在前一种情况下，Customer对象会被设置到customer变量中（通过result属性）并默认的转移将流程带到customerReady状态。如果没有查到顾客，那么会抛出异常，流程会转移到registrationForm状态。 注册新顾客registrationForm要求用户填写配送地址：12345678910111213141516171819202122232425&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;%@ taglib prefix="form" uri="http://www.springframework.org/tags/form" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;Spring Pizza&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h2&gt;Customer Registration&lt;/h2&gt; &lt;form:form commandName="order"&gt; &lt;input type="hidden" name="_flowExecutionKey" value="$&#123;flowExecutionKey&#125;"/&gt; &lt;b&gt;Phone number: &lt;/b&gt;&lt;form:input path="customer.phoneNumber"/&gt;&lt;br/&gt; &lt;b&gt;Name: &lt;/b&gt;&lt;form:input path="customer.name"/&gt;&lt;br/&gt; &lt;b&gt;Address: &lt;/b&gt;&lt;form:input path="customer.address"/&gt;&lt;br/&gt; &lt;b&gt;City: &lt;/b&gt;&lt;form:input path="customer.city"/&gt;&lt;br/&gt; &lt;b&gt;State: &lt;/b&gt;&lt;form:input path="customer.state"/&gt;&lt;br/&gt; &lt;b&gt;Zip Code: &lt;/b&gt;&lt;form:input path="customer.zipCode"/&gt;&lt;br/&gt; &lt;input type="submit" name="_eventId_submit" value="Submit" /&gt; &lt;input type="submit" name="_eventId_cancel" value="Cancel" /&gt; &lt;/form:form&gt; &lt;/body&gt;&lt;/html&gt; 该表单绑定到了Order.customer对象上。 检查配送区域顾客提供了地址后，需要确认住址是否在配送范围内，因此使用了决策状态。 决策状态checkDeliveryArea有一个&lt;if&gt;元素，它将顾客的邮编传递到pizzaFlowActions Bean的checkDeliveryArea()方法中，该方法会返回一个Boolean值。 如果顾客在配送范围内，那么流程将转移到addCustomer状态，否则进入deliveryWarning视图状态。deliveryWarnin视图：1234567891011121314&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;Spring Pizza&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h2&gt;Delivery Unavailable&lt;/h2&gt; &lt;p&gt;The address is outside of our delivery area. The order may still be taken for carry-out.&lt;/p&gt; &lt;a href="$&#123;flowExecutionUrl&#125;&amp;_eventId=accept"&gt;Accept&lt;/a&gt; | &lt;a href="$&#123;flowExecutionUrl&#125;&amp;_eventId=cancel"&gt;Cancel&lt;/a&gt; &lt;/body&gt;&lt;/html&gt; 其中有两个链接，允许用户继续订单或者取消订单。通过使用与welcome状态相同的flowExecutionUrl变量，这些链接分别触发流程中的accept和cancel事件。如果发送的是accept事件，那么流程会转移到addCustomer状态。否则，子流程会转移到cancel状态。 存储顾客数据addCustomer有一个&lt;evaluate&gt;元素，它会调用pizzaFlowActions.addCustomer()方法，将order.customer流程参数传递进去。 一旦这个流程完成，就会执行默认转移，流程会转移到ID为customerReady的结束状态。 结束流程当customer流程完成所有的路径后，会到达customerReady的结束状态。当调用它的披萨流程恢复时，它会接收到一个customerReady事件，这个事件将使得流程转移到buildOrder状态。 注意，customerReady结束状态包含了一个&lt;output&gt;元素。在流程中，它等同于Java的return语句。它会从子流程中传递一些数据到调用流程。例如，&lt;output&gt;元素返回customer变量，这样披萨流程中的identifyCustomer子流程状态就可以将其指定给订单。 另外，如果用户在任意地方触发了cancel事件，将会通过cancel状态结束流程，这也会在披萨流程中触发cancel事件并导致转移到披萨流程的结束状态。 构建订单下面就是确定顾客想要什么样的披萨，提示用户创建披萨并将其放入订单，如图： 可以看到，showOrder状态位于订单子流程的中心位置。这是用户进入这个流程时的状态，也是用户添加披萨订单后转移的目标状态。它展现了订单的当前状态，并允许用户添加其他的披萨到订单中。 添加披萨订单时，会转移到createPizza状态。这是一个视图状态，允许用户对披萨进行选择。 在showOrder状态，用户可以提交订单，也可以取消。 123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;flow xmlns="http://www.springframework.org/schema/webflow" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/webflow http://www.springframework.org/schema/webflow/spring-webflow-2.0.xsd"&gt; &lt;input name="order" required="true" /&gt; &lt;!-- Order --&gt; &lt;view-state id="showOrder"&gt; &lt;transition on="createPizza" to="createPizza" /&gt; &lt;transition on="checkout" to="orderCreated" /&gt; &lt;transition on="cancel" to="cancel" /&gt; &lt;/view-state&gt; &lt;view-state id="createPizza" model="flowScope.pizza"&gt; &lt;on-entry&gt; &lt;set name="flowScope.pizza" value="new com.springinaction.pizza.domain.Pizza()" /&gt; &lt;evaluate result="viewScope.toppingsList" expression="T(com.springinaction.pizza.domain.Topping).asList()" /&gt; &lt;/on-entry&gt; &lt;transition on="addPizza" to="showOrder"&gt; &lt;evaluate expression="order.addPizza(flowScope.pizza)" /&gt; &lt;/transition&gt; &lt;transition on="cancel" to="showOrder" /&gt; &lt;/view-state&gt; &lt;!-- End state --&gt; &lt;end-state id="cancel" /&gt; &lt;end-state id="orderCreated" /&gt;&lt;/flow&gt; 这个子流程实际上回操作主流程创建的Order对象，在这里我们使用&lt;input&gt;元素来将Order对象传递进流程。 接下来会看到showOrder状态，它是一个基本的视图状态，具有3个不同的转移，分别用于创建披萨、提交订单和取消订单。 createPizza的视图是一个表单，这个表单可以添加新的Pizza对象到订单。&lt;on-entry&gt;元素添加了一个新的Pizza对象到流程作用域内，当表单提交时它将填充进订单。值得注意的是，这个视图状态引用的model是流程作用域同一个Pizza对象。Pizza对象将绑定到创建披萨的表单中：1234567891011121314151617181920212223242526&lt;%@ taglib prefix="form" uri="http://www.springframework.org/tags/form" %&gt;&lt;div&gt; &lt;h2&gt;Create Pizza&lt;/h2&gt; &lt;form:form commandName="pizza"&gt; &lt;input type="hidden" name="_flowExecutionKey" value="$&#123;flowExecutionKey&#125;"/&gt; &lt;b&gt;Size: &lt;/b&gt;&lt;br/&gt; &lt;form:radiobutton path="size" label="Small (12-inch)" value="SMALL"/&gt;&lt;br/&gt; &lt;form:radiobutton path="size" label="Medium (14-inch)" value="MEDIUM"/&gt;&lt;br/&gt; &lt;form:radiobutton path="size" label="Large (16-inch)" value="LARGE"/&gt;&lt;br/&gt; &lt;form:radiobutton path="size" label="Ginormous (20-inch)" value="GINORMOUS"/&gt;&lt;br/&gt; &lt;br/&gt; &lt;b&gt;Toppings: &lt;/b&gt;&lt;br/&gt; &lt;form:checkboxes path="toppings" items="$&#123;toppingsList&#125;" delimiter="&lt;br/&gt;"/&gt;&lt;br/&gt;&lt;br/&gt; &lt;input type="submit" class="button" name="_eventId_addPizza" value="Continue"/&gt; &lt;input type="submit" class="button" name="_eventId_cancel" value="Cancel"/&gt; &lt;/form:form&gt;&lt;/div&gt; 当通过Continue按钮提交订单时，尺寸和配料选择会绑定到Pizza对象中，并且触发addPizza转移。与这个转移关联的&lt;evaluate&gt;元素表明在转移到showOrder状态之前，流程作用域内的Pizza对象会传递给订单的addPizza()方法中。 有两种方法可以结束流程，用户可以点击showOrder视图中的Cancel按钮或者Checkout按钮。这两种操作都会使流程转移到一个&lt;end-state&gt;。但是选择的结束状态ID决定了退出这个流程时触发事件，进而最终确定主流程的下一个行为。主流程要么基于cancel要么基于orderCreated事件进行状态转移。在前者情况下，外边的流程会结束；后者，会转移到takePayment子流程。 支付在披萨流程要结束的时候，最后的子流程提示用户输入他们的支付信息，如下图： 支付子流程也是使用&lt;input&gt;元素接收一个Order对象作为输入。 可以看到，进入支付子流程的时候，用户会到达takePayment状态。这是一个视图状态，在这里用户可以选择信用卡、支票或者现金进行支付。提示支付信息后，进入verifyPayment状态，这是一个行为状态，会校验支付信息是否可以接受。 123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;flow xmlns="http://www.springframework.org/schema/webflow" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/webflow http://www.springframework.org/schema/webflow/spring-webflow-2.0.xsd"&gt; &lt;input name="order" required="true"/&gt; &lt;view-state id="takePayment" model="flowScope.paymentDetails"&gt; &lt;on-entry&gt; &lt;set name="flowScope.paymentDetails" value="new com.springinaction.pizza.domain.PaymentDetails()" /&gt; &lt;evaluate result="viewScope.paymentTypeList" expression="T(com.springinaction.pizza.domain.PaymentType).asList()" /&gt; &lt;/on-entry&gt; &lt;transition on="paymentSubmitted" to="verifyPayment" /&gt; &lt;transition on="cancel" to="cancel" /&gt; &lt;/view-state&gt; &lt;action-state id="verifyPayment"&gt; &lt;evaluate result="order.payment" expression= "pizzaFlowActions.verifyPayment(flowScope.paymentDetails)" /&gt; &lt;transition to="paymentTaken" /&gt; &lt;/action-state&gt; &lt;!-- End state --&gt; &lt;end-state id="cancel" /&gt; &lt;end-state id="paymentTaken" /&gt;&lt;/flow&gt; 在流程进入takePayment视图时，&lt;on-entry&gt;元素将构建一个支付表单并使用SpEL表达式在流程范围内创建PaymentDetails实例，该实例实际上是表单背后的对象。它也会创建视图作用域的paymentDetails变量，这个变量是一个包含了PaymentType enum的值的列表。在这里，SpEL的T()作用于PaymentType类，这样就可以调用静态的asList()方法。 1234567891011121314151617181920package com.springinaction.pizza.domain;import java.util.Arrays;import java.util.List;import org.apache.commons.lang3.text.WordUtils;public enum PaymentType &#123; CASH, CHECK, CREDIT_CARD; public static List&lt;PaymentType&gt; asList() &#123; PaymentType[] all = PaymentType.values(); return Arrays.asList(all); &#125; @Override public String toString() &#123; return WordUtils.capitalizeFully(name().replace('_', ' ')); &#125;&#125; 在面对支付表单的时候，用户可能提交支付，也可能会取消。根据做出的选择，支付子流程将名为paymentTaken或cancel的&lt;end-state&gt;结束。就像其他的子流程一样，不论哪种&lt;end-state&gt;都会结束子流程并将控制交给主流程。但是所采用的id将决定主流程接下来的转移。 目前我们已经依次介绍了披萨流程及其子流程，下面快速了解下如何对流程及其状态的访问增加安全保护。 保护Web流程Spring Web Flow中的状态、转移甚至整个流程都可以借助&lt;secured&gt;元素实现安全性，该元素会作为这些元素的子元素。例如，为了保护对一个视图状态的访问：123&lt;view-state id="restricted"&gt; &lt;secured attributes="ROLE_ADMIN" match="all"/&gt;&lt;/view-state&gt; 按照这里的配置，只有授权ROLE_ADMIN访问权限（借助attributes属性）的用户才能访问这个视图状态。attributes属性使用逗号分隔的权限列表来表明用户要访问指定状态、转移或流程所需要的权限。match属性可以设置为any或all。如果是any，那么用户至上具备一个attributes属性所列的权限。如果的all，那么用户必须具有所有权限。具体见下一章。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring实战》学习笔记-第二章：装配Bean]]></title>
    <url>%2F%E3%80%8ASpring%E5%AE%9E%E6%88%98%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E8%A3%85%E9%85%8DBean.html</url>
    <content type="text"><![CDATA[创建应用对象之间协作关系的行为通常被称作装配（Wiring），这也是依赖注入的本质。 声明Bean创建Spring配置Spring容器提供了两种配置Bean的方式，其一是使用XML文件作为配置文件，其二是基于Java注解的配置方式。以下是一个典型的Spring XML配置文件：12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- 此处声明各个Bean --&gt;&lt;/beans&gt; 在标签内可以放置相关的Spring配置信息，另外，Spring的核心框架自带了10个命名空间的配置： 命名空间 用途 aop 为声明切面以及将＠AspectJ注解的类代理为Spring切面提供了配置元素 beans beans支持声明Bean和装配Bean，是Spring最核心也是最原始的命名空间 context 为配置Spring应用上下文提供了配置元素，包括自动检测和自动装配Bean、注入非Spring直接管理的对象 jee 提供了与Java EE API 的集成，例如JNDI和EJB jms 为声明消息驱动的POJO提供了配置元素 lang 支持配置由Groovy、JRuby或BeanShell等脚本实现的Bean mvc 启用Spring MVC的能力，例如面向注解的控制器、视图控制器和拦截器 oxm 支持Spring 的对象到XML映射配置 tx 提供声明式事务配置 util 提供各种各样的工具类元素，包括把集合配置为Bean、支持属性占位符元素 声明一个简单的Bean12345678910111213141516171819package com.springinaction.springidol;public class Juggler implements Performer &#123; private int beanBags = 3; public Juggler() &#123; &#125; public Juggler(int beanBags) &#123; this.beanBags = beanBags; &#125; @Override public void perform() throws PerformanceException &#123; System.out.println("JUGGLING " + beanBags + " BEANBAGS"); &#125;&#125; 1&lt;bean id="duke" class="com.springinaction.springidol.Juggler"&gt;&lt;/bean&gt; &lt;bean&gt;元素是Spring中最基本的配置单元，通过该元素Spring将创建一个对象。当Spring容器加载该Bean时，Spring将使用默认的构造器来实例化该Bean，实际上，duke会使用如下代码来创建：new com.springinaction.springidol.Juggler(); 通过构造器注入让bean使用另外一个构造方法： 123&lt;bean id="duke" class="com.springinaction.springidol.Juggler"&gt; &lt;constructor-arg value="15"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 在构造Bean的时候，可以使用&lt;constructor-arg&gt;标签来告诉Spring额外的信息，这样Spring就不再会使用默认的构造器来实例化该Bean。测试代码： 123456789101112131415package com.springinaction.springidol;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class TestSpring &#123; @Test public void testDuke() throws PerformanceException &#123; ApplicationContext context = new ClassPathXmlApplicationContext("spring-idol.xml"); Performer performer = (Performer) context.getBean("duke"); performer.perform(); &#125;&#125; 通过运行结果JUGGLING 15 BEANBAGS可以15被注入到了构造器中。 通过构造器注入对象引用现在需要一个新的类PoeticJuggler，该类需要Poem类作为其参数并通过构造器注入。123456789101112131415161718192021222324package com.springinaction.springidol;public class PoeticJuggler extends Juggler &#123; private Poem poem; // 注入Poem public PoeticJuggler(Poem poem) &#123; super(); this.poem = poem; &#125; // 注入豆袋子数量和Poem public PoeticJuggler(int beanBags, Poem poem) &#123; super(beanBags); this.poem = poem; &#125; @Override public void perform() throws PerformanceException &#123; super.perform(); System.out.println("While reciting..."); poem.recite(); &#125;&#125; 在配置文件中就需要声明一个 Poem的类，并将其注入到PoeticJuggler中： 123456&lt;bean id="sonnet29" class="com.springinaction.springidol.Sonnet29"&gt;&lt;/bean&gt;&lt;bean id="poeticDuke" class="com.springinaction.springidol.PoeticJuggler"&gt; &lt;constructor-arg value="15" /&gt; &lt;constructor-arg ref="sonnet29" /&gt;&lt;/bean&gt; 这里使用ref属性来将Id为sonnet29的Bean引用传递给构造器，当Spring遇到sonnet29和poeticDuke的bean声明时，所执行的逻辑脚本将是： 12Poem sonnet29 = new Sonnet29();Performer poeticDuke = new PoeticJuggler(15, sonnet29 ); 通过工厂方法创建Bean在没有公开的构造方法时，可以通过工厂方法来创建Bean，及元素的factory-method属性来装配工厂创建的Bean。比如Stage是一个没有公开构造方法的类，但是可以通过getInstance获取其实例，那么可以通过下面的配置方式：12&lt;bean id="theStage" class="com.springinaction.springidol.Stage" factory-method="getInstance" /&gt; Bean的作用域 作用域 定义 singleton（默认） 在每一个Spring容器中，一个Bean定义只有一个对象实例 prototype 允许Bean的定义可以被实例化任意次（每次调用都创建一个实例） request 在一次HTTP请求中，每个Bean定义对应一个实例。该作用域仅在基于Web的Spring上下文（例如SpringMVC）中才有效 session 在一个HTTP Sesion中，每个Bean定义对应一个实例。该作用域仅在基于Web的Spring上下文（例如SpringMVC）中才有效 global-session 在一个全局HTTP Sesion中，每个Bean定义对应一个实例。该作用域仅在Portlet上下文中才有效 配置方法，设置标签的scope属性：1&lt;bean id="sonnet29" class="com.springinaction.springidol.Sonnet29" scope="prototype"/&gt; Spring的单例只能保证在每个应用上下文中只有一个Bean的实例，你也可以通过定义多个的方式来实例化同一个Bean。 初始化和销毁Bean可以为Bean定义初始化和销毁操作，只需使用init-method和destroy-method参数来配置标签即可。 比如，舞台（Auditorium）需要在表演开始前开灯（turnOnLights），在结束时关灯（turnOffLights），那么就可以做下面的声明：12&lt;bean id="auditorium" class="com.springinaction.springidol.Auditorium" init-method="turnOnLights" destroy-method="turnOffLights" /&gt; 默认的init-method和destroy-method可以使用的default-init-method和default-destroy-method为上下文中所有的Bean设置共同的初始化和销毁方法。 注入Bean属性Spring可以借助属性的set方法来配置属性的值，以实现setter方式的注入。 下面是一个音乐家（Instrumentalist）类，它演奏时需要歌曲（song）和乐器（instrument）两个属性。 1234567891011121314151617181920212223242526272829303132package com.springinaction.springidol;public class Instrumentalist implements Performer &#123; private String song; private Instrument instrument; public Instrumentalist() &#123; &#125; public void perform() throws PerformanceException &#123; System.out.print("Playing " + song + " : "); instrument.play(); &#125; public void setSong(String song) &#123; // 注入歌曲 this.song = song; &#125; public String getSong() &#123; return song; &#125; public String screamSong() &#123; return song; &#125; public void setInstrument(Instrument instrument) &#123; // 注入乐器 this.instrument = instrument; &#125;&#125; 配置文件中需要为Instrumentalist 注入这两个属性的值。 注入简单值使用&lt;property&gt;标签可以通过调用属性的setter方法为Bean注入属性，而类似的&lt;constructor-arg&gt;是通过构造函数注入的。123&lt;bean id="kenny" class="com.springinaction.springidol.Instrumentalist"&gt; &lt;property name="song" value="Happy" /&gt;&lt;/bean&gt; &lt;property&gt;元素会指示Spring调用setSong()方法将song属性的值设置为”Happy”。 注意value的属性值可以指定数值型（int、float、Double等）以及boolean等，Spring在调用set方法前会自动根据类型进行转换。 引用其他Bean在演奏家kenny中需要一个乐器，那么我们就可以为其引用一个实现了Instrument接口的乐器。 12345&lt;bean id="saxphone" class="com.springinaction.springidol.Saxophone" /&gt;&lt;bean id="kenny" class="com.springinaction.springidol.Instrumentalist"&gt; &lt;property name="song" value="Happy" /&gt; &lt;property name="instrument" ref="saxphone"&gt;&lt;/property&gt;&lt;/bean&gt; 通过Performer接口引用一个参赛者，就可以产生任意类型的参赛者进行表演，面向接口编程和依赖注入实现了松耦合。 注入内部Bean前文中，演奏家使用的instrument是其他Bean都可以进行共用的，若要独用一个类，那么可以声明一个类为内部Bean：123456&lt;bean id="kenny" class="com.springinaction.springidol.Instrumentalist"&gt; &lt;property name="song" value="Happy" /&gt; &lt;property name="instrument"&gt; &lt;bean class="com.springinaction.springidol.Saxophone" /&gt; &lt;/property&gt;&lt;/bean&gt; 如上面的代码，通过直接声明一个元素作为元素的子节点。内部Bean不限于setter注入，也可以通过构造方法注入。 内部Bean没有Id属性，它们不能被复用，内部Bean仅适用于一次注入，而不能被其他Bean引用。 装配集合 集合元素 用途 &lt;list&gt; 装配list类型的数据，允许重复 &lt;set&gt; 装配set类型的数据，不允许重复 &lt;map&gt; 装配map类型的数据，key和value可以是任意类型 &lt;props&gt; 装配properties类型的数据，key和value必须是String类型 下面一个演奏家可以演奏多种乐器：123456789101112131415161718192021package com.springinaction.springidol;import java.util.Collection;public class OneManBand implements Performer &#123; public OneManBand() &#123; &#125; public void perform() throws PerformanceException &#123; // 遍历演奏各个乐器 for (Instrument instrument : instruments) &#123; instrument.play(); &#125; &#125; private Collection&lt;Instrument&gt; instruments; public void setInstruments(Collection&lt;Instrument&gt; instruments) &#123;// 注入instruments集合 this.instruments = instruments; &#125;&#125; 装配List、Set和Array可以使用下面的方式装配List,也可以使用来装配：123456789&lt;bean id="hank" class="com.springinaction.springidol.OneManBand"&gt; &lt;property name="instruments"&gt; &lt;list&gt; &lt;ref bean="guitar"/&gt; &lt;ref bean="cymbal"/&gt; &lt;ref bean="harmonica"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 装配Map当OneManBand表演时，perform()方法可以把乐器（instrument）的音符打印出来，我们还想知道每个音符是由哪个乐器产生的，因此需要做以下改变：12345678910111213141516171819202122package com.springinaction.springidol;import java.util.Map;public class OneManBandMap implements Performer &#123; public OneManBandMap() &#123; &#125; public void perform() throws PerformanceException &#123; for (String key : instruments.keySet()) &#123; System.out.print(key + " : "); Instrument instrument = instruments.get(key); instrument.play(); &#125; &#125; private Map&lt;String, Instrument&gt; instruments; public void setInstruments(Map&lt;String, Instrument&gt; instruments) &#123;// 以map类型注入instruments this.instruments = instruments; &#125;&#125; Spring配置map注入：123456789&lt;bean id="hankk" class="com.springinaction.springidol.OneManBandMap"&gt; &lt;property name="instruments"&gt; &lt;map&gt; &lt;entry key="GUITAR" value-ref="guitar" /&gt; &lt;entry key="CYMBAL" value-ref="cymbal" /&gt; &lt;entry key="HARMONICA" value-ref="harmonica" /&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt; 中的元素由一个键和一个值组成，键和值可以是简单类型，也可以是其他Bean的引用： 属性 用途 key 指定map中entry的键为String key-ref 指定map中entry的键为Spring山下文中其他Bean的引用 value 指定map中entry的值为String value-ref 指定map中entry的值为Spring山下文中其他Bean的引用 装配Properties集合若OneManBandMap中的Instrument属性所配置的Map的每一个entry的键和值都是String类型，可以使用java.util.Properties来代替Map：123456789&lt;bean id="hank" class="com.springinaction.springidol.OneManBand"&gt; &lt;property name="instruments"&gt; &lt;props&gt; &lt;prop key="GUITAR"&gt;Strum Strum Strum&lt;/prop&gt; &lt;prop key="CYMBAL"&gt;Crush Crush Crush&lt;/prop&gt; &lt;prop key="HARMONICA"&gt;Hum Hum Hum&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt; 元素用于把值或者Bean引用注入到Bean的属性中； 用于定义一个java.util.Properties类型的集合值； 用于定义集合的一个成员 装配空值1&lt;property name="someNonNullProperty"&gt;&lt;null/&gt;&lt;/property&gt; 使用表达式装配如果为属性装配的值只有在运行期间才能获取，那该如何实现？Spring表达式语言（ Spring Expression Language , SpEL），可以通过运行期执行的表达式将值装配到Bean的属性或者构造器参数中，其特性有： 使用Bean的id来引用Bean； 调用方法和访问对象的属性； 对值进行算术、关系和逻辑运算； 正则表达式匹配； 集合操作。 SpEL基本用法字面值比如&lt;property name=&quot;count&quot; value=&quot;#{5}&quot;/&gt;，#{ }标记会提示Spring这是个SpEL表达式。 可以与非SpEL表达式混用：&lt;property name=&quot;message&quot; value=&quot;The value is #{5}&quot;/&gt;。 另外，浮点型、科学计数法、布尔型（true和false）也可以直接使用。 字符串使用时，需要用单引号或者双引号括起。 引用Bean、Properties和方法（避免空指针）新声明一个id为carl的模仿者，Kenny唱什么他就唱什么：123&lt;bean id="carl" class="com.springinaction.springidol.Instrumentalist"&gt; &lt;property name="song" value="#&#123;kenny.song&#125;" /&gt;&lt;/bean&gt; 注入到Carl的song属性的表达式是由两部分组成的，第一部分（kenny）指向了kenny的Bean，第二部分（song）指向了kenny Bean的song属性，其实等价于下面的代码：12Instrumentalist carl = new Instrumentalist();carl.setSong(kenny.getSong()); 还可以调用其他Bean的方法：&lt;property name=&quot;song&quot; value=&quot;#{songSelector.selectSong()}&quot;/&gt;&lt;property name=&quot;song&quot; value=&quot;#{songSelector.selectSong().toUpperCase()}&quot;/&gt; 如果selectSong()返回一个null，那么SpEL会抛出空指针异常，可以采用下面的方法避免：&lt;property name=&quot;song&quot; value=&quot;#{songSelector.selectSong()?.toUpperCase()}&quot;/&gt;使用?.来代替.来访问toUpperCase()方法，访问之前会确保左边项不为null，若为null就不会再继续调用。 操作类可以使用T()运算符调用类作用域的方法和常量。比如：&lt;property name=&quot;multiplier&quot; value=&quot;#{T(java.lang.Math).PI}&quot;/&gt;&lt;property name=&quot;randomNumber&quot; value=&quot;#{T(java.lang.Math).random()}&quot;/&gt; 在SpEL值上进行操作 运算符类型 运算符 例子 算术运算 +, -, *, /, %, ^ #{T(java.lang.Math).PI * circle.radius ^ 2} 关系运算 &lt;, &gt;, ==, &lt;=, &gt;=, lt,gt, eq, le, ge #{counter.total == 100} 逻辑运算 and, or, not（或!） #{!product.available} 条件运算 ?: (ternary), ?: (Elvis) #{m&gt;=n?m:n} 正则表达式 matches #{admin.email matches ‘[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.com’}]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring实战》学习笔记-第五章：构建Spring web应用]]></title>
    <url>%2F%E3%80%8ASpring%E5%AE%9E%E6%88%98%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E6%9E%84%E5%BB%BASpring%20web%E5%BA%94%E7%94%A8.html</url>
    <content type="text"><![CDATA[之前一直在看《Spring实战》第三版，看到第五章时发现很多东西已经过时被废弃了，于是现在开始读《Spring实战》第四版了，章节安排与之前不同了，里面应用的应该是最新的技术。 本章中，将会接触到Spring MVC基础，以及如何编写控制器来处理web请求，如何通明地绑定请求参数到业务对象上，同时还可以提供数据校验和错误处理的功能。 Spring MVC初探跟踪Spring MVC请求 在请求离开浏览器时，会带有用户所请求内容的信息，例如请求的URL、用户提交的表单信息。 请求旅程的第一站是Spring的DispatcherServlet。Spring MVC所有的请求都会通过一个前端控制器Servlet。前端控制器是常用的Web应用程序模式，在这里一个单实例的Servlet将请求委托给应用程序的其他组件来执行实际的处理。在Spring MVC中，DispatcherServlet 就是前端控制器。 DispatcherServlet的任务是将请求发送给Spring MVC控制器。控制器是一个用于处理请求的Spring组件。在典型的应用程序中可能会有多个控制器， Dispatcher Servlet需要知道应该将请求发送给哪个控制器。所以DispatcherServlet会查询一个或多个处理器映射来确定请求的下一站在哪里。处理器映射会根据请求所携带的URL信息来进行决策。 一旦选择了合适的控制器，DispatcherServlet会将请求发送给选中的控制器。到达了控制器，请求会卸下其负载（用户提交的信息）并等待控制器处理这些信息（实际上，设计良好的控制器本身只处理很少甚至不处理工作，而是将业务逻辑委托给个或多个服务对象）。 控制器在完成逻辑处理后通常会产生一些信息，这些信息需要返回给用户并在浏览器上显示。这些信息被称为模型（Model）。不过仅仅给用户返回原始的信息是不够的–这些信息需要以用户友好的方式进行格式化，一般是HTML。所以，信息需要发送给—个视图（View），通常会是JSP。 控制器所做的最后一件事是将模型数据打包，并且标示出用于渲染输出的视图名称。它接下来会将请求连同模型和视图名称发送回DispatcherServlet。 这样，控制器就不会与特定的视图相耦合，传递给DispatcherServlet的视图名称并不直接表示某个特定的JSP。它仅仅传递了一个逻辑名，这个名字将会用来查找用来产生结果的真正视图。DispatcherServlet将会使用视图解析器来将逻辑视图名匹配为一个特定的视图实现。 既然DispatcherServlet已经知道由哪个视图渲染结果，那么请求的任务基本上也就完成了。它的最后一站是视图的实现（可能是JSP），在这里它交付模型数据。请求的任务就完成了。视图将使用模型数据渲染输出，并通过这个输出将响应对象传递给客户端。 搭建Spring MVC配置DispatcherServletDispatcherServlet是Spring MVC的核心，它负责将请求分发到其他各个组件。 在旧版本中，DispatcherServlet之类的servlet一般在web.xml文件中配置，该文件一般会打包进最后的war包种；但是Spring3引入了注解，我们在这一章将展示如何基于注解配置Spring MVC。 注意：在使用maven构建web工程时，由于缺少web.xml文件，可能会出现web.xml is missing and &lt;failOnMissingWebXml&gt; is set to true这样的错误，那么可以通过在pom.xml文件中添加如下配置来避免这种错误：123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 既然不适用web.xml文件，你需要在servlet容器中使用Java配置DispatcherServlet，具体的代码列举如下：12345678910111213141516171819202122package spittr.config;import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;public class SpittrWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected String[] getServletMappings() &#123; return new String[] &#123; "/" &#125;; &#125; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class&lt;?&gt;[] &#123; RootConfig.class &#125;; &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class&lt;?&gt;[] &#123; WebConfig.class &#125;; &#125;&#125; 任意继承自AbstractAnnotationConfigDispatcherServletInitializer的类都会被自动用来配置DispatcherServlet，这个类负责配置DispatcherServlet、初始化Spring MVC容器和Spring容器。 SpittrWebAppInitializer重写了三个方法，getRootConfigClasses()方法用于获取Spring应用容器的配置文件，这里我们给定预先定义的RootConfig.class；getServletConfigClasses()负责获取SpringMVC应用容器，这里传入预先定义好的WebConfig.class；getServletMappings()方法负责指定需要由DispatcherServlet映射的路径，这里给定的是”/“，意思是由DispatcherServlet处理所有向该应用发起的请求。 两种应用上下文当DispatcherServlet启动时，会创建一个Spring应用上下文并且会加载配置文件中声明的bean，通过getServletConfigClasses()方法，DispatcherServlet会加载WebConfig配置类中所配置的bean。 在Spring web应用中，通常还有另外一种应用上下文：ContextLoaderListener。 DispatcherServlet用来加载web组件bean，如控制器（controllers）、视图解析器（view resolvers）以及处理器映射（handler mappings）等。而ContextLoaderListener则用来加载应用中的其他bean，如运行在应用后台的中间层和数据层组件。 AbstractAnnotationConfigDispatcherServletInitializer会同时创建DispatcherServlet和ContextLoaderListener。getServletConfigClasses()方法返回的@Configuration类会定义DispatcherServlet应用上下文的bean。同时，getRootConfigClasses()返回的@Configuration类用来配置ContextLoaderListener上下文创建的bean。 相对于传统的web.xml文件配置的方式，通过AbstractAnnotationConfigDispatcherServletInitializer来配置DispatcherServlet是一种替代方案。需要注意的是，这种配置只适用于Servlet 3.0，例如Apache Tomcat 7或者更高。 激活Spring MVC正如有多种方式可以配置DispatcherServlet，激活Spring MVC组件也有不止一种方法。一般的，都会通过XML配置文件的方式来配置Spring，例如可以通过&lt;mvc:annotation-driven&gt;来激活基于注解的Spring MVC。 最简单的配置Spring MVC的一种方式是通过@EnableWebMvc注解：12345678910package spittr.config;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.EnableWebMvc;@Configuration@EnableWebMvcpublic class WebConfig &#123;&#125; @Configuration表示这是Java配置类；@EnableWebMvc注解用于启动Spring MVC特性。 这样就可以激活Spring MVC了，但是还有其他一些问题： 没有配置视图解析器（view resolvers），这种情况下，Spring会默认使用BeanNameViewResolver，它会通过寻找那些与视图id匹配的bean以及实现了View接口的类进行视图解析； 没有激活组件扫描：这样Spring会寻找配置中明确声明的任意控制器； DispatcherServlet会处理所有的请求，包括静态资源请求，如图片和样式（这些往往不是我们想要的）。 因此，需要为WebConfig增加一些配置：12345678910111213141516171819202122232425262728293031package spittr.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.ViewResolver;import org.springframework.web.servlet.config.annotation.DefaultServletHandlerConfigurer;import org.springframework.web.servlet.config.annotation.EnableWebMvc;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import org.springframework.web.servlet.view.InternalResourceViewResolver;@Configuration@EnableWebMvc@ComponentScan("spitter.web") // 激活Spring MVCpublic class WebConfig extends WebMvcConfigurerAdapter &#123; // 配置一个JSP视图解析器 @Bean public ViewResolver viewResolver() &#123; InternalResourceViewResolver resolver = new InternalResourceViewResolver(); resolver.setPrefix("/WEB_INF/views/"); resolver.setSuffix(".jsp"); resolver.setExposeContextBeansAsAttributes(true); return resolver; &#125; @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) &#123; configurer.enable(); &#125;&#125; 首先需要注意的是，WebConfig使用了@ComponentScan注解，因此会在spitter.web包下扫描寻找组件，这些组件包括使用@Controller进行注解的控制器。这样就不再需要在配置类中显式地声明其他控制器。 接下来，添加了一个ViewResolverbean，即InternalResourceViewResolver。它通过匹配符合设置的前缀和后缀的视图来用来寻找对应的JSP文件，比如视图home会被解析为/WEB-INF/views/home.jsp。这里的三个函数的含义依次是：setPrefix()方法用于设置视图路径的前缀；setSuffix()用于设置视图路径的后缀，即如果给定一个逻辑视图名称——“home”，则会被解析成”/WEB-INF/views/home.jsp”； setExposeContextBeansAsAttributes(true)使得可以在JSP页面中通过${}访问容器中的bean。 然后，WebConfig继承自WebMvcConfigurerAdapter，并且重写了configureDefaultServletHandling()方法，通过调用enable()方法从而可以让DispatcherServlet将静态资源的请求转发给默认的servlet。 1234567891011121314package spittr.config;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.ComponentScan.Filter;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.FilterType;import org.springframework.web.servlet.config.annotation.EnableWebMvc;@Configuration@ComponentScan(basePackages = &#123; "spitter" &#125;, excludeFilters = &#123; @Filter(type = FilterType.ANNOTATION, value = EnableWebMvc.class) &#125;)public class RootConfig &#123;&#125; 需要注意的一点是，RootConfig 使用了@ComponentScan注解。 Spittr应用介绍这一章要用的例子应用，从Twitter获取了一些灵感，因此最开始叫Spitter；然后又借鉴了最近比较流行的网站Flickr，因此我们也把e去掉，最终形成Spittr这个名字。这也有利于区分领域名称（类似于twitter，这里用spring实现，因此叫spitter）和应用名称。 Spittr类似于Twitter，用户可以通过它添加一些推文。Spittr有两个重要的概念：spitter（应用的用户）和spittle（用户发布简单状态）。本章将会构建该应用的web层、创建用于展示spittle的控制器以及用户注册流程。 编写简单的控制器Spring MVC中，控制器仅仅是拥有@RequestMapping注解方法的类，从而可以声明它们可以处理何种请求。 在开始之前，我们先假设一个控制器，它可以处理匹配/的请求并会跳转到主页面。123456789101112131415package spittr.web;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;@Controller // 声明一个控制器public class HomeController &#123; @RequestMapping(value = "/", method = RequestMethod.GET) // 处理GET请求 public String home() &#123; return "home"; &#125;&#125; @Controller是一个构造型注解，它基于@Component，组件扫描器会自动地将HomeController声明为Spring上下文的一个bean。 home()方法采用了@RequestMapping注解，属性value指定了该方法处理的请求路径，method方法指定了可以处理的HTTP方法。这种情况下，当一个来自/的GET方法请求时，就会调用home()方法。 home()方法仅仅返回了一个”home”的String值，Spring MVC会对这个String值进行解析并跳转到指定的视图上。DispatcherServlet则会请求视图解析器将这个逻辑视图解析到真实视图上。 我们已经配置了InternalResourceViewResolver，“home”视图会被解析到/WEB-INF/views/home.jsp。 12345678910111213141516171819&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core"%&gt;&lt;%@ taglib prefix="spring" uri="http://www.springframework.org/tags"%&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;Spittr&lt;/title&gt;&lt;link rel="stylesheet" type="text/css" href="&lt;c:url value="/resources/style.css" /&gt;"&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Welcome to Spittr&lt;/h1&gt; &lt;a href="&lt;c:url value="/spittles" /&gt;"&gt;Spittles&lt;/a&gt; | &lt;a href="&lt;c:url value="/spitter/register" /&gt;"&gt;Register&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 下面对HomeController进行测试。 测试控制器一般的web测试需要将工程发布到一个web容器中，启动后才能观察运行结果。如： 从另外的角度来看，HomeController其实是一个简单的POJO对象，那么可以使用下面的方法对其进行测试：12345678910111213141516171819package spittr.web;import org.junit.Test;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.request.MockMvcRequestBuilders;import org.springframework.test.web.servlet.result.MockMvcResultMatchers;import org.springframework.test.web.servlet.setup.MockMvcBuilders;public class HomeControllerTest &#123; @Test public void testHomePage() throws Exception &#123; HomeController controller = new HomeController(); // 设置MockMvc MockMvc mockMvc = MockMvcBuilders.standaloneSetup(controller).build(); mockMvc.perform(MockMvcRequestBuilders.get("/")).andExpect(MockMvcResultMatchers.view().name("home")); &#125;&#125; 相对于直接调用home()方法测试它的返回值，上面的测试中发起了一个来自/的 GET 请求，并且对其结果视图进行断言。将HomeController的实例传送给MockMvcBuilders.standaloneSetup，并且调用build()方法来创建一个MockMvc实例。然后，使用MockMvc实例产生了一个GET请求，并且设置了视图的期望。 定义类层级的请求处理12345678910111213141516package spittr.web;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;@Controller // 声明一个控制器@RequestMapping("/") // 控制器匹配路径public class HomeController &#123; @RequestMapping(method = RequestMethod.GET) // 处理GET请求 public String home() &#123; return "home";// 视图名称 &#125;&#125; 在这个新版的HomeController中，将请求匹配路径移到了类层级，HTTP方法的匹配仍处在方法层级。当有控制类中有一个类层级的@RequestMapping，该类中所有的用@RequestMapping注解的处理方法共同组成了类层级的@RequestMapping。 @RequestMapping的value属性接受String数组，那么就可以使用如下配置：12345@Controller // 声明一个控制器@RequestMapping("/", "/homepage") // 控制器匹配路径public class HomeController &#123;...&#125; 这种情况下，home()方法就可以处理来自/和/homepage的GET请求。 将model数据传送给视图在Spittr应用中，需要一个页面，用来显示最近提交的spittle清单。首先需要定义一个数据访问的仓库，用来抓取spittle：123456789101112131415package spittr.data;import java.util.List;import spittr.Spittle;public interface SpittleRepository &#123; /** * @param max * 待返回的最大的Spittle ID * @param count * 返回Spittle对象的个数 * @return */ List&lt;Spittle&gt; findSpittles(long max, int count);&#125; 如果要获取最近的20个Spittle对象，那么只需调用这样调用：List&lt;Spittle&gt; recent = spittleRepository.findSpittles(Long.MAX_VALUE, 20); 下面对Spittle进行定义：123456789101112131415161718192021222324252627282930313233343536373839package spittr;import java.util.Date;import org.apache.commons.lang3.builder.EqualsBuilder;import org.apache.commons.lang3.builder.HashCodeBuilder;public class Spittle &#123; private final Long id; private final String message;// 消息 private final Date time;// 时间戳 private Double latitude; private Double longitude; public Spittle(String message, Date time) &#123; this(message, time, null, null); &#125; public Spittle(String message, Date time, Double latitude, Double longitude) &#123; this.id = null; this.message = message; this.time = time; this.latitude = latitude; this.longitude = longitude; &#125; @Override public boolean equals(Object that) &#123; return EqualsBuilder.reflectionEquals(this, that, "id", "time"); &#125; @Override public int hashCode() &#123; return HashCodeBuilder.reflectionHashCode(this, "id", "time"); &#125; //getters and setters &#125; Spittle对象中现在包含信息、时间戳、位置这几个属性。 下面利用Spring的MockMvc来断言新的控制器的行为是否正确：12 上面的测试通过创建一个SpittleRepository接口的mock实现，该实现会通过findSpittles()方法返回一个包含20个Spittle对象的集合。然后将这个bean注入到SpittleController实例中，并设置MockMvc使用该实例。 不同于HomeControllerTest，该测试使用了setSingleView()，发起一个/spittles的GET请求，并断言视图是否为spittles以及model是否含有一个spittleList的属性值。 当然，现在运行这个测试代码肯定是会出错的，因为还没有SpittleController。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package spittr.web;import java.util.ArrayList;import java.util.Date;import java.util.List;import org.hamcrest.core.IsCollectionContaining;import org.junit.Test;import org.mockito.Mockito;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.request.MockMvcRequestBuilders;import org.springframework.test.web.servlet.result.MockMvcResultMatchers;import org.springframework.test.web.servlet.setup.MockMvcBuilders;import org.springframework.web.servlet.view.InternalResourceView;import spittr.Spittle;import spittr.data.SpittleRepository;public class SpittleControllerTest &#123; @Test public void shouldShowRecentSpittles() throws Exception &#123; List&lt;Spittle&gt; expectedSpittles = createSpittleList(20); SpittleRepository mockRepository = Mockito.mock(SpittleRepository.class); Mockito.when(mockRepository.findSpittles(Long.MAX_VALUE, 20)).thenReturn(expectedSpittles); SpittleController controller = new SpittleController(mockRepository); MockMvc mockMvc = MockMvcBuilders.standaloneSetup(controller) .setSingleView(new InternalResourceView("/WEB_INF/views/spittles.jsp")).build(); // 调用MockMvc.perform(RequestBuilder requestBuilder)发起一个http请求，然后将得到ResultActions mockMvc.perform(MockMvcRequestBuilders.get("/spittles"))// 添加验证断言来判断执行请求后的结果是否是预期的； .andExpect(MockMvcResultMatchers.view().name("spittles"))// view()：得到视图验证器； // 得到相应的***ResultMatchers后，接着再调用其相应的API得到ResultMatcher， // 如ModelResultMatchers.attributeExists(final String... names)判断Model属性是否存在。 .andExpect(MockMvcResultMatchers.model().attributeExists("spittleList"))// model()：得到模型验证器； .andExpect(MockMvcResultMatchers.model().attribute("spittleList", IsCollectionContaining.hasItems(expectedSpittles.toArray()))); &#125; private List&lt;Spittle&gt; createSpittleList(int count) &#123; List&lt;Spittle&gt; spittles = new ArrayList&lt;Spittle&gt;(); for (int i = 0; i &lt; count; i++) &#123; spittles.add(new Spittle("Spittle ", new Date())); &#125; return spittles; &#125;&#125; SpittleController中，使用@Autowired注解注入了spittleRepository属性。 需要注意的是spittles()方法使用了Model（控制器和视图之间传递的数据）作为入参，Model本质上是一个map，它会被传送至view，因此数据可以提供给客户端。如果在调用addAttribute()方法时没有指定key，那么就会从传入的对象中获取，比如代码中传入的参数属性是List，那么key就是spittleList。最后，该方法返回spittles作为传动给model的视图名称。 也可以显示的指定key：1model.addAttribute(spittleRepository.findSpittles(Long.MAX_VALUE, 20)); 也可以直接采用map的方式：12345678@RequestMapping(method = RequestMethod.GET)public String spittles(Map model) &#123; // 将spittles添加到model中 model.put("spittles", spittleRepository.findSpittles(Long.MAX_VALUE, 20)); // 返回视图名称 return "spittles";&#125; 不管采用何种方式实现spittles()方法，结果都是一样的。一个Spittle对象集合会存储在model中，并分配到名为spittles的view中，根据测试方法中的配置，该视图就是/WEB-INF/views/spittles.jsp。 现在model已经有数据了，那么JSP页面中如何获取数据呢？当视图是一个JSP页面时，model数据会作为请求属性被拷贝到请求中，因此可以通过JSTL（JavaServer Pages Standard Tag Library）&lt;c:forEach&gt;来获取：1234567891011121314&lt;c:forEach items="$&#123;spittleList&#125;" var="spittle"&gt; &lt;li id="spittle_&lt;c:out value="spittle.id"/&gt;"&gt; &lt;div class="spittleMessage"&gt; &lt;c:out value="$&#123;spittle.message&#125;" /&gt; &lt;/div&gt; &lt;div&gt; &lt;span class="spittleTime"&gt;&lt;c:out value="$&#123;spittle.time&#125;" /&gt;&lt;/span&gt; &lt;span class="spittleLocation"&gt; (&lt;c:out value="$&#123;spittle.latitude&#125;" /&gt;, &lt;c:out value="$&#123;spittle.longitude&#125;" /&gt;) &lt;/span&gt; &lt;/div&gt; &lt;/li&gt;&lt;/c:forEach&gt; 下面对SpittleController进行扩展，让它可以处理一些输入。 接受输入请求Spring MVC提供了如下方式供客户端传递数据到控制器处理方法： Query parameters Form parameters Path variables 处理查询参数：@RequestParamSpittr应用的一个需求就是要对spittle列表分页展示，但是SpittleController仅仅展示最近的spittle。如果要让用户可以每次得到一页的spittle记录，那么就需要让用户可以通过某种方式将他们想看的spittle记录的参数传递到后台。 在浏览spittle时，如果想要查看下一页的spittle，那么就需要传递比当前页的最后一个spittle的id小一位的id，也可以传递想要展示的spittle的数量。 为了实现分页，需要编写一个控制器满足： before参数，结果中的spittle的id都要在这个参数之前； count参数，结果中要包含的spittle的个数 下面我们对上面的spittles()方法进行小小的改动，让它可以使用before和count参数。首先对测试方法进行改动：123456789101112131415161718@Testpublic void shouldShowRecentSpittles() throws Exception &#123; List&lt;Spittle&gt; expectedSpittles = createSpittleList(20); SpittleRepository mockRepository = Mockito.mock(SpittleRepository.class); Mockito.when(mockRepository.findSpittles(238900, 50)).thenReturn(expectedSpittles); SpittleController controller = new SpittleController(mockRepository); MockMvc mockMvc = MockMvcBuilders.standaloneSetup(controller) .setSingleView(new InternalResourceView("/WEB_INF/views/spittles.jsp")).build(); // 调用MockMvc.perform(RequestBuilder requestBuilder)发起一个http请求，然后将得到ResultActions mockMvc.perform(MockMvcRequestBuilders.get("/spittles?max=238900&amp;count=50"))// 添加验证断言来判断执行请求后的结果是否是预期的； .andExpect(MockMvcResultMatchers.view().name("spittles"))// view()：得到视图验证器； // 得到相应的***ResultMatchers后，接着再调用其相应的API得到ResultMatcher， // 如ModelResultMatchers.attributeExists(final String... names)判断Model属性是否存在。 .andExpect(MockMvcResultMatchers.model().attributeExists("spittleList"))// model()：得到模型验证器； .andExpect(MockMvcResultMatchers.model().attribute("spittleList", IsCollectionContaining.hasItems(expectedSpittles.toArray())));&#125; 这个测试方法的主要改动就是它发起的GET请求传递了两个参数：max和count。对spittles()进行修改：123456@RequestMapping(method=RequestMethod.GET)public List&lt;Spittle&gt; spittles( @RequestParam(value="max", defaultValue=MAX_LONG_AS_STRING) long max, @RequestParam(value="count", defaultValue="20") int count) &#123; return spittleRepository.findSpittles(max, count);&#125; 这种情况下，如果没有max参数没有指定，那么就会使用默认的设置。由于查询参数是String类型的，因此defaultValue属性值也需要设置为String类型，需要对Long.MAX_VALUE进行设置：private static final String MAX_LONG_AS_STRING = &quot;9223372036854775807&quot;; 虽然，这里defaultValue的属性为String类型，当运行到函数时，将会根据函数的参数类型进行转换。 查询参数是请求中传送信息给控制器的最常用方式，另外一种流行的方式就是将参数作为请求路径的一部分。 通过路径参数传递数据：@PathVariable假设现在应用需要展示单独的一篇Spittle，那么就需要一个id作为查询参数，对应的处理方法可以是：12345678@RequestMapping(value="show", method=RequestMethod.GET)public String showSpittle( @RequestParam("spittle_id") long spittleId, Model model ) &#123; model.addAttribute(spittleRepository.findOne(spittleId)); return "spittle";&#125; 这个handler方法将会处理形如/spittles/show?spittle_id=12345的请求，但是这并不符合资源导向的观点。理想情况下，应该使用URL路径对资源进行区分，而不是查询参数，即应该使用/spittles/12345这种形式。 为了实现资源导向的控制器，我们先在测试中获得这个需求（使用了静态引入）：1234567891011121314@Testpublic void testSpittle() throws Exception &#123; Spittle expectedSpittle = new Spittle("Hello", new Date()); SpittleRepository mockRepository = Mockito.mock(SpittleRepository.class); when(mockRepository.findOne(12345)).thenReturn(expectedSpittle); SpittleController controller = new SpittleController(mockRepository); MockMvc mockMvc = standaloneSetup(controller).build(); mockMvc.perform(get("/spittles/12345")) .andExpect(view().name("spittle")) .andExpect(model().attributeExists("spittle")) .andExpect(model().attribute("spittle", expectedSpittle));&#125; 该测试中发起了一个/spittles/12345的GET请求，并且对其返回结果视图进行断言。 为了满足路径参数，Spring MVC允许在@RequestMapping路径中使用占位符（需要用大括号包围），下面是使用占位符来接受一个id作为路径的一部分：12345678@RequestMapping(value="/&#123;spittleId&#125;", method=RequestMethod.GET)public String spittle( @PathVariable("spittleId") long spittleId, Model model ) &#123; model.addAttribute(spittleRepository.findOne(spittleId)); return "spittle";&#125; spittle()方法的spittleId入参使用了@PathVariable(&quot;spittleId&quot;)注解，表明请求中占位符位置的值都会被传送到handler的spittleId参数。@RequestMapping中value属性的占位符必须和@PathVariable包裹的参数一致。如果@PathVariable中没有给定参数，那么将默认使用入参的册数参数名。即可以使用下面的方法：12345678@RequestMapping(value="/&#123;spittleId&#125;", method=RequestMethod.GET)public String spittle( @PathVariable long spittleId, Model model ) &#123; model.addAttribute(spittleRepository.findOne(spittleId)); return "spittle";&#125; spittle()方法会将接收的参数值传递给spittleRepository的findOne()方法并查找到一个Spittle，并将其放置到model中，model的key值会是spittle，接下来就可以在视图中引用这个Spittle：12345678&lt;div class="spittleView"&gt; &lt;div class="spittleMessage"&gt; &lt;c:out value="$&#123;spittle.message&#125;" /&gt; &lt;/div&gt; &lt;div&gt; &lt;span class="spittleTime"&gt;&lt;c:out value="$&#123;spittle.time&#125;" /&gt;&lt;/span&gt; &lt;/div&gt;&lt;/div&gt; 查询参数和路径参数可以处理一些少量的请求数据，但是当请求数据过大时，它们就不再适用，下面就来讲解一下如何处理表单数据。 处理表单Web应用不仅仅是将内容推送给用户，它同时也会让用户填写表单并将数据提交给应用。 对于表单有两种处理方式：展示表单以及处理用户提交的表单数据。在Spittr中，需要提供一个供新用户进行注册的表单。 SpitterController：展示用户注册表单1234567891011121314151617package spittr.web;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;@Controller@RequestMapping("/spitter")public class SpitterController &#123; // 处理来自/spitter/register的get请求 @RequestMapping(value = "/register", method = RequestMethod.GET) public String showRegistrationForm() &#123; return "registerForm"; &#125;&#125; showRegistrationForm方法的@RequestMapping注解，以及类级别的注解@RequestMapping，表明了这个方法会处理来自/spitter/register的get请求，该方法仅仅返回了一个名为registerForm的逻辑视图。根据之前在InternalResourceViewResolver中的配置，这个逻辑视图会导向到/WEB-INF/views/registerForm.jsp该界面。 对应的测试方法： 123456789101112131415161718package spittr.web;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.*;import static org.springframework.test.web.servlet.setup.MockMvcBuilders.*;import org.junit.Test;import org.springframework.test.web.servlet.MockMvc;public class SpitterControllerTest &#123; @Test public void shouldShowRegistration() throws Exception &#123; SpitterController controller = new SpitterController(); MockMvc mockMvc = standaloneSetup(controller).build(); mockMvc.perform(get("/spitter/register")).andExpect(view().name("registerForm")); &#125;&#125; 也可以通过启动项目访问界面的方式验证：12345678910111213141516171819&lt;%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c" %&gt;&lt;%@ page session="false" %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Spitter&lt;/title&gt; &lt;link rel="stylesheet" type="text/css" href="&lt;c:url value="/resources/style.css" /&gt;" &gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Register&lt;/h1&gt; &lt;form method="POST"&gt; First Name: &lt;input type="text" name="firstName" /&gt;&lt;br/&gt; Last Name: &lt;input type="text" name="lastName" /&gt;&lt;br/&gt; Username: &lt;input type="text" name="username" /&gt;&lt;br/&gt; Password: &lt;input type="password" name="password" /&gt;&lt;br/&gt; &lt;input type="submit" value="Register" /&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 接下来需要对提交的表单进行处理。 编写表单处理控制器在处理POST请求时，控制器需要接受表单数据并且将这些数据存储为一个Spitter对象。为了避免重复提交，应该重定向到一个新的界面：用户信息页。在处理post请求时，一个聪明的做法就是在处理完成后发送一个重定向的请求，从而可以避免重复提交。 下面来实现控制器方法，从而可以处理注册请求。123456789101112131415161718 private SpitterRepository spitterRepository; public SpitterController() &#123; &#125; // 注入SpitterRepository @Autowired public SpitterController(SpitterRepository spitterRepository) &#123; this.spitterRepository = spitterRepository; &#125; public String processRegistration(Spitter spitter) &#123; // 保存Spitter spitterRepository.save(spitter); // 重定向到新的页面 return "redirect:/spitter/" + spitter.getUsername(); &#125;` processRegistration方法使用Spitter对象作为入参，该对象的属性会从请求中填充。该方法中调用了spitterRepository的save方法对Spitter对象进行存储。最后返回了一个带有redirect:的字符串。 当InternalResourceViewResolver遇到redirect:时，它会自动地将其当做一个重定向请求，从而可以重定向到用户详情页面，如/spitter/xiaoming。 同时，InternalResourceViewResolver也可以识别前缀forward:，这种情况下，请求会被转向到给定的URL地址。 下面需要编写处理处理用户详情页面的方法：123456@RequestMapping(value = "/&#123;username&#125;", method = RequestMethod.GET)public String showSpitterProfile(@PathVariable("username") String username, Model model) &#123; Spitter spitter = spitterRepository.findByUsername(username); model.addAttribute(spitter); return "profile";&#125; 参数校验从Spring3.0开始，Spring支持Java校验api，从而可以从而可以不需要添加其他配置，仅仅需要有一个Java API 的实现，如Hibernate Validator。 Java Validation API定义了许多注解，可以使用这些注解来约束参数的值，所有的注解都在包javax.validation.constraints中。 注解 描述 @AssertFalse（@AssertTrue） 对象必须是布尔类型，并且必须为false（true） @DecimalMax(value)、@DecimalMin(value) 限制对象必须是一个数字，其值不大于（不小于）指定的BigDecimalString值 @Digits(integer,fraction) 对象必须为一个小数，且整数部分的位数不能超过integer，小数部分的位数不能超过fraction @Future 必须是一个将来的日期 @Max(value)、@Min(value) 必须为一个不大于（不小于）指定值的数字 @NotNull 限制对象不能为空 @Null 限制对象必须为空 @Past 必须是一个过去的日期 @Pattern(value) 必须符合指定的正则表达式 @Size(min,max) 限制字符长度必须在min到max之间 使用示例：1234567891011121314151617public class Spitter &#123; private Long id; @NotNull @Size(min = 5, max = 16) private String username; @NotNull @Size(min = 5, max = 25) private String password; @NotNull @Size(min = 2, max = 30) private String firstName; ... 既然已经对Spitter的参数添加了约束，那么就需要改动processRegistration方法来应用校验：1234567891011@RequestMapping(value = "/register", method = RequestMethod.POST)public String processRegistration(@Valid Spitter spitter, Errors errors) &#123; // 若校验中出现错误，那么就返回到注册界面 if (errors.hasErrors()) &#123; return "registerForm"; &#125; // 保存Spitter spitterRepository.save(spitter); // 重定向到新的页面 return "redirect:/spitter/" + spitter.getUsername();&#125; 总结这一章比较适合Spring MVC的入门学习资料。主要涵盖了Spring MVC处理web请求的处理过程、如何写简单的控制器和控制器方法来处理Http请求、如何使用mockito框架测试控制器方法。 基于Spring MVC的应用有三种方式读取数据：查询参数、路径参数和表单输入。本章用两节介绍了这些内容，并给出了类似错误处理和参数验证等关键知识点。 由于缺少真正的入库操作，因此本章节的一些方法不能真正的运作。 在接下来的章节中，我们会对Spring视图进行深入了解，对如何在JSP页面中使用Spring标签库进行展开。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring实战》学习笔记-第三章：最小化SpringXML配置]]></title>
    <url>%2F%E3%80%8ASpring%E5%AE%9E%E6%88%98%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E6%9C%80%E5%B0%8F%E5%8C%96SpringXML%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[Spring提供了几种技巧，可以减少XML的配置数量： 自动装配（autowiring）：可以减少&lt;property&gt;和&lt;constructor-arg&gt;元素，让Spring自动识别如何装配Bean的依赖关系； 自动检测（autodiscovery）：Spring能够自动识别哪些类需要被装配成Spring Bean，从而减少对&lt;bean&gt;的使用。 自动装配Bean属性4种自动装配 byName：把与Bean属性具有相同名字（或id）的其他Bean自动装配到Bean的对应属性中； byType：把与Bean属性具有相同类型的其他Bean自动装配到Bean的对应属性中； constructor：把与Bean的构造函数的入参具有相同类型的其他Bean自动装配到Bean的构造函数对应的入参中； autodetect：先尝试使用constructor，失败后再使用byType。 byName为属性自动装配id与该属性的名字相同的Bean。使用方法：123&lt;bean id="kenny" class="com.springinaction.springidol.Instrumentalist" autowire="byName"&gt; &lt;property name="song" value="Happy" /&gt;&lt;/bean&gt; 通过配置Bean Kenny的autowire=&quot;byName&quot;属性，Spring就可以利用此信息自动装配Kenny的instrument属性了。 缺点：需要假设Bean的名字（如instrument）与其他Bean的属性的名字一样，若其他多个Bean的属性都是instrument，那么让他们将使用同一个instrument。 byType当Spring根据类型匹配到多个Bean时，会抛出异常，形如： org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name ‘kenny’ defined in class path resource [spring-idol.xml]: Unsatisfied dependency expressed through bean property ‘instrument’: : No qualifying bean of type [com.springinaction.springidol.Instrument] is defined: expected single matching bean but found 2: saxphone,guitar; 为了避免这种异常（expected single matching bean but found 2）的出现，Spring提供了两种方案：可以自动装配标识一个首选Bean，或者可以取消某个Bean的自动装配的候选资格。 标识首选Bean：primary=”true”可以使用primary属性将Bean设置为首选Bean，那么它将会得到优选被选择权：1234567&lt;bean id="saxphone" class="com.springinaction.springidol.Saxophone" /&gt;&lt;bean id="guitar" class="com.springinaction.springidol.Guitar" primary="true"/&gt;&lt;bean id="kenny" class="com.springinaction.springidol.Instrumentalist" autowire="byType"&gt; &lt;property name="song" value="Happy" /&gt;&lt;/bean&gt; 有两个Bean类型满足kenny的instrument属性，但是guitar设置了primary=&quot;true&quot;，因此会注入guitar。 排除其他Bean： autowire-candidate=”false”123456&lt;bean id="saxphone" class="com.springinaction.springidol.Saxophone" autowire-candidate="false"/&gt;&lt;bean id="guitar" class="com.springinaction.springidol.Guitar"/&gt;&lt;bean id="kenny" class="com.springinaction.springidol.Instrumentalist" autowire="byType"&gt; &lt;property name="song" value="Happy" /&gt;&lt;/bean&gt; 通过排除其他Bean的候选资格来达到和上面设置primary同样的效果。 constructor当有多个Bean匹配某个构造函数的入参时，Spring同样会抛出异常。 默认自动装配方式可以在根元素&lt;beans&gt;上添加default-autowire属性来设置该配置文件中的的自动装配方式。 混用自动装配和显示装配显示装配会覆盖掉自动装配：1234567&lt;bean id="saxphone" class="com.springinaction.springidol.Saxophone" autowire-candidate="false"/&gt;&lt;bean id="guitar" class="com.springinaction.springidol.Guitar"/&gt;&lt;bean id="kenny" class="com.springinaction.springidol.Instrumentalist" autowire="byType"&gt; &lt;property name="song" value="Happy" /&gt; &lt;property name="instrument" ref="saxphone"&gt;&lt;/property&gt;&lt;/bean&gt; 虽然取消了saxphone的候选资格，但最终仍是saxphone注入到了kenny的属性中。 注意当使用constructor自动装配时，就不能混合使用constructor自动装配和标签了。 使用注解装配启用注解装配：&lt;context:annotation-config /&gt;。 Spring自带的@Autowired注解 JSR-330的@Inject注解 JSR-250的@Resource注解 @Autowired使用方法：123456789101112131415161718192021// 1、可以标注setter@Autowiredpublic void setInstrument(Instrument instrument) &#123;this.instrument = instrument;&#125;// 2、标注其他方法@Autowiredpublic void heresYourInstrument(Instrument instrument) &#123;this.instrument = instrument;&#125;// 3、标注构造器@Autowiredpublic Instrumentalist(Instrument instrument) &#123;this.instrument = instrument;&#125;// 4、直接标注属性@Autowiredprivate Instrument instrument; 使用@Autowired进行自动装配时，在遇到多个匹配的Bean或者没有匹配的Bean也会出现问题。 可选的自动装配通过设置@Autowired的required属性为false来配置可选。12@Autowired(required=false)private Instrument instrument; 这时，若没有找到匹配到的instrument Bean，应用也不会出现异常，instrument会被设置为null。 注意：当使用构造器装配时，只有一个构造器可以将@Autowired的required属性设置为true，其他使用@Autowired注解的required属性必须设置为false。此外，当使用@Autowired标注多个构造器时，Spring会从所有满足装配条件的构造器中选择入参最多的那个。 限制歧义性的依赖当有多个Bean满足装配条件时，可以配合使用@Qualifier注解。123@Autowired@Qualifier("guitar")private Instrument instrument; @Qualifier注解缩小了自动装配候选Bean的范围。 @Inject和@Autowired一样，@Inject可以装配 属性、方法和构造器；但是@Inject没有required属性，因此@Inject注解所依赖的bean是必须存在的，如果不存在就会抛出异常。 使用@Inject注入一个Provider，从而可以实现Bean引用的延迟注入以及注入多个Bean实例的功能。 123456789private Set&lt;Knife&gt; knives;@Injectpublic KnifeJuggler(Provider&lt;Knife&gt; knifeProvider) &#123; knives = new HashSet&lt;Knife&gt;(); for (int i = 0; i &lt; 5; i++) &#123; knives.add(knifeProvider.get()); &#125;&#125; KnifeJuggler类需要注入多个Knife实例，假设Knife Bean的作用域是prototype的，那么KnifeJuggler将获得一个Provider，这时只有provider被注入；在调用provider的get()方法之前，实际的Knife对象没有被注入。 限定@Inject所注入的属性：@Named123@Inject@Named("guitar")private Instrument instrument; 在注解中使用表达式：@Value可以使用@Value装配简单值：String类型和基本类型，如：12@Value("Happy")private String song; @Value可以配合SpEL使用：12@Value("#&#123;systemProperties.myFavoriteSong&#125;")private String song; #自动检测Bean： 可以减少和 的使用，但仍需配置。使用 除了可以完成上述工作，还可以自动检测Bean和定义Bean，它会扫描指定的包及其所有子包，并查找出能够自动注册为Spring Bean的类，base-package标识了所要扫描的包：&lt;context:component-scan base-package=&quot;com.springinaction.springidol&quot;/&gt; 标注Bean @Component：通用的构造型注解，标识该类为Spring组件； @Controller：标识该类为Spring MVC controller； @Repository：标识为数据仓库； @Service：标识为服务； @Component：标注为自定义注解。 12345678910package com.springinaction.springidol;import org.springframework.stereotype.Component;@Componentpublic class Guitar implements Instrument &#123; public void play() &#123; System.out.println("Strum strum strum"); &#125;&#125; Spring扫描com.springinaction.springidol包时，会发现使用@Component注解所标注的Guitar，会自动将它注册为Spring Bean，其id会是guitar。 定义组件扫描策略 过滤器类型 描述 annotation 扫描使用指定注解所标注的类，通过expression属性指定要扫描的注解 assignable 扫描派生于expression属性所指定类型的那些类 aspectj 扫描与expression属性所指定的AspectJ表达式多匹配的那些类 custom 使用自定义的org.springframework.core.type.TypeFilter实现类，该类由expression属性指定 regex 扫描类名称与expression属性所指定的正则表达式所匹配的类 以下配置实现了：自动注册所有实现了Instrument接口的类，并且排除使用自定义@SkipIt注解的类。 123456&lt;context:component-scan base-package="com.springinaction.springidol"&gt; &lt;context:include-filter type="assignable" expression="com.springinaction.springidol.Instrument" /&gt; &lt;context:exclude-filter type="annotation" expression="com.springinaction.springidol.SkipIt" /&gt;&lt;/context:component-scan&gt;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring实战》学习笔记-第七章：Spring MVC进阶]]></title>
    <url>%2F%E3%80%8ASpring%E5%AE%9E%E6%88%98%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9ASpring%20MVC%E8%BF%9B%E9%98%B6.html</url>
    <content type="text"><![CDATA[本章主要内容： 备用的Spring MVC配置项 处理文件上传 控制器中的异常处理 使用flash属性 “等等，客官！不止这些” 也许大家在看电视广告时对上面这句话比较熟悉，广告里通常在已经对商品做了完整的介绍，这时，电视里就会冒出这句：等等，客官，还不止这些。。。接着，就会继续吹嘘他们的商品还有更多让你意想不到的功能。 其实，Spring MVC（或者说Spring的每一个模块）就给人一种“不止这些”的感觉，就在你以为已经对Spring MVC的功能有了完备的了解时，又会发现可以利用它做的更多。 在第五章中，我们使用Spring MVC的基本功能以及如何编写控制器来处理各种各样的请求。接着在第六章中创建了JSP和Thymeleaf视图来将model数据对用户进行了展示。也许你会觉得Spring MVC不过如此。但是等等，还不止这些！ 本章中会继续讨论Spring MVC，比如编写控制器来处理文件上传，如何处理控制器中的异常，以及如何在model上传递数据从而可以在重定向时使用。 首先，在第五章中使用了AbstractAnnotationConfigDispatcherServletInitializer来设置Spring MVC，并且说了可以使用其他备用设置选择。因此在文件上传和异常处理之前，先来探索一下如何使用其他方式来设置DispatcherServlet和ContextLoaderListener。 Spring MVC备用配置第五章中，通过继承AbstractAnnotationConfigDispatcherServletInitializer来快速地对Spring MVC进行了设置。该类假设你想要一个基础的DispatcherServlet和ContextLoaderListener设置，并且通过Java而不是XML文件来配置Spring。 尽管这样配置对大多数Spring应用都是适用的，但是总有意外，比如你想要除了DispatcherServlet之外的servlet和filter，或者你想对DispatcherServlet做一些进一步的配置，再或者，你想在Servlet3.0之前的版本上部署应用，那么你就要使用传统的web.xml文件对DispatcherServlet进行配置了。 幸运的是，在（garden-variety）普通的AbstractAnnotationConfigDispatcherServletInitializer不适用于你的需求时，还有其他的一些方式供你使用。下面，我们就开始如何定制化的配置DispatcherServlet吧。 DispatcherServlet个性化配置SpittrWebAppInitializer中所包含的三个方法仅仅是必须重写的三个抽象方法，同时还有许多其他方法可以重写从而可以实现更多的配置。 其中一个就是customizeRegistration()，在AbstractAnnotationConfigDispatcherServletInitializer注册了DispatcherServlet之后，就会调用customizeRegistration()方法，并根据servlet的注册返回值传送ServletRegistration.Dynamic，通过对customizeRegistration()的重写，就可以对DispatcherServlet进行额外的配置。 比如，在稍后的章节中（7.2），你会看到Spring MVC如何处理多个请求和文件上传。如果打算使用Servlet3.0来实现多部分配置，那么就需要激活DispatcherServlet配置来实现多路请求。可以使用下面的方式重写customizeRegistration()方法：12345@Overrideprotected void customizeRegistration(Dynamic registration) &#123; registration.setMultipartConfig( new MultipartConfigElement("/tmp/spittr/uploads"));&#125; 其中ServletRegistration.Dynamic作为入参，你可以做很多事情，比如调用setLoadOnStartup()来设置加载时优先级，调用setInitParameter()来设置初始化参数，调用setMultipartConfig()来设置Servlet3.0的多路支持。在上述示例中，设置了多路支持的上传文件临时存储路径为：/tmp/spittr/uploads。 添加额外的servlet和filter根据之前的配置，可以生成DispatcherServlet和ContextLoaderListener，但是你需要注册额外的servlet、filter或者listener时怎么办呢？ 使用基于Java配置的一个好处就是你可以尽量多的定义初始化类。因此，如果需要定义额外的组件，只需新建相应的初始化类即可。最简单的方法就是实现Spring的WebApplicationInitializer接口。 例如，下面的代码展示了如何通过实现WebApplicationInitializer接口的方式来注册一个servlet：1234567891011121314import javax.servlet.ServletContext;import javax.servlet.ServletException;import javax.servlet.ServletRegistration.Dynamic;import org.springframework.web.WebApplicationInitializer;import com.myapp.MyServlet;public class MyServletInitializer implements WebApplicationInitializer &#123; @Override public void onStartup(ServletContext servletContext) throws ServletException &#123; // 定义servlet Dynamic myServlet = servletContext.addServlet("myServlet", MyServlet.class); // 映射servlet myServlet.addMapping("/custom/**"); &#125;&#125; 上述代码仅仅是一个基本的servlet注册初始化类，实现了对servlet的注册并映射到一个路径。你也可以使用这种方式来手动地注册DispatcherServlet（不过这好像没有必要，因为AbstractAnnotationConfigDispatcherServletInitializer在这方面已经做得很不错了）。 同样的，你也可以通过上述方式来注册listener和filter。例如：1234567@Overridepublic void onStartup(ServletContext servletContext) throws ServletException &#123; // 注册一个filter javax.servlet.FilterRegistration.Dynamic filter = servletContext.addFilter("myFilter", MyFilter.class); // 添加映射 filter.addMappingForUrlPatterns(null, false, "/custom/*");&#125; WebApplicationInitializer是一个在注册servlet、filter、listener时比较推荐的方式，当然你是使用基于Java的配置方式并将应用部署在Servlet3.0容器上的。如果你仅仅需要注册一个filter并将其映射到DispatcherServlet，那么使用AbstractAnnotationConfigDispatcherServletInitializer将是一个捷径。 要注册多个filter并将它们映射到DispatcherServlet，你所要做的仅仅是重写getServletFilters()方法。比如： 1234@Overrideprotected Filter[] getServletFilters() &#123; return new Filter[] &#123; new MyFilter() &#125;;&#125; 如你所见，该方法返回了一个javax.servlet.Filter的数组，这里仅仅返回了一个filter，但是它可以返回很多个。同时这里不再需要为这些filter去声明映射，因为通过getServletFilters()返回的filter会自动地映射到DispatcherServlet。 当部署到Servlet3.0的容器时，Spring提供了很多方法来注册servlet、filter和listener，而不再需要web.xml。如果你使用的不是Servlet3.0版本的容器，或者你就喜欢使用基于web.xml的配置方式，那么该如何对Spring MVC进行配置呢？ 使用web.xml声明DispatcherServlet下面是一个典型的web.xml文件，其中对DispatcherServlet和ContextLoaderListener进行了声明：12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app version="2.5" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaeehttp://java.sun.com/xml/ns/javaee/web-app_2_5.xsd"&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/spring/root-context.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;!-- 注册ContextLoaderListener --&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;!-- 注册DispatcherServlet --&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- DispatcherServlet映射 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 正如在第五章中所说的，DispatcherServlet和ContextLoaderListener可以加载Spring应用上下文。contextConfigLocation上下文参数指定了用来定义由ContextLoaderListener加载的根应用上下文的XML文件的位置。DispatcherServlet用来通过文件中定义的bean（名称基于指定的servlet名称：appServlet）来加载应用上下文。因此，DispatcherServlet会从/WEB-INF/appServlet-context.xml文件中加载应用上下文。 如果你想指定DispatcherServlet配置文件的位置，那么可以通过设置contextConfigLocation初始化参数的方式实现。例如，下面的DispatcherServlet配置就会从/WEB-INF/spring/appServlet/servlet-context.xml文件中加载：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;servlet&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;!-- 注册DispatcherServlet --&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; /WEB-INF/spring/appServlet/servlet-context.xml &lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;``` 本书中采用的都是基于Java的配置方式，所以你需要对Spring MVC进行设置从而可以从`@Configuration`注解的类中加载配置。为了使用基于Java的配置，需要通知DispatcherServlet和ContextLoaderListener去使用AnnotationConfigWebApplicationContext，该类是`WebApplicationContext`接口的实现类，它可以对Java配置类进行加载。可以通过设置DispatcherServlet的`contextClass`参数和初始化参数来实现。下面对web.xml进行配置从而可以使用Java配置：```xml&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app version="2.5" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaeehttp://java.sun.com/xml/ns/javaee/web-app_2_5.xsd"&gt; &lt;!-- 使用Java配置 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextClass&lt;/param-name&gt; &lt;param-value&gt; org.springframework.web.context.support.AnnotationConfigWebApplicationContext &lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 指定所使用的Java配置类 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;spittr.config.RootConfig&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt; org.springframework.web.context.ContextLoaderListener &lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 使用Java配置 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextClass&lt;/param-name&gt; &lt;param-value&gt; org.springframework.web.context.support.AnnotationConfigWebApplicationContext &lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 指定DispatcherServlet的配置类 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; spittr.config.WebConfigConfig &lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 以上就是配置Spring MVC的一些方法，下面来看如何使用Spring MVC处理文件上传。 处理multipart表单数据一个web应用通常都会允许用户上传内容，比如像Facebook、Flickr这样的站点，都会允许用户上传小片的。我们的Spittr应用中在两处会用到文件上传：一是新用户注册的时候，这时需要选择一个头像之类的；还有就是当用户新建一个Spittle（推文？）时，也许需要在文中插入一张图片。 来自传统的表单提交的请求结果一般比较简单并且采用多个键值对的方式。例如，当提交一个注册信息的表单时，请求会是这样的：firstName=Charles&amp;lastName=Xavier&amp;email=professorx%40xmen.org&amp;username=professorx&amp;password=letmein01 虽然这种编码方式对于传统的基于文本的提交是最够的，但是它却没有强大到可以携带二进制数据，比如上传一个图像。相反的，Multipart/form-data将表单分割成独立的部分，每个部分都有各自的类型。传统的表单域都有文本数据，但是当要上传一些东西时，该部分可以是二进制的，如下面的multipart请求体：1234567891011121314151617181920------WebKitFormBoundaryqgkaBn8IHJCuNmiWContent-Disposition: form-data; name="firstName"Charles------WebKitFormBoundaryqgkaBn8IHJCuNmiWContent-Disposition: form-data; name="lastName"Xavier------WebKitFormBoundaryqgkaBn8IHJCuNmiWContent-Disposition: form-data; name="email"charles@xmen.com------WebKitFormBoundaryqgkaBn8IHJCuNmiWContent-Disposition: form-data; name="username"professorx------WebKitFormBoundaryqgkaBn8IHJCuNmiWContent-Disposition: form-data; name="password"letmein01------WebKitFormBoundaryqgkaBn8IHJCuNmiWContent-Disposition: form-data; name="profilePicture"; filename="me.jpg"Content-Type: image/jpeg[[ Binary image data goes here ]]------WebKitFormBoundaryqgkaBn8IHJCuNmiW-- 在这个multipart请求中，值得注意的，profilePicture部分是与其他部分不同的，它有一个Content-Type头部用来表示这是一个JPEG图像。虽然不是很明显，profilePicture的内容是一个二进制数据而不是简单文本。 虽然multipart请求看起来比较复杂，但是在Spring MVC中处理起来还是比较简单的。在编写控制器方法来处理文件上传之前，还需要配置一个multipart解析器来告知DispatcherServlet如何读取multipart请求。 配置multipart解析器DispatcherServlet并没有实现任何逻辑用来将数据转换成multipart请求。它使用了Spring的MultipartResolver接口的实现类来解析multipart请求中的内容。从Spring3.1开始，Spring提供了两种MultipartResolver实现类供选择： CommonsMultipartResolver：使用Jakarta Commons FileUpload来解析multipart请求； StandardServletMultipartResolver：依靠Servlet 3.0支持来解析（Spring 3.1及以上）； 一般来讲，StandardServletMultipartResolver应该是第一选择。它使用servlet容器中现有的支持，并且不需要其他附加的项目依赖。但是，如果你将应用部署在Servlet 3.0之前的版本，或者你没有使用Spring3.1及以上版本，那么就要使用CommonsMultipartResolver。 使用Servlet 3.0解析multipart请求StandardServletMultipartResolver没有构造器参数和属性需要设置，这样它的设置就比较简单，就像在Spring配置文件中声明一个bean：1234@Beanpublic MultipartResolver multipartResolver() &#123; return new StandardServletMultipartResolver();&#125; 也许你想这么简单的方法，我该如何加一下限制呢？比如，如何限制一个用户可以上传的文件大小，或者如何设置上传过程中文件的临时存放位置。因为没有构造器和属性可以设置，StandardServletMultipartResolver好像是有限制的。 其实是有办法来设置StandardServletMultipartResolver的，但是它的设置不是在Spring配置中进行的，而是在Servlet配置中。起码要配置一下存放临时文件的位置，进一步来讲，还要将multipart配置为DispatcherServlet的一部分。 如果你是在继承自WebMvcConfigurerAdapter的servlet初始化类中配置的DispatcherServlet，那么就可以在servlet注册时通过调用setMultipartConfig()方法来配置multipart详情。比如：1234DispatcherServlet ds = new DispatcherServlet();Dynamic registration = context.addServlet("appServlet", ds);registration.addMapping("/");registration.setMultipartConfig(new MultipartConfigElement("/tmp/spittr/uploads")); 如果你是在继承自AbstractAnnotationConfigDispatcherServletInitializer或者AbstractDispatcherServletInitializer的servlet初始化类进行的配置，没有创建DispatcherServlet的实例或者使用servlet上下文对其进行注册。因此就没有直接的引用供Dynamicservlet注册来使用。但是你可以重写customizeRegistration()方法来进行配置：1234@Overrideprotected void customizeRegistration(Dynamic registration) &#123; registration.setMultipartConfig(new MultipartConfigElement("/tmp/spittr/uploads"));&#125; MultipartConfigElement的唯一参数设置了上传文件时临时文件的存放位置。也可以进行其他一些设置： 文件上传的最大值（byte），默认没有限制； 所有multipart请求的文件最大值（byte），不管有多少个请求，默认无限制； 直接上传文件（不需存储到临时目录）的最大值（byte），默认是0，也就是所有的文件都要写入硬盘； 例如，你想设置文件大小不超过2MB，所有请求的总和不超过4MB，并且所有文件都要写入硬盘，那么就可以这样设置：1234@Overrideprotected void customizeRegistration(Dynamic registration) &#123; registration.setMultipartConfig(new MultipartConfigElement("/tmp/spittr/uploads", 2097152, 4194304, 0));&#125; 如果你是使用的传统的web.xml的方式来设置的DispatcherServlet，那么就需要使用多个&lt;multipart-config&gt;元素，其默认值和MultipartConfigElement相同，并且&lt;location&gt;是必填项：12345678910&lt;servlet&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;multipart-config&gt; &lt;location&gt;/tmp/spittr/uploads&lt;/location&gt; &lt;max-file-size&gt;2097152&lt;/max-file-size&gt; &lt;max-request-size&gt;4194304&lt;/max-request-size&gt; &lt;/multipart-config&gt;&lt;/servlet&gt; 配置Jakarta Commons FileUpload解析器最简单的CommonsMultipartResolver声明方式是这样的：1234@Beanpublic MultipartResolver multipartResolver() &#123; return new CommonsMultipartResolver();&#125; 与StandardServletMultipartResolver不同的是，它不需要配置一个临时目录。默认情况下会使用servlet容器的临时目录。但是，你也可以通过uploadTempDir属性进行设置，同时还可以对其他参数进行设置：12345678@Beanpublic MultipartResolver multipartResolver() throws IOException &#123; CommonsMultipartResolver multipartResolver = new CommonsMultipartResolver(); multipartResolver.setUploadTempDir(new FileSystemResource("/tmp/spittr/uploads")); multipartResolver.setMaxUploadSize(2097152); multipartResolver.setMaxInMemorySize(0); return multipartResolver;&#125; 这里设置了文件的最大大小为2MB，最大的内存中大小为0，即每个上传文件都会直接写入磁盘的。但是它是无法设置multipart请求总的文件大小的。 处理multipart请求通过上面的配置，Spring已经支持multipart请求，那么就可以开始编写控制器来处理文件上传了。最普遍的做法就是使用@RequestPart注解一个控制器参数。 假设你想让用户可以在注册时上传图像，那么就需要对注册表单进行更改从而用户可以选择一个图片，同时还需要更改SpitterController中的processRegistration()方法以获取上传的文件。下面的代码是使用Thymeleaf的注册页面：12345678910111213141516 &lt;form method="POST" th:object="$&#123;spitter&#125;" enctype="multipart/form-data"&gt; ... &lt;label&gt;Profile Picture&lt;/label&gt;: &lt;input type="file" name="profilePicture" accept="image/jpeg,image/png,image/gif" /&gt;&lt;br/&gt; &lt;input type="submit" value="Register" /&gt; ... ``` 可以发现`&lt;form&gt;`标签多了`enctype="multipart/form-data"`属性，该属性会告知浏览器要将当前form作为multipart数据处理。除此之外，还添加了一个新的file类型的`&lt;input&gt;`标签，该标签允许用户选择一个图片进行上传。`accept`属性设置了允许选择的图片类型。根据它的`name`属性，图片数据会放在`profilePicture`部分进行发送。现在所需做的就是更新`processRegistration()`方法，来获取上传的图片，其中一种方法就是添加一个用`@RequestPart`注解的byte数组：```java@RequestMapping(value = "/register", method = RequestMethod.POST)public String processRegistration(@RequestPart("profilePicture") byte[] profilePicture, @Valid Spitter spitter, Errors errors) &#123; 当注册表单提交时，请求部分的数据就会赋予到profilePicture属性中，如果用户没有选中一个文件，那么该数组就会是一个空值（不是null）。既然已经获取到上传的文件，下面所需要的就是将文件保存。 接收multipart文件处理上传文件的原始数据比较简单但是是有局限的，因此，Spring提供了MultipartFile，使用它可以获取到富对象从而更好地处理multipart数据，下面就是MultipartFile接口：1234567891011121314package org.springframework.web.multipart;import java.io.File;import java.io.IOException;import java.io.InputStream;public interface MultipartFile &#123; String getName(); String getOriginalFilename(); String getContentType(); boolean isEmpty(); long getSize(); byte[] getBytes() throws IOException; InputStream getInputStream() throws IOException; void transferTo(File dest) throws IOException;&#125; MultipartFile提供获取上传文件的方法，同时提供了很多其他方法，比如原始文件名称、大小和内容类型等。另外还提供了一个InputStream可以将文件数据作为数据流读取。 另外，MultipartFile还提供了一个方便的transferTo()方法帮助你将上传文件写入到文件系统。例如，你可以将如下代码加入到processRegistration()中：1profilePicture.transferTo(new File("/data/spittr/" + profilePicture.getOriginalFilename())); 像这样将文件保存到本地文件系统非常简单，但是将文件管理的工作留给了你。你需要保证有足够的空间，保证对文件进行了备份以防硬件问题。同事还需要进行多服务器之间的文件同步。 将文件保存到Amazon S3另外的办法就是将上面这些都托管给其他人，可以存放在云端，下面的代码可以将上传的图像保存到Amazon S3：12345678910111213141516171819202122private void saveImage(MultipartFile image) throws ImageUploadException &#123; try &#123; AWSCredentials awsCredentials = new AWSCredentials(s3AccessKey, s2SecretKey); // 配置S3服务 S3Service s3 = new RestS3Service(awsCredentials); // 创建S3 bucket对象 S3Bucket bucket = s3.getBucket("spittrImages"); S3Object imageObject = new S3Object(image.getOriginalFilename()); // 设置图像数据 imageObject.setDataInputStream(image.getInputStream()); imageObject.setContentLength(image.getSize()); imageObject.setContentType(image.getContentType()); AccessControlList acl = new AccessControlList(); // 设置权限 acl.setOwner(bucket.getOwner()); acl.grantPermission(GroupGrantee.ALL_USERS, Permission.PERMISSION_READ); imageObject.setAcl(acl); // 保存图片 s3.putObject(bucket, imageObject); &#125; catch (Exception e) &#123; throw new ImageUploadException("Unable to save image", e); &#125; saveImage()的第一步就是设置Amazon Web Service (AWS)认证，你需要提供S3的密钥和私钥，这些在注册S3服务时Amazon都会给你的。 认证过AWS之后，saveImage()创建了一个JetS3t的RestS3Service实例，可以通过它操作S3文件系统。它会获取一个spittrImages的bucket引用，并创建用于包含图标的S3Object对象，然后将突破数据填充到S3Object中。 在调用putObject()方法将图片数据写入S3之前，saveImage()方法设置了S3Object的权限，允许有所有用户查看。这很重要，因为如果没有设置的话，那么这些图片对于应用程序的用户来说都是不可见得了。如果出现什么问题的话，会抛出ImageUploadException异常。 接收上传文件为Part如果你将应用部署在Servlet 3.0的容器上，那么你可以选择不使用MultipartFile，Spring MVC也可以将javax.servlet.http.Part作为控制器的入参，使用Part后processRegistration()方法就是这样的了：123@RequestMapping(value = "/register", method = RequestMethod.POST)public String processRegistration(@RequestPart("profilePicture") Part profilePicture, @Valid Spitter spitter, Errors errors) &#123; 大多数情况下Part接口和MultipartFile没什么区别，如下面的代码所示：12345678910111213141516package javax.servlet.http;import java.io.*;import java.util.*;public interface Part &#123; public InputStream getInputStream() throws IOException; public String getContentType(); public String getName(); public String getSubmittedFileName(); public long getSize(); public void write(String fileName) throws IOException; public void delete() throws IOException; public String getHeader(String name); public Collection&lt;String&gt; getHeaders(String name); public Collection&lt;String&gt; getHeaderNames();&#125; 一些方法就是名称上的不同，比如getSubmittedFileName()和getOriginalFilename()是对应的。write()和transferTo()是对应的，可以这样使用：profilePicture.write(&quot;/data/spittr/&quot; + profilePicture.getOriginalFilename()); 值得注意的是，如果你使用Part作为参数，那么就不再需要配置StandardServletMultipartResolverbean，它只需在使用MultipartFile时进行配置。 异常处理一直以来我们都是假设Spittr应用中的一切都是正常运行的，但是如果哪里出现错误了呢？或者在处理请求时出现了异常？这时该向客户端发送什么响应呢？ 不论发生什么，好的或者坏的，一个servlet请求的输出只能是一个servlet响应。如果在处理请求的过程中出现异常，输出结果仍然是一个servlet响应，需要将异常转换为一个响应。 Spring提供了一些将异常转化为响应的方法： 某些Spring异常会自动的映射为特定的HTTP状态码； 使用@ResponseStatus注解将一个异常映射为HTTP状态码； 使用ExceptionHandler注解的方法可以用来处理异常 映射异常为HTTP状态码Spring可以自动地将其异常映射为状态码，如下表： Spring异常 HTTP状态码 BindException 400 - Bad Request ConversionNotSupportedException 500 - Internal Server Error HttpMediaTypeNotAcceptableException 406 - Not Acceptable HttpMediaTypeNotSupportedException 415 - Unsupported Media Type HttpMessageNotReadableException 400 - Bad Request HttpMessageNotWritableException 500 - Internal Server Error HttpRequestMethodNotSupportedException 405 - Method Not Allowed MethodArgumentNotValidException 400 - Bad Request MissingServletRequestParameterException 400 - Bad Request MissingServletRequestPartException 400 - Bad Request NoSuchRequestHandlingMethodException 404 - Not Found TypeMismatchException 400 - Bad Request 表格里的异常通常是在DispatcherServlet中出错由Spring自身抛出的。例如，如果DispatcherServlet无法找到合适的控制器来处理请求，那么就会抛出NoSuchRequestHandlingMethodException，对应的状态码就是404。 虽然这些内置的映射有点用，但是不一定适用于其他的应用异常。还好，Spring提供了@ResponseStatus注解将一个异常映射为HTTP状态码。 比如下面SpittleController中的请求处理方法就可以返回HTTP 404状态：123456789@RequestMapping(value = "/&#123;spittleId&#125;", method = RequestMethod.GET)public String spittle(@PathVariable("spittleId") long spittleId, Model model) &#123; Spittle spittle = spittleRepository.findOne(spittleId); if (spittle == null) &#123; throw new SpittleNotFoundException(); &#125; model.addAttribute(spittle); return "spittle";&#125; 如果findOne()方法返回了一个null，那么就会抛出SpittleNotFoundException。这里，SpittleNotFoundException就是一个未经检查的异常：12345package spittr.web;public class SpittleNotFoundException extends Exception &#123;&#125; 如果在处理请求时调用了spittle()方法，并且传入的ID是空的，那么SpittleNotFoundException就会默认产生500的响应。实际上，如果没有找到对应的映射都会返回500的错误。但是你也可以通过对SpittleNotFoundException进行映射改变这种情况。 当抛出SpittleNotFoundException时就表示一个请求的资源不存在，404恰好符合这种情况。那么，我们就使用@ResponseStatus来将其映射到404。 123456789package spittr.web;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.ResponseStatus;@ResponseStatus(value=HttpStatus.NOT_FOUND, reason="Spittle Not Found")public class SpittleNotFoundException extends Exception &#123;&#125; 编写异常处理方法将异常映射为状态码大多数情况下是比较简单有效的，但是如果想让响应不仅仅只有一个状态码呢？也许你想对异常进行一些处理，就行处理请求一样。 例如，SpittleRepository的save()方法在用户重复创建Spittle时抛出了一个DuplicateSpittleException，那么SpittleController的saveSpittle()方法就需要处理该异常。如下面的代码所示，saveSpittle()方法可以直接处理该异常：12345678910@RequestMapping(method = RequestMethod.POST)public String saveSpittle(SpittleForm form, Model model) &#123; try &#123; spittleRepository.save(new Spittle(null, form.getMessage(), new Date(), form.getLongitude(), form.getLatitude())); return "redirect:/spittles"; &#125; catch (DuplicateSpittleException e) &#123; return "error/duplicate"; &#125;&#125; 上面的代码并没有什么特别的，这就是一个简单的Java异常处理。 这样做还可以，但是这个方法有点复杂。如果saveSpittle()方法专注于业务处理，让其他方法来处理异常该多好。下面就为SpittleController添加一个新的方法来处理DuplicateSpittleException异常：1234@ExceptionHandler(DuplicateSpittleException.class)public String handleDuplicateSpittle() &#123; return "error/duplicate";&#125; @ExceptionHandler注解应用在handleDuplicateSpittle()方法上，用来指定在有DuplicateSpittleException异常抛出时执行。 有意思的是，@ExceptionHandler注解的方法在同一个控制器里是通用的额，即无论SpittleController的哪一个方法抛出DuplicateSpittleException异常，handleDuplicateSpittle()方法都可以对其进行处理，而不再需要在每一个出现异常的地方进行捕获。 也许你在想，@ExceptionHandler注解的方法能不能捕获其他controller里的异常啊？在Spring3.2里是可以的，但仅仅局限于定义在控制器增强类（controller advice class）里的方法。 那么什么是控制器增强类呢？下面我们就来看看这个控制器增强类。 控制器增强类（controller advice class）如果controller类的特定切面可以跨越应用的所有controller进行使用，那么这将会带来极大的便捷。例如，@ExceptionHandler方法就可以处理多个controller抛出的异常了。如果多个controller类都抛出同一个异常，也许你会在这些controller进行重复的@ExceptionHandler方法编写。或者，你也可以编写一个异常处理的基类，供其他@ExceptionHandler方法进行继承。 Spring3.2带来了另外一种处理方法：控制器增强类，即使用@ControllerAdvice进行注解的类，它们会有下面几个方法构成： @ExceptionHandler注解的 @InitBinder注解的 @ModelAttribute注解的 @ControllerAdvice注解的类中的这些方法会在整个应用中的所有controller的所有@RequestMapping注解的方法上应用。 @ControllerAdvice注解本身是使用了@Component注解的，因此，使用@ControllerAdvice注解的类会在组件扫描时进行提取，就行使用@Controller注解的类一样。 @ControllerAdvice的最实用的一个功能就是将所有的@ExceptionHandler方法集成在一个类中，从而可以在一个地方处理所有controller中的异常。例如，假设你想处理应用中所有的DuplicateSpittleException异常，可以采用下面的方法：123456789101112131415161718192021package spittr.web;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;// 声明控制器增强@ControllerAdvicepublic class AppWideExceptionHandler &#123; // 定义异常处理方法 @ExceptionHandler(DuplicateSpittleException.class) public String handleDuplicateSpittle() &#123; return "error/duplicate"; &#125; @ExceptionHandler(SpittleNotFoundException.class) public String handleSpittleNotFound() &#123; return "error/duplicate"; &#125;&#125; 现在，不论哪一个controller抛出DuplicateSpittleException，都会调用handleDuplicateSpittle()方法来处理。 在redirect请求中携带数据正如前文提到的，在处理完一个POST请求后进行重定向是一个不错的选择，起码这样可以避免用户点击刷新造成的POST请求重发的问题。 在第五章中，已经在控制器方法返回的视图名称中使用了redirect:前缀，这时返回的String不是用来寻找视图，而是浏览器进行跳转的路径：return &quot;redirect:/spitter/&quot; + spitter.getUsername(); 也许你认为Spring处理重定向只能这样了，但是等等：Spring还可以做得更多。 特别是一个重定向方法如何向处理重定向的方法发送数据呢？一般的，当一个处理函数结束后，方法中的model数据都会作为request属性复制到request中，并且request会传递到视图中进行解析。因为控制器和视图面对的是同一个request，因此request属性在forward时保留了下来。 但是，当一个控制器返回的是一个redirect时，原来的request会终止，并且会开启一个新的HTTP请求。原来request中所有的model数据都会清空。新的request不会有任何的model数据。 明显的，现在不能再redirect时使用model来传递数据了。但是还有其他方法用来从重定向的方法中获取数据： 将数据转换为路径参数或者查询参数 在flash属性中发送数据首先来看一下Spring如何在路径参数或者查询参数中传递数据。 使用URL模版重定向将数据转化为路径参数和查询参数看起来比较简单。在之前的代码里，新建的Spitter的username就是作为路径参数进行传递的。但是这里的username是转换为String进行传递的。使用String传递URL和SQL时是比较危险的事情。 除了使用重定向链接，Spring提供了使用模版来定义重定向链接。例如下面的代码：return &quot;redirect:/spitter/{username}&quot;; 你所需做的就是设置model中的相关值。因此，processRegistration()方法需要接收model作为入参，并将username设置其中。123456@RequestMapping(value="/register", method=POST)public String processRegistration(Spitter spitter, Model model) &#123; spitterRepository.save(spitter); model.addAttribute("username", spitter.getUsername()); return "redirect:/spitter/&#123;username&#125;";&#125; 由于这里使用了占位符而不是直接使用重定向String进行连接，就可以将username中的不安全字符隐藏起来。这样就比让用户直接输入username并将其添加到路径后面要更加安全。 另外，model中其他的原始值也会作为查询参数添加到重定向URL中。例如，除了username，model同时也包括新建的Spitter对象的id属性：1234567@RequestMapping(value="/register", method=POST)public String processRegistration(Spitter spitter, Model model) &#123; spitterRepository.save(spitter); model.addAttribute("username", spitter.getUsername()); model.addAttribute("spitterId", spitter.getId()); return "redirect:/spitter/&#123;username&#125;";&#125; 返回的重定向String并没有什么变化，但是由于model中的spitterId属性并没有映射到URL中的占位符，它会自动作为查询参数。 如果username是habuma，spitterId是42，那么返回的重定向路径将是/spitter/habuma?spitterId=42。 使用路径参数和查询参数传递数据比较简单，但是它也有局限性。它只适用于传递简单值，比如String和数字，不能传递比较复杂的东西，那么我们就需要flash属性来帮忙。 使用flash属性比如说你不再是想在重定向中传送一个username或者ID，而是传送一个真正的Spitter对象。如果只传送了一个ID，那么处理重定向的方法不得不去数据库中查找该对象。但是在重定向之前你已经有有一个Spitter对象了，为什么不将它传送给重定向处理方法呢？ Spitter对象不像String或者int那么简单，因此不能作为路径参数或者查询参数进行传送。但是，它可以作为model的一个属性。 但是在上面的讨论中，model属性最终都会拷贝到request中，并随着redirect的触发而消失。因此，你需要将Spitter对象放在一个会随着redirect存活的地方。 其中一个方法是将其放在session中，session是可以长期存活的，可以跨越多个request。因此，你可以将Spitter对象在redirect之前放在session中，并在redirect之后取出。当然你还要在取出之后将其从session中清理。 事实证明，Spring允许将数据存放在session中，从而在redirect时传递数据。但是Spring认为你不应该负责管理这些数据。相反，Spring提供了将数据作为flash属性进行传送的功能。Flash属性，即在到下一个request之前一直携带数据，然后它们就走了。 Spring提供了通过RedirectAttributes来设置flash属性，RedirectAttributes作为Model的子接口，新增了一些方法用来设置flash属性。 特别的，RedirectAttributes提供了addFlashAttribute()方法用来添加flash属性。那么就可以利用它来重写processRegistration()方法：1234567@RequestMapping(value="/register", method=POST)public String processRegistration(Spitter spitter, RedirectAttributes model) &#123; spitterRepository.save(spitter); model.addAttribute("username", spitter.getUsername()); model.addFlashAttribute("spitter", spitter); return "redirect:/spitter/&#123;username&#125;";&#125; 这里，可以调用addFlashAttribute()方法将Spitter对象作为一个值添加到flash属性中。另外，你也可以不填对应的key值：model.addFlashAttribute(spitter);由于你传递了一个Spitter对象，因此key会自动生成为spitter。 在重定向之前，所有的flash属性都会拷贝到session中，在重定向之后，存储在session中的flash属性会从session中移出到model中。然后处理重定向请求的方法就可以使用Spitter对象了，如下图所示： 下面对showSpitterProfile()进行一点点更，在从数据库查找之前对Spitter进行检查：12345678@RequestMapping(value = "/&#123;username&#125;", method = RequestMethod.GET)public String showSpitterProfile(@PathVariable("username") String username, Model model) &#123; if (!model.containsAttribute("spitter")) &#123; Spitter spitter = spitterRepository.findByUsername(username); model.addAttribute(spitter); &#125; return "profile";&#125; 正如你所见，该方法的第一件事是检查model中是否含有spitter的属性，如果有就啥也不做了。Spitter对象会被直接传送到视图中进行解析。如果没有再去数据库里查。 总结每当使用Spring时，好像总有更多：更多的特性、更多的选择以及更多的途径可以达到目标，Spring MVC有很多花样繁多的功能。 Spring MVC的配置就是一个你需要进行选择的地方。本章中，我们从如何配置Spring MVC的DispatcherServlet和ContextLoaderListener说起。你可以看到如何进行DispatcherServlet注册以及其他的servlet和filter的注册。另外，如果将应用部署在比较旧的容器上，我们还可以使用web.xml进行配置。 接着，我们看了如何处理Spring MVC控制器抛出的异常。尽管@RequestMapping方法可以处理异常，如果你将异常处理部分抽取出来那么你的代码就会比较清爽。 为了完成通用的任务，比如异常处理，会在整个应用中使用，Spring3.2开始提供了@ControllerAdvice来创建增强型控制器，从而可以在一个地方完成通用的异常处理。 最后，我们研究了如何在重定向时传递数据，那就是使用Spring的flash属性。 至此，也许你会觉得，不过如此嘛！但是我们讨论的仅仅是Spring MVC功能的一小部分。在16章中我们还会讨论其他功能，比如如何利用它来创建REST API。 下面的章节，我们先放一放Spring MVC，来看一下Spring Web Flow，这是一个流框架，是Spring MVC的扩展，它能够在Spring中实现面向会话的Web开发。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Spring实战》学习笔记-第一章：Spring之旅]]></title>
    <url>%2F%E3%80%8ASpring%E5%AE%9E%E6%88%98%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9ASpring%E4%B9%8B%E6%97%85.html</url>
    <content type="text"><![CDATA[简洁的Spring为了降低Java开发的复杂性，Spring采取了以下4种关键策略： 基于POJO的轻量级和最小侵入性编程； 通过依赖注入和面向接口实现松耦合； 基于切面和惯例进行声明式编程； 通过切面和模板减少样板式代码。 激发POJO的潜能相对于EJB的臃肿，Spring尽量避免因自身的api而弄乱用户的应用代码，Spring不会强迫用户实现Spring规范的接口或继承Spring规范的类，相反，在基于Spring构建的应用中，它的类通常没有任何痕迹表明你使用了Spring。最坏的场景是，一个类或许会使用Spring注解，但它依旧是POJO。 Spring赋予POJO魔力的方式之一就是通过依赖注入来装载它们。 依赖注入任何一个有意义的应用一般都需要多个组件，这些组件之间必定需要进行相互协作才能完成特定的业务，从而导致组件之间的紧耦合，牵一发而动全身。代码示例： 12345678910111213141516package com.springinaction.knights;public class DamselRescuingKnight implements Knight &#123; private RescueDamselQuest quest; public DamselRescuingKnight() &#123; quest = new RescueDamselQuest();// 与RescueDamselQuest紧耦合 &#125; @Override public void embarhOnQuest() throws QuestException &#123; quest.embark(); &#125;&#125; 正如你所见，DamselRescuingKnight 在它的构造函数中自行创建了RescueDamselQuest，这使得DamselRescuingKnight和RescueDamselQuest紧密地耦合到了一起，因此极大地限制了这个骑士的执行能力。如果一个少女需要救援，这个骑士能够召之即来。但是如果一条恶龙需要杀掉，那么这个骑士只能爱莫能助了。 另一方面，可以通过依赖注入的方式来完成对象之间的依赖关系，对象不再需要自行管理它们的依赖关系，而是通过依赖注入自动地注入到对象中去。 代码示例： 12345678910111213141516package com.springinaction.knights;public class BraveKnight implements Knight &#123; private Quest quest; public BraveKnight(Quest quest) &#123; this.quest = quest;// quest被注入到对象中 &#125; @Override public void embarhOnQuest() throws QuestException &#123; quest.embark(); &#125;&#125; 不同于之前的DamselRescuingKnight，BraveKnight没有自行创建探险任务，而是在构造器中把探险任务作为参数注入，这也是依赖注入的一种方式，即构造器注入。 更为重要的是，BraveKnight中注入的探险类型是Quest，Quest只是一个探险任务所必须实现的接口。因此，BraveKnight能够响RescueDamselQuest、SlayDraonQuest等任意一种Quest实现，这正是多态的体现。 这里的要点是BraveKnight没有与任何特定的Quest实现发生耦合。对它来说，被要求挑战的探险任务只要实现了Quest接口，那么具体是哪一类型的探险就无关紧要了。这就是依赖注入最大的好处–松耦合。如果一个对象只通过接口（而不是具体实现或初始化的过程）来表明依赖关系，那么这种依赖就能够在对象本身毫不知情的情况下，用不同的具体实现进行替换。 注入一个Quest到Knight创建应用组件之间协作关系的行为称为装配，Spring有多种装配Bean的方式，其中最常用的就是通过XML配置文件的方式装配。示例代码：使用Spring将SlayDragonQuest注入到BraveKnight中。123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="knight" class="com.springinaction.knights.BraveKnight"&gt; &lt;constructor-arg ref="quest"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id="quest" class="com.springinaction.knights.SlayDragonQuest"&gt;&lt;/bean&gt;&lt;/beans&gt; Spring是如何注入的？Spring通过应用上下文（ApplicationContext）来装载Bean，ApplicationContext全权负责对象的创建和组装。 Spring自带了多种ApplicationContext来加载配置，比如，Spring可以使用ClassPathXmlApplicationContext来装载XML文件中的Bean对象。 123456789101112package com.springinaction.knights;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class KnightMain &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("knights.xml");// 加载Spring上下文 Knight knight = (Knight) context.getBean("knight");// 获取knight Bean knight.embarhOnQuest();// 使用knight &#125;&#125; 这个示例代码中，Spring上下文加载了knights.xml文件，随后获取了一个ID为knight的Bean的实例，得到该对象实例后，就可以进行正常的使用了。需要注意的是，这个类中完全不知道是由哪个Knight来执行何种Quest任务，只有knights.xml文件知道。 应用切面通常情况下，系统由许多不同组件组成，其中的每一个组件分别负责一块特定功能。除了实现自身核心的功能之外，这些组件还经常承担着额外的职责，诸如日志、事务管理和安全等，此类的系统服务经常融入到有自身核心业务逻辑的组件中去，这些系统服务通常被称为横切关注点，因为它们总是跨越系统的多个组件，如下图所示。 AOP可以使得这些服务模块化，并以声明的方式将它们应用到相应的组件中去，这样，这些组件就具有更高内聚性以及更加关注自身业务，完全不需要了解可能涉及的系统服务的复杂性。总之，AOP确保POJO保持简单。 如图所示，我们可以把切面想象为覆盖在很多组件之上的一个外壳。利用AOP，你可以使用各种功能层去包裹核心业务层。这些层以声明的方式灵活应用到你的系统中，甚至你的核心应用根本不知道它们的存在。 AOP应用接上面骑士的故事，现在需要一个诗人来歌颂骑士的勇敢事迹，代码如下「Minstrel是中世纪的音乐记录器」： 1234567891011package com.springinaction.knights;public class Minstrel &#123; public void singBeforeQuest() &#123; // 探险之前调用 System.out.println("Fa la la; The knight is so brave!"); &#125; public void singAfterQuest() &#123; // 探险之后调用 System.out.println("Tee hee he; The brave knight did embark on a quest!"); &#125;&#125; 如代码中所示，诗人会在骑士每次执行探险前和结束时被调用，完成骑士事迹的歌颂。骑士必须调用诗人的方法完成歌颂： 123456789101112131415161718192021222324package com.springinaction.knights;public class BraveKnight implements Knight &#123; private Quest quest; private Minstrel minstrel; public BraveKnight(Quest quest) &#123; this.quest = quest;// quest被注入到对象中 &#125; public BraveKnight(Quest quest, Minstrel minstrel) &#123; this.quest = quest;// quest被注入到对象中 this.minstrel = minstrel; &#125; @Override public void embarhOnQuest() throws QuestException &#123; minstrel.singAfterQuest(); quest.embark(); minstrel.singAfterQuest(); &#125;&#125; 但是，感觉是骑士在路边抓了一个诗人为自己「歌功颂德」，而不是诗人主动地为其传扬事迹。简单的BraveKnight类开始变得复杂，如果骑士不需要诗人，那么代码将会更加复杂。 但是有了AOP，骑士就不再需要自己调用诗人的方法为自己服务了，这就需要把Minstrel声明为一个切面： 123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;bean id="knight" class="com.springinaction.knights.BraveKnight"&gt; &lt;constructor-arg ref="quest"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id="quest" class="com.springinaction.knights.SlayDragonQuest"&gt;&lt;/bean&gt; &lt;!-- 声明诗人Minstrel，待切入的对象（刀） --&gt; &lt;bean id="minstrel" class="com.springinaction.knights.Minstrel"&gt;&lt;/bean&gt; &lt;aop:config&gt; &lt;aop:aspect ref="minstrel"&gt; &lt;!-- 定义切面，即定义从哪里切入 --&gt; &lt;aop:pointcut expression="execution(* *.embarkOnQuest(..))" id="embark" /&gt; &lt;!-- 声明前置通知，在切入点之前执行的方法 --&gt; &lt;aop:before method="singBeforeQuest" pointcut-ref="embark" /&gt; &lt;!-- 声明后置通知，在切入点之后执行的方法 --&gt; &lt;aop:after method="singAfterQuest" pointcut-ref="embark" /&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; 通过运行结果可以发现，在没有改动BraveKnight的代码的情况下，就完成了Minstrel对其的歌颂，而且BraveKnight并不知道Minstrel的存在。 使用Spring模版使用Spring模版可以消除很多样板式代码，比如JDBC、JMS、JNDI、REST等。 容纳Bean在Spring中，应用对象生存于Spring容器中，如图所示，Spring容器可以创建、装载、配置这些Bean，并且可以管理它们的生命周期。 Spring的容器实现 Bean工厂（org.springframework.beans.factory.BeanFactory）：最简单的容器，提供基本的DI支持； 应用上下文（org.springframework.context.ApplicationContext）：基于BeanFactory之上构建，提供面向应用的服务。 常用的几种应用上下文 ClassPathXmlApplicationContext：从类路径中的XML配置文件加载上下文，会在所有的类路径（包括jar文件）下查找； FileSystemXmlApplicationContext：从文件系统中读取XML配置文件并加载上下文，在指定的文件系统路径下查找； XmlWebApplicationContext：读取Web应用下的XML配置文件并加载上下文； Bean的生命周期 Spring对Bean进行实例化； Spring将值和Bean的引用注入进Bean对应的属性中； 如果Bean实现了BeanNameAware接口，Spring将Bean的ID传递给setBeanName()接口方法； 如果Bean实现了BeanFactoryAware接口，Spring将调setBeanFactory()接口方法，将BeanFactory容器实例传入； 如果Bean实现了ApplicationContextAware接口，Spring将调用setApplicationContext()接口方法，将应用上下文的引用传入； 如果Bean实现了BeanPostProcessor接口，Spring将调用postProcessBeforeInitialization()接口方法； 如果Bean实现了InitializationBean接口，Spring将调用afterPropertiesSet()方法。类似的如果Bean使用了init-method声明了初始化方法，该方法也会被调用； 如果Bean实现了BeanPostProcessor接口，Spring将调用ProcessAfterInitialization()方法； 此时此刻，Bean已经准备就绪，可以被应用程序使用了，它们将一直驻留在应用上下文中，直到该应用上下文被销毁； 如果Bean实现了DisposableBean接口，Spring将调用destory()方法，同样的，如果Bean中使用了destroy-method声明了销毁方法，也会调用该方法； 纵观SpringSpring模块 核心Spring容器容器是Spring框架最核心的部分，它负责Spring应用中Bean的创建、配置和管理。Spring模块都构建与核心容器之上，当配置应用时，其实都隐式地使用了相关的核心容器类。另外，该模块还提供了许多企业级服务，如邮件、JNDI访问、EJB集成和调度等。 AOPAOP是Spring应用系统开发切面的基础，与依赖注入一样，可以帮助应用对象解耦。借助于AOP，可以将遍布于应用的关注点（如事务和安全等）从所应用的对象中解耦出来。 数据访问与集成Spring的JDBC和DAO模块封装了大量的样板代码，这样可以使得在数据库代码变得简洁，也可以更专注于我们的业务，还可以避免数据库资源释放失败而引发的问题。另外，Spring AOP为数据访问提供了事务管理服务。同时，Spring还与流程的ORM（Object-Relational Mapping）进行了集成，如Hibernate、MyBatis等。 Web和远程调用Spring提供了两种Web层框架：面向传统Web应用的基于Servlet的框架和面向使用Java Portlet API的基于Portlet的应用。Spring远程调用服务集成了RMI、Hessian、Burlap、JAX-WS等。 测试Spring提供了测试模块来测试Spring应用。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat项目中class文件替换无效引发的思考]]></title>
    <url>%2Ftomcat%E9%A1%B9%E7%9B%AE%E4%B8%ADclass%E6%96%87%E4%BB%B6%E6%9B%BF%E6%8D%A2%E6%97%A0%E6%95%88%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83.html</url>
    <content type="text"><![CDATA[最近在项目部署需要修改补丁文件时，我发现了一个特别古怪的问题： 替换掉原先的class文件无效，重启服务器也无效！ 一般来说，我们更新网站，就是把更新后的文件，如jsp、class文件，替换掉原先的class文件即可。服务器如Tomcat，会自动为我们完成热部署。如果内存有溢出的话，重启一下服务器就OK了。可是今天，我却发现，替换之后的class文件，无论如何也不生效。 想了很多种可能：Tomcat里面配置自动解析WAR包的配置会不会有影响（项目非war包）？Tomcat里面web.xml相关模式是否有影响？…… 弄了半天，修改后的class文件仍然无法起作用。 被修改的类文件，并不同普通的类文件，而是一个接口里面的静态常量。而在Java中，对常量和变量的处理是不一样的。常量是在编译期就已经确定的。也就是说：项目在经javac编译成class文件后，常量在应用中不是以常量名的形式存在的，而是以常量值的形式存在。 举个简单的例子： 我在修改之前的常量是这样：123public class Properties &#123; public static final String BACKUP_STATE_7 = "Failure recovery";&#125; 修改之后是这样： 123public class Properties &#123; public static final String BACKUP_STATE_7 = "Failure recovery File normal";&#125; 而在程序中，我们这样使用常量：Properties.BACKUP_STATE_7 可是，在java中编译之后，使用该常量的地方都变成了：Failure recovery 所以，我只是替换我更改后的常量类，项目中使用常量的地方，并没有改变，仍然是Failure recovery 我们都知道，java是在运行期对类进行装载的，所以，它总是会访问到最新版本的类。但是，对于常量域的引用，会在编译期被转化为它表示的值。所以，也就出现了今天的问题。 所以说，静态常量，我们使用时一定要慎重。一旦有修改就需要将整个项目重新编译替换。 那么，我又有问题了：如果我现在将上面的常量设置为null，只替换这个文件会怎么样呢？ 也即是如下： 123public class Properties &#123; public static final String BACKUP_STATE_7 = null;&#125; 替换后，也会出现上面的情况吗？ 答案应该是替换后的null（未经尝试，大家可以自己试一下）。原因也跟Java的设计者有关系。 参考：http://blog.csdn.net/liu765023051/article/details/43156631]]></content>
      <categories>
        <category>绊脚石</category>
      </categories>
      <tags>
        <tag>错误处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vsftp为不同用户设置不同的ftp的根目录]]></title>
    <url>%2Fvsftp%E4%B8%BA%E4%B8%8D%E5%90%8C%E7%94%A8%E6%88%B7%E8%AE%BE%E7%BD%AE%E4%B8%8D%E5%90%8C%E7%9A%84ftp%E7%9A%84%E6%A0%B9%E7%9B%AE%E5%BD%95.html</url>
    <content type="text"><![CDATA[需求要求ftp登录后的根目录是/var/test/，但是又不能影响其他用户的登录路径，因为有些程序是直接在根目录进行操作的，而没有目录切换的过程。 操作过程方法1新建用户1234useradd test1useradd test2passwd test1passwd test2 vsftpd配置12345678910# 用户登录路径，local_root 针对系统用户local_root=/var/ftp/# 锁定用户到各自目录为其根目录chroot_local_user=YES# anon_root 针对匿名用户anon_root=/var/www/htmlallow_writeable_chroot=YES# 用户配置目录user_config_dir=/etc/vsftpd/userconfig 配置各自用户访问根目录123cd /etc/vsftpd/mkdir userconfigcd userconfig/ 在userconfig目录下为不同用户配置不同的根目录：vim test1：1local_root=/var/ftp/test1/ vim test2：1local_root=/var/ftp/test2/ 重启服务1service vsftpd restart 验证新建/var/ftp/test1/、/var/ftp/test2/目录，并在目录下新增一些测试文件。 123456789101112cd /var/pub/mkdir test1mkdir test2cd test1touch atouch aacd ../test2/touch btouch bbcd ..chown -R test1:test1 test1chown -R test2:test2 test2 结果 方法2默认情况下，ftp登录后是以用户的home目录作为根目录的，因此只要修改用户的主目录即可。 vi /etc/passwd 找到要修改的用户那几行，修改掉即可。此法很暴力，建议慎用。 /etc/passwd文件格式登录名：加密口令：数字用户ID:数字组ID:注释字段：起始目录：sh程序 参考：http://blog.sina.com.cn/s/blog_a97c78020101o8fv.htmlhttp://xiaomaimai.blog.51cto.com/1182965/274002]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim 实用指令]]></title>
    <url>%2FVIM%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[vim 常用指令收集。 vim 列编辑插入字符（可以实现快速多行注释、多行缩进） 将光标移动到要操作的位置； ctrl-v 进入可视块模式； 使用j或者k进行光标上下移动，选取待操作的行； shift-i 进入插入模式，输入要插入的内容； esc按两次，退出插入模式即可； 最终会在选中的每行出现插入的内容； 删除列字符 光标定位到要操作的地方； CTRL+v进入可视块模式，选取这一列操作多少行； d删除。 vim单词间移动 w - 跳到下一个单词的开头 e - 跳到这个单词的末尾 % - 跳到对应的(),{},[]处 *(#) - 跳到当前光标的下一个(上一个) 相同单词的地方 如果你认为单词是由默认方式，那么就用小写的e和w。默认上来说，一个单词由字母，数字和下划线组成。如果你认为单词是由blank字符分隔符，那么你需要使用大写的E和W。 w - 向后移动一个单词，将符号或标点当作单词处理 W - 向后移动一个单词，不把符号或标点当作单词处理 b - 向前移动一个单词，把符号或标点当作单词处理 B - 向前移动一个单词，不把符号或标点当作单词处理 移动光标 0 - 到行头 ^ - 到本行的第一个非blank字符 $ - 到行尾 g_ - 到本行最后一个不是blank字符的位置。 fa - 到下一个为a的字符处，你也可以fs到下一个为s的字符。 t, - 到逗号前的第一个字符。逗号可以变成其它字符。 3fa - 在当前行查找第三个出现的a。 F和T和f和t一样，只不过是相反方向。 行号+G - 跳转到指定行 n+ - 光标下移n行 n- - 光标上移n行 Ctrl+g - 查询当前行信息和当前文件信息 删除相关 dt&quot; - 删除所有的内容，直到遇到双引号&quot;，双引号可以变成其它字符。 dd - 删除一行 dw - 删除一个单词/光标之后的单词剩余部分 ndw - 删除以当前字符开始的n个字 x - 删除当前字符 d$ - 删除至行尾，光标之后的该行部分 d0 - 删除至行首 ndd - 删除以当前行开始的n行 插入模式 i - 从光标前开始插入 I - 从行首开始插入 a - 从光标后开始插入 A - 从行尾开始插入 o - 在当前行之下另起一行，开始插入字符 O - 在当前行之上另起一行，开始插入字符 s - 删除当前字符，然后进入插入模式 S - 清空当前行，然后进入插入模式 (同cc) 替换 :%s/abc/123 - 替换每一行的第一个abc为123 :%s/abc/123/g - 替换每一行的所有abc为123 :s/abc/123/g - 替换当前行的第一个abc为123 其他重复上一次动作 . - 重复上次改变vim 粘贴时取消自动缩进 在vim里，粘贴代码之前最好进入粘贴模式，这样就会关闭自动缩进 1set paste 将代码粘贴进去之后再关闭粘贴模式 1set nopaste]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis+Spring+Maven的简单整合Demo]]></title>
    <url>%2FMyBatis%2BSpring%2BMaven%E7%9A%84%E7%AE%80%E5%8D%95%E6%95%B4%E5%90%88Demo.html</url>
    <content type="text"><![CDATA[本文主要是示范基于Maven的MyBatis+Spring的简单使用，其中主要涉及到的是MyBatis的配置使用，另外还有部分log4j的配置使用。 项目概述本文项目是基于MyEclipse、JDK1.7、MySQL进行开发的，主要功能是通过MyBatis实现对User这个Bean类进行增删改查操作。先展示下整个项目的结构： 新建web project如图所示（勾选Maven支持）： 一路next，勾选产生web.xml 最后生成的项目pom.xml文件中会有很多乱七八糟的&lt;dependency&gt;，可以将他们删了，本小项目中暂时用不掉这些。 准备数据库表使用mybatis数据库，没有就新建一个。1234567891011use mybatis;drop table if exists tb_user;create table tb_user( id int primary key auto_increment comment '主键', username varchar(40) not null unique comment '用户名', password varchar(40) not null comment '密码', email varchar(40) comment '邮件', age int comment '年龄', sex char(2) not null comment '性别'); 相关的Java处理类 数据库表对应的实体类User.java：（省略了相关的getter和setter） 123456789101112package com.liuhao.entity;public class User &#123; private int id; private String username; private String password; private String sex; private String email; private int age; //getter() and setter () &#125; UserDao.java，可以对User进行插入、更新、删除、查找、列出所有等操作： 123456789101112package com.liuhao.dao;import java.util.List;import com.liuhao.entity.User;public interface UserDao &#123; public int insert(User user); public int update(User user); public int delete(String userName); public List&lt;User&gt; selectAll(); public int countAll(); public User findByUserName(String userName);&#125; UserService接口： 123456789101112package com.liuhao.service;import java.util.List;import com.liuhao.entity.User;public interface UserService &#123;. public int insert(User user); public int update(User user); public int delete(String userName); public List&lt;User&gt; selectAll(); public int countAll(); public User findByUserName(String userName);&#125; 实现service接口，执行dao操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.liuhao.service.impl;import java.util.List;import com.liuhao.dao.UserDao;import com.liuhao.entity.User;import com.liuhao.service.UserService;public class UserServiceImpl implements UserService &#123; public UserDao userDao; public UserDao getUserDao() &#123; return userDao; &#125; public void setUserDao(UserDao userDao) &#123; this.userDao = userDao; &#125; @Override public int insert(User user) &#123; return userDao.insert(user); &#125; @Override public int update(User user) &#123; return userDao.update(user); &#125; @Override public int delete(String userName) &#123; return userDao.delete(userName); &#125; @Override public List&lt;User&gt; selectAll() &#123; return userDao.selectAll(); &#125; @Override public int countAll() &#123; return userDao.countAll(); &#125; @Override public User findByUserName(String userName) &#123; return userDao.findByUserName(userName); &#125;&#125; 相关配置文件 Mapper文件配置/test/config/com/liuhao/dao/UserDao.xml： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version="1.0" encoding="UTF-8" ?&gt; &lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.liuhao.dao.UserDao"&gt; &lt;!-- 查询表中记录总数 --&gt; &lt;select id="countAll" resultType="int"&gt; select count(*) c from tb_user &lt;/select&gt; &lt;!-- 查询表中的所有用户 --&gt; &lt;select id="selectAll" resultType="com.liuhao.entity.User"&gt; select * from tb_user order by username asc &lt;/select&gt; &lt;!-- 向数据库中插入用户 --&gt; &lt;insert id="insert" parameterType="com.liuhao.entity.User"&gt; insert into tb_user(username,password,email,sex,age) values(#&#123;username&#125;,#&#123;password&#125;,#&#123;email&#125;,#&#123;sex&#125;,#&#123;age&#125;) &lt;/insert&gt; &lt;!-- 更新库中的用户 --&gt; &lt;update id="update" parameterType="com.liuhao.entity.User"&gt; update tb_user set username=#&#123;username&#125;,password=#&#123;password&#125;,email=#&#123;email&#125;,sex=#&#123;sex&#125;,age=#&#123;age&#125; where username=#&#123;username&#125; &lt;/update&gt; &lt;!-- 删除用户 --&gt; &lt;delete id="delete" parameterType="String"&gt; delete from tb_user where username=#&#123;username&#125; &lt;/delete&gt; &lt;!-- 根据用户名查找用户 --&gt; &lt;select id="findByUserName" parameterType="String" resultType="com.liuhao.entity.User"&gt; select * from tb_user where username=#&#123;username&#125; &lt;/select&gt;&lt;/mapper&gt; Mybatis应用配置文件/test/config/MyBatis-Configuration.xml: 12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN""http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;mappers&gt; &lt;mapper resource="com/liuhao/dao/UserDao.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; Spring配置文件,本例中我们放在/test/config/applicationContext.xml： 123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"&gt;&lt;/property&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/mybatis"&gt;&lt;/property&gt; &lt;property name="username" value="root"&gt;&lt;/property&gt; &lt;property name="password" value="123456"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="configLocation" value="classpath:MyBatis-Configuration.xml"&gt;&lt;/property&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;bean id="userDao" class="org.mybatis.spring.mapper.MapperFactoryBean"&gt; &lt;property name="mapperInterface" value="com.liuhao.dao.UserDao"&gt;&lt;/property&gt; &lt;property name="sqlSessionFactory" ref="sqlSessionFactory"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="userService" class="com.liuhao.service.impl.UserServiceImpl"&gt; &lt;property name="userDao" ref="userDao"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; web.xml配置： 12345678910111213141516171819&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd" id="WebApp_ID" version="3.0"&gt; &lt;display-name&gt;test&lt;/display-name&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 配置上下文监听 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt;&lt;/web-app&gt; 项目是基于Maven构建的，pom.xml： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;test&lt;/groupId&gt; &lt;artifactId&gt;test&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;test&lt;/name&gt; &lt;description /&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis和spring相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;3.0.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;3.0.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-dao&lt;/artifactId&gt; &lt;version&gt;2.0.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySQL数据库驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.5&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- JUnit测试框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log4j日志框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.directory.studio&lt;/groupId&gt; &lt;artifactId&gt;org.apache.logging.log4j&lt;/artifactId&gt; &lt;version&gt;1.2.16&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;sourceDirectory&gt;src&lt;/sourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;warSourceDirectory&gt;$&#123;basedir&#125;/WebRoot&lt;/warSourceDirectory&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 另外项目中使用了log4j进行日志采集，配置如下： 123456789101112131415161718192021222324252627282930313233343536373839#log4j.rootLogger=DEBUG,CONSOLE,A1#log4j.rootLogger=INFO,CONSOLE,A2log4j.rootLogger=DEBUG,INFO,CONSOLE,A1,A2,A3log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.Threshold=DEBUGlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH\:mm\:ss&#125; %c %-5p %m%nlog4j.appender.A1=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.A1.File=D:/logs/debug.loglog4j.appender.A1.Threshold=INFOlog4j.appender.A1.ImmediateFlush=truelog4j.appender.A1.layout=org.apache.log4j.PatternLayoutlog4j.appender.A1.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss&#125; %-5p %-25c -&gt; %m%nlog4j.appender.A2=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.A2.File=D:/logs/log.loglog4j.appender.A2.Threshold=INFOlog4j.appender.A2.ImmediateFlush=truelog4j.appender.A2.layout=org.apache.log4j.PatternLayoutlog4j.appender.A2.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss&#125; %-5p %-25c -&gt; %m%nlog4j.appender.A3=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.A3.File=D:/logs/error.loglog4j.appender.A3.Threshold=ERRORlog4j.appender.A3.ImmediateFlush=truelog4j.appender.A3.layout=org.apache.log4j.PatternLayoutlog4j.appender.A3.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH\:mm\:ss&#125; %-5p %-25c -&gt; %m%nlog4j.logger.com.springframework=DEBUGlog4j.logger.com.ibatis=DEBUG log4j.logger.com.ibatis.common.jdbc.SimpleDataSource=DEBUG log4j.logger.com.ibatis.common.jdbc.ScriptRunner=DEBUG log4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=DEBUG log4j.logger.java.sql.Connection=DEBUG log4j.logger.java.sql.Statement=DEBUG log4j.logger.java.sql.PreparedStatement=DEBUG log4j.logger.java.sql.ResultSet=DEBUG 测试代码如果按照上述代码进行部署，应该不会出问题。本人应为少加了MySQL的驱动，和同事搞了差不多一个上午。。。 基于JUnit的测试代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.liuhao.test;import java.util.List;import org.junit.Before;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import com.liuhao.entity.User;import com.liuhao.service.UserService;public class TestMyBatis &#123; ApplicationContext context = null; UserService userService = null; @Before public void initContext() &#123; this.context = new ClassPathXmlApplicationContext( "applicationContext.xml"); this.userService = (UserService) context.getBean("userService"); &#125; @Test public void TestInsert() &#123; User user = new User(); // username需要是唯一的 user.setUsername("刘哈哈"); user.setPassword("passtest"); user.setEmail("liuhao2995@163.com"); user.setSex("男"); user.setAge(23); userService.insert(user); &#125; @Test public void TestCountAll() &#123; System.out.println("数据库中的记录条数:" + userService.countAll()); &#125; @Test public void TestSelectAll() &#123; List&lt;User&gt; list = userService.selectAll(); for (int i = 0; i &lt; list.size(); i++) &#123; User user = list.get(i); System.out.println("用户名:" + user.getUsername() + "\t密码:" + user.getPassword() + "\t邮箱：" + user.getEmail()); &#125; &#125; @Test public void TestFindByName() &#123; User user = userService.findByUserName("刘哈哈"); System.out.println("用户名:" + user.getUsername() + "\t密码:" + user.getPassword() + "\t邮箱：" + user.getEmail()); &#125; @Test public void TestUpdate() &#123; User user = new User(); user.setUsername("刘哈哈"); user.setPassword("xxxxxxxx"); user.setEmail("xxxxxx@163xxx"); user.setSex("男"); user.setAge(23); userService.update(user); &#125; @Test public void TestDelete() &#123; userService.delete("刘哈哈"); &#125;&#125; 源码下载：http://download.csdn.net/detail/bruce_6/8876565参考：http://www.cnblogs.com/dennisit/archive/2013/04/10/3012972.html]]></content>
      <categories>
        <category>JavaWeb</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
        <tag>Spring</tag>
        <tag>Maven</tag>
        <tag>log4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Head First Python 学习笔记-Chapter4：持久化--将数据写入文件]]></title>
    <url>%2FHead%20First%20Python%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Chapter4%EF%BC%9A%E6%8C%81%E4%B9%85%E5%8C%96--%E5%B0%86%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E6%96%87%E4%BB%B6.html</url>
    <content type="text"><![CDATA[第四章主要涉及文件的写入，包括使用with语句、pickle处理文件等。 简单文件写入123&gt;&gt;&gt; out = open('data.out', 'w') # 以w模式打开，在写入前会清空文件&gt;&gt;&gt; print("测试一下",file=out)&gt;&gt;&gt; out.close() # 一定要进行close，即刷新输出 可以看到在当前工作目录下生成了一个data.out文件，内容为：测试一下。 当尝试往一个不存在的文件写入时，程序首先会创建一个新文件。 读取/写入文件12345678910111213141516171819202122232425262728man = []other = []try: data = open('sketch.txt') for each_line in data: try: (role, line_spoken) = each_line.split(':', 1) line_spoken = line_spoken.strip() # 去除字符串中的首尾空字符 if role == 'Man': man.append(line_spoken) elif role == 'Other Man': other.append(line_spoken) except: pass data.close()except: print('文件不存在！')try: man_file = open('man_data.txt','w') other_file = open('other_data.txt','w') print(man,file=man_file) print(other,file=other_file) man_file.close() other_file.close()except IOError: print('文件异常') 使用with处理文件异常 通常的try/expect/finally方式： 12345678try: data = data = open('missing', 'w') print(data.readline(), end='')except IOError as err: print('File error' + str(err))finally: if 'data' in locals(): data.close() 使用with进行处理： 12345try: with open('missing', 'w') as data: print("It's...", file=data)except IOError as err: print('File error' + str(err)) with语句利用了一种名为上下文管理协议（context management protocol）的python技术。 使用with时，不再需要操心关闭打开的文件，因为python解释器会自动的进行。 pickle可以保存和加载几乎任何Python数据对象，包括列表。使用pickle很简单，只需要导入所需的模块，然后使用dump()保存数据，以后再某个时间点可以使用load()来恢复数据。但是这些操作的一个要求就是必须要以二进制访问模式打开这些文件。出现异常时，pickle会产生一个PickleError类型的异常。 1234567import pickle # 一定要导入pickle模块with open('mydata.pickle', 'wb') as mysavadata: #b代表使用二进制模式打开文件 pickle.dump([1, 2, 'three'], mysavadata) # 使用dump保存数据文件with open('mydata.pickle', 'rb') as myrestoredata: a_list = pickle.load(myrestoredata) # 使用load从文件恢复数据print(a_list) 知识点open()函数open(file, mode=&#39;r&#39;, buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)：打开一个文件并返回对应的文件对象，若文件不存在，将抛出OSError异常。 主要参数： file：可以是一个代表文件路径（绝对路径或者相对路径）字符串或者一个包装好的文件对象 mode：可选，用以指定文件打开的模式，分为以下几种： 字符 含义 r 只读（默认） w 只写，并且先将文件清空 x 创建新文件并写入, 若文件已存在则会失败 a 只写，将写入的内容添加到已有内容的后面 b 二进制模式 t 文本模式（默认） + 打开硬盘文件用于更新（读和写） str.strip([chars])函数没有参数则清除首尾的空白字符，有参数（比如a），怎将首尾中的a全部清除，直到不是a的字符，如：1234&gt;&gt;&gt; ' spacious '.strip()'spacious'&gt;&gt;&gt; 'www.example.com'.strip('cmowz.')'example' locals()：返回当前作用域中的变量集合当一行代码要使用变量x的值时，Python会到所有可用的名字空间去查找变量，按照如下顺序： 局部名字空间：特指当前函数或类的方法。如果函数定义了一个局部变量x，Python将使用这个变量，然后停止搜索。 全局名字空间：特指当前的模块。如果模块定义了一个名为x的变量，函数或类，Python将使用这个变量然后停止搜索。 内置名字空间：对每个模块都是全局的。作为最后的尝试，Python将假设x是内置函数或变量。 如果Python在这些名字空间找不到x它将放弃查找并引发一个NameError的异常，同时传递There is no variable named &#39;x&#39;这样一条信息。 象Python中的许多事情一样，名字空间在运行时直接可以访问。特别地，局部名字空间可以通过内置的locals函数来访问。全局（模块级别）名字空间可以通过globals函数来访问。 str()函数返回对象的string类型，str(object)将调用object.__str__()，类似于Java中的toString()方法 with语句有一些任务，可能事先需要设置，事后做清理工作。对于这种场景，Python的with语句提供了一种非常方便的处理方式。一个很好的例子是文件处理，你需要获取一个文件句柄，从文件中读取数据，然后关闭文件句柄。 如果不用with语句，代码如下：123file = open("/tmp/foo.txt")data = file.read()file.close() 这里有两个问题。一是可能忘记关闭文件句柄；二是文件读取数据发生异常，没有进行任何处理。下面是处理异常的加强版本：12345file = open("/tmp/foo.txt")try: data = file.read()finally: file.close() 虽然这段代码运行良好，但是太冗长了。这时候就是with一展身手的时候了。除了有更优雅的语法，with还可以很好的处理上下文环境产生的异常。下面是with版本的代码：12with open("/tmp/foo.txt") as file: data = file.read() if/elif1234if role == 'Man': man.append(line_spoken)elif role == 'Other Man': # elif相当于 else if other.append(line_spoken)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>文件写入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Head First Python 学习笔记-Chapter6：自定义数据对象：字典与类]]></title>
    <url>%2FHead%20First%20Python%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Chapter6%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%EF%BC%9A%E5%AD%97%E5%85%B8%E4%B8%8E%E7%B1%BB.html</url>
    <content type="text"><![CDATA[本文将涉及到字典和类。字典可以有效地组织数据，可以将数据与名称关联（类似于Map），从而实现快速查找。另外，也可以自定义类来处理一些功能，通过为对象增加一些属性和方法完成所需的功能。 所需文件获取地址：http://python.itcarlow.ie/chapter6/hfpy_ch6_data.zip 字典dictionary字典是一个内置的数据结构，允许将数据与键进行关联，这样可以使内存中的数据与实际数据的结构保持一致。也可以称之为“映射”、“散列”、“关联数组”等。 创建字典dict可以使用两种方式进行创建空字典，一种是使用大括号创建，一种是使用工厂函数dict()创建。12345678&gt;&gt;&gt; cheese = &#123;&#125;&gt;&gt;&gt; palin = dict()&gt;&gt;&gt; type(cheese)&lt;class 'dict'&gt;&gt;&gt;&gt; type(palin)&lt;class 'dict'&gt; 添加数据通过将值与键关联，向这两个字典中添加一些数据。注意两种添加方式的不同。1234&gt;&gt;&gt; cheese['Name'] = 'John Cheese'&gt;&gt;&gt; cheese['Occupations'] = ['actor', 'comedian', 'writer', 'file producer']&gt;&gt;&gt; palin = &#123;'Name' : 'John Cheese', 'Occupations' : ['actor', 'comedian', 'writer', 'file producer']&#125; 访问数据通过字典名称加上[key]就可以访问到对应的值。123456&gt;&gt;&gt; palin['Name']'John Cheese'&gt;&gt;&gt; cheese['Occupations']['actor', 'comedian', 'writer', 'file producer']&gt;&gt;&gt; cheese['Occupations'][2]'writer' 与列表不同的是，字典并不会维持插入的顺序，只是保持key-value之间的关联关系。 完成上篇文章中的需求，现在运动员的数据变成了Sarah Sweeney,2002-6-17,2:58,2.58,2:39,2-25,2-55,2:54,2.18,2:55,2:55,2:22,2-21,2.22这种形式，其中不仅包含运动员数据，还有其他一些信息，需要进行特殊处理。 1234567891011121314151617181920212223def sanitize(time_str): if '-' in time_str: spliter = '-' elif ':' in time_str: spliter = ':' else: return time_str (mins, secs) = time_str.split(spliter) return(mins + '.' + secs)def get_coach_data(filename): try: with open(filename) as file: data = file.readline(); dataList = data.strip().split(',') return &#123;'Name' : dataList.pop(0), 'DOB' : dataList.pop(0), 'Times' : sorted(set([sanitize(str) for str in dataList]))[0:3]&#125; except IOError as err: print('File error:' + str(err)) return Nonesarah = get_coach_data('sarah2.txt')print(sarah['Name'] + "'s fastest times are: " + str(sarah['Times'])) 类方法、属性、实例 定义类使用class关键字来定义类，同时可以使用__init__()方法来完成类的初始化构造（类似于Java中的构造方法）。1234class Athlete: def __init__(self): # 完成对象'Athlete'的初始化工作 ... 创建对象实例在创建类的实例时，实际上调用了__init()__方法对类的实例进行了初始化。1234a = Athlete()b = Athlete()c = Athlete()d = Athlete() self的重要性self类似于Java中的this，用于指向当前对象实例。 定义一个类时，实际上实在定义一个定制工厂函数，任何可以在代码中使用这个工厂函数来创建实例： Python在处理a = Athlete()这行代码时，会把工厂函数调用转化为以下调用，可以明确类（Athlete）、方法（__init__()）和所处理对象实例（a）：Athlete().__init__(a) 如果没有self参数这个赋值，Python解释器将无法得出方法调用要应用到哪个实例，self参数可以帮助标识要处理哪个对象实例的数据。 每个方法的第一个参数都是self下面对Athlete对象进行扩展，在一个名为thing的属性中存储一个值，同时增加一个how_big()方法返回thing的长度。12345class Athlete: def __init__(self, value=0): self.thing = value def how_big(self): return(len(self.thing)) 在一个对象实例调用类方法时，Python要求第一个参数是调用对象实例，这往往赋至各方法的self参数。 你写的代码 Python执行的代码 d = Athlete(&quot;Xiaoming&quot;) Athlete.__init__(d, &quot;Xiaoming&quot;) d.how_big() Athlete.how_big(d) 利用类存储数据改写之前的代码12345678910111213141516171819202122def get_coach_data(filename): try: with open(filename) as file: data = file.readline(); dataList = data.strip().split(',') # 此处返回一个Athlete对象 return Athlete(dataList.pop(0), dataList.pop(0), dataList) except IOError as err: print('File error:' + str(err)) return Noneclass Athlete: def __init__(self, name, dob=None, times=[]): self.name = name self.dob = dob self.times = times def getTop3(self): # sanitize方法没有变化，不再列出 return sorted(set(sanitize(str) for str in self.times))[0:3]sarah = get_coach_data('sarah2.txt')print(sarah.name + "'s fastest times are: " + str(sarah.getTop3())) 添加新的方法当需要额外新的功能时，可以向类中添加新的方法来实现所需的功能。1234567891011121314class Athlete: def __init__(self, name, dob=None, times=[]): self.name = name self.dob = dob self.times = times # 获取时间前3的数据列表 def getTop3(self): return sorted(set(sanitize(str) for str in self.times))[0:3] # 添加一条新的时间数据 def add_time(self, time): self.times.append(time) # 添加多条新的数据 def add_times(self,times): self.times.extend(times) 类的继承Python允许通过继承来创建一个类，包括用list、set、dict提供的内部数据结构类。下面定义了一个NameList类，()中的list就表示它继承自list，因此它就具有了list的相关属性和方法。123456789101112131415class NameList(list): def __init__(self, name): list.__init__([]) self.name = name&gt;&gt;&gt; nameList = NameList('a')&gt;&gt;&gt; type(nameList)&lt;class '__main__.NameList'&gt;&gt;&gt;&gt; nameList.append(2)&gt;&gt;&gt; nameList.append('b')&gt;&gt;&gt; nameList[2, 'b']&gt;&gt;&gt; nameList.name'a' 利用继承重写Athlete类：12345678910# 继承自list类class AthleteList(list): def __init__(self, name, dob=None, times=[]): list.__init__([]) self.name = name self.dob = dob self.extend(times) # 不再吸引times属性，数据本身就是 # 获取时间前3的数据列表 def getTop3(self): return sorted(set(sanitize(str) for str in self))[0:3] 其他知识点array.pop(i)pop()属于array的方法，可以删除索引i处的数值，并返回该数值。默认参数为-1，因此默认会删除并返回数组中的最后一个元素。12345678&gt;&gt;&gt; array = [1, 2, 3, 4]&gt;&gt;&gt; array.pop() # 弹出最后一个元素4&gt;&gt;&gt; array.pop(2) # 弹出索引2处的元素3&gt;&gt;&gt; array [1, 2]&gt;&gt;&gt; list set dict 名称 特点 list 列表，数据有序，可重复 set 集合，数据无序，不可重复 dict 键值对，若把key-value看作一个整体，那么dict与set类似]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Head First Python 学习笔记-Chapter5：数据处理]]></title>
    <url>%2FHead%20First%20Python%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Chapter5%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86.html</url>
    <content type="text"><![CDATA[本章的目的是学习简单的数据处理，首先给出了一些文本数据，需要将这些文本数据读取，并转换为列表，然后对列表中的数据进行统一格式化，最后进行排序。 本章所需的数据获取地址：获取数据 数据处理未优化的代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 对时间字符串进行格式化，统一形式为mins.secsdef sanitize(time_string): if '-' in time_string: splitter = '-' elif ':' in time_string: splitter = ':' else: return(time_string) (mins, secs) = time_string.split(splitter) return(mins + '.' + secs)# 读取文件，并将记录时间转换成列表with open('james.txt') as jaf: data = jaf.readline()james = data.strip().split(',')with open('julie.txt') as juf: data = juf.readline()julie = data.strip().split(',')with open('mikey.txt') as mif: data = mif.readline()mikey = data.strip().split(',')with open('sarah.txt') as saf: data = saf.readline()sarah = data.strip().split(',')clean_james = []clean_julie = []clean_mikey = []clean_sarah = []---------臃肿的部分------------for each_t in james: clean_james.append(sanitize(each_t))for each_t in julie: clean_julie.append(sanitize(each_t))for each_t in mikey: clean_mikey.append(sanitize(each_t))for each_t in sarah: clean_sarah.append(sanitize(each_t))print(sorted(clean_james))print(sorted(clean_julie))print(sorted(clean_mikey))print(sorted(clean_sarah))---------臃肿的部分------------ 优化的代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def sanitize(time_str): if '-' in time_str: spliter = '-' elif ':' in time_str: spliter = ':' else: return time_str (mins, secs) = time_str.split(spliter) return(mins + '.' + secs)# 将读取文件的代码抽取成函数def get_coach_data(filename): try: with open(filename) as file: data = file.readline(); return data.strip().split(',') except IOError as err: print('File error:' + str(err)) return None# 去除列表中的重复数据def clean_data(data): clean_data = [] for item in data: if item not in clean_data: clean_data.append(item) return clean_datajames = get_coach_data('james.txt')julie = get_coach_data('julie.txt')mikey = get_coach_data('mikey.txt')sarah = get_coach_data('sarah.txt')james_format = [sanitize(data) for data in james]julie_format = [sanitize(data) for data in julie]mikey_format = [sanitize(data) for data in mikey]sarah_format = [sanitize(data) for data in sarah]clean_james = clean_data(james_format)clean_julie = clean_data(julie_format)clean_mikey = clean_data(mikey_format)clean_sarah = clean_data(sarah_format)print(sorted(clean_james)[0:3])print(sorted(clean_julie)[0:3])print(sorted(clean_mikey)[0:3])print(sorted(clean_sarah)[0:3]) 两种排序方法原地排序（In-place sorting）：data.sort()该方法会对排列数据（data）按指定的顺序进行排序，然后用排好顺序的数据替换掉原有的数据，因此原有的数据顺序会丢失。 复制排序（Copied sorting）：sorted(data)对数据按指定的顺序进行排序，然后返回原数据的一个有序副本。原数据依然保留，只是对副本进行排序 1234567891011121314151617&gt;&gt;&gt; data = [6,3,1,2,5,4]&gt;&gt;&gt; data[6, 3, 1, 2, 5, 4]&gt;&gt;&gt; data.sort() # 对数据进行原地排序&gt;&gt;&gt; data[1, 2, 3, 4, 5, 6] # 原数据的顺已经改变&gt;&gt;&gt; &gt;&gt;&gt; data = [6,3,1,2,5,4]&gt;&gt;&gt; data_sort = sorted(data) # 对数据进行复制排序，返回一个有序副本&gt;&gt;&gt; data[6, 3, 1, 2, 5, 4] # 原数据顺序仍然存在&gt;&gt;&gt; data_sort[1, 2, 3, 4, 5, 6] 列表推导式（list comprehension）使用方法[表达式 for 变量 in 列表] 或者 [表达式 for 变量 in 列表 if 条件] 使用示例12345678910111213141516171819202122# 将分钟数转化成秒数&gt;&gt;&gt; mins = [1,2,3]&gt;&gt;&gt; secs = [m * 60 for m in mins]&gt;&gt;&gt; secs[60, 120, 180]# 求列表中数字的平方&gt;&gt;&gt; data = [1,2,3,4]&gt;&gt;&gt; data_square = [num * num for num in data]&gt;&gt;&gt; data_square[1, 4, 9, 16]# 还可以跟其他条件，对列表中的数据进行筛选处理&gt;&gt;&gt; result = [num * 2 for num in data if num &gt; 2]&gt;&gt;&gt; result[6, 8]# 也可以增加更多的for语句的部分：&gt;&gt;&gt; result = [[x,y] for x in range(2) for y in range(2)]&gt;&gt;&gt; result[[0, 0], [0, 1], [1, 0], [1, 1]]&gt;&gt;&gt; Set：无序、不可重复初始化1.创建一个空的set1distances = set() 2.为set提供一个数据列表（需要用大括号包围）123&gt;&gt;&gt; distances = &#123;10.6,11,8,10.6,"two",7&#125;&gt;&gt;&gt; distances&#123;8, 10.6, 11, 'two', 7&#125; # 自动过滤掉了重复的数据 3.为set指定一个现有的列表1234&gt;&gt;&gt; list = [2,2,3,5,6]&gt;&gt;&gt; distances = set(list)&gt;&gt;&gt; distances&#123;2, 3, 5, 6&#125; 零碎知识点list列表分片列表分片主要用于获取列表的一个子部分，即通过L[x:y]取得并返回列表L在偏移量x到y（包括x不包括y）之间的一个新列表，如下所示：12&gt;&gt;&gt; [1,2,3,4,5,6][2:5][3, 4, 5] 另外，如果偏移量留空，则第一个偏移量默认为列表的头部，第二个默认为末尾：12&gt;&gt;&gt; [1,2,3,4,5,6][:][1, 2, 3, 4, 5, 6] 如果这样做，相当于对原列表做一个浅拷贝。 分片实际还接收第三个参数，其代表步长，默认情况下，该值为1。下面将步长改为2：12&gt;&gt;&gt; [1,2,3,4,5,6][::2][1, 3, 5] 如果把步长设为负值会有什么效果呢？12&gt;&gt;&gt; [1,2,3,4,5,6][::-2][6, 4, 2] 相当于反转了列表，从列表的尾部开始遍历。 工厂函数工厂函数用于创建某种类型的新的数据项，例如set()就是一个工厂函数，因为它会创建一个新的集合。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>文件写入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Head First Python 学习笔记-Chapter3：文件读取和异常处理]]></title>
    <url>%2FHead%20First%20Python%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Chapter3%EF%BC%9A%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html</url>
    <content type="text"><![CDATA[第三章中主要介绍了简单的文件读取和简单的异常处理操作。 首先建立文件目录：HeadFirstPython\chapter3，在Head First Pythong官方网站下载需要使用的文件：sketch.txt，并放入到之前建好的目录中。 相关语法读取文件123the_file = open('sketch.txt) # 打开文件，获取到文件对象# 对文件中的数据进行一些处理the_file.close() # 关闭文件 异常捕获12345678910111213141516import systry: # 可能会出现异常的代码 f = open('myfile.txt') s = f.readline() i = int(s.strip())# 对异常进行处理# 类似于Java中的catch块except OSError as err: # 可以指定待捕获的异常 print("OS error: &#123;0&#125;".format(err))except ValueError: pass # 不做任何操作，直接跳过except: print("Unexpected error:", sys.exc_info()[0]) 交互式环境下获取文件在python交互环境中（pyhton idle）中，可以使用如下的一些命令进行一些文件操作： 12345678910111213141516171819&gt;&gt;&gt; import os # 从标准库导入os&gt;&gt;&gt; os.getcwd() # 获取当前的工作目录，类似于Linux下的pwd'D:\\program\\Python34'&gt;&gt;&gt; os.chdir("D:\code\python\HeadFirstPython\chapter3") # 切换工作目录&gt;&gt;&gt; os.getcwd()'D:\\code\\python\\HeadFirstPython\\chapter3'&gt;&gt;&gt; data = open('sketch.txt') # 打开文件，获取到文件对象，相当于一个迭代器iterator&gt;&gt;&gt; print(data.readline(),end="") # 读取文件的一行，data.readline()Man: Is this the right room for an argument?&gt;&gt;&gt; print(data.readline(),end="")Other Man: I've told you once.&gt;&gt;&gt; data.seek(0) # 使data回到文件起始位置0# 使用for循环获得文件的每一行&gt;&gt;&gt; for eachline in data: print(eachline,end="") 对数据进一步的处理：异常处理再看一下文件中的数据，发现每一行都是用“:”进行分隔的，因此考虑在输出时进行优化。在对文件进行处理时，会出现相应的问题，比如文件中有些行是不含有“:”的，这时就会跑抛出ValueError异常，当文件不存在或者读取失败时，则会抛出IOError，等等。面对这些异常，有两种处理思路： 提前考虑好程序中可能出现的异常，对这些情况进行处理，从而避免异常的发生。 采用异常捕获机制：让异常发生，但是对异常进行捕获，捕获到后再进行相关的操作。 第一种思路：123456789101112import osif os.path.exists('sketch.txt'): data = open('sketch.txt') for each_line in data: if each_line.find(':') != -1: (role, line_spoken) = each_line.split(':', 1) print(role, end='') print(' said: ', end='') print(line_spoken,end='') data.close()else: print('文件不存在！') 第二种思路：捕获异常：1234567891011121314try: data = open('sketch2.txt') for each_line in data: # if each_line.find(':') != -1: try: (role, line_spoken) = each_line.split(':', 1) print(role, end='') print(' said: ', end='') print(line_spoken,end='') except: pass # 不做任何操作，直接跳过 data.close()except: print('文件不存在') 相关知识点1、split()：对字符串进行分割，函数原型是str.split(sep=None, maxsplit=-1)，它包含两个参数，第一个是使用分割符，第二个是最大分割次数。如：123456789101112&gt;&gt;&gt; '1,2,3'.split(',')['1', '2', '3']&gt;&gt;&gt; '1,2,3'.split(',', maxsplit=1)['1', '2,3']&gt;&gt;&gt; '1,2,,3,'.split(',')['1', '2', '', '3', '']&gt;&gt;&gt; '1 2 3'.split()['1', '2', '3']&gt;&gt;&gt; '1 2 3'.split(maxsplit=1)['1', '2 3']&gt;&gt;&gt; ' 1 2 3 '.split()['1', '2', '3'] 2、open()：用来读取文件，同时创建了一个迭代器，可以对文件进行按行读取3、readline()：读取文件的一行4、seek()：将迭代器重新指向文件的开始处（第一行）5、close()：关闭打开的文件6、find()：查找子串在字符串中的位置，不存在则返回-1]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>异常处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018黑马软件测试全套视频教程]]></title>
    <url>%2Fresource-heima-softtest-2018-2017.html</url>
    <content type="text"><![CDATA[后台经常有留言要各种资源的，感觉成了一个专做资源的号了…… 不过，还是之前的宗旨，看到好的就分享给大家。 本周给大家带来的是：2018 黑马软件测试全套视频教程。 也是一个群里的小伙伴要的。 老规矩，先放出目录，大家感受下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635目录├─黑马2018软件测试学习附完整视频+工具│ ├─1.软件测试前置基础知识│ │ ├─day1│ │ │ ├─01 计算机基本介绍.mp4│ │ │ ├─02 硬件系统.avi│ │ │ ├─03 软件系统.avi│ │ │ ├─04 计算机组成总绍.avi│ │ │ ├─05 二进制基本介绍.avi│ │ │ ├─06 常见进制与转换.avi│ │ │ ├─07 其它进制转二进制.avi│ │ │ ├─08 编码基本介绍.avi│ │ │ ├─09 数据计量单位.avi│ │ │ ├─10 编程语言介绍.avi│ │ │ ├─11 编程语言完.avi│ │ │ ├─12 DOS 命令01.avi│ │ │ ├─13 DOS命令02.avi│ │ │ ├─14 xmind使用.avi│ │ ├─day2│ │ │ ├─01 回顾.avi│ │ │ ├─02 常见命令01.avi│ │ │ ├─03 常见DOS命令02.avi│ │ │ ├─04 练习讲解.avi│ │ │ ├─05 文件复制和剪切.avi│ │ │ ├─06 web与HTML基本介绍.avi│ │ │ ├─07 hbuilder 基本介绍.avi│ │ │ ├─08 网页的骨架介绍.avi│ │ │ ├─09 HTML语法介绍.avi│ │ │ ├─10 HTML标签语法补充.avi│ │ │ ├─11 图片基本使用.avi│ │ │ ├─11 图片属性总结.avi│ │ │ ├─13 超链接标签.avi│ │ ├─day3│ │ │ ├─01 回顾.avi│ │ │ ├─02 路径名词解释.avi│ │ │ ├─03 相对路径01.avi│ │ │ ├─04 相对路径02.avi│ │ │ ├─05 form 表单基本介绍.avi│ │ │ ├─06 form 标签属性.avi│ │ │ ├─07 常见的表单元素01.avi│ │ │ ├─08 常见的表单元素02.avi│ │ │ ├─09 web标准基本介绍.avi│ │ │ ├─10 CSS基本介绍.avi│ │ │ ├─11 CSS体验.avi│ │ │ ├─12 选择器基本介绍.avi│ │ │ ├─13 类名选择器使用.avi│ │ │ ├─14 id 选择器使用.avi│ │ │ ├─15 简单选择器及命名规则.avi│ │ ├─day4│ │ │ ├─01 作业回顾.avi│ │ │ ├─02 元素展示类型分类.avi│ │ │ ├─03 元素类型转换.avi│ │ │ ├─04 简单选择器权重.avi│ │ │ ├─05 CSS特性总结.avi│ │ │ ├─06 后代选择器.avi│ │ │ ├─07 选择器总结.avi│ │ │ ├─08 CSS写法介绍.avi│ │ │ ├─09 CSS文件存放位置总结.avi│ │ │ ├─10 练习总结.avi│ │ │ ├─11 音频标签基本介绍.avi│ │ │ ├─12 视频标签.avi│ │ │ ├─13 常见的文字样式.avi│ │ │ ├─14 内容总结.avi│ │ ├─day5│ │ │ ├─01 作业回顾.avi│ │ │ ├─02 文字阴影.avi│ │ │ ├─03 过渡属性.avi│ │ │ ├─04 软件测试行业基本介绍.avi│ │ │ ├─05 软件测试基本介绍.avi│ │ │ ├─06 测试对象.avi│ │ │ ├─07 测试级别01.avi│ │ │ ├─08 测试级别02.avi│ │ │ ├─09 系统测试分类.avi│ │ │ ├─10 常见测试方法.avi│ │ │ ├─11 软件质量特性.avi│ │ │ ├─12 软件测试流程.avi│ │ │ ├─13 常见软件架构.avi│ │ │ ├─14 浏览器和图片类型.avi│ ├─2.Linux和数据库SQL│ │ ├─2天linux视频教程│ │ │ ├─linux_day01│ │ │ │ ├─1-linux操作系统介绍.mp4│ │ │ │ ├─10-ls权限介绍.mp4│ │ │ │ ├─11-cp命令.mp4│ │ │ │ ├─12-mv命令.mp4│ │ │ │ ├─13-cat和重定向命令.mp4│ │ │ │ ├─14-more命令.mp4│ │ │ │ ├─15-管道.mp4│ │ │ │ ├─16-回顾今天.mp4│ │ │ │ ├─2-linux图形界面.mp4│ │ │ │ ├─3-linux目录结构.mp4│ │ │ │ ├─4-cd命令.mp4│ │ │ │ ├─5-ls命令.mp4│ │ │ │ ├─6-mkdir命令.mp4│ │ │ │ ├─7-touch命令.mp4│ │ │ │ ├─8-rm命令.mp4│ │ │ │ ├─9-命令格式介绍.mp4│ │ │ ├─linux_day02│ │ │ │ ├─1-回顾昨天.mp4│ │ │ │ ├─10-chmod命令字母法.mp4│ │ │ │ ├─11-chmod命令数字法.mp4│ │ │ │ ├─12-回顾今天.mp4│ │ │ │ ├─13-vim介绍.mp4│ │ │ │ ├─14-vim演示.mp4│ │ │ │ ├─2-软链接.mp4│ │ │ │ ├─3-硬链接.mp4│ │ │ │ ├─4-grep命令.mp4│ │ │ │ ├─5-find命令.mp4│ │ │ │ ├─6-tar打包.mp4│ │ │ │ ├─7-gzip命令.mp4│ │ │ │ ├─8-一步到位压缩和解压.mp4│ │ │ │ ├─9-其他命令.mp4│ │ ├─数据库4天│ │ │ ├─day01│ │ │ │ ├─1-数据库介绍.mp4│ │ │ │ ├─10-查询编辑器介绍.mp4│ │ │ │ ├─11-sql语句-创建表.mp4│ │ │ │ ├─12-sql语句-删除表.mp4│ │ │ │ ├─13-sql语句-增加数据.mp4│ │ │ │ ├─14-sql语句-删除修改数据.mp4│ │ │ │ ├─15-回顾今天.mp4│ │ │ │ ├─2-sql和mysql介绍.mp4│ │ │ │ ├─3-服务端和客户端.mp4│ │ │ │ ├─4-mysql安装.mp4│ │ │ │ ├─5-navicat操作.mp4│ │ │ │ ├─6-数据类型.mp4│ │ │ │ ├─7-主键约束.mp4│ │ │ │ ├─8-非空约束和默认值.mp4│ │ │ │ ├─9-备份与恢复.mp4│ │ │ ├─day02│ │ │ │ ├─1-逻辑删除.mp4│ │ │ │ ├─10-聚合函数.mp4│ │ │ │ ├─11-分组.mp4│ │ │ │ ├─12-分组后过滤.mp4│ │ │ │ ├─14-分页.mp4│ │ │ │ ├─15-分页练习.mp4│ │ │ │ ├─16-连接查询-等值连接.mp4│ │ │ │ ├─17-连接查询-内连接.mp4│ │ │ │ ├─2-简单查询.mp4│ │ │ │ ├─3-比较运算.mp4│ │ │ │ ├─4-逻辑运算.mp4│ │ │ │ ├─5-模糊查询.mp4│ │ │ │ ├─6-范围查询.mp4│ │ │ │ ├─7-空判断.mp4│ │ │ │ ├─8-回顾上午.mp4│ │ │ │ ├─9-排序.mp4│ │ │ ├─mysql_day03│ │ │ │ ├─1-3个表连接.mp4│ │ │ │ ├─10-行子查询.mp4│ │ │ │ ├─11-表子查询.mp4│ │ │ │ ├─12-子查询中关键字.mp4│ │ │ │ ├─13-回顾.mp4│ │ │ │ ├─14-查询演练-子查询.mp4│ │ │ │ ├─15-查询演练-数据分表.mp4│ │ │ │ ├─2-连接查询后过滤.mp4│ │ │ │ ├─3-左连接.mp4│ │ │ │ ├─4-右连接.mp4│ │ │ │ ├─5-自关联介绍.mp4│ │ │ │ ├─6-自关联查询.mp4│ │ │ │ ├─7-自关联关联3次.mp4│ │ │ │ ├─8-标量子查询.mp4│ │ │ │ ├─9-列子查询.mp4│ │ │ ├─mysql_day04│ │ │ │ ├─1-查询演练-数据分表.mp4│ │ │ │ ├─10-视图.mp4│ │ │ │ ├─11-事务.mp4│ │ │ │ ├─12-索引.mp4│ │ │ │ ├─13-外键.mp4│ │ │ │ ├─14-修改密码.mp4│ │ │ │ ├─15-忘记root密码.mp4│ │ │ │ ├─2-查询演练-连接查询.mp4│ │ │ │ ├─3-ER模型.mp4│ │ │ │ ├─4-命令行客户端.mp4│ │ │ │ ├─5-命令行客户端-备份与恢复.mp4│ │ │ │ ├─6-函数.mp4│ │ │ │ ├─7-流程控制语句.mp4│ │ │ │ ├─8-自定义函数.mp4│ │ │ │ ├─9-存储过程.mp4│ ├─3.深入了解软件测试基础视频│ │ ├─day1│ │ │ ├─01 开发--瀑布模型.mp4│ │ │ ├─02 软件开发模型.mp4│ │ │ ├─03 v模型概述.mp4│ │ │ ├─04 v模型优缺点.avi│ │ │ ├─05 w模型.avi│ │ │ ├─06 h模型简介和总结.avi│ │ │ ├─07 黑盒测试分类.avi│ │ │ ├─08 软件测试分类.avi│ │ │ ├─09 等价类划分法.avi│ │ │ ├─10 加法案例.avi│ │ │ ├─11 qq和电话号码案例.avi│ │ │ ├─12 登录界面.avi│ │ │ ├─13 总结.avi│ │ ├─day2│ │ │ ├─01 复习.avi│ │ │ ├─02 边界值.mp4│ │ │ ├─03 标题案例.mp4│ │ │ ├─04 成绩案例.avi│ │ │ ├─05 密码框案例.avi│ │ │ ├─06 边界值总结.avi│ │ │ ├─07 因果图符号.avi│ │ │ ├─08 因果图案例分析01.avi│ │ │ ├─09 因果图案例分析02.avi│ │ │ ├─10 判定表概念.avi│ │ │ ├─11 好学生判断.avi│ │ │ ├─12 场景法.avi│ │ │ ├─13 流程法.avi│ │ │ ├─14 错误推断法.avi│ │ │ ├─15 总结.avi│ │ ├─day3│ │ │ ├─01 复习.avi│ │ │ ├─02 正交表概念.mp4│ │ │ ├─03 正交表概念.mp4│ │ │ ├─04 114查询系统案例.avi│ │ │ ├─05 混合正交表的使用.avi│ │ │ ├─06 测试用例方法总结.avi│ │ │ ├─07 测试的力度和评审.avi│ │ │ ├─08 哪些属于软件缺陷.avi│ │ │ ├─09 缺陷的表现形式.avi│ │ │ ├─10 缺陷的根源、费用.avi│ │ │ ├─11 软件缺陷状态.avi│ │ │ ├─12 软件缺陷严重程度的划分.avi│ │ │ ├─13 软件测试优先级.avi│ │ │ ├─14 缺陷分类.avi│ │ │ ├─15 缺陷修改说明.avi│ │ │ ├─16 总结.avi│ │ ├─day4│ │ │ ├─01 复习.avi│ │ │ ├─02 缺陷报告注意事项.mp4│ │ │ ├─03 缺陷书写规范.mp4│ │ │ ├─04 缺陷的跟踪.avi│ │ │ ├─05 缺陷密度.avi│ │ │ ├─06 缺陷数据分析.avi│ │ │ ├─07 常见缺陷的查找.avi│ │ │ ├─08 缺陷管理级别.avi│ │ │ ├─09 svn的安装.avi│ │ │ ├─10 版本库新建、更新、提交.avi│ │ │ ├─11 添加和删除.avi│ │ │ ├─12 改名字.avi│ │ │ ├─13 文件的移动.avi│ │ │ ├─14 更新历史版本和权限.avi│ │ │ ├─15 总结.avi│ ├─4.编程数据结构python6学习教程│ │ ├─python6天│ │ │ ├─01课堂视频│ │ │ │ ├─01 计算机组成-硬件设备.mp4│ │ │ │ ├─02 计算机组成-软件设备.mp4│ │ │ │ ├─03 程序的执行流程和小结.mp4│ │ │ │ ├─04 编程语言和Python.mp4│ │ │ │ ├─05 Python开发环境.mp4│ │ │ │ ├─06 上午复习.mp4│ │ │ │ ├─07 Python语言介绍.mp4│ │ │ │ ├─08 Python基础语法介绍(非重要).mp4│ │ │ │ ├─09 注释的作用和语法.mp4│ │ │ │ ├─10 变量-变量的作用和命名规则.mp4│ │ │ │ ├─11 变量-变量的类型和作用.mp4│ │ │ │ ├─12 变量-不同类型变量的运算规则.mp4│ │ │ ├─02课堂视频│ │ │ │ ├─01 昨天复习.mp4│ │ │ │ ├─02 输入和输出_IO理解.mp4│ │ │ │ ├─03 输入和输出_标准输出函数_print函数.mp4│ │ │ │ ├─04 输入和输出_格式化输出.mp4│ │ │ │ ├─05 输入和输出_标准输入函数_input函数.mp4│ │ │ │ ├─06 变量类型转换.mp4│ │ │ │ ├─07 BUG学习.mp4│ │ │ │ ├─08 if语句_理解.mp4│ │ │ │ ├─09 if语句_练习.mp4│ │ │ │ ├─10 if语句_and、or、not运算规则.mp4│ │ │ │ ├─11 if语句_分数等级案例.mp4│ │ │ │ ├─12 if语句_猜拳游戏.mp4│ │ │ ├─03课堂视频│ │ │ │ ├─01 昨天复习.mp4│ │ │ │ ├─02 while循环_循环概述和语法格式.mp4│ │ │ │ ├─03 while循环_输出练习.mp4│ │ │ │ ├─04 while循环_计算累加练习.mp4│ │ │ │ ├─05 while循环_continue关键字.mp4│ │ │ │ ├─06 while循环_break关键字.mp4│ │ │ │ ├─07 while循环_课堂练习.mp4│ │ │ │ ├─08 while循环_课堂练习(2).mp4│ │ │ │ ├─09 函数_函数的概念和语法.mp4│ │ │ │ ├─10 函数_函数参数.mp4│ │ │ │ ├─11 函数_函数的返回值.mp4│ │ │ ├─04课堂视频│ │ │ │ ├─01 上次课程复习.mp4│ │ │ │ ├─02 函数强化练习.mp4│ │ │ │ ├─03 函数_位置参数在关键字参数前面.mp4│ │ │ │ ├─04 函数_return 关键字注意.mp4│ │ │ │ ├─05 函数_默认参数.mp4│ │ │ │ ├─06 函数_局部变量和全局变量.mp4│ │ │ │ ├─07 函数_函数文档.mp4│ │ │ │ ├─08 函数_单一职责原则.mp4│ │ │ │ ├─09 容器_容器概述.mp4│ │ │ │ ├─10 容器_字符串遍历.mp4│ │ │ │ ├─11 容器_字符串替换_replace.mp4│ │ │ │ ├─12 容器_字符串容器特点.mp4│ │ │ │ ├─13 容器_字符串_查找子字符串.mp4│ │ │ │ ├─14 容器_字符串切片.mp4│ │ │ │ ├─15 容器_字符串_完成邮箱案例.mp4│ │ │ │ ├─16 容器_字符串_切片负数步长.mp4│ │ │ │ ├─17 容器_字符串_完成邮箱案例_方式2.mp4│ │ │ │ ├─18 容器_字符串_去除两侧空格.mp4│ │ │ ├─05课堂视频│ │ │ │ ├─01 函数回顾.mp4│ │ │ │ ├─02 字符串回顾.mp4│ │ │ │ ├─03 列表定义.mp4│ │ │ │ ├─04 列表的遍历.mp4│ │ │ │ ├─05 列表遍历_while嵌套遍历.mp4│ │ │ │ ├─06 列表优缺点.mp4│ │ │ │ ├─07 列表_插入和删除.mp4│ │ │ │ ├─08 列表_元素排序.mp4│ │ │ │ ├─09 列表_查找元素.mp4│ │ │ │ ├─10 上午复习.mp4│ │ │ │ ├─11 列表案例_老师分配_创建老师.mp4│ │ │ │ ├─12 列表案例_老师分配_分配和打印老师.mp4│ │ │ │ ├─13 列表案例_老师分配_思路讲解.mp4│ │ │ │ ├─14 元组_元组定义.mp4│ │ │ │ ├─15 字典_字典定义.mp4│ │ │ │ ├─16 字典_添加和修改、获得元素.mp4│ │ │ ├─06课堂视频│ │ │ │ ├─01 昨天回顾.mp4│ │ │ │ ├─02 字典的遍历.mp4│ │ │ │ ├─03 字典_使用 while 循环遍历.mp4│ │ │ │ ├─04 员工管理系统_展示和思路分析.mp4│ │ │ │ ├─05 员工管理系统_框架搭建.mp4│ │ │ │ ├─06 员工管理系统_添加员工信息.mp4│ │ │ │ ├─07 员工管理系统_删除员工信息.mp4│ │ │ │ ├─08 员工管理系统_查看员工信息.mp4│ │ │ │ ├─09 员工管理系统_修改员工信息.mp4│ │ │ │ ├─10 文件_二进制模式和文本模式.mp4│ │ │ │ ├─11 文件_文件读写.mp4│ │ │ │ ├─12 文件编码.mp4│ │ │ │ ├─13 文件打开方式.mp4│ │ │ │ ├─14 文件读写方法.mp4│ │ │ │ ├─15 文件拷贝.mp4│ │ │ │ ├─16 文件和目录操作.mp4│ ├─5.web自动化测试视频selenium│ │ ├─day1│ │ │ ├─01_为什么要自动化测试.mp4│ │ │ ├─02_自动化优缺点.avi│ │ │ ├─03_自动化测试分类.avi│ │ │ ├─04_自动化测试课程大纲.avi│ │ │ ├─05_什么样的项目适合做自动化.avi│ │ │ ├─06_主流工具介绍.avi│ │ │ ├─07什么是Selenium.avi│ │ │ ├─08_selenium特点.avi│ │ │ ├─09_selenium家族介绍.avi│ │ │ ├─10_seleniumIDE安装方式.avi│ │ │ ├─11_练习1_tt官网.avi│ │ │ ├─12_Firebug安装.avi│ │ │ ├─13_firebug使用.avi│ │ │ ├─14_练习2_天涯论坛.avi│ │ │ ├─15_IDE脚本编辑与操作.avi│ │ │ ├─16_常用操作命令_1.avi│ │ │ ├─16_常用操作命令_2.avi│ │ │ ├─17_seleniumIDE安装与运行总结.avi│ │ │ ├─18_什么是WebDriver.avi│ │ │ ├─19_WebDriver支持的语言.avi│ │ │ ├─20_为什么要搭建环境.avi│ │ │ ├─21_selenium安装.avi│ │ │ ├─22_selenium安装、卸载、查看.avi│ │ │ ├─23_selenium-浏览器.avi│ │ │ ├─24_WebDriver概述、环境总结.avi│ │ │ ├─25_元素定位分类.avi│ │ ├─day2│ │ │ ├─01_回顾.avi│ │ │ ├─02_定位方式分类-汇总.avi│ │ │ ├─03_案例1-id定位分析.avi│ │ │ ├─04_案例1-id案例实践.avi│ │ │ ├─05_案例1-id知识拓展.avi│ │ │ ├─06_id定位总结.avi│ │ │ ├─07_name定位.avi│ │ │ ├─08_class定位.avi│ │ │ ├─09_tag_name定位.avi│ │ │ ├─10_link_text.avi│ │ │ ├─11_partial_link_text.avi│ │ │ ├─12_6种元素定位梳理.avi│ │ │ ├─13_find_elements_by_xxx.avi│ │ │ ├─14_2.1-2.6定位总结.avi│ │ │ ├─15_为什么学习Xpath和css定位.avi│ │ │ ├─16_Xpath定位策略介绍.avi│ │ │ ├─17_Xpath定位-绝对路径、相对路径分析.avi│ │ │ ├─18_Xpath定位-案例1.avi│ │ │ ├─19_层级与属性、属性与逻辑结合.avi│ │ │ ├─20_Xpath-延伸.avi│ │ │ ├─21_Firebug快速生成绝对路径及相对路径.avi│ │ │ ├─22_Xpath总结.avi│ │ │ ├─23_css常用定位方式.avi│ │ │ ├─24_css定位_id.avi│ │ │ ├─25_css_class、元素选择器、属性选择器、层级选择器.avi│ │ │ ├─26_css延伸.avi│ │ │ ├─27_css选择器总结.avi│ │ │ ├─28_css与Xpath类似功能对比.avi│ │ │ ├─29_八种元素总结-汇总.avi│ │ │ ├─30_元素定位另一种方法By.avi│ ├─6.移动端项目测试视频appium│ │ ├─api基础文件的上传和拉取操作 -08.mp4│ │ ├─api基础获取屏幕内元素-09.mp4│ │ ├─api基础（计算器小案例）-07.mp4│ │ ├─appium入门-案例流程图-04.mp4│ │ ├─appium入门案例实现（上）-05.mp4│ │ ├─appium入门案例实现（下）-06.mp4│ │ ├─appium安装-03.mp4│ │ ├─移动端测试知识－01.mp4│ │ ├─移动端测试知识－02.mp4│ ├─7.接口视频Jmeter│ │ ├─接口视频│ │ │ ├─day01视频│ │ │ │ ├─day01.01_接口测试_概述.avi│ │ │ │ ├─day01.02_接口测试_接口.avi│ │ │ │ ├─day01.03_接口测试_接口测试.avi│ │ │ │ ├─day01.04_接口测试_环境搭建.avi│ │ │ │ ├─day01.05_接口测试_插件安装.avi│ │ │ │ ├─day01.06_接口测试_RESTful_概述.avi│ │ │ │ ├─day01.07_接口测试_RESTful_风格.avi│ │ │ │ ├─day01.08_接口测试_JSON.avi│ │ │ │ ├─day01.09_接口测试_查询.avi│ │ │ │ ├─day01.10_接口测试_增删改.avi│ │ │ │ ├─day01.11_接口测试_总结.avi│ │ │ ├─day02视频│ │ │ │ ├─day02.01_Jmeter_概述.mp4│ │ │ │ ├─day02.02_Jmeter_安装以及简单实用.mp4│ │ │ │ ├─day02.03_Jmeter_线程组.avi│ │ │ │ ├─day02.04_Jmeter_线程组_应用.avi│ │ │ │ ├─day02.05_Jmeter_线程组_优化_http请求默认值.avi│ │ │ │ ├─day02.06_Jmeter_线程组_高级_属性与调度器.avi│ │ │ │ ├─day02.07_Jmeter_参数化_概述.avi│ │ │ │ ├─day02.08_Jmeter_参数化_CSV_实现思想.avi│ │ │ │ ├─day02.09_Jmeter_参数化_CSV_实现流程.avi│ │ │ │ ├─day02.10_Jmeter_参数化_CSV_流程总结.avi│ │ │ │ ├─day02.11_Jmeter_线程组_特殊线程组.avi│ │ │ │ ├─day02.12_Jmeter_线程组_总结.avi│ ├─8.性能测试LoadRunner│ │ ├─1-性能测试本质介绍.mp4│ │ ├─10-LoadRunner三大组件介绍.avi│ │ ├─11-协议探测器的使用.avi│ │ ├─12-录制脚本操作.avi│ │ ├─13-脚本查看方式以及函数介绍.avi│ │ ├─14-init和end和Action介绍.avi│ │ ├─15-LoadRunner脚本运行及查看结果.avi│ │ ├─16-Html不同录制级别的区别.avi│ │ ├─17-LoadRunner流程介绍.avi│ │ ├─18-案例分析及作业.avi│ │ ├─2-性能测试分类.avi│ │ ├─3-性能测试指标.avi│ │ ├─4-性能测试之需求分析.avi│ │ ├─5-性能测试之需求分析2.avi│ │ ├─6-性能测试计划和方案.avi│ │ ├─7-性能测试用例设计思路.avi│ │ ├─8-性能测试执行.avi│ │ ├─9-LoadRunner的安装和破解.avi│ ├─9.QC管理学习(类禅道)学习│ │ ├─day01│ │ │ ├─1-QC介绍.avi│ │ │ ├─10-创建项目第三种方式.avi│ │ │ ├─11-项目中添加用户以及创建项目管理员.avi│ │ │ ├─12-平台管理员添加方式.avi│ │ │ ├─13-QC平台的其他操作.avi│ │ │ ├─14-切换前台.avi│ │ │ ├─15-前台设置-个人信息修改.avi│ │ │ ├─16-前台设置-设置用户.avi│ │ │ ├─17-添加自定义组.avi│ │ │ ├─18-缺陷生命周期变化过程.avi│ │ │ ├─19-项目经理组缺陷状态参与.avi│ │ │ ├─2-QC的学习目标.avi│ │ │ ├─20-总结.avi│ │ │ ├─3-QC安装前提条件.avi│ │ │ ├─4-sqlserver的安装.avi│ │ │ ├─5-升级sp4.avi│ │ │ ├─6-QC安装.avi│ │ │ ├─7-QC的破解.avi│ │ │ ├─8-创建空项目.avi│ │ │ ├─9-创建项目方式2.avi│ │ ├─day02│ │ │ ├─1-缺陷生命周期定制.avi│ │ │ ├─10-缺陷模块.avi│ │ │ ├─11-缺陷中的字段介绍.avi│ │ │ ├─12-缺陷状态V1.0版本.avi│ │ │ ├─13-缺陷状态V2.0.avi│ │ │ ├─14-缺陷状态V3.0.avi│ │ │ ├─15-缺陷状态V4.0.avi│ │ │ ├─16-从excel表导入QC.avi│ │ │ ├─17-excel导入QC的步骤.avi│ │ │ ├─18-excel表导入QC排错.avi│ │ │ ├─19-QC总结.avi│ │ │ ├─2-设置项目模板字段类型.avi│ │ │ ├─3-设置项目模板用户自定义字段.avi│ │ │ ├─4-项目下拉列表.avi│ │ │ ├─5-需求模块.avi│ │ │ ├─6-用例模块.avi│ │ │ ├─7.用例集模块-执行一条用例.avi│ │ │ ├─8-用例集模块-多条用例执行.avi│ │ │ ├─9-用例执行过程中提交Bug.avi│ ├─软件测试教程讲义│ │ ├─QC管理工具视频(类禅道软件)讲义│ │ │ ├─day01│ │ │ │ ├─1-教学资料│ │ │ │ │ ├─测试工具QC.xmind│ │ │ │ ├─2-其他资料（含笔记+总结）.rar│ │ │ ├─day02│ │ │ │ ├─1-教学资料│ │ │ │ │ ├─QC课程第二天.xmind│ │ │ │ ├─2-其他资料（含笔记+总结）.rar│ │ ├─linux基本命令讲义│ │ │ ├─linux基本命令.pdf│ │ ├─python讲义│ │ │ ├─python讲义.pdf│ │ ├─web自动化讲义│ │ │ ├─web自动化讲义.pdf│ │ ├─基础班笔记│ │ │ ├─01 计算机基础.doc│ │ │ ├─02 HTML01.doc│ │ │ ├─03 HTML03.doc│ │ │ ├─04 HTML04.doc│ │ │ ├─05 软件质量.doc│ │ ├─性能测试笔记│ │ │ ├─2-性能测试资料│ │ │ │ ├─性能测试分类浅谈.docx│ │ │ │ ├─性能测试场景用例模版.doc│ │ │ │ ├─性能测试脚本用例模版.doc│ │ ├─接口讲义│ │ │ ├─接口讲义.pdf│ │ ├─数据库讲义│ │ │ ├─数据库讲义.pdf│ │ ├─深入了解软件测试资料│ │ │ ├─day1资料.zip│ │ │ ├─day2资料.zip│ │ │ ├─day3资料.zip│ │ │ ├─day4资料.zip│ ├─软件测试相搭配的测试工具│ │ ├─LNMP工具│ │ │ ├─ZenTaoPMS.8.2.5.zip│ │ │ ├─iwebshop2.1.11090110_data.zip│ │ │ ├─libiconv-1.14.tar.gz│ │ │ ├─mysql-5.6.35-linux-glibc2.5-x86_64.tar.gz│ │ │ ├─nginx-1.10.2.tar.gz│ │ │ ├─php-5.3.29.tar.gz│ │ ├─linux相关工具│ │ │ ├─CentOS6.vmwarevm.zip│ │ │ ├─VMwareworkstation_full_12.1.0.2487.1453173744.exe│ │ ├─mysql相关工具│ │ │ ├─mysql-essential-5.1.55-win32.zip│ │ │ ├─navicat112_premium_cs_x86.exe│ │ │ ├─navicat注册机.7z│ │ │ ├─npp.7.2.Installer.x32.exe│ │ ├─web自动化相关工具│ │ │ ├─65.0.3311.4_chrome_installer.exe│ │ │ ├─Firefox 35.0.1.dmg│ │ │ ├─Firefox Setup 35.0.1.exe│ │ │ ├─chromedriver.exe│ │ │ ├─firebug-2.0.19.xpi│ │ │ ├─firepath-0.9.7-fx.xpi│ │ │ ├─pycharm-community-2018.1.dmg│ │ │ ├─python-3.6.4.exe│ │ │ ├─python-3.6.5-macosx10.9.pkg│ │ │ ├─selenium-2.48.0.tar.gz│ │ │ ├─selenium_ide-2.9.1-fx.xpi│ │ ├─基础班工具│ │ │ ├─ChromeStandalone_65.0.3325.162_Setup.exe│ │ │ ├─Firefox-59.0.1.6648-setup(1).exe│ │ │ ├─HBuilder.9.0.2.windows.zip│ │ │ ├─xmind.exe│ │ ├─接口相关工具│ │ │ ├─Firefox Setup 24.0.rar│ │ │ ├─Typora.rar│ │ │ ├─apache-jmeter-3.1.zip│ │ │ ├─jdk-8u144-windows-x64.exe│ │ │ ├─jmeter环境.rar│ │ │ ├─mysql-connector-java-5.1.35-bin.jar│ │ │ ├─python-3.5.0-amd64（64位）.exe│ │ │ ├─sqlite-jdbc-3.21.0.jar│ │ │ ├─sqlitestudio-3.1.1.zip│ │ │ ├─谷歌.rar├─09.软件测试工具│ ├─LNMP工具│ │ ├─ZenTaoPMS.8.2.5.zip│ │ ├─iwebshop2.1.11090110_data.zip│ │ ├─libiconv-1.14.tar.gz│ │ ├─mysql-5.6.35-linux-glibc2.5-x86_64.tar.gz│ │ ├─nginx-1.10.2.tar.gz│ │ ├─php-5.3.29.tar.gz│ ├─linux相关工具│ │ ├─CentOS6.vmwarevm.zip│ │ ├─VMwareworkstation_full_12.1.0.2487.1453173744.zip│ ├─mysql相关工具│ │ ├─mysql-essential-5.1.55-win32.zip│ │ ├─navicat112_premium_cs_x86.zip│ │ ├─navicat注册机.7z│ │ ├─npp.7.2.Installer.x32.zip│ ├─所有测试工具软件集合│ │ ├─65.0.3311.4_chrome_installer.zip│ │ ├─ChromeStandalone_65.0.3325.162_Setup.zip│ │ ├─Firefox 35.0.1.dmg│ │ ├─HBuilder.9.0.2.windows.zip│ │ ├─MySql jar包.zip│ │ ├─PostMan.rar│ │ ├─QTP工具│ │ │ ├─QTP10.iso│ │ │ ├─QTP10汉化-T6803-15001（HP Functional Testing 10.00 Simplified Chinese Software）.iso│ │ │ ├─QTP10破解.rar│ │ ├─Typora.rar│ │ ├─VMwareworkstation_full_12.1.0.2487.1453173744.zip│ │ ├─allpairs.rar│ │ ├─apache-jmeter-3.1.zip│ │ ├─chromedriver.zip│ │ ├─fiddler.zip│ │ ├─fiddler4_4.6.1.5.zip│ │ ├─firebug-2.0.19.xpi│ │ ├─firepath-0.9.7-fx.xpi│ │ ├─iwebshop2.1.11090110_data.zip│ │ ├─jdk-8u144-windows-x64.zip│ │ ├─jenkins-1.642.4.zip│ │ ├─jmeter环境.rar│ │ ├─loadrunner工具│ │ │ ├─loadrunner-11安装程序│ │ │ │ ├─loadrunner-11.rar│ │ │ ├─loadrunner-11汉化破解│ │ │ │ ├─HP LoadRunner 11.00 Patch Chinese.iso│ │ │ │ ├─lr破解.zip│ │ ├─pycharm-community-2018.1.dmg│ │ ├─python-3.5.0-amd64（64位）.zip│ │ ├─python-3.6.4.zip│ │ ├─python-3.6.5-macosx10.9.zip│ │ ├─selenium-2.48.0.tar.gz│ │ ├─selenium_ide-2.9.1-fx.xpi│ │ ├─sqlitestudio-3.1.1.zip│ │ ├─xmind.zip├─10.超值面试简历视频│ ├─01.面试指导视频.zip│ ├─02. 12套简历+封面+自荐信.rar│ ├─03.程序员专用简历.rar│ ├─04.套中英文简历.rar├─11.软件测试各种模板文档│ ├─学习软件测试所用各种文档（十年测试经验分享）.zip├─测试宝典V1_1_定版.pdf 不过，有群友反应，这套资源不全。 因为，在看视频的过程中，发现《5.web自动化测试视频selenium-day01的04_自动化测试大纲》中，提到有四个章节，并且有 UnitTest 相关的内容，但是发现上面的目录中根本没有 UnitTest 相关的字眼，所以，这位群友怀疑视频不全。 这简直就是群友里的福尔摩斯啊！ P.S. 从上面截图可以看出，两点：1】2018的视频；2】清晰度还不错； 我处于人道主义，主动扛起了找一套完整视频的艰巨任务！ 于是我又进入了纷繁的资源世界！ 你还别说，还真让我找到了一套很接近答案的答案： 很完整，有没有？ web 自动化测试是 5 天版本，有没有？ 下面，验货吧~ 精力有限，我只能随机采样了。 嗯，清晰度也不错，还是用 Mac 讲的。 接下来，重要的环节，时间！ 首先想到的是取代码注释里找，无奈，这位老师没有按套路写注释： 不过在代码文件里看到了一个日志文件： 结果很明显了，是 2017 年的视频。 另外，视频中的一个图也可以验证： 老师登录网易邮箱时的画面里截取的。 不过，有影响吗？ 2017 的和 2018 的差别很大吗？ 我们需要追求最新的吗？ 我觉得完全没必要 学习，2017 的也足够了！ 好了，两套都分享给大家。 关注下方公众号，后台回复【008】获取黑马测试 2018 款视频，回复【009】获取黑马测试 2017 款。 声明：以上所有资源均来自网络，如有侵权请联系本人删除。]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网页上复制文字，粘贴后出现乱码]]></title>
    <url>%2Fcopy-from-internet-has-unusual-code.html</url>
    <content type="text"><![CDATA[发现这么一个问题： 想从某网页上复制一些文字，结果发现，粘贴出来，好多乱码！ 问题发现这么一个问题： 想从某网页上复制一些文字，结果发现，粘贴出来，好多乱码！ 123│ │ │ ├─11 编程语言完.avi/ y7 ~6 |* M l│ │ │ ├─12 DOS 命令01.avi% J0 t0 r6 j0 r" Z- E- u│ │ │ ├─13 DOS命令02.avi 我又仔细去网页上看了一下： 看到没，很多隐藏的乱码！ 看下网页源代码： 123456&lt;span style="display:none"&gt;&amp;nbsp;&amp;nbsp;k: r; x0 \( y, t&lt;/span&gt;│&amp;nbsp;&amp;nbsp;│&amp;nbsp;&amp;nbsp;│&amp;nbsp;&amp;nbsp;├─11 编程语言完.avi&lt;font class="jammer"&gt;/ y7 ~6 |* M&amp;nbsp;&amp;nbsp;l&lt;/font&gt;&lt;br /&gt; │&amp;nbsp;&amp;nbsp;│&amp;nbsp;&amp;nbsp;│&amp;nbsp;&amp;nbsp;├─12 DOS 命令01.avi&lt;font class="jammer"&gt;% J0 t0 r6 j0 r&amp;quot; Z- E- u&lt;/font&gt;&lt;br /&gt; │&amp;nbsp;&amp;nbsp;│&amp;nbsp;&amp;nbsp;│&amp;nbsp;&amp;nbsp;├─13 DOS命令02.avi&lt;br /&gt; 明显，这里的乱码就是使用 Span 标签，通过定义 CSS 来控制乱码不在网页上显示。 解决方法1、查看页面源文件，将带有想复制内容那一部分复制粘贴到记事本，或者直接网页另存为； 2、利用文本编辑器打开保存的 HTML 文件，将其中“span”全替换为“title”。 3、重新打开本地保存的 HTML 文件，再复制就正常了。 另外还有两种常用的隐藏乱码的方法，对于这两个隐藏乱码的页面也可以参照上面的两个方法进行处理。 这两个乱码定义如下： 12&lt;font style="font-size:0px;color:#FFFFFF"&gt;乱码文字&lt;/font&gt; 定义白色背景下的段尾乱码；&lt;font style="font-size:0px;color:#F5F5F5"&gt;乱码文字&lt;/font&gt; 定义淡蓝色背景下的段尾乱码； 参考方法：第一种方法的处理，不同的是第 3 步，选择不同的标签，而第二解决方法即把span变为font，即可实现。}]]></content>
      <categories>
        <category>绊脚石</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 15 Mysql 中 order by 是如何工作的？]]></title>
    <url>%2Fmysql-zhuanlan-15-how-order-by-works.html</url>
    <content type="text"><![CDATA[有如下 SQL 语句： 1select city,name,age from t where city='杭州' order by name limit 1000 ; 执行流程是怎样的？ 全字段排序MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。 这里使用 city 作为查询条件，为了避免全表扫描，可以在 city 上加上索引。 上面语句的执行流程如下： 1、初始化 sort_buffer，确定放入 city、name、age 三个字段；2、从索引中找到第一个满足 city 条件的主键 id；3、回表，根据主键 id 取出整行数据，取 city、name、age 三个字段的值，存入 sort_buffer；4、重复步骤 2、3，这样所有满足 city 条件的字段，并存入到了 sort_buffer 中；5、对 sort_buffer 中的数据按字段 name 做快速排序；6、按照排序结果取前 1000 行返回给客户端。 执行流程如下图所示： 可以看出，排序是在 sort_buffer 中完成的，若 sort_buffer_size 的大小不足以放下待排序的数据，那么就需要借助磁盘临时文件来完成。 你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。 1234567891011121314151617/* 打开 optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; /* @a 保存 Innodb_rows_read 的初始值 */select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* 执行语句 */select city, name,age from t where city='杭州' order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G/* @b 保存 Innodb_rows_read 的当前值 */select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* 计算 Innodb_rows_read 差值 */select @b-@a; 这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files 中看到是否使用了临时文件。 number_of_tmp_files 表示排序过程中用到的临时文件数。 内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件。 examined_rows 表示参与排序的行数是 4000 行。 sort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。 rowid 排序上述算法中，只对原表中的数据读了一次，剩下的操作都是在 sort_buffer 和临时文件中进行的，如果要返回的字段过多时， sort_buffer 明显放不下，这样就要用到很多临时文件，排序性能就会很差。 1SET max_length_for_sort_data = 16; max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。 新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。 新算法的执行流程： 1、初始化 sort_buffer，确定放入 name、id 两个字段；2、从索引中找到第一个满足 city 条件的主键 id；3、回表，根据主键 id 取出整行数据，取 name、id 的值，存入 sort_buffer；4、重复步骤 2、3，这样所有满足 city 条件的字段，并存入到了 sort_buffer 中；5、对 sort_buffer 中的数据按字段 name 做快速排序；6、遍历排序结果，取前 1000 行，按照 id 再去原表查询 city、name 和 age 三个字段返回给客户端。 如下图： 全字段排序 VS rowid 排序如果担心内存小，影响排序效率，才会采用 rowid 排序算法，但是需要回到原表查询结果； 如果内存足够大，MySQL 会优先选择全字段排序。 体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。 优化如果能够保证从 city 取出的数据已经是按 name 递增排序的，那就不用再排序了。 比如，这样的联合索引： 1alter table t add index city_user(city, name); 那么查询流程就变成了这样： 1、从索引 (city,name) 中找到第一个满足 city 条件的主键 id；2、回表，根据主键 id 取出整行数据，取 city、name、age 三个字段的值，作为结果集直接返回；3、重复 1、2 步骤，直到 city 条件不再满足； 如图： 还可以利用覆盖索引，继续优化，减少回表的步骤！ 1alter table t add index city_user_age(city, name, age);]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超细讲解Django打造大型企业官网【全集】]]></title>
    <url>%2Fresource-django-netease-class.html</url>
    <content type="text"><![CDATA[今天，群里的小伙伴让帮忙下载个资源，我看了下，还不错，就分享给大家。 黄易网易云课堂价值 499 的《超细讲解Django打造大型企业官网》全套视频。 官方课程概述本套课程的目标是从零基础开始，使用 Django 框架开发企业级的项目。 课程知识点全网最详细，项目实战最贴近企业需求。本套课程除了非常详细的讲解 Django 框架本身的知识点以外，还讲解了 web 开发中所需要用到的技术，比如有短信验证码、图形验证码、邮件发送、ajax等。 更紧随时代潮流加入了第三方分享服务、视频加密播放技术、支付功能等。 学完本套课程后，你将独立做出一个具有后台管理系统，并且前端非常优美实用的网站。对于从事一份 python web 开发相关的工作简直轻而易举！还在等什么？赶快来学习吧！ 课程目录课程一共 335 节课，目录较长，你们随意感受下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346目录连载章节1jango预热课时1【虚拟环境】为什么需要虚拟环境06:30课时2【虚拟环境】virtualenv创建虚拟环境13:57课时3【虚拟环境】virtualenvwrapper使用16:44课时4【Django预热】URL组成部分详解14:04课时5【Django预热】课程准备工作08:49课时6【Django预热】Django介绍13:44章节2jango URL课时7【Django URL】第一个Django项目剖析（1）22:11课时8【Django URL】第一个Django项目剖析（2）23:40课时9【Django URL】Django的项目规范20:10课时10【Django URL】DEBUG模式详解13:08课时11【Django URL】视图函数介绍08:57课时12【Django URL】URL映射补充05:08课时13【Django URL】url中传递参数给视图函数20:05课时14【Django URL】Django内置的URL转换器14:42课时15【Django URL】urls分层模块化13:42课时16【Django URL】url命名与反转url28:28课时17【Django URL】应用命名空间和实例命名空间09:52课时18【Django URL】include函数详解13:54课时19【Django URL】re_path函数详解19:02课时20【Django URL】reverse函数补充16:13课时21【Django URL】自定义path转换器35:36课时22【Django URL】URL映射时指定默认参数09:52章节3jango模版课时23【Django模版】模版介绍16:01课时24【Django模版】模版查找路径配置15:55课时25【Django模版】模版变量使用详解25:12课时26【Django模版】if标签使用详解10:32课时27【Django模板】for标签使用详解23:22课时28【Django模块】with标签使用详解08:53课时29【Django模板】url标签使用详解19:45课时30【Django模板】autoescape标签使用详解10:15课时31【Django模板】verbatim标签使用详解07:53课时32【Django模板】DTL常用过滤器（1）16:16课时33【Django模版】DTL常用过滤器（2）12:04课时34【Django模板】DTL常用过滤器（3）11:54课时35【Django模板】DTL常用过滤器（4）11:59课时36【Django模板】DTL常用过滤器（5）12:20课时37【Django模板】自定义过滤器步骤详解15:29课时38【Django模板】自定义过滤器实战15:37课时39【Django模版】模版结构优化之include标签详解16:57课时40【Django模版】模版结构优化之继承详解16:30课时41【Django模版】模版中加载静态文件详解38:14章节4jango数据库课时42【Django数据库】数据库操作相关软件和包介绍16:57课时43【Django数据库】Django使用原生SQL语句操作数据库24:58课时44【Django数据库】图书管理系统案例（1）31:21课时45【Django数据库】图书管理系统案例（2）24:16课时46【Django数据库】ORM模型介绍15:02课时47【Django数据库】创建和映射ORM模型25:13课时48【Django数据库】ORM模型基本的增删改查操作28:48课时49【Django数据库】ORM常用Field详解（1）22:45课时50【Django数据库】navie时间和aware时间详解27:44课时51【Django数据库】ORM常用Field详解（2）26:42课时52【Django数据库】ORM常用Field详解（3）13:48课时53【Django数据库】Field中常用参数详解25:06课时54【Django数据库】Meta类中常见配置13:02课时55【Django数据库】ORM外键使用详解29:52课时56【Django数据库】ORM外键删除操作详解26:23课时57【Django数据库】表关系之一对多25:55课时58【Django数据库】表关系之一对一23:42课时59【Django数据库】表关系之多对多21:36课时60【Django数据库】ORM查询条件详解-准备工作16:30课时61【Django数据库】pycharm连接数据库05:48课时62【Django数据库】ORM查询条件详解-exact和iexact23:40课时63【Django数据库】ORM查询条件详解-contains和Icontains16:11课时64【Django数据库】ORM查询条件详解-in和关联模型查询30:43课时65【Django数据库】ORM查询条件详解-gt、gte、lt和lte05:49课时66【Django数据库】ORM查询条件详解-startswith和endswith07:08课时67【Django数据库】ORM查询条件详解-range11:15课时68【Django数据库】ORM查询条件详解-date、time、year、week_day等22:46课时69【Django数据库】ORM查询条件详解-isnull和regex08:00课时70【Django数据库】ORM聚合函数详解-准备工作11:07课时71【Django数据库】ORM聚合函数详解-Avg16:57课时72【Django数据库】ORM聚合函数详解-aggregate和annotate18:43课时73【Django数据库】ORM聚合函数详解-Count15:48课时74【Django数据库】ORM聚合函数详解-Max和Min06:45课时75【Django数据库】ORM聚合函数详解-Sum17:09课时76【Django数据库】F表达式详解16:16课时77【Django数据库】Q表达式详解18:12课时78【Django数据库】objects对象所属类原理剖析24:02课时79【Django数据库】QuerySet API详解-filter、exclude、annotate18:08课时80【Django数据库】QuerySet API详解-order_by31:19课时81【Django数据库】QuerySet API详解-values和values_list27:17课时82【Django数据库】QuerySet API详解-all方法05:02课时83【Django数据库】QuerySet API详解-select_related13:11课时84【Django数据库】QuerySet API详解-prefetch_related29:50课时85【Django数据库】QuerySet API详解-defer和only12:37课时86【Django数据库】QuerySet API详解-get方法04:59课时87【Django数据库】QuerySet API详解-create方法04:12课时88【Django数据库】QuerySet API详解-get_or_create和bulk_create08:17课时89【Django数据库】QuerySet API详解-count和exists12:27课时90【Django数据库】QuerySet API详解-distinct09:22课时91【Django数据库】QuerySet API详解-update和delete10:00课时92【Django数据库】QuerySet API详解-切片操作09:01课时93【Django数据库】QuerySet API详解-QuerySet转换为SQL的条件07:34课时94【Django数据库】ORM作业讲解-准备工作09:06课时95【Django数据库】ORM作业讲解（1）15:45课时96【Django数据库】ORM作业讲解（2）07:03课时97【Django数据库】ORM作业讲解（3）16:36课时98【Django数据库】ORM迁移详解-migrations命令补充14:23课时99【Django数据库】ORM迁移详解-migrate命令报错解决方案37:51课时100【Django数据库】根据已有的表生成ORM模型详解40:06课时101Django数据库练习题章节5jango视图高级课时102【Django视图高级】限制请求method装饰器32:22课时103【Django视图高级】重定向详解17:27课时104【Django视图高级】HttpRequest对象讲解23:24课时105【Django视图高级】QueryDict的用法讲解18:31课时106【Django视图高级】HttpResponse对象讲解.15:18课时107【Django视图高级】JsonResponse用法详解06:21课时108【Django视图高级】生成和下载csv文件16:27课时109【Django视图高级】大型CSV文件的处理方式16:37课时110【Django视图高级】类视图讲解18:22课时111【Django视图高级】TemplateView讲解06:20课时112【Django视图高级】ListView视图讲解23:32课时113【Django视图高级】Paginator和Page类常用属性和方法11:09课时114【Django视图高级】手动实现普通分页效果18:05课时115【Django视图高级】手动实现通用分页算法25:36课时116【Django视图高级】给类视图添加装饰器09:30课时117【Django视图高级】状态码错误处理19:34章节6jango表单课时118【Django表单】Django中表单的使用方式38:55课时119【Django表单】用表单验证数据是否合法14:53课时120【Django表单】表单中常用的验证器.08:18课时121【Django表单】自定义验证字段的方法22:20课时122【Django表单】简化表单错误信息的提取09:39课时123【Django表单】ModelForm用法讲解（1）18:46课时124【Django表单】ModelForm用法讲解（2）14:35课时125【Django文件上传】文件上传基本流程讲解08:24课时126【Django文件上传】自动处理上传的文件和获取上传文件url17:26课时127【Django文件上传】限制上传的文件类型11:38章节7:Memcached缓存系统课时128【memcached】memcached介绍11:02课时129【memcached】memcached的安装和参数详解28:22课时130【memcached】telnet操作memcached30:52课时131【memcached】Python操作memcached24:12课时132【memcached】memcached的安全机制12:36课时133【memcached】在django中使用memcached20:54章节8:Cookie和Session课时134【Cookie和Session】cookie的工作机制10:45课时135【Cookie和Session】在django中操作cookie25:22课时136【Cookie和Session】Session的概念和机制09:28课时137【Cookie和Session】在Django中操作session23:09课时138【Cookie和Session】更改Session的存储机制08:53章节9:上下文处理器和中间件课时139【上下文处理器】用户系统案例35:00课时140【上下文处理器】用上下文处理器完善用户系统案例16:00课时141【上下文处理器】内置上下文处理器讲解-debug、request、auth08:59课时142【上下文处理器】内置上下文处理器讲解-messages18:33课时143【上下文处理器】内置上下文处理器讲解-media、static、csrf15:11课时144【中间件】中间件原理和定义方式详解29:08课时145【中间件】中间件第三种即将被遗弃的写法06:52课时146【中间件】内置中间件详解-CommonMiddleware14:43课时147【中间件】内置中间件详解-GZip、Messages、Security等18:47章节10:安全课时148【CSRF攻击】CSRF攻击介绍和原理分析06:42课时149【CSRF攻击】攻击案例-ICBC项目结构搭建18:35课时150【CSRF攻击】攻击案例-ICBC网站登录、注册、转账功能实现24:26课时151【CSRF攻击】攻击案例-装饰器和中间件优化ICBC网站15:46课时152【CSRF攻击】攻击案例-病毒网站实现隐藏转账14:50课时153【CSRF攻击】攻击案例-CSRF防御原理和解决方案09:04课时154【CSRF攻击】Ajax处理CSRF防御22:10课时155【XSS攻击】XSS攻击原理.13:03课时156【XSS攻击】XSS攻击防御-普通字符串处理07:16课时157【XSS攻击】XSS攻击防御-富文本字符串处理21:03课时158【ClickJacking攻击】点击劫持攻击实现和防御措施18:46课时159【SQL注入】SQL注入的实现和防御措施20:20章节11:验证和授权课时160【验证和授权】验证和授权系统概述00:00课时161【验证和授权】内置User模型的基本使用20:09课时162【验证和授权】扩展User模型-使用Proxy模型12:40课时163【验证和授权】扩展User模型-一对一方式扩展23:27课时164【验证和授权】扩展User模型-继承AbstractUser25:21课时165【验证和授权】扩展User模型-继承AbstractBaseUser19:31课时166【验证和授权】登录、退出登录以及登录限制案例27:38课时167【验证和授权】权限-添加权限的两种方式12:05课时168【验证和授权】权限-用户和权限相关操作13:10课时169【验证和授权】权限-权限验证装饰器10:35课时170【验证和授权】分组-group、permission、user的操作14:04课时171【验证和授权】补充-在模板中添加权限控制05:22章节12:Redis键值对数据库课时172【Redis】Redis概述和使用场景介绍16:01课时173【Redis】Redis的安装以及客户端连接07:09课时174【Redis】Redis的字符串以及过期时间操作06:50课时175【Redis】Redis列表操作15:29课时176【Redis】Redis集合操作10:30课时177【Redis】Redis的哈希操作09:35课时178【Redis】Redis的事务操作09:50课时179【Redis】Redis的发布和订阅操作06:15课时180【Redis】RDB和AOF的两种数据持久化机制38:09课时181【Redis】Redis设置连接密码07:03课时182【Redis】其他机器连接本机redis06:55课时183【Redis】Python操作redis21:11章节13:项目实战课时184【前端环境配置】项目实战演示和环境说明16:26课时185【前端环境配置】nvm和node.js环境配置15:00课时186【前端环境配置】npm使用详解07:22课时187【gulp配置】gulp介绍和安装14:31课时188【gulp配置】gulp创建任务03:58课时189【gulp配置】gulp创建处理css文件任务08:49课时190【gulp配置】gulp给文件重命名05:40课时191【gulp配置】gulp处理JavaScript文件的任务12:18课时192【gulp配置】合并多个文件07:32课时193【gulp配置】创建压缩图片任务06:11课时194【gulp配置】监听文件修改，自动执行任务05:09课时195【gulp配置】修改代码实时刷新浏览器10:38课时196【项目环境搭建】项目环境搭建和安装相应包08:51课时197【项目环境搭建】编写gulpfile.js文件16:07课时198【项目环境搭建】sass语法介绍和转换为css22:00课时199【前端首页】导航条实现（1）16:14课时200【前端首页】导航条实现（2）21:20课时201【前端首页】导航条实现（3）13:43课时202【前端首页】主题盒子布局和导航条吸顶效果13:08课时203【前端首页】轮播图布局和样式16:58课时204【前端首页】JS面向对象和实现一次轮播29:56课时205【前端首页】实现自动轮播08:13课时206【前端首页】鼠标hover事件控制轮播图暂停和继续16:42课时207【前端首页】切换轮播图的箭头样式及其显示和隐藏事件15:22课时208【前端首页】轮播图上下切换22:38课时209【前端首页】小圆点结构和样式17:59课时210【前端首页】根据轮播图的个数动态修改小圆点结构和样式09:28课时211【前端首页】小圆点点击事件和自动更新当前选中的小圆点15:13课时212【前端首页】实现自动无限循环轮播20:50课时213【前端首页】左右箭头切换实现循环轮播.04:34课时214【前端首页】新闻列表tab栏布局完成15:09课时215【前端首页】新闻列表页布局完成28:12课时216【前端首页】加载更多按钮的布局和样式06:15课时217【前端首页】侧边栏-标题和广告位布局完成10:01课时218【前端首页】侧边栏-关注第三方平台盒子布局和样式29:33课时219【前端首页】侧边栏-热门推荐完成20:14课时220【前端首页】footer布局和样式（1）29:49课时221【前端首页】footer布局和样式（2）24:40课时222【新闻详情页】样式重构和模块化21:47课时223【新闻详情页】新闻详情标题和作者等信息布局完成29:47课时224【新闻详情页】新闻内容布局完成06:14课时225【新闻详情页】登录和未登录下评论输入框的布局27:40课时226【新闻详情页】评论列表布局完成10:29课时227【课堂首页】课程首页整体布局和样式抽取06:23课时228【课堂首页】课堂导航条完成20:17课时229【课堂首页】课程列表单个课程布局19:41课时230【课堂首页】使用flex实现多个课程自动布局11:53课时231【课堂首页】鼠标hover到课程上的悬浮效果03:38课时232【课堂首页】scss文件重构06:50课时233【课堂详情页】课程详情页整体布局08:27课时234【课程详情页】课程详情页布局（1）21:15课时235【课程详情页】课程详情页布局（2）27:13课时236【课程详情页】课程详情页布局（3）15:28课时237【其他页面】剩余页面代码解析09:40课时238【登录和注册】登录和注册的模态对话框实现26:47课时239【登录和注册】实现关闭和隐藏模态对话框13:04课时240【登录和注册】登录和注册页面切换16:41课时241【登录和注册】登录页面元素布局完成14:31课时242【登录和注册】登录和注册页面完成14:43课时243【后端开发】后端开发准备工作16:55课时244【后端开发】adminlte框架集成和登录页面实现17:26课时245【后端开发】User模型创建27:43课时246【后端开发】登录功能实现（1）31:34课时247【后端开发】登录功能实现（2）05:59课时248【后端开发】重构Restful API的实现17:20课时249【后端开发】将静态页面改造成Django模板（1）19:56课时250【后端开发】将静态页面改造成Django模板（2）09:44课时251【前端开发】登录模态对话框和网站的集成29:53课时252【前端开发】登录功能和模态对话框集成20:31课时253【前端开发】toast提示错误消息15:44课时254【后端开发】登录状态更改和退出登录18:46课时255【后端开发】图形验证码的制作和点击更换27:45课时256【后端开发】短信验证码的发送29:26课时257【后端开发】短信验证码与注册页面的集成24:14课时258【后端开发】memcached存储验证码08:42课时259【后端开发】注册功能后台代码完成15:02课时260【后端开发】注册页面前端逻辑完成25:58课时261【后端开发】CMS管理系统访问和限制11:30课时262【后端开发】CMS管理页面主框架搭建23:49课时263【后端开发】新闻发布页面布局完成27:02课时264【后端开发】解决首页下拉菜单的小bug06:54课时265【后端开发】新闻分类模板完成13:30课时266【后端开发】添加新闻分类前后台功能完成33:11课时267【后端开发】新闻分类的编辑和删除功能实现22:46课时268【后端开发】新闻分类细节补充（不能错过）11:50课时269【后端开发】使用ajax上传缩略图到自己的服务器31:53课时270【后端开发】使用ajax上传图片到七牛云40:39课时271【后端开发】ajax上传图片到七牛细节处理24:21课时272【后端开发】UEditor富文本编辑器的集成34:09课时273【后端开发】发布新闻功能完成22:43课时274【后端开发】将首页新闻列表改成活的数据11:18课时275【后端开发】djangorestframework实现新闻列表功能31:21课时276【后端开发】将JSON数据渲染成html页面26:57课时277【后端开发】给arttemplate添加时间处理过滤器11:40课时278【后端开发】切换分类异步加载文章22:09课时279【后端开发】新闻详情页完成16:05课时280【后端开发】新闻查询性能优化08:17课时281【后端开发】django-debug-toolbar使用详解21:40课时282【后端开发】新闻评论后端功能实现11:12课时283【后端开发】新闻评论前端功能实现26:56课时284【后端开发】新闻详情页ORM性能优化08:41课时285【后端开发】自定义login_required限制访问09:19课时286【后端开发】轮播图管理-轮播图页面样式实现20:58课时287【后端开发】轮播图管理-添加轮播图卡片事件11:29课时288【后端开发】轮播图管理-轮播图上传功能完成15:23课时289【后端开发】轮播图管理-轮播图卡片关闭事件03:05课时290【后端开发】轮播图管理-添加轮播图功能完成19:51课时291【后端开发】轮播图管理-异步加载轮播图列表15:51课时292【后端开发】轮播图管理-轮播图删除功能完成08:25课时293【后端开发】轮播图管理-修改轮播图和限制轮播图个数19:04课时294【后端开发】解决移除新增轮播图小bug05:08课时295【后端开发】首页轮播图数据修改和bug解决04:47课时296【后端开发】新闻管理-新闻列表和查询条件布局完成21:36课时297【后端开发】新闻管理-实现新闻分页功能22:42课时298【后端开发】时间选择器控件的集成15:52课时299【后端开发】根据时间、标题、分类查询新闻并分页显示26:31课时300【后端开发】将文章发布时间格式化为本地时间05:16课时301【后端开发】编辑新闻功能完成16:03课时302【后端开发】删除新闻功能完成07:47课时303【后端开发】课程管理-发布课程界面和模型完成17:05课时304【后端开发】课程管理-视频云存储讲解08:10课时305【后端开发】课程管理-发布课程功能完成19:10课时306【后端开发】课程管理-视频加密播放实现27:27课时307【后端开发】购买课程-课程订单页面完成06:28课时308【后端开发】购买课程-支付宝和微信支付功能准备工作12:55课时309【后端开发】购买课程-生成课程订单16:50课时310【后端开发】购买课程-配置pycharm同步代码到服务器13:41课时311【后端开发】购买课程-添加数据（选看）04:41课时312【后端开发】购买课程-支付宝和微信支付功能完成30:54课时313【后端开发】购买课程-购买课程流程补充11:37课时314【后端开发】付费资讯模型创建11:04课时315【后端开发】付费资讯购买和下载（1）30:38课时316【后端开发】付费资讯购买和下载（2）10:54课时317【后端开发】搜索-普通方式实现搜索功能08:27课时318【后端开发】搜索-haystack实现全文搜索（1）18:43课时319【后端开发】搜索-haystack实现全文搜索（2）10:56课时320【后端开发】权限管理-自定义django命令05:22课时321【后端开发】权限管理-网站分组和权限创建完成14:53课时322【后端开发】权限管理-员工管理界面完成12:16课时323【后端开发】权限管理-添加员工功能完成17:05课时324【后端开发】权限管理-页面访问限制19:19章节14jango项目部署课时325【部署】在开发机上的准备工作23:23课时326【部署】服务器上安装vim、mysql、memcached等10:52课时327【部署】服务器上安装Python环境、git、虚拟环境等12:36课时328【部署】生产环境Django项目配置17:00课时329【部署】用uwsgi部署Django项目11:24课时330【部署】用nginx+uwsgi部署项目11:39课时331【部署】用supervisor管理uwsgi进程 试用感受随便下载了两个，试听了下，老师发音有着，我也不知道是哪里口音，听着还有点意思，Django 发音类似「撞狗」。 想要的关注下方公众号后，回复【007】即可获取。 声明：以上所有资源均来自网络，如有侵权请联系本人删除。]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows右下角任务栏图标不显示]]></title>
    <url>%2Fwindows-icon-unusual.html</url>
    <content type="text"><![CDATA[右下角任务栏图标不显示。 问题某些应用程序中的图标不显示，桌面上有几个，文件夹中也有一些。 应用程序所安装的文件夹中，图标也同样不显示。 右下角任务栏图标不显示。 解决办法在桌面创建一个文本文件cc.txt，粘贴下面的代码： 12345678910111213141516171819202122232425262728rem 关闭Windows外壳程序explorertaskkill /f /im explorer.exerem 清理系统图标缓存数据库attrib -h -s -r "%userprofile%\AppData\Local\IconCache.db"del /f "%userprofile%\AppData\Local\IconCache.db"attrib /s /d -h -s -r "%userprofile%\AppData\Local\Microsoft\Windows\Explorer\*"del /f "%userprofile%\AppData\Local\Microsoft\Windows\Explorer\thumbcache_32.db"del /f "%userprofile%\AppData\Local\Microsoft\Windows\Explorer\thumbcache_96.db"del /f "%userprofile%\AppData\Local\Microsoft\Windows\Explorer\thumbcache_102.db"del /f "%userprofile%\AppData\Local\Microsoft\Windows\Explorer\thumbcache_256.db"del /f "%userprofile%\AppData\Local\Microsoft\Windows\Explorer\thumbcache_1024.db"del /f "%userprofile%\AppData\Local\Microsoft\Windows\Explorer\thumbcache_idx.db"del /f "%userprofile%\AppData\Local\Microsoft\Windows\Explorer\thumbcache_sr.db"rem 清理 系统托盘记忆的图标echo y|reg delete "HKEY_CLASSES_ROOT\Local Settings\Software\Microsoft\Windows\CurrentVersion\TrayNotify" /v IconStreamsecho y|reg delete "HKEY_CLASSES_ROOT\Local Settings\Software\Microsoft\Windows\CurrentVersion\TrayNotify" /v PastIconsStreamrem 重启Windows外壳程序explorerstart explorer 修改文件cc.txt的后缀名，改为cc.bat 双击该文件，运行。 问题解决！]]></content>
      <categories>
        <category>绊脚石</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 14 为什么count(*)越来越慢？]]></title>
    <url>%2Fmysql-zhuanlan-14-how-count-works.html</url>
    <content type="text"><![CDATA[select count(*) 应该是一个比较常用的语句，用来统计记录行数。 但是，慢慢地你会发现，这个语句越来越慢了，为什么呢？ count(*) 的实现方式首先，我们来看下它的实现方式。 MySQL 中，不同的存储引擎，count(*) 的实现方式是不同的。 1、MyISAM 引擎，比较简单粗暴，直接将表的总行数存储在磁盘上，因此效率很高； 2、InnoDB 引擎中，执行时，需要一行行的把数据查出来，然后累加； 为啥 MyISAM 就可以这样做呢？因为它不支持事务啊，不用担心数据不一致的问题。 而 InnoDB 就不一样了。 由于 MVCC 的存在，InnoDB 在当前执行环境下，对一共有多少数据行是不确定的，比如： 假设，表 t 中有 1000 条数据，有下面三个用户并行的会话： 1、A 启动事务，查询表的总行数；2、C 直接插入一条数据，然后查询总行数；3、B 启动事务，插入一条数据，然后查询总行数；4、C 查询总行数； 注意，上面启动的事务都没有提交。 A、B、C 查询的结果都不相同。 B 读到的是 1002，是因为可重复读隔离级别的存在，而 C 未开启事务，因此无法看到别的事务的更新； 综上，InnoDB 引擎中，在每一个会话中，都需要逐行读取数据，然后计数返回总行数。 InnoDB 对 count(*) 的优化InnoDB 中，主键索引存储的是数据，辅助索引存储的只是主键值。 因此，辅助索引比主键索引小得多，轻量得多。 这种情况下，InnoDB 在执行 count(*) 时，就会判断使用哪个索引，会选择最小的树来进行遍历。 在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。 小结1、由于 MyISAM 引擎不需要支持事务，因此可以快速返回 count(*)；2、show table status 命令虽然返回很快，但是不准确；3、InnoDB 执行 count(*) 时会遍历全表，因此性能较差； count(*)、count(1)、count(主键)、count(字段)的区别以下，基于 InnoDB。 含义区别count() 是一个聚合函数，对于返回的结果集，会逐行判断，若返回的不是 NULL，就会加 1，否则不加。 因此，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。 性能区别分析性能，考虑以下几个原则： 1、server 层要什么就会返回什么；2、InnoDB 只返回必要的值；3、优化器只优化了 count(*) 对于 count(主键id)，InnoDB 会遍历全表，取每行的主键 id，返回给 server 层，server 层拿到数据后，进行判断累加。 对于 count(1)，InnoDB 仍遍历全表，但是不取值，server 层对返回的每一行数据新增一个 1，然后进行判断累加； 因此，count(1) 要更快些，因为无需取值。从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。 对于 count(字段)： 1、如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；2、如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。 但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。 结论：按照效率排序的话，count(字段)&lt;count(主键 id)&lt;count(1)≈count(*)，所以我建议你，尽量使用 count(*)。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 13 为什么表数据删掉一半，表文件大小不变？]]></title>
    <url>%2Fmysql-zhuanlan-13-clear-disk-space.html</url>
    <content type="text"><![CDATA[经常会有同学来问我，我的数据库占用空间太大，我把一个最大的表删掉了一半的数据，怎么表文件的大小还是没变？ InnoDB 表的组成：表结构定义和数据。 数据删除流程InnoDB 中，数据是以 B+ 树结构来存储数据的： 假设删掉表记录 R4，此时 InnoDB 只是把 R4 标记为已删除状态，后续这个位置可以插入新的数据，但是磁盘文件大小并不会变化。 何时复用？ 比如，插入一个 ID 是 400 的记录，就可以直接复用原来 R4 的空间，若插入的是 800，为了保持 B+ 树的结构，就不能复用该空间了。 删除整页数据 当删除了整页数据后，InnoDB 会将该页标记为已删除，整页都可复用。 同时，若两个相邻的数据页利用率都比较低，系统会把两页上的数据整合到一个页中，另一个页就会标记为可复用。 删除整个表 此时，所有的数据页都会标记为可复用，但是磁盘空间仍然不会变小。 总结 delete 操作，只是把记录的位置标记为「可复用」，但是磁盘大小不会变化，这些可以复用，而未被使用的空间，看起来就像空洞。 增删改-造成空洞当数据是随机插入时，就可能造成索引的数据页分裂。 如图所示，由于 page A 写满，此时插入 ID 为 550 的数据，就不得不申请新的数据页，页分裂完成后，A 上就会留下空洞。 另外，更新索引上的值，其实是删除旧值，插入新值，这个过程同样会造成空洞。 综上，经过大量增删改操作的表，都是可能存在大量空洞的，若要收缩表空间，就要清除这些空洞。 重建表-清除空洞如何清除空洞？ 直接的想法就是，新建一个表结构相同的表，然后按主键 ID 递增的顺序，将原表中的数据，插入到新表。 这样，新表中就不会存在空洞了。新表的主键索引也会更加紧凑，数据页的利用率也更高。 上面的操作可以通过下面的语句自动完成： 1alter table A engine=InnoDB; MySQL 会自动完成转存数据、交换表名、删除旧表的操作。 详细流程： 1、新建临时文件，扫描原表 A 的所有数据页；2、根据表 A 的记录生成 B+ 树，存储到临时文件中；3、生成临时文件过程中，对 A 的所有操作都会记录在一个日志文件中，对应图中的 state2 状态；4、临时文件生成后，将日志文件中的操作应用于临时文件，得到一个完整的数据文件，对于 state3；5、用临时文件替换表 A 的数据文件； 表重建的过程是允许对表 A 做增删改操作的，因此是一个 Online DDL（MySQL5.6+） 另外，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。 上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。 因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何搜索百度云资源？带你打开新世界大门！]]></title>
    <url>%2Fhow-search-in-baiduyun.html</url>
    <content type="text"><![CDATA[百度云 一个神奇的存在 在其他云盘纷纷倒下时 它依然坚挺着 你是不是在想 如何能够搜索全网的资源？ 原文地址：好物分享 | 也许是最好用的百度云资源搜索工具 今天就给大家分享一个神器：PanDownload 这里不是看它加速有多牛逼 教你如何使用 PanDownload 来搜索全网资源！ 获取全网资源不知道有几个人试过这个功能： 比如，群友问有没有 python selenium 的视频 我就用着两个关键词搜索，下面是搜索结果： 其中，灰色的应该是失效的分享，无法打开 点开某个搜索结果后 我们就可以下载该资源，或者保存到网盘 相对于网页形式的，这点还是比较方便的。 我们再搜点其他的看看： 想要的，基本上都能找到。 妈妈再也不用担心找不到资源了！ 如何甄别资源资源是很多了，但是如何鉴别资源好坏呢？ 这里分享一下我的一般做法。 首先，我会随便找一个视频下载下来进行试看 看下视频时间是否较新，不用最新，起码是近两年的！ 若年代较为久远，则直接放弃！ 若通过视频无法甄别出时间 那就下载资源的相关资料或者代码 在其中一般也能够找到一些蛛丝马迹 再者，通过试看 可以了解讲课老师的风格如何 是否是自己喜欢的 若面对一个自己都不喜欢的老师 那是很难坚持下去的！ 其他功能1、可以自动感应剪贴板上的百度云分享连接，复制后自动打开，分享码也可以自动填写； 2、对网盘进行重复文件清理，空目录清理等，貌似是百度云的 VIP 功能； 3、指定分享文件的提取码，默认是 1024； 4、多条分享地址批量转存； 等等 好了，说了这么多 是不是还有人不知道这个软件哪来的？ 实在不想搜索的话 关注下方公众号，后台回复【102】获取吧！]]></content>
      <categories>
        <category>好物分享</category>
      </categories>
      <tags>
        <tag>百度云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 12 为什么我的MySQL会突然变慢？]]></title>
    <url>%2Fmysql-zhuanlan-12-sql-become-slow.html</url>
    <content type="text"><![CDATA[日常中，也许会遇到这种场景，一条 SQL 语句，正常执行速度很快。但是，有时却变得很慢，而且很难复现，随机性比较高，并且持续时间短，到底是什么情况？ 之前的文章中，我们说过，MySQL 的每一次更新并没有每次都写入磁盘，InnoDB 引擎会先将记录写到 redo log 里，然后在适当的时候，再把这个记录更新到磁盘。 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。 那么，有理由怀疑，是 redo log 写入磁盘时导致的。 redo log 何时写入磁盘？1、redo log 写满了，此时系统会停止所有更新操作，把脏页刷到磁盘；2、系统内存不足，需要淘汰脏页，就要把脏页写到磁盘；3、系统空闲时，会进行脏页清除；4、系统异常关闭时； 这几种场景对系统性能的影响： 场景三是在空闲时操作的，对系统没什么影响，场景四是系统关闭时，也不需要考虑。 场景一，此时 redo log 写满，系统直接不再接受更新，所有的更新都被阻塞，需要尽量避免这种情况。 场景二，内存不足，由于 InnoDB 的策略是尽量使用内存，当要读入的数据没有在内存页时，需要申请新的数据页，这时就需要从已占用的内存中淘汰最久不使用的数据页。若要淘汰的是一个干净页，则直接淘汰；若要淘汰的是一个脏页，则需要先刷到磁盘，再淘汰。 所以，以下两种情况会导致查询突然变慢：1、该查询需要淘汰的脏页较多；2、redo log 写满，更新全部堵住； InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。 InnoDB 刷脏页的控制策略innodb_io_capacity 通过设置该参数，告诉 InnoDB 主机的磁盘能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。 要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。 其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码： 123mysql&gt; select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';select @a/@b; innodb_flush_neighbors 该参数表示，刷脏页时，是否连同“邻居”一起刷掉。 值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。 如果是机械硬盘，可以设置为 1，从而减少随机 IO；若是 SSD 等高 IOPS 的设备，可以设置为 0。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 11 怎么给字符串字段加索引？]]></title>
    <url>%2Fmysql-zhuanlan-11-index-for-string.html</url>
    <content type="text"><![CDATA[两种： 全字段索引 前缀索引 举例： 12345mysql&gt; create table SUser(ID bigint unsigned primary key,email varchar(64), ... )engine=innodb; 可以对 email 字段创建全字段索引，或者前缀索引。 123mysql&gt; alter table SUser add index index1(email);或mysql&gt; alter table SUser add index index2(email(6)); 区别 1、全字段索引占用空间大，前缀索引占用空间小；2、全字段索引查询效率高，前缀索引则会增加额外的记录扫描次数。 执行过程 1select id,name,email from SUser where email='zhangssxyz@xxx.com'; 1、全字段索引 ① 从 index1 索引树中找到索引值是 zhangssxyz@xxx.com 的记录，然后得到主键值；② 根据主键值获取到该行的完整数据（回表），再判断 email 是否满足条件，将这行记录加入结果集；③ 沿着索引树继续查找下一条满足条件的数据，若不满足，循环结束； 2、前缀索引 ① 从 index2 索引树上查找索引值是 zhangs 的记录，找到一条后，得到主键值；② 根据主键值获取到该行的完整数据（回表），再判断 email 是否满足条件，将这行记录加入结果集；③ 沿着索引树继续查找下一条满足条件的数据，发现仍然满足条件，重复上面的操作；④ 重复上一步，直到在 index2 上取到的值不满足条件，循环结束。 很明显，使用前缀索引，导致查询次数增多。 如何减少前缀索引查询次数？ 区分度，区分度越高，前缀重复的可能性越小，进而，查询次数就越少。 通过如下语句，可以查询到不通前缀长度，分别有多少个不同的值： 1234567mysql&gt; select count(distinct email) as L count(distinct left(email,4)）as L4, count(distinct left(email,5)）as L5, count(distinct left(email,6)）as L6, count(distinct left(email,7)）as L7,from SUser; 自己可以预先设定一个可以接受的重复比例，比如大于 L * 95%。 前缀索引对覆盖索引的影响 使用前缀索引将无法利用覆盖索引的优化。 查询时，系统并不确定前缀索引的定义是否截断了完整信息。 前缀索引的优化 1、倒序存储 适合字段值前面部分重复度高，后半部分重复度低，这时可以倒序存储数据。 查询时可以这么写： 1mysql&gt; select field_list from t where id_card = reverse('input_id_card_string'); 2、做 hash 新增一个字段，专门存储字段的 hash 值： 1mysql&gt; alter table t add id_card_crc int unsigned, add index(id_card_crc); 每次插入数据时，都要调用 crc32() 这个函数得到校验码填到这个新字段。 这个字段有可能重复，需要联合判断 id_card 的值是否精确相同。 1mysql&gt; select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string' 二者的区别 1、都不支持范围查询2、hash 字段需要额外的空间3、CPU 消耗：倒序插入时需要额外调用 reverse 函数，hash 需要调用 crc32() 函数。reverse 函数消耗的 CPU 更小一些；4、hash 字段方式的查询效率更高，因为计算出来的 hash 值重复的可能性较小，扫描次数接近于 1 总结 1、直接创建完整索引，这样可能比较占用空间；2、创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；3、倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；4、创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。 如何选择？ 当数据量大时，一个学校每年预估 2 万新生，50 年才 100 万记录，能节省多少空间，直接全字段索引。省去了开发转换及局限性风险，碰到超大量迫不得已再用后两种办法。从业务量预估优化和收益，这不失为一个不错的想法。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下如何调试 Python？]]></title>
    <url>%2Flinux-python-debug.html</url>
    <content type="text"><![CDATA[一般开发者都是在 IDE 中进行程序的调试，当然，有 IDE 的话，当然首选 IDE 进行调试。 但是，有时我们的业务场景，限制只能在 Linux 命令行模式进行调试。 这时该怎么办呢？ 今天，就给大家介绍一个 Linux 下调试 Python 程序的工具。 pdb简介pdb 调试器是 Python 标准库提供的，因此最为方便，不需要安装其他组件，直接 import 后就能使用。 pdb 调试器提供了调试所需的大多数功能，如断点、单行步进、堆栈帧的检查等等。 常用命令1234567891011l # 查看运行到哪行代码 n # 单步运行，跳过函数 s # 单步运行，可进入函数 p 变量 # 查看变量值 b 行号 # 断点设置到第几行 b # 显示所有断点列表 cl 断点号 # 删除某个断点 cl # 删除所有断点 c # 跳到下一个断点 r # return 当前函数 exit # 退出 使用示例 本文 Python 环境：Python 3.5.2 我们先准备一小段演示程序： 123456789# -*- coding: utf-8 -*-def add(a, b): return a + bif __name__ == '__main__': print("===start===") c = add(1, 3) print("===end===") 使用方法 1： 运行 pdb 的最简单方法是从命令行，将程序作为参数传递来调试。 1$ python -m pdb test_pdb.py 这时，就开始单步执行了。 这种方法对代码没有侵入性，但是每次都需要设置断点。 使用方法 2： 在代码头部引入 pdb，然后可以在代码里，通过 pdb.set_trace() 来设置断点： 123456789101112# -*- coding: utf-8 -*-import pdbdef add(a, b): pdb.set_trace() return a + bif __name__ == '__main__': print("===start===") pdb.set_trace() c = add(1, 3) print("===end===") 此时，运行程序，就会自动跳转到设置的断点处： 总结没了图形化页面，调试只能这么来了，不过还好，pdb 使用看着不难吧。 其实还有一些增强的调试器，比如 IPython 的 ipdb 和 pdb++，它们一般都提供了更好的用户体验，添加了有用的额外功能，例如语法突出高亮、更好的回溯和自省。 后面有机会再给大家分享吧！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s集群容器内部无法和集群外的Node通信]]></title>
    <url>%2Fk8s-ipv6-calico.html</url>
    <content type="text"><![CDATA[k8s集群容器内部无法和集群外的Node通信 问题k8s 集群下容器内部，只能和集群中的三台 Node 通信，无法和集群同 vlan 的网段地址其他 Node 通信，如 mysql 数据库服务器地址。 在容器外部的机器上是可以正常访问 MySQL 服务器的，但是在容器内部却不行： 解决过程这个 k8s 集群使用 calico 网络方案。 发现 IPv6 的 NAT 没有打开。 calico 开启 natout 开关后，可以正常通信了！]]></content>
      <categories>
        <category>网络相关</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快递地址格式，也蕴含着知识]]></title>
    <url>%2Fthink-about-address.html</url>
    <content type="text"><![CDATA[之前赠书，都是出版社直接将书寄出。今天第一次自己亲手把书寄给了几个小伙伴，感觉还是不错的。 但是就是有一点小麻烦，麻烦在哪里呢？就是填快递单子。 现在都是扫一下二维码，然后填收件地址，麻烦就麻烦在填收件地址这里了。 几个小伙伴给的地址格式五花八门，有下面几种： A 的风格是信息都放在一个对话框内，并用空格来间隔。 B 的特点是三项重要信息分别发送给我，分散在三个对话框内。 C 的特点是信息清晰明了，并且在一个完整的对话框内。 哪种风格我操作起来更高效呢？ 这里，我们不是说谁好谁不好，仅仅是我填信息时想到的一些。 现在扫码填收货信息的页面一般是这样的，所谓的可以智能识别： 因为这些操作都是我在微信里完成的，这就需要我提前将信息整理好，复制，带到这个页面，粘贴。 最理想的就是可以自动识别出姓名、地址和联系方式。 因此，帅比B 的格式是最消耗工作量的，我需要一条条复制，然后粘贴到一起，然后再带到这个页面。 而帅比A 和 帅比C 的格式工作量相当，我都需要进行再编辑，因为不符合自动识别的格式或者顺序。 当然，他们应该很少寄东西，应该不知道有这些问题。 那么最好的格式是什么样的呢？ 我做了实验，能够识别的较好的格式就是下面这种： 12姓名，地址，电话如：刘哈哈，江苏省苏州市姑苏区xxx，15866668888 个人实验，顺丰、韵达、圆通、申通、中通，都能很好的识别。 好了，今天的主要内容到这就结束了。 P.S. 手机上码文真蛋疼！]]></content>
      <categories>
        <category>闲扯系列</category>
      </categories>
      <tags>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[等了5年，它终于支持Markdown了！]]></title>
    <url>%2Fevernote-markdown.html</url>
    <content type="text"><![CDATA[也许是我后知后觉了，到今天我才发现印象笔记（Windows 版）支持 Markdown 了。 为什么选择印象？我一直是大象的拥趸，翻了下笔记列表，发现自己从 14 年开始使用的大象，也许更早。 期间，我试用过好多其他的云笔记，为知、有道、麦库、彩云、OneNote 等等。 其中，为知、有道用的比较多，那就来说说它们俩。 1、受不了有道的UI虽然有道云笔记的功能越来越丰富，迭代的速度也是大象不能比的。 有道在 16 年就支持 Markdown 了，当然我也去使用了，有一段时间我以为我会在有道留下来。 然而，有道的 UI（Windows版）是我不能忍的！ 各位看官，看下有道的文件夹图标，能忍吗？反正我不能忍。 还有广告，有道差这点钱吗，非要在这么显眼的地方放个广告吗？ 对，就因为这两个也许你能忍的小缺陷，我逃离了有道。 2、不再是「云笔记」的为知slogan：大脑是用来思考的，记录的事交给我们 不得不说，为知的 slogan 是最符合云笔记的定位的。 有一段时间，为知成了我的主力云笔记。 它基本上满足了我所有的需求：Markdown、剪藏、多层目录、笔记快捷方式等等。 它还有丰富的插件，当然，很吸引我的是它的一个小功能：桌面任务列表，如图： 对于我这种上班狗，任务多又乱，一不留神，领导交待的事情我就给忘了。 有这个桌面任务列表，多少可以提醒我有多少待办任务，还可以实现云端同步。 然而，一切都被这个通知砸个稀碎： 意思就是，免费版的不再支持云端同步。 我…… 3、又爱又恨的印象slogan：使用印象笔记 共同成就更多 我觉得大象的 slogan 明显没有为知的好了。 现在印象是我的主力了，印象笔记的基本功能可以满足日常使用，整体 UI 是这几个里面看着最舒服的一个。 另外，印象的一大特色就是关联了很多外部应用，EverMemo、clippings.io 等等，这些小工具都支持导出到印象。 我一直期望值大象什么时候能够支持 Markdown，这样我就不用再去纠结，前端时间发现 Mac 版的已经支持了，我这个苦逼的 Windows 版被暂时忽略，桑心… 前几天，在折腾时，设置里无意中发现了可以勾选体验 Beta 版本，我就想也许 Beta 版本有什么惊喜等着我。 久等了，Markdown今天，我例行「检查更新」时，意外的发现有了新版本，更新日志了赫然写着支持 Markdown，毫不犹豫，我点击了更新！ 更新完成： P.S. 这个新建 Markdown 的图标有必要弄这么大么？ 1、初体验新建一个 Markdown 笔记： 这个编辑界面的配置和功能和有道的很相似，编辑栏都会分为左右两侧，左侧用于编辑，右侧用来预览。 再来看一下它的工具栏（动图）： 功能支持的很丰富： 你能想到的：表格、图片、代码、公式等； 你想不到的：流程图、时序图、甘特图等； 插入图表，包括饼图、柱状图、条形图、折线图等 我连什么是甘特图都不知道…… 2、效果演示下面我就挑几个效果演示一下。 代码 一般，也就能看的阶段。 图表 这里，只要改变 type 的值，就可以获得不同的图表： 饼图（pie） 柱状图（column） 条形图（bar） 折线图（line） 流程图 基本的流程图功能，满足！ 时序图 甘特图 没用过甘特图，还特地 Google 了一把： 甘特图内在思想简单。基本是一条线条图，横轴表示时间，纵轴表示活动（项目），线条表示在整个期间上计划和实际的活动完成情况。它直观地表明任务计划在什么时候进行，及实际进展与计划要求的对比。 在工作中用甘特图作计划进度表、项目进度表再合适不过了。 具体的 Markdown 语法这里就不再讲解，大家可以去网上查阅。 要想掌握，一句话，多用！ 图片 印象笔记的 Markdown 编辑器还支持图片编辑功能，可以自由地设置本地图片的长宽高，操作方式也非常便利，直接在图片名称后面（无需空格）添加以下语法均可以按照以下要求控制图片大小： @w=300 @h=150 @w=200h=100 @h=100w=200 总结不管怎样，大象对于 Markdown 的支持还是很不错的，坚定了我留在大象的信心。 但是我 iOS 版本还是只支持查看，不支持编辑，不知道后续是否会进行支持。 另外，笔记通过链接分享的功能什么时候会有？]]></content>
      <categories>
        <category>好物分享</category>
      </categories>
      <tags>
        <tag>云笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写作真的是面向未来的技能吗？]]></title>
    <url>%2Fwhy-need-write.html</url>
    <content type="text"><![CDATA[很多人，特别是一些大 V，他们无不在强调，写作的重要性。 比如最近又在风头浪尖的老罗（罗振宇），他之前说过：未来社会最重要的资产是影响力，而写作就是构建影响力的一个重要方法！ 看了之后，我自己也是心潮澎湃，搓搓双手，意淫着，立马可以写出爆款来！ 可是，真的是这样吗？ 我们先不谈你是否能够练成写作的本领。 之前有新闻说了，随着科技的发展，人工智能的愈加完善！未来，很多文章都是可以由机器生成的。 计算机可以自动收集到海量的消息源，并且运用它们那通天的计算能力，根据一些技巧，「写出」各种各样的爆款！ 到时，你根本分辨不出哪个是人写的，哪个是机写的。 那我还需要练习写作吗？ 当然，不需要的话，我就不会在这写了。 写作是什么？ 写作是思想输出的过程，写作可以培养你思考的习惯，唯有经过思考的东西，才是计算机不易模仿的。 学习最好的结果就是输出！ 而写作就是其中最直截了当的输出方式。 通过写作，你可以对你的所学进行一个梳理，同时可以注入你的思考。 之前，我在读小北的梦呓的一篇文章《写给在校大学生的一些建议！》，小北大佬，给在校大学生提的一个重要建议，就是要学会写作！ 你所表达的文字，首先会经过你大脑的思考，过滤，斟酌，辨别，进而输出成文。所以学会写作，其实是一个深度的思考，这也是对于知识系统性复盘的一个过程。 看了之后，我觉得自己，现在意识到写作的重要性，已经有些晚了，之前自己读的很多书，学过的知识，都没有进行输出！ 现在，写一些东西也缺乏条理，有时不知道写一些什么。 不过，我想，从现在开始，也行还来得及，不断增加有效输入，每天通过刻意练习，输出自己的思考，渐渐形成习惯，也许还有机会！ 也许我是大器晚成呢！哈哈！ 综上 如果你还是在校学生，墙裂建议开始练习写作，如果你已经工作了，已可以在业务练习写作。 如果你已经是写作高手，那赶快来指导我一下啊！]]></content>
      <categories>
        <category>闲扯系列</category>
      </categories>
      <tags>
        <tag>写作</tag>
        <tag>未来</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 09 普通索引还是唯一索引？]]></title>
    <url>%2Fmysql-zhuanlan-09-chose-index.html</url>
    <content type="text"><![CDATA[普通索引和唯一索引如何选择？ 脑图地址：https://mubu.com/doc/aRFaYEd5EG 几种索引 普通索引 作用：加快对数据的访问速度 一般加在经常查询或者排序的字段上 允许字段值重复 唯一索引 保证数据记录的唯一性 目的是为了避免数据重复 维护数据完整性 如何选择 查询效率 普通索引会查询多个，需要多出查找和判断下一条记录的动作 唯一索引查询一次 性能差不多 InnoDB 的数据是按数据页为单位来读写的 一个数据页可以放近千个 key 很少出现跨数据页查询的情况 更新效率 change buffer 更新数据页时，若数据页在内存中，则直接更新 若数据页不在内存中，则先将更新操作缓存在 change buffer 中 redo log 里记录了数据页的修改以及 change buffer 新写入的信息 下次查询时，先将数据读入内存，然后再执行缓存在 buffer 中的操作 可以持久化，在内存中有拷贝，也会写入磁盘 何时 merge 数据？ 访问该数据页 后台定期 merge 关闭数据库时 优点 减少磁盘读 IO 唯一索引的更新过程 唯一索引需要确保数据的唯一性 若目标数据页不在内存中，需要将数据读取到内存 不会使用到 change buffer，直接在内存中更新 普通索引 若目标数据页不在内存中，直接将更新缓存到 change buffer 中 适合写多读少的业务 若写完立马就读，就需要数据的 merge 不但不能减少磁盘 IO，会增加了 change buffer 的维护代价 结论 数据从磁盘读入内存涉及随机 IO 的访问 唯一索引的更新代价更大 索引最终选择 查询能力上差别不大 更新性能差别较大 若业务没有字段的唯一性要求，推荐使用普通索引 另外，就算有唯一性需求，唯一性也可以用业务层来保证，例如 uuid 普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你应该知道的关于Ansible的15件事]]></title>
    <url>%2F15-things-about-ansible.html</url>
    <content type="text"><![CDATA[最近一直在用 Ansible 做一些东西，决定分享我在学习过程中学到的一些东西，我认为你应该知道的关于 Ansible 的 15 件事的清单。 如果你觉得有什么遗漏的，欢迎留言分享！ 1 - 您可以将参数传递给角色创建角色来组织您的剧本是一个很好的做法。 假设我们想要创建一个安装Jenkins的角色。 此角色的文件夹结构可能如下所示： 123456jenkins/ files/ templates/ tasks/ handlers/ defaults/ 文件夹 defaults 用于存储角色的默认变量值。在其中我们可以有这个 main.yml 文件： 123jenkins_port: 8080jenkins_context_path: /jenkinsjenkins_home: /jenkins 您可以通过将不同的参数传递给角色来覆盖默认变量，如下所示： 123roles: - &#123; role: jenkins, jenkins_port: 8181, jenkins_home: '/jenkins1' &#125; - &#123; role: jenkins, jenkins_port: 8080, jenkins_home: '/jenkins2' &#125; 2 - 如何使命令模块具有幂等性幂等性是某些操作的属性，可以多次执行而不改变初始应用程序的结果。 这个概念出现在大多数Ansible模块中：您指定了所需的最终状态，Ansible决定是否应该运行任务。 默认情况下，此原则不适用于command模块。 默认情况下，如果您在playbook中有以下任务，它将始终运行： 1- command: /usr/bin/create-database.sh 为了实现幂等性，您可以使用属性creates 。 如果存在，Ansible将仅在模式指定的文件不存在时运行命令任务。 或者，您可以使用removes ，它仅在指定的文件存在时才执行任务。 1- command : /usr/bin/create-database.sh creates = /path/to/database 始终要记住，Ansible有很多模块，大多数常见操作都不需要使用命令模块。 例如，有一些模块用于创建文件系统 ， 修改iptables和管理cron条目 。 默认情况下，所有这些模块都是幂等的，因此您始终应该更喜欢它们。 3 - 使用Ansible安装程序模块收集有关主机的信息你可能已经看到Ansible在运行一个剧本时所做的第一件事是这样的： 1TASK [ setup] ******************* ok: [ servername] 发生这种情况是因为Ansible在执行第一个任务之前调用特殊模块setup 。 设置模块连接到主机并收集各种详细信息：IP地址，磁盘空间，CPU架构，可用内存等。 手动调用此模块可能很有用，可以快速收集有关主机的信息。 为此，只需运行以下命令： 123456789$ ansible localhost -m setuplocalhost | SUCCESS =&gt; &#123; "ansible_facts": &#123; "ansible_all_ipv4_addresses": [ "10.27.12.77", "192.168.33.1" ], (MANY more facts) &#125; 4 - 您可以列出剧本的所有任务想要记住剧本的作用吗？ 使用–list-tasks标志运行ansible-playbook ，Ansible将列出其所有任务： 123456789101112131415$ ansible-playbook install-jenkins.yml --list-tasksPLAY: #1 tasks: TASK: meta TASK: open-jdk : Install open jdk 1.8 TASK: mount-partition : Creating the filesystem for the device &#123;&#123; device &#125;&#125; (if needed) TASK: mount-partition : Mounting the device &#123;&#123; device &#125;&#125; on path &#123;&#123; path &#125;&#125; TASK: jenkins : Ensure Jenkins repo is installed. TASK: jenkins : Add Jenkins repo GPG key. TASK: jenkins : Ensure Jenkins is present. TASK: jenkins : Ensures that the home directory exists TASK: jenkins : include TASK: jenkins : Ensure Jenkins is started and runs on startup. TASK: jenkins : Wait for Jenkins to start up before proceeding. TASK: jenkins : Get the jenkins-cli jarfile from the Jenkins server. 5 - 如果要存储敏感信息，请使用ansible-vault如果您的某个任务需要敏感信息（比如数据库用户和密码），最好将这些信息加密，而不是以纯文本形式存储。 Ansible附带一个名为ansible-vault的命令行工具，允许您创建和管理加密文件。 这样，您可以将加密文件提交到源代码控制，只有拥有解密密码的用户才能读取它。 123456789101112131415# Encrypt an existing file. You'll need to create an encryption password.ansible-vault encrypt secrets.yml# Creates a new, encrypted file. You'll need to create an encryption password.ansible-vault create secrets.yml# Decrypt a file. You'll have to enter password used for encryption.# Use it with caution! Don't leave your files unecrypted.ansible-vault decrypt secrets.yml# Edit an encrypted file (uses vim by default, can be overriden by the environment variable $EDITOR)ansible-vault edit secrets.yml# Print the contents of the encrypted fileansible-vault edit secrets.yml 如果您在Playbook中导入vars_file secrets.yml，Ansible将失败，因为它不知道如何读取加密文件。 您必须指定命令行参数–ask-vault-pass ，这将使Ansible提示您加密文件的密码。 1ansible-playbook playbook.yml -i hosts --ask-vault-password 另一种方法是将密码存储在一个文件中（不应该提交），并使用–vault-password-file参数指定文件的路径。 如果此文件标记为可执行文件，Ansible将运行它并使用输出作为密码。 6 - 使用with_items可能是个好主意当您使用with_items子句时，Ansible将创建一个名为{ {item } }的变量，其中包含当前迭代的值。 有些模块可以很好地处理项目集合，实际上比使用不同参数多次运行相同任务更快。 123456789101112131415161718192021# Installing all packages with one task (faster) - name: install required packages using the apt module apt: package=&#123;&#123; item &#125;&#125; update_cache=yes sudo: True with_items: - git - memcached - nginx # Installing packages individually (slower) - name: install git apt: package=git update_cache=yes sudo: True - name: install memcached apt: package=memcached update_cache=yes sudo: True - name: install nginx apt: package=nginx update_cache=yes sudo: True 7 - 本地行动的运作方式有时您可能希望在本地计算机上运行任务，而不是在远程计算机上运行它。 当我们想要等待服务器启动（如果它刚刚启动）或者我们想要在负载均衡器池中添加一些节点（或删除它们）时，这可能很有用： 1234567891011tasks: - name: take out of load balancer pool local_action: &gt; command /usr/bin/take_out_of_pool &#123;&#123; inventory_hostname &#125;&#125; - name: update application yum: name=acme-web-stack state=latest - name: add back to load balancer pool local_action: &gt; command /usr/bin/take_out_of_pool &#123;&#123; inventory_hostname &#125;&#125; 下面是如何启动EC2实例并等待其可用的示例： 1234567891011- name: Launching EC2 Instance # instance options here register: ec2- name: Waiting for ec2 instances to listen on port 22 wait_for: state=started host=&#123;&#123; item.public_dns_name &#125;&#125; port=22 with_items: ec2.instances 8 - 您可以告诉Ansible仅运行一次任务有时您可能只想运行一次任务，即使有多个主机也是如此。 例如，假设您有多个连接到同一数据库的应用程序服务器，并且您有一个执行数据库迁移的任务。 在这种情况下，您只需运行此任务一次。 要实现这一点，您可以使用run_once参数告诉Ansible只运行一次命令： 123- name: run the database migrations command: bundle exec rake db:migrate run_once: true 9 - 处理程序是特殊类型的任务处理程序是具有唯一名称的任务，只有在被另一个任务通知时才会执行。 它们对于重新启动服务或重新引导系统非常有用。 被通知的处理程序将在剧本结束时执行一次 ，无论他们被通知多少次。 您可以使用handler子句声明它们并使用notify触发它们。 下面是一个示例，说明当文件内容发生更改时如何重新启动两个服务，但仅当文件更改时（从Ansible 文档中提取）： 12345- name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: - restart memcached - restart apache 应该在你的剧本中的其他地方声明处理程序： 123456handlers: - name: restart memcached # The service module was used, but you could use whatever module you wanted service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted 10 - 用流水线加速您可以采取一些措施使Ansible运行得更快： 启用流水线操作 启用流水线操作可以减少在远程服务器上执行模块所需的SSH操作数，方法是将脚本传送到SSH会话而不是复制它。 启用后，这可以显着提高性能。 不过你应该小心。 只有在sudoers文件（/ etc / sudoers）中的所有远程计算机上禁用选项requiretty管道requiretty才有效。 12[ssh_connection]pipelining = True 关闭事实收集或启用事实缓存 如果您未在任务中使用任何Ansible事实，则可以禁用“事实收集”步骤以提高速度。 为此，只需在playbook中添加属性gather_facts: False ： 12345- hosts: servername gather_facts: False tasks: - name: ... # ... 或者，如果您确实需要使用Ansible事实（由安装任务自动收集），您可以缓存它们，以便后续执行更快。 Ansible文档在此详细介绍了这一点 ，如果您想了解更多信息。 11 - Ansible有几个通知模块使用Ansible自动进行蓝绿部署？ 运行Playbooks以在AWS上配置新实例？ 让您的团队使用其中一个通知模块。 例如，下面的任务将发送带有自定义消息的松弛通知： 1234567891011- hosts: servername tasks: - name: Send notification message via Slack local_action: module: slack # To retrieve your slack token, open your team settings and look for the # Incoming Webhooks plugin token: &lt;your&gt;/&lt;token&gt;/&lt;goes here&gt; msg: "Hello team! I just finished updating our production environment." channel: "#general" username: "ansible-bot" 还有一些模块可用于通知irc，twillio，hipchat，jabber 等等 。 12 - EC2实例按其标签自动分组使用Amazon Web Services和Ansible的EC2动态库存脚本时，所有实例都将根据其特征（例如类型，密钥对和标记）进行分组。 EC2标签只是key =与您的实例关联的名称值，您可以随意使用它们。 有些人使用标签对其生产/登台服务器进行分组，在蓝绿部署期间标记Web服务器甚至“活动”服务器。 当按标记对主机进行分组时，EC2动态库存脚本使用以下模式（不带括号）： 1tag_[TAG_NAME]_[TAG_VALUE] 因此，如果要在标签为env=staging所有主机上运行任务，只需将其添加到您的playbook： 1234hosts: tag_env_stagingtasks: - name: This task will be run on all servers with env == staging # ... 为了使它更有趣，您可以使用Ansible模式（ docs ）更具体地说明哪些主机应该受任务影响。 例如，如果要在生产数据库服务器上执行特定任务（假设它们已正确标记），则可以使用交叉模式（ :&amp; ），如下所示： 1234hosts: tag_env_production&amp;:tag_type_dbtasks: - name: This task will be run on all servers with tags 'env=production' and 'type=db' # ... 13 - 您可以在“Dry Run”模式下运行Ansible支持在干运行模式下运行一个剧本（也称为检查模式），在这种模式下，Ansible 不会对你的主机进行任何更改，而只是报告如果没有这个标志运行剧本就会发生什么变化。 1$ ansible-playbook --check playbook.yml 虽然这在某些情况下很有用，但如果您的任务使用条件步骤，它可能无法正常工作。 14 - 任务可以一步一步地进行有时您不想在游戏手册中运行所有任务。 当你编写一个新的剧本并想要测试它时，这有点常见。 Ansible提供了一种方法，通过使用–step标志，让您决定要运行哪些任务。 它会让你选择是否要运行任务（y），跳过它（n）或（c）ontinue而不要求。 12345678910111213# playbook.yml- hosts: servername tasks: - name: First task # ... - name: Second task # ...$ ansible-playbook provision.yml -i hosts --step&gt; Perform task: TASK: setup (y/n/c): n #&gt; Perform task: TASK: First task (y/n/c): n&gt; Perform task: TASK: Second task (y/n/c): y 15 - 可以根据标签运行任务您可以将一个或多个标签添加到任务或游戏中。 为此，只需使用tags属性标记要标记的内容： 123456789101112# playbook.yml- hosts: servername tags: - server tasks: - name: Download optional files tags: - download - optional - name: Install dependencies tags: - dependencies 稍后您可以使用标志–tags （或简称-t ）和–skip-tags –tags 来决定运行或跳过哪些标签： 12345# will run only tasks with the tag 'dependencies'$ ansible-playbook --tags=dependencies playbook.yml# will run all tasks except the ones that contain the tag 'optional'$ ansible-playbook --skip-tags=optional playbook.yml 您可以通过用逗号分隔来指定多个标记。 参考： http://codeheaven.io/15-things-you-should-know-about-ansible/]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible：如何穿过跳板机？]]></title>
    <url>%2Fansible-jump-server.html</url>
    <content type="text"><![CDATA[在公司开发中，为了安全起见，生产环境跟开发环境是相互隔离开来的。也就是说在开发环境网络中无法直接 ssh 登录到生产环境的机器， 如果需要登录生产环境的机器，通常会需要借助跳板机，先登录到跳板机，然后通过跳板机登录到生产环境。 那么，使用 Ansible 时，如何配置，可以直接穿过跳板机呢？ 大致的过程如下面的图示： 123+-------------+ +----------+ +--------------+| 开发环境机器A | &lt;---&gt; | 跳板机B | &lt;--&gt; | 生产环境机器B |+-------------+ +----------+ +--------------+ 我们可以通过 ssh 命令的 ProxyCommand 选项来解决以上问题。 通过 ProxyCommand 选项，机器 A 能够灵活使用任意代理机制与机器 C 上的 SSH Server 端口建立连接，接着机器 A 上的 SSH Client 再与该连接进行数据交互，从而机器 A 上的 SSH Client 与机器 C 上的 SSH Server 之间建立了与一般直接 SSH 连接不太一样的间接 SSH 连接。 不过由于间接 SSH 连接的透明性，逻辑上可认为机器 A 上的 SSH Client 与机器 C 上的 SSH Server 建立了直接 SSH 连接。 原理 ssh 命令自提供的代理机制，在机器 A 上另外单独建立与 B 的 SSH 连接，该 SSH 连接的 B 端侧与机器 C 上的 SSH Server 端口建立连接，该 SSH 连接的 A 端侧与机器 A 上的 SSH Client建立连接。 测试环境A-本机：192.22.9.23B-跳板机：192.22.9.21C-目标机：192.22.4.46 条件：A-&gt;B的互信 测试步骤测试 1A–&gt;B：root 用户的互信C：root 的登录信息 12345# ansible all -m ping --ssh-common-args='-o ProxyCommand="ssh -W %h:%p -q root@192.22.9.21"'192.22.4.46 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125; 可以成功穿过跳板机。 测试 2A–&gt;B：一般用户（luke）的互信C：root 的登录信息 12345# ansible all -m ping --ssh-common-args='-o ProxyCommand="ssh -W %h:%p -q luke@192.22.9.21"'192.22.4.46 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125; 跳板机普通用户，访问目标机器的 root 目录 12345678910111213141516# ansible all --ssh-common-args='-o ProxyCommand="ssh -W %h:%p -q luke@192.22.9.21"' -m command -a 'ls /root/'192.22.4.46 | CHANGED | rc=0 &gt;&gt;1115.txtanaconda-ks.cfgdeploytelegrafdeploytelegraf.tar.gzepic-brook.18.11.20.01.tar.gzepic-josh-threshold.0.1.26.tar.gzimages.tar.gzmetric.tar.gzpython-httplib2-0.9.2-1.el7.noarch.rpmrestatessensu-1.6.1-1.el7.x86_64.rpmsshpass-1.06-2.el7.x86_64.rpmtest1115.txttl.txt 结论 访问权限取决于目标机器的登录用户。 测试 3A–&gt;B：一般用户（luke）的互信C：一般用户（luke）的登录信息 12345# ansible all -m ping --ssh-common-args='-o ProxyCommand="ssh -W %h:%p -q luke@192.22.9.21"'192.22.4.46 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125; 123# ansible all --ssh-common-args='-o ProxyCommand="ssh -W %h:%p -q luke@192.22.9.21"' -m command -a 'pwd'192.22.4.46 | CHANGED | rc=0 &gt;&gt;/home/luke 跳板机普通用户，目标机普通用户，无法访问 root 123# ansible all --ssh-common-args='-o ProxyCommand="ssh -W %h:%p -q luke@192.22.9.21"' -m command -a 'ls /root/'192.22.4.46 | FAILED | rc=2 &gt;&gt;ls: cannot open directory /root/: Permission deniednon-zero return code 目标机器的普通用户无法访问 root 权限的路径。 测试 4A–&gt;B：root 用户的互信C：luke 的登录信息 123# ansible all --ssh-common-args='-o ProxyCommand="ssh -W %h:%p -q root@192.22.9.21"' -m command -a 'pwd'192.22.4.46 | CHANGED | rc=0 &gt;&gt;/home/luke 总结1、若要使用跳板机功能，需要本机和跳板机的互信，任一用户的互信都可以。 2、目标机器的操作权限，取决于目标机器的登录用户信息，与跳板机的登录信息无关。 3、穿过跳板机，无法保证所有的 Ansible 功能都支持，特别是一些复杂的功能，如 synchronize 模块。后续需要用的模块需要一一测试。]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从URL输入到页面展现到底发生什么？]]></title>
    <url>%2Fwhat-happend-when-a-url-input-in-browser.html</url>
    <content type="text"><![CDATA[前言打开浏览器从输入网址到网页呈现在大家面前，背后到底发生了什么？经历怎么样的一个过程？先给大家来张总体流程图，具体步骤请看下文分解！ 总体来说分为以下几个过程: DNS 解析:将域名解析成 IP 地址 TCP 连接：TCP 三次握手 发送 HTTP 请求 服务器处理请求并返回 HTTP 报文 浏览器解析渲染页面 断开连接：TCP 四次挥手 一、URL 到底是啥URL（Uniform Resource Locator），统一资源定位符，用于定位互联网上资源，俗称网址。比如 http://www.w3school.com.cn/html/index.asp，遵守以下的语法规则： scheme://host.domain:port/path/filename 各部分解释如下： scheme - 定义因特网服务的类型。常见的协议有 http、https、ftp、file，其中最常见的类型是 http，而 https 则是进行加密的网络传输。 host - 定义域主机（http 的默认主机是 www） domain - 定义因特网域名，比如 w3school.com.cn port - 定义主机上的端口号（http 的默认端口号是 80） path - 定义服务器上的路径（如果省略，则文档必须位于网站的根目录中）。 filename - 定义文档/资源的名称 二、域名解析（DNS）在浏览器输入网址后，首先要经过域名解析，因为浏览器并不能直接通过域名找到对应的服务器，而是要通过 IP 地址。 大家这里或许会有个疑问：计算机既可以被赋予 IP 地址，也可以被赋予主机名和域名。比如 www.hackr.jp。 那怎么不一开始就赋予个 IP 地址？这样就可以省去解析麻烦。我们先来了解下什么是 IP 地址 2.1 IP 地址IP 地址是指互联网协议地址，是 IP Address 的缩写。IP 地址是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。 IP 地址是一个 32 位的二进制数，比如 127.0.0.1 为本机 IP。 域名就相当于 IP 地址乔装打扮的伪装者，带着一副面具。它的作用就是便于记忆和沟通的一组服务器的地址。 用户通常使用主机名或域名来访问对方的计算机，而不是直接通过 IP 地址访问。 因为与 IP 地址的一组纯数字相比，用字母配合数字的表示形式来指定计算机名更符合人类的记忆习惯。但要让计算机去理解名称，相对而言就变得困难了。因为计算机更擅长处理一长串数字。为了解决上述的问题，DNS 服务应运而生。 2.2 什么是域名解析DNS 协议提供通过域名查找 IP 地址，或逆向从 IP 地址反查域名的服务。 DNS 是一个网络服务器，我们的域名解析简单来说就是在 DNS 上记录一条信息记录。 1例如 baidu.com 220.114.23.56（服务器外网IP地址）80（服务器端口号） 2.3 浏览器如何通过域名去查询 URL 对应的 IP 呢 浏览器缓存：浏览器会按照一定的频率缓存 DNS 记录。 操作系统缓存：如果浏览器缓存中找不到需要的 DNS 记录，那就去操作系统中找。 路由缓存：路由器也有 DNS 缓存。 ISP 的 DNS 服务器：ISP 是互联网服务提供商(Internet Service Provider)的简称，ISP 有专门的 DNS 服务器应对 DNS 查询请求。 根服务器：ISP 的 DNS 服务器还找不到的话，它就会向根服务器发出请求，进行递归查询（DNS 服务器先问根域名服务器.com 域名服务器的 IP 地址，然后再问.baidu 域名服务器，依次类推） 2.4 小结浏览器通过向 DNS 服务器发送域名，DNS 服务器查询到与域名相对应的 IP 地址，然后返回给浏览器，浏览器再将 IP 地址打在协议上，同时请求参数也会在协议搭载，然后一并发送给对应的服务器。 接下来介绍向服务器发送 HTTP 请求阶段，HTTP 请求分为三个部分：TCP 三次握手、http 请求响应信息、关闭 TCP 连接。 三、TCP 三次握手在客户端发送数据之前会发起 TCP 三次握手用以同步客户端和服务端的序列号和确认号，并交换 TCP 窗口大小信息。 3.1 TCP 三次握手的过程如下： 客户端发送一个带 SYN=1，Seq=X 的数据包到服务器端口（第一次握手，由浏览器发起，告诉服务器我要发送请求了） 服务器发回一个带 SYN=1， ACK=X+1， Seq=Y 的响应包以示传达确认信息（第二次握手，由服务器发起，告诉浏览器我准备接受了，你赶紧发送吧） 客户端再回传一个带 ACK=Y+1， Seq=Z 的数据包，代表“握手结束”（第三次握手，由浏览器发送，告诉服务器，我马上就发了，准备接受吧） 3.2 为啥需要三次握手谢希仁著《计算机网络》中讲「三次握手」的目的是为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 四、发送 HTTP 请求TCP 三次握手结束后，开始发送 HTTP 请求报文。请求报文由请求行（request line）、请求头（header）、请求体四个部分组成，如下图所示： 4.1 请求行包含请求方法、URL、协议版本 请求方法包含 8 种：GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE。 URL 即请求地址，由 &lt;协议&gt;：//&lt;主机&gt;：&lt;端口&gt;/&lt;路径&gt;?&lt;参数&gt; 组成 协议版本即 http 版本号 1POST /chapter17/user.html HTTP/1.1 以上代码中 POST 代表请求方法，/chapter17/user.html 表示 URL，HTTP/1.1 代表协议和协议的版本。现在比较流行的是 Http1.1 版本。 4.2 请求头包含请求的附加信息由关键字/值对组成，每行一对，关键字和值用英文冒号 : 分隔。 请求头部通知服务器有关于客户端请求的信息。它包含许多有关的客户端环境和请求正文的有用信息。 其中比如：Host，表示主机名，虚拟主机；Connection,HTTP/1.1 增加的，使用 keepalive，即持久连接，一个连接可以发多个请求；User-Agent，请求发出者，兼容性以及定制化需求。 4.3 请求体可以承载多个请求参数的数据，包含回车符、换行符和请求数据，并不是所有请求都具有请求数据。 1name=tom&amp;password=1234&amp;realName=tomson 上面代码，承载着 name、password、realName 三个请求参数。 五、服务器处理请求并返回 HTTP 报文5.1 服务器服务器是网络环境中的高性能计算机，它侦听网络上的其他计算机（客户机）提交的服务请求，并提供相应的服务，比如网页服务、文件下载服务、邮件服务、视频服务。而客户端主要的功能是浏览网页、看视频、听音乐等等，两者截然不同。 每台服务器上都会安装处理请求的应用——web server。常见的 web server 产品有 apache、nginx、IIS 或 Lighttpd 等。 web server 担任管控的角色，对于不同用户发送的请求，会结合配置文件，把不同请求委托给服务器上处理相应请求的程序进行处理（例如 CGI 脚本，JSP 脚本，servlets，ASP 脚本，服务器端 JavaScript，或者一些其它的服务器端技术等），然后返回后台程序处理产生的结果作为响应。 5.2 MVC 后台处理阶段后台开发现在有很多框架，但大部分都还是按照 MVC 设计模式进行搭建的。 MVC 是一个设计模式，将应用程序分成三个核心部件：模型（model）– 视图（view）–控制器（controller），它们各自处理自己的任务，实现输入、处理和输出的分离。 1、视图（view） 它是提供给用户的操作界面，是程序的外壳。 2、模型（model） 模型主要负责数据交互。 在 MVC 的三个部件中，模型拥有最多的处理任务。一个模型能为多个视图提供数据。 3、控制器（controller） 它负责根据用户从”视图层”输入的指令，选取”模型层”中的数据，然后对其进行相应的操作，产生最终结果。 控制器属于管理者角色，从视图接收请求并决定调用哪个模型构件去处理请求，然后再确定用哪个视图来显示模型处理返回的数据。 这三层是紧密联系在一起的，但又是互相独立的，每一层内部的变化不影响其他层。每一层都对外提供接口（Interface），供上面一层调用。 至于这一阶段发生什么？ 简而言之，首先浏览器发送过来的请求先经过控制器，控制器进行逻辑处理和请求分发，接着会调用模型，这一阶段模型会获取 redis db 以及 MySQL 的数据，获取数据后将渲染好的页面，响应信息会以响应报文的形式返回给客户端，最后浏览器通过渲染引擎将网页呈现在用户面前。 5.3 http 响应报文响应报文由响应行（request line）、响应头部（header）、响应主体三个部分组成。如下图所示： (1) 响应行包含：协议版本，状态码，状态码描述 状态码规则如下：1xx：指示信息–表示请求已接收，继续处理。2xx：成功–表示请求已被成功接收、理解、接受。3xx：重定向–要完成请求必须进行更进一步的操作。4xx：客户端错误–请求有语法错误或请求无法实现。5xx：服务器端错误–服务器未能实现合法的请求。 (2) 响应头部包含响应报文的附加信息，由 名/值 对组成 (3) 响应主体包含回车符、换行符和响应返回数据，并不是所有响应报文都有响应数据 六、浏览器解析渲染页面浏览器拿到响应文本 HTML 后，接下来介绍下浏览器渲染机制 浏览器解析渲染页面分为一下五个步骤： 根据 HTML 解析出 DOM 树 根据 CSS 解析生成 CSS 规则树 结合 DOM 树和 CSS 规则树，生成渲染树 根据渲染树计算每一个节点的信息 根据计算好的信息绘制页面 6.1 根据 HTML 解析 DOM 树 根据 HTML 的内容，将标签按照结构解析成为 DOM 树，DOM 树解析的过程是一个深度优先遍历。即先构建当前节点的所有子节点，再构建下一个兄弟节点。 在读取 HTML 文档，构建 DOM 树的过程中，若遇到 script 标签，则 DOM 树的构建会暂停，直至脚本执行完毕。 6.2 根据 CSS 解析生成 CSS 规则树 解析 CSS 规则树时 js 执行将暂停，直至 CSS 规则树就绪。 浏览器在 CSS 规则树生成之前不会进行渲染。 6.3 结合 DOM 树和 CSS 规则树，生成渲染树 DOM 树和 CSS 规则树全部准备好了以后，浏览器才会开始构建渲染树。 精简 CSS 并可以加快 CSS 规则树的构建，从而加快页面相应速度。 6.4 根据渲染树计算每一个节点的信息（布局） 布局：通过渲染树中渲染对象的信息，计算出每一个渲染对象的位置和尺寸 回流：在布局完成后，发现了某个部分发生了变化影响了布局，那就需要倒回去重新渲染。 6.5 根据计算好的信息绘制页面 绘制阶段，系统会遍历呈现树，并调用呈现器的“paint”方法，将呈现器的内容显示在屏幕上。 重绘：某个元素的背景颜色，文字颜色等，不影响元素周围或内部布局的属性，将只会引起浏览器的重绘。 回流：某个元素的尺寸发生了变化，则需重新计算渲染树，重新渲染。 七、断开连接当数据传送完毕，需要断开 tcp 连接，此时发起 tcp 四次挥手。 发起方向被动方发送报文，Fin、Ack、Seq，表示已经没有数据传输了。并进入 FIN_WAIT_1 状态。(第一次挥手：由浏览器发起的，发送给服务器，我请求报文发送完了，你准备关闭吧) 被动方发送报文，Ack、Seq，表示同意关闭请求。此时主机发起方进入 FIN_WAIT_2 状态。(第二次挥手：由服务器发起的，告诉浏览器，我请求报文接受完了，我准备关闭了，你也准备吧) 被动方向发起方发送报文段，Fin、Ack、Seq，请求关闭连接。并进入 LAST_ACK 状态。(第三次挥手：由服务器发起，告诉浏览器，我响应报文发送完了，你准备关闭吧) 发起方向被动方发送报文段，Ack、Seq。然后进入等待 TIME_WAIT 状态。被动方收到发起方的报文段以后关闭连接。发起方等待一定时间未收到回复，则正常关闭。(第四次挥手：由浏览器发起，告诉服务器，我响应报文接受完了，我准备关闭了，你也准备吧 作者：浪里行舟原文地址：https://github.com/ljianshu/Blog/issues/24]]></content>
      <categories>
        <category>网络相关</category>
      </categories>
      <tags>
        <tag>URL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java/Spring使用IPv6地址连接到MySQL服务器]]></title>
    <url>%2Fipv6-mysql.html</url>
    <content type="text"><![CDATA[RT 地址格式IPv6 地址有两个逻辑部分：64 位网络前缀和 64 位主机地址部分。（主机地址通常是从接口 MAC 地址自动生成的。） IPv6 地址由 8 组 16 位十六进制值表示，以冒号（:）分隔，如下所示： IPv6 地址的典型示例： 12001:0db8:85a3:0000:0000:8a2e:0370:7334 另外，十六进制数字不区分大小写。 使用IPv4地址连接到MYSQL的方法（传统方式）1234urlString = "jdbc:mysql://10.144.1.216:3306/dbName";Class.forName(driver);DriverManager.setLoginTimeout(getConnectionTimeOut());dbConnection = DriverManager.getConnection(urlString,user,password); 使用IPv6地址连接到MYSQL的方法（新方法）1234urlString = "jdbc:mysql://address=(protocol=tcp)(host=fe80::5ed6:baff:fe14:a23e)(port=3306)/db";Class.forName(driver);DriverManager.setLoginTimeout(getConnectionTimeOut());dbConnection = DriverManager.getConnection(urlString,user,password); 注意如果直接在 IPv4 地址格式的基础上，将 IPv4 地址直接换成 IPv6 地址，启动项目时，可能会出现下面的异常： 1234com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Cannot load connection class because of underlying exception: 'java.lang.NumberFormatException: For input string: "fe80::5ed6:baff:fe14:a23e]:3306"'. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) 附 Spring 配置方式1234spring.datasource.url=jdbc:mysql://address=(protocol=tcp)(host=fe80::5ed6:baff:fe14:a23e)(port=3306)/test?useUnicode=true&amp;characterEncoding=utf8spring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driver 参考： http://blog.ashwani.co.in/blog/2012-10-10/mysql-with-ipv6/ https://flyli815.iteye.com/blog/2125088]]></content>
      <categories>
        <category>网络相关</category>
      </categories>
      <tags>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy配置IPv6和IPv4的互相代理实验]]></title>
    <url>%2Fipv6-haproxy-ipv4.html</url>
    <content type="text"><![CDATA[RT 这里我们使用简单的 httpd 服务进行测试。 实验环境 序号 IPv4地址 IPv6地址 1 10.144.91.124 fd88:5110:a240::886:f250 2 10.144.91.125 fd88:5110:a240::886:f251 3 10.144.85.73 fd88:5110:a240::886:f252 测试IPv6访问在机器 3 上安装 httpd，配置监听 IPv4 和 IPv6 的 80 端口。 文件：/etc/httpd/conf/httpd.conf 12Listen 10.144.85.73:80Listen [fd88:5110:a240::886:f252]:80 在 1 上通过 curl 访问： 1curl 10.144.85.73:80 IPv4 可以正常访问，返回数据较长，这里不再展示。 12# curl -g [fd88:5110:a240::886:f252]:80curl: (7) Failed connect to fd88:5110:a240::886:f252:80; Connection refused IPv6 地址无法访问到 httpd 服务。IPv6 访问不稳定，有时可以正常返回数据。 机器 1 上抓包来看，数据包发送出去了： 12345623:42:52.924028 IP6 epic1.52564 &gt; fd88:5110:a240::886:f252.http: Flags [S], seq 480439591, win 28800, options [mss 1440,sackOK,TS val 17786404 ecr 0,nop,wscale 7], length 023:42:52.924033 ethertype IPv6, IP6 epic1.52564 &gt; fd88:5110:a240::886:f252.http: Flags [S], seq 480439591, win 28800, options [mss 1440,sackOK,TS val 17786404 ecr 0,nop,wscale 7], length 023:42:52.924035 ethertype IPv6, IP6 epic1.52564 &gt; fd88:5110:a240::886:f252.http: Flags [S], seq 480439591, win 28800, options [mss 1440,sackOK,TS val 17786404 ecr 0,nop,wscale 7], length 023:42:52.937267 ethertype IPv6, IP6 fd88:5110:a240::886:f252.http &gt; epic1.52564: Flags [R.], seq 0, ack 480439592, win 0, length 023:42:52.937270 ethertype IPv6, IP6 fd88:5110:a240::886:f252.http &gt; epic1.52564: Flags [R.], seq 0, ack 1, win 0, length 023:42:52.937271 IP6 fd88:5110:a240::886:f252.http &gt; epic1.52564: Flags [R.], seq 0, ack 1, win 0, length 0 此时机器 3 上抓不到包。 HAproxy 代理测试在机器 1 上安装 HAproxy。 IPv6 代理 IPv4我们配置 机器 1 的 IPv6 地址来代理 机器 3 的 IPv4 地址，配置如下： 12345678listen httpd6 bind fd88:5110:a240::886:f250:8080 balance roundrobin option httplog option tcpka option httpchk option tcplog server http1 10.144.85.73:80 check inter 5000 rise 2 fall 3 另外，配置了 HAproxy 的管理页面，这里不再赘述。 理论上，可以在浏览器中输入 http://[fd88:5110:a240::886:f250]:8080/，来测试。 由于公司环境，VPN 没有代理 IPv6 地址，所以只能通过 curl 的方式测试。 在机器 3 上访问： 1curl -g [fd88:5110:a240::886:f250]:8080 数据可以正常返回，返回用时不稳定，大部分情况下返回结果用时很长，用时近 15s。也有访问无返回的情况。 通过 机器 2 访问时，一切正常！返回速度也很快！ IPv4 代理 IPv6现在机器 3 的 httpd 服务无法通过 IPv6 正常访问，我们只能采用迂回的方式来做这个测试了。 既然，在机器 2 上可以通过 IPv6 访问 HAproxy 代理的服务，那我们在机器 2 上再做一层 HAproxy。 机器 2 的 HAproxy 配置： 12345678listen httpd4 bind 0.0.0.0:18080 balance roundrobin option httplog option tcpka option httpchk option tcplog server http1 fd88:5110:a240::886:f250:8080 check inter 5000 rise 2 fall 3 这里的后端 http1 的地址使用的是机器 2 上的 HAproxy 的对外地址。 这里，可以通过浏览器访问 http://10.144.91.125:18080/： 结论1、通过 HAproxy 可以实现 IPv4 代理 IPv6，IPv6 代理 IPv4；2、地址转换时感觉还是有些问题，不确定是否是 httpd 服务的问题还是机器；3、下一步需要部署真实服务再进行验证；]]></content>
      <categories>
        <category>网络相关</category>
      </categories>
      <tags>
        <tag>IPv6</tag>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPv6 相关技术调研]]></title>
    <url>%2Flittle-about-ipv6.html</url>
    <content type="text"><![CDATA[最近，需要对系统进行 IPv6 化的改造，于是，我就假模假样的做起了调研。 IPv6 的表示方法IPv6 地址为 128 位长，但通常写作 8 组，每组为四个十六进制数的形式。例如： 2001:0db8:85a3:08d3:1319:8a2e:0370:7344 如果四个数字都是零，可以被省略。例如： 2001:0db8:85a3:0000:1319:8a2e:0370:7344 等价于 2001:0db8:85a3::1319:8a2e:0370:7344 在某些情况下，一个 IPv6 地址中问可能包含很长的一段 0，可以把连续的一段 0 压缩为 ::。 但为保证地址解析的唯一性，地址中 :: 只能出现一次，例如： 123FF01:0:0:0:0:0:0:1101 → FF01::11010:0:0:0:0:0:0:1 → ::10:0:0:0:0:0:0:0 → :: 综上： 123452001:0DB8:0000:0000:0000:0000:1428:57ab2001:0DB8:0000:0000:0000::1428:57ab2001:0DB8:0:0:0:0:1428:57ab2001:0DB8:0::0:1428:57ab2001:0DB8::1428:57ab 都使合法的地址，并且他们是等价的。 不合法的：2001::25de::cade，零压缩出现了两次。 同时前导的零可以省略，因此： 2001:0DB8:02de::0e13 等价于 2001:DB8:2de::e13。 IPv6 和 IPv4由于 IPv4 到 IPv6 之间有一个漫长的过渡过程，因此，需要将 IPv6 兼容 IPv4 或者 IPv6 映射为 IPv4。 兼容 IPv4 的地址（IPv4-compatible address） 在兼容情况下：如果 IPv4 表示为 X.X.X.X，那么对应的 IPv6 即为 ::X.X.X.X（高位补零，同时进行零压缩）； 这里的 X.X.X.X 是 IPv4 公共地址的十进制点号表示法，用于 IPv6/IPv4 节点们（同时支持）在使用仅支持 IPv4 的网络上用 IPv6 的协议进行通信。 但是事实证明这种技术不是个好主意，RFC4291中废弃了对这类地址的使用，大家知道有这么一回事就可以了。 IPv4 映射地址（IPv4-mapped address） 形如 ::FFFF:X.X.X.X（33-128 位为 ::FFFF），这里的 X.X.X.X 是 IPv4 公共地址的十进制点号表示法，，用于 IPv6 地址表示 IPv4 地址。 主要用于某些场景下 IPv6 节点与 IPv4 节点通信，Linux 内核对这类地址很好地支持。 如何 ping 一个 IPv6 的地址？在 Linux 发行版中，使用 ping6 命令 ping IPv6 主机或者地址。 在浏览器中使用 IPv6 的地址访问 web 资源，IPv6 的地址必须要使用中括号 [] 包起来。 fe80::6e92:bfff:fe04:663c IPv6 的过渡技术IPv4 升级到 IPv6 肯定不会是一蹴而就的，是需要经历一个十分漫长的过渡阶段，要数十年的时间都不为过。现阶段，就出现了 IPv4 慢慢过渡到 IPv6 的技术。过渡技术要解决最重要的问题就是，如何利用现在大规模的 IPv4 网络进行 IPv6 的通信。 要解决上面的问题，这里主要介绍 3 种过渡技术： 1、双栈技术2、隧道技术3、转换技术（有一些文献叫做翻译技术） 本章节会对以上的过渡技术，选取几个典型的、我们未来最有机会接触到的具体的过渡技术结合实验观察过渡技术的具体实现和数据包的表现形式。 双栈技术通信节点同时支持 IPv4 和 IPv6。 例如在同一个交换机下面有 2 个 Linux 的节点，2 个节点都是 IPv4/IPv6 双栈，节点间原来使用 IPv4 上的 UDP 协议通信传输，现在需要升级为 IPv6 上的 UDP 传输。 由于 2 个节点都支持 IPv6，那只要修改应用程序为 IPv6 的 socket 通信基本达到目的了。 上面的例子在局域网通信的改造是很容易的。但在广域网，问题就变得十分复杂了。 因为主要问题是在广域网上的 2 个节点间往往经过多个路由器，按照双栈技术的部署要求，之间的所有节点都要支持 IPv4/IPv6 双栈，并且连接双栈网络的接口必须同时配置 IPv4 公网 地址和 IPv6 地址，才能正常工作，这里就无法解决I Pv4 公网地址匮乏的问题。 双协议栈典型应用场景 如图所示，主机向 DNS 服务器发送 DNS 请求报文，请求域名 www.example.com 对应的 IP 地址。DNS 服务器将回复该域名对应的 IP 地址。 该 IP 地址可能是 10.1.1.1 或 3ffe:yyyy::1。 主机系统发送 A 类查询，则向 DNS 服务器请求对应的 IPv4 地址；系统发送 AAAA 查询，则向 DNS 服务器请求对应的 IPv6 地址。 图中 Router 支持双协议栈功能。如果主机访问 IPv4 地址为 10.1.1.1 的网络服务器，则可以通过 Router 的 IPv4 协议栈访问目标节点。如果主机访问 IPv6 地址为 3ffe:yyyy::1 的网络服务器，则可以通过 Router 的IPv6协议栈访问目标节点。 因此，双栈技术一般不会直接部署到网络中，而是配合其他过渡技术一起使用，例如在隧道技术中，在隧道的边界路由器就是双栈的，其他参与通信的节点不要求是双栈的。 隧道技术当前的网络仍然是 IPv4 为主，因此尽可能地充分利用 IPv4 网络进行 IPv6 通信是十分好的手段之一。隧道技术就是这样子的一种过渡技术。 隧道将 IPv6 的数据报文封装在 IPv4 的报文头部后面（IPv6 的数据报文是 IPv4 的载荷部分），IPv6 通信节点之间传输的 IPv6 数据包就可以穿越 IPv4 网络进行传输。 隧道技术的一个很重要的优点是透明性，通过隧道进行通信的两个 IPv6 节点（或者节点上的应用程序）几乎感觉不到隧道的存在。 根据隧道的出口入口的构成，隧道可以分为路由器-路由器，主机-路由器隧道、路由器-主机、主机-主机隧道等类型。 上图是一种典型的隧道技术：路由器-路由器隧道，两个 IPv6 网络中的主机通过隧道方式穿越了 IPv4 进行通信。 其中 C 节点和 D 节点被称为边界路由器，边界路由器必须要支持 IPv4-IPv6 双栈。当 IPv6 网络 1 的主机 A 将 IPv6 数据包发给边界路由器 C，C 对 IPv6 数据包进行 IPv4 封装，然后在 IPv4 网络上进行传输，发送到边界路由器 D，D 收到 IPv4 的数据包后剥掉 IPv4 的包头，还原 IPv6 的数据包，发送到 IPv6 网络 2 的主机 B。 转换技术有一些文献叫做：翻译技术。 隧道技术是比较好地解决了在很长期一段时间内还是 IPv4 网络是主流的情况下 IPv6 节点（或者双栈节点）间的通信问题。但是由于 IPv4 到 IPv6 的过渡是十分漫长的，因此也需要解决 IPv6 节点与 IPv4 节点通信的问题。协议转换技术可以用来解决这个问题。 协议转换技术根据协议在网络中位置的不同，分为网络层协议转换、传输层协议转换和应用层协议转换等。 协议转换技术的核心思路就是在 IPv4 和 IPv6 通信节点之间部署中间层，将 IPv4 和 IPv6 相互映射转换。 我们非常熟悉的 NAT 也是一种典型的协议转换技术，是将私网 IPv4 地址映射转换为公网 IPv4 地址，这种转换技术又称为 NAT44。 参考： http://t.cn/RmdLf6Phttp://t.cn/EU9ejDNhttp://t.cn/EU9dCvF]]></content>
      <categories>
        <category>网络相关</category>
      </categories>
      <tags>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 08 懵逼，可重复读好像失效了？]]></title>
    <url>%2Fmysql-zhuanlan-08-current-read.html</url>
    <content type="text"><![CDATA[我们之前学习了隔离级别和锁，在隔离级别里有一个可重复读，锁里有个行锁。 可重复读：事务期间，看不懂别的事务的更新； 行锁：有事务 1 在更新某行数据时，若有其他事务 2 进来，会被锁住 矛盾来了：事务 2 等待结束，获取到行锁时，看到的是哪个数据呢？ 按可重复读隔离级别来说，看到的应该是事务启动时的最新数据，即事务 1 修改之前的数据； 但是这样不就造成了事务 1 的修改丢失了吗？ 本文脑图：https://mubu.com/doc/hyPYP01r-G 话不多说，我们先手动实验一把。 实验我们建个表先： 123456mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `k` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2); 然后做如下操作： 说明：1、begin/start transaction 运行后其实并不会立即启动事务，执行第一个操作 InnoDB 表的语句时才会真正启动；2、显示启动事务：start transaction with consistent snapshot 很容易看到实验结果： A 读到的值是 1 B 读到的值是 3 看上去 B 事务违反了可重复读隔离级别的概念，为啥呢？ 原因探索之前在学习事务隔离级别时，我们接触到了一个「视图」的概念，这个视图和我们平常接触的 view 视图并不一样。 MySQL 中的两个「视图」的区别一、常说的视图：view ① 是用查询语句定义的虚拟表；② 在调用时执行查询，并生成结果；③ 创建方法：create view...； 二、MVCC 中的一致性视图（consistent read view） ① 用于支持隔离级别的实现：RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）② 没有物理结构，作用是事务执行期间用来定义我能看到什么数据；③ 其中，可重复读：每个事务启动是都会重建读视图，整个事务存在期间都用这个视图； 快照是什么很多文章都会说可重复读隔离级别下，事务启动时会生成整个库的快照。 那么这个快照是什么？ 我们要先了解下数据的版本问题： 其实每个事务都有一个标识 id：trx_id，是在事务启动时向存储引擎的事务系统申请的，并且是按照申请顺序严格递增的。 每行数据都有版本的概念，这里的版本其实就是修改历史，而这个修改历史是跟事务挂钩的，比如： 如图所示，一行数据被多次事务修改时，这行数据会存储多个版本，如 V1、V2、V3 等。 每个版本会记录了关联的事务 id，这里的版本并不是物理上存在的，需要根据版本号+undo log 来获取。 其实，快照就是版本号的集合。 事务启动时发生了什么可重复读隔离级别下，事务的属性是这样的：可以看到所有已提交的更新，所有未提交的更新都不能看到。对于同一行数据，以最新一次的事务提交为数据基准。 另外，事务启动后，很可能存在其他活跃事务（启动且未提交），我们把这些活跃事务的 id 组成一个数组，并且记数组中 trx_id 最小的记为低水位，trx_id 最大的记为高水位。 因此，所有的事务 id 可以分成下图这种： trx_id 在绿色部分，已提交，可见 在红色部分，未提交，不可见 黄色部分 trx_id 在数组中，未提交，不可见 trx_id 不在数组中，已提交，可见 举个例子 1、假设有一组事务 id：[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]； 2、其中已提交（可见）：[1, 2, 3, 6, 7]，未开始的（不可见）：[10, 11, 12]，当前 id：[8] 3、那么活跃 id 数组（不可见）：[4, 5, 9]，高水位：9，低水位：4； 4、高低水位之间既有已提交但不在数组中的（可见）：[6, 7]，又有活跃的（不可见）：[4, 5, 9] 实验复盘按照上面的数组和水位的概念，我们来捋一下文章开头的实验。 首先，假设事务 A 的 id 为 10，启动后，A 的活跃数组就是 [10]； 接下来是事务 B，id 为 11，启动后，B 的活跃数组是 [10, 11]； 最后是 C，id 为 12，启动后，活跃数组是 [10, 11, 12]； C 处理完毕后，直接提交事务；k 的值由 1 变为 2， 此时就存储了两个版本的数据：（事务id-9, 1），（事务id-12, 2） 接下来 B 来处理，它会将 k 的值更新为 3，此时就有三个版本的数据：（事务id-9, 1），（事务id-12, 2）,（事务id-11, 3） 最后 A 事务，由于 A 启动时，B、C 事务都未提交，所以它们的数据更新对于 A 来说都是看不到的，因此 A 获取到的结果是 1。 更新的逻辑不知道你注意到没有，上面的复盘中，有一个重要的点，我们没有说。 按照可重复读的逻辑，B 执行更新时，看到的 k 的值应该是 1，执行更新的话，就直接造成了 C 操作中的数据丢失。 但是事务 B 在更新时，为什么读取到了事务 C 更新的数据？ 这里有一条规则，就是更新数据都是先读后写的，而这个读，只能读当前的最新值，称为当前读（current read）， 即，更新数据时总是读取已经提交完成的最新版本。 另外，除了 update 语句外，select 语句如果加锁，也是当前读。 12读锁（S 锁，共享锁）：mysql&gt; select k from t where id=1 lock in share mode;写锁（X 锁，排他锁）：mysql&gt; select k from t where id=1 for update; 总结可重复读的能力是怎么实现的？ 把握以下几点： 1、可重复读的核心就是一致性读（consistent read）； 2、而事务更新数据的时候，只能用当前读。 3、如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 另外，本文的几个重要概念： 1、一致性视图，保证了当前事务从启动到提交期间，读取到的数据是一致的（包括当前事务的修改）。 2、当前读，保证了当前事务修改数据时，不会丢失其他事务已经提交的修改。 3、两阶段锁协议，保证了当前事务修改数据时，不会丢失其他事务未提交的修改。 4、RR 是通过事务启动时创建一致性识图来实现，RC 是语句执行时创建一致性识图来实现 课后题目我们用下面的语句初始化一个表： 123456mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, c) values(1,1),(2,2),(3,3),(4,4); 你是否可以尝试制造出下面的「诡异」现象？ 诡异之处在于，我们的目的是将“字段 c 和 id 值相等的行”的 c 值清零，但是发现更新语句执行成功后，c 的值并没有被清零！ 答案 我们用如下操作流程就可以： 事务 A 事务 B 查询结果 start transaction with consistent snapshot; start transaction with consistent snapshot; select * from t; 1 2 3 4 update t set c = 5; commit; update t set c = 0 where id=c; select * from t; 1 2 3 4 commit; select * from t; 5 5 5 5 原因分析 主要原因就算当前读！ 事务 B 是在事务 A 之后启动的，但是事务 B 的更新提交是在 事务 A 之前。 事务 A 第一次查询时，由于可重复读，读取到的自然是 1 2 3 4。 事务 A 更新时，根据当前读规则，此时 c 的值已经是 5，不再满足更新条件 id=c，因此更新不会真正执行。 所以，事务 A 再次查询时，获取到的仍然是 1 2 3 4，事务 A 提交后，再查询时，获取到的自然是最新的数据了。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[现在的年轻人好像都很优秀！]]></title>
    <url>%2Fwhy-are-they-so-excellent.html</url>
    <content type="text"><![CDATA[再不加把劲，就要被后面大浪拍死了！ 1、 周末，亲戚带着孩子到家里来玩，小朋友 5 岁，她没事做，就一个人在那「搞创作」，信手涂鸦。 我看了下，她画得有模有样，有一种自成一派的感觉。 可惜，忘了拍照了，走得时候，画作都被一并带走了。 小孩的妈妈说，她并没有上过什么画画培训班，就是自己对着小人书画着玩的。 我有点惊讶，现在让我来画，估计都画不出。 吃过饭，她又乖乖地看起了书。一个还没有上小学的小孩，读起没有拼音的故事书来竟然毫不费力。 她妈妈说，回到家没事做，她要么就是自己画画，要么就在那读书。 2、 做公众号有一段时间了，结识了其他很多比我优秀的多的号主。 我发现，现在的他们即比我优秀，还比我年轻！ 比如，K 哥、小詹、亮哥、老表、小鹿，等等很多。 他们有的已经工作，有的研究生在读，有的本科毕业在工作，有的在准备考研了，有的只不过才大二。 想想自己，我大二时在干嘛？我读研时又在干嘛？ 3、 年轻人一波又一波，长江后浪推前浪，我自己还没开始浪，就要被拍在沙滩上了！ 想一下，为什么年轻人越来越优秀了？ 首先，肯定是他们能够接触到的知识、认知比我那时要多得多，我上大学时还用着诺基亚，每月为 300 条短信而「斤斤计较」。 现在呢？网络的发展，让他们能够接触到很多东西，视野在很早就得到了拓展。 再者，也需要他们自身的努力，就算坐拥矿山，自己不努力，也是白搭！ 他们不是每天都在打游戏，在那浑浑噩噩，他们在努力！ 努力读书，写代码，工作，接触更多的东西！ 4、 有时仔细想想，自己跟这些年轻的人相比，好像没有什么优势，还处处是劣势。 年纪又大，精力又差，还不好管教…… 现在需要做的是认清现实，承认不足，从现在追起，就算追不上他们，超过昨天的自己就赢了吧！ 再不加把劲，就要被后面大浪拍死了！]]></content>
      <categories>
        <category>闲扯系列</category>
      </categories>
      <tags>
        <tag>扯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 06/07 简单说说MySQL中的锁]]></title>
    <url>%2Fmysql-zhuanlan-06-07-lock.html</url>
    <content type="text"><![CDATA[本文思维导图：https://mubu.com/doc/AOa-5t-IsG 锁是计算机协调多个进程或纯线程并发访问某一资源的机制。 在数据库中，除传统的计算资源（CPU、RAM、I/O）的争用以外，数据也是一种供许多用户共享的资源。 如何保证数据并发访问的一致性、有效性是所在有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。 为什么要有锁？使用数据库，避免不了并发问题，当并发事务同时访问一个资源时，有可能导致数据不一致，因此需要一种机制来将数据访问顺序化，以保证数据库数据的一致性。 锁就是其中的一种机制。 我们可以用公厕做个比喻。 公厕是可供多个消费者使用的，因此可能出现多个人同时需要使用厕所的情况。 但是，厕所只有一个，总不能大家一起吧？ 为了避免冲突，于是厕所里装了锁，某一个人在上测试时，可以在里面用锁锁住，其他人就不能再从外面打开了，只能等待。 等里面的人出来了，从里面把锁打开，外面的人才能进去。 下面，带你一起梳理下 MySQL 的锁管理机制和锁的执行流程，先有一个大致的脉络。 MySQL 的锁管理机制 1、全局读锁 — FLUSH TABLES WITH READ LOCK（SQL层） 2、表级 table-level 数据锁（SQL层） 3、Meta-data 元数据锁：在 table cache 缓存里实现的，为 DDL（Data Definition Language）提供隔离操作。 4、存储引擎特有机制 — row locks行锁，page locks页锁，table locks表级，版本控制（在引擎中实现） 相对其他数据库而言，MySQL 的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。 MySQL 的锁执行流程 1、计算语句使用到的所有表；2、在每个表：打开表，从 table cache 缓存里得到 TABLE 对象，并在此表加上 meta-data 元数据锁；3、等待全局读锁后改变数据；4、在每个表：锁表，在表加上 table-level 数据锁；5、执行语句：调用：handler::write_row()/read_rnd()/read_index() 等；隐式地调用引擎级 engine-level 锁机制；6、在每个表：释放表的数据锁；7、在每个表：释放表的 DDL 锁并把表放回 table cache 缓存里； 下面，我们开始简单针对每一种锁，看下都有什么特点。 全局锁加了全局锁后，整个库变为只读状态，所有的写操作都会被阻塞，包括： 数据的增删改 表结构的创建、修改 更新事务 加全局锁的命令：Flush tables with read lock，即 FTWRL。 全局锁的主要使用场景是全库的逻辑备份，加了全局锁进行备份时有一定的使用风险： 1、若在主库备份，备份期间只读，会影响业务；2、若在从库备份，从库只读，无法及时同步主可以的更新，造成主从不一致； mysqldump –single-transaction也许你还记得，我们在之前讲事务的时候，有一个隔离级别叫做可重复读，也就是设置了隔离级别进入事务后，别的事务更改数据不会影响当前的读取。 使用 mysqldump 命令，结合 --single-transaction 参数，可以将隔离级别设置为：REPEATABLE READ。 并且随后再执行一条 START TRANSACTION 语句，让整个数据在 dump 过程中保证数据的一致性，这个选项对 InnoDB 的数据表很有用，且不会锁表。 为了确保使用 –single-transaction 命令时，最终 dump 文件的有效性。需没有下列语句 ALTER TABLE, CREATE TABLE, DROP TABLE, RENAME TABLE, TRUNCATE TABLE，因为一致性读不能隔离上述语句。所以如果在 dump 过程中，使用上述语句，可能会导致 dump 出来的文件数据不一致或者不可用。 为啥不直接使用 mysqldump –single-transaction 来备份？ 因为，有些引擎不支持事务啊，比如 MyISAM 引擎，所以，现在大家都在力推用 InnoDB 替代 MyISAM。 set global readonly=true？set global readonly=true 也可以将全局表设为只读状态，有啥区别呢？ 首先，修改 global 变量的方式影响面更大，不建议使用。 另外，异常处理机制上和 FTWRL 有差异： FTWRL 命令：客户端异常断开，MySQL 会自动释放全局锁，整个库回到正常更新的状态 readonly 状态下，客户端发生异常，数据库会一直保持 readonly 状态，导致整个库长时间处于不可写状态 注意点 FTWRL 前有读写的话 ，FTWRL 都会等待读写执行完毕后才执行 FTWRL 执行的时候要刷脏页的数据到磁盘，要保持数据的一致性 执行 FTWRL 时候会等待所有事务都提交完毕 表级锁表锁语法 1LOCK TABLES tbl_name ; # 不影响其他表的写操作 解锁也是： 1UNLOCK TABLES; 注意点： 这两个语句在执行的时候都需要注意个特点，就是隐式提交的语句，在退出 mysql 终端的时候都会隐式的自动执行 unlock tables，也就是如果要让表锁定生效就必须一直保持对话。 lock tables 除了会限制别的线程的读写外，也会限制本线程接下来的操作对象 锁住整个表的影响面较大 P.S. MYSQL 的 read lock 和 wirte lock read-lock：允许其他并发的读请求，但阻塞写请求，即可以同时读，但不允许任何写，也叫共享锁write-lock：不允许其他并发的读和写请求，是排他的（exclusive），也叫独占锁 元数据锁（MDL：metadata lock）元数据锁不需要显式使用，在访问一个表的时候会自动加上。 它的作用主要是保证读写的正确性。 表的增删改查操作，需要先加 MDL 读锁； 表结构变更操作，需要先加 MDL 写锁 MDL 读锁之间不互斥，多个线程可以同时对一张表增删改查。 MDL 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。 如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。 因此，需要避免长事务，因为长事务会造成锁一直不能释放，后续的操作会堆积，这个库的线程很快就会爆满。 行锁行锁是引擎层实现的，像 MyISAM 引擎就直接不支持行锁，这些引擎在并发控制只能用表锁！ InnoDB 的行锁两阶段协议： 需要的时候加上 事务结束时释放 当需要锁多个行时，尽量把影响并发的锁往后放，这样可以最大程度的减少事务之间的锁等待，提升并发度。 另外，InnoDB 的 行锁建立在索引的基础上，锁的是索引。因此，如果更新的列没建索引会锁住整个表。 死锁 不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源。 死锁对策 1、主动等待超时，由参数 innodb_lock_wait_timeout 设置，但是业务无法等待； 2、主动死锁检测（innodb_deadlock_detect=on） 发生死锁后，InnoDB 一般都可以检测到，并使一个事务释放锁回退，另一个则可以获取锁完成事务。 另外，我们可以采取以下方式避免死锁： 通过表级锁来减少死锁产生的概率； 多个程序尽量约定以相同的顺序访问表（这也是解决并发理论中哲学家就餐问题的一种思路）； 同一个事务尽可能做到一次锁定所需要的所有资源。 另外，死锁检测也非常耗费资源，判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。 比如有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的，这将消耗大量的 CPU 资源。 如何解决死锁检测耗费资源的情况？ 1、关掉死锁检测，需要保证不会发生死锁；2、控制并发，对应相同行的更新，在进入引擎之前排队； 数据库服务端实现，中间件实现 不要在客户端实现，因为客户端的数量未知 改 MySQL 源码 将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高 更新一条记录时具体什么时候用行锁什么时候是表锁引擎支持行锁就行锁，比如 innodb； 引擎不支持行锁就表锁，比如 myisam； Online DDL 的过程在 MySQL5.6 中，开始支持更多的 alter table 类型操作来避免 copy data，同时支持了在线上 DDL 的过程中不阻塞 DML 操作，真正意义上的实现了 Online DDL。 1、拿 MDL 写锁2、降级成 MDL 读锁3、真正做 DDL4、升级成 MDL 写锁5、释放 MDL 锁 1、2、4、5 如果没有锁冲突，执行时间非常短。第 3 步占用了 DDL 绝大部分时间，这期间这个表可以正常读写数据，是因此称为「online」 总结 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 这些存储引擎通过总是一次性同时获取所有需要的锁以及总是按相同的顺序获取表锁来避免死锁。 表级锁更适合于以查询为主，并发用户少，只有少量按索引条件更新数据的应用，如 Web 应用 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 最大程度的支持并发，同时也带来了最大的锁开销。 在 InnoDB 中，除单个 SQL 组成的事务外，锁是逐步获得的，这就决定了在 InnoDB 中发生死锁是可能的。 行级锁只在存储引擎层实现，而 Mysql 服务器层没有实现。 行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统 上述特点来看，很难说哪种锁更好，只能相对于所处的业务场景来选择更加适合的锁机制。 如果仅从锁的角度来看，表级锁更适合以查询为主的应用场景，而行级锁则更适合于大量按索引条件并发更新少量数据的应用场景。 对于平时常用的存储引擎，MyISAM 采用的是表级锁，InnoDB 采用的是行级锁加表级锁。 参考：https://dwz.cn/oudQ7cM9]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好物分享 | 一个支持文字识别的图书管理软件]]></title>
    <url>%2Fgood-things-shaishufang.html</url>
    <content type="text"><![CDATA[之前朋友圈经常发一些图书的精彩摘录，比如这样的： 很多小伙伴问我是怎么做的，今天特地分享一下。 其实我就是用了一个图书管理软件：晒书房。 简介为什么推荐「晒书房」呢？ 下面一段，来自官方： 整理藏书，发现好书，记录心得，与附近书友分享。 读书人喜欢的整理工具：馆藏分类、标签，写书评、书摘，记录阅读状态，还能将生成的书目导出到本地。 高精度文字识别技术，随手摘录图书精彩段落，与更多书友分享交流！ 这里有数十万跟你一样热爱读书、尤其信奉纸质书阅读的书友。书房就是您的名片，书对了、人就对了！ 其实，我选择晒书房，一个重要原因就是它支持文字识别，并且是免费的，不限次数的！ 之前也下载了很多类似软件，要么我广告太多，要么就是文字识别要收费！ 这其实抓住了我的一个痛点，平常读书时，喜欢记笔记，遇到好的段落想着把它摘录下来。 现在，我会愿意通过文字识别的方式转化成电子的，而不是手写在本子上，虽说我的字很好看~ 另外，电子的更容易分享和管理。 使用流程使用大概流程是这样的： 1、录入图书：可以通过扫描图书的二维码，也可以通过书名搜索的方式； 2、开始自己的阅读； 3、遇到好的段落，拍照进行文字识别； 还可以翻页扫描。 4、写下自己的想法，发布成个人动态； 当然，它的功能还很多，比如支持图书扫码录入，支持个人图书馆，等等。 这里，我们就不再一一介绍。 其实，晒书房一个特性是它的社交属性，已书为桥梁，将各位读者串联起来，不过我还是更乐意把它当做一个工具。 缺点和建议一个我最纠结的缺点就是，识别的文字是以个人动态的方式存储的，而且不支持导出！ 希望的产品建议： 对接豆瓣评分，评价系统； 对接 Kindle，将 kindle 中的文章标注读取出来； 导出我的动态； 作为一个技术宅，我觉得有必要自己尝试实现一下我的动态导出功能了！]]></content>
      <categories>
        <category>好物分享</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 05 如何设计高性能的索引？]]></title>
    <url>%2Fmysql-zhuanlan-05-high-performance-index.html</url>
    <content type="text"><![CDATA[上回我们主要研究了为什么使用索引，以及索引的数据结构。今天带你了解如何设计高性能的索引。 其中，有这么一个点，说的是 InnoDB 引擎中使用的是聚簇索引，其主索引的实现树中的叶子结点存储的是完整的数据记录，而辅助索引中存储的则只是辅助键和主键的值。 这样在用辅助索引进行查询时，会先查出主键的值，然后再去主索引中根据主键的值查询目标值。 比如，假想一个表如下图存储了 4 行数据。其中 Id 作为主索引，Name 作为辅助索引。 Id Name Company 5 Gates Microsoft 7 Bezos Amazon 11 Jobs Apple 14 Ellison Oracle 对于聚簇索引，若使用主键索引进行查询，select * from tab where id = 14 这样的条件查找主键，则按照 B+ 树的检索算法即可查找到对应的叶节点，之后获得行数据。 若使用辅助索引进行查询，对 Name 列进行条件搜索，则需要两个步骤： 1、第一步在辅助索引 B+ 树中检索 Name，到达其叶子节点获取对应的主键值。2、第二步根据主键值在主索引 B+ 树中再执行一次 B+ 树检索操作，最终到达叶子节点即可获取整行数据。 上面这个过程称为回表。 回表：在数据中，当查询数据的时候，在索引中查找索引后，获得该行的 rowid，根据 rowid 再查询表中数据，就是回表。 显然，使用辅助索引出现了回表操作，这势必会影响查询性能，那有什么办法能够减少回表吗？ 下面就开始我们的主题：如何让 MySQL 索引更高效！ 覆盖索引上面，我们查询的是 select *，如果是根据 Name 查询 Id 呢？即 select Id from tab where Name=&#39;Jobs&#39;。 很明显，由于辅助索引 Name 上已经存储了 Id 的值，所以这时，查询便不会再次回表查询。 如果索引已经包含了所有满足查询需要的数据，这时我们称之为覆盖索引（Covering Index），这时就不再需要回表操作。 覆盖索引是一种非常强大的工具，能大大提高查询性能，只需要读取索引而不用读取数据有以下一些优点： 1、索引条目通常远小于数据行大小，只需要读取索引，则 MySQL 会极大地减少数据访问量。 2、因为索引是按照列值顺序存储的，所以对于 IO 密集的范围查找会比随机从磁盘读取每一行数据的 IO 少很多。 3、覆盖索引对 InnoDB 表特别有用。因为 InnoDB 的辅助索引在叶子节点中保存了行的主键值，所以如果二级主键能够覆盖查询，则可以避免对主键索引的二次查询； 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 联合索引/最左匹配原则又名复合索引，由两个或多个列的索引。 它规定了 MySQL 从左到右地使用索引字段，对字段的顺序有一定要求。 另外，一个查询可以只使用索引中的一部分，更准确地说是最左侧部分（最左优先），这就是传说中的最左匹配原则。 即最左优先，如： 如果有一个 2 列的索引 (col1,col2)，则相当于已经对 (col1)、(col1,col2) 上建立了索引； 如果有一个 3 列索引 (col1,col2,col3)，则相当于已经对 (col1)、(col1,col2)、(col1,col2,col3) 上建立了索引； 但是 (col2,col3) 上并没有。 假定数据表有一个包含 2 列的联合索引（a, b），则索引的 B+ 树结构可能如下： 键值都是排序的，通过叶子节点可以逻辑上顺序的读出所有数据。 数据（1,1）（1,2）（2,1）（2,4）（3,1）（3,2）是按照（a，b）先比较 a 再比较 b 的顺序排列。 所以从全局看，a 是全局有序的，而 b 则不是。 基于上面的结构，对于以下查询显然是可以使用（a，b）这个联合索引的： 123select * from table where a=xxx and b=xxx ;select * from table where a=xxx; 但是对于下面的 sql 是不能使用这个联合索引的，因为叶子节点的 b 值，1,2,1,4,1,2 显然不是排序的。 1select * from table where b=xxx 只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。 注意1、主键字段其实跟所有非主键索引建立了联合索引，只是说如果主键字段没有在联合索引中明确声明，只会在其他索引中处于最右边； 2、最左前缀匹配原则，MySQL 会一直向右匹配直到遇到范围查询（&gt;、&lt;、between、like）就停止匹配。 比如 a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立 (a,b,c,d) 顺序的索引，d 是用不到索引的，如果建立 (a,b,d,c) 的索引，则都可以用到，a,b,d 的顺序可以任意调整。 3、= 和 in 的条件可以乱序 MySQL 的查询优化器会帮你优化成索引可以识别的形式。MySQL 查询优化器会判断纠正 SQL 语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。 为什么要使用联合索引？1、 减少开销 “一个顶三个”。建一个联合索 引(col1,col2,col3)，实际相当于建了 (col1),(col1,col2),(col1,col2,col3) 三个索引。 每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！ 2、 覆盖索引 对联合索引 (col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么 MySQL 可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机 IO 操作。 减少 io 操作，特别的随机 io 其实是 dba 主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。 3、 效率高 索引列越多，通过索引筛选出的数据越少。 有 1000W 条数据的表，有如下sql: select col1,col2,col3 from table where col1=1 and col2=2 and col3=3，假设假设每个条件可以筛选出 10% 的数据。 如果只有单值索引，那么通过该索引能筛选出 1000W_10%=100w 条数据，然后再回表从 100w 条数据中找到符合 col2=2 and col3= 3 的数据，然后再排序，再分页； 如果是联合索引，通过索引筛选出 1000w_10% 10% 10%=1w，效率提升可想而知！ 索引下推索引条件下推（ICP：index condition pushdown）是 MySQL 中一个常用的优化，尤其是当 MySQL 需要从一张表里检索数据时。 ICP（index condition pushdown）是 MySQL 利用索引（二级索引）元组和筛字段在索引中的 WHERE 条件从表中提取数据记录的一种优化操作。 ICP 的思想是：存储引擎在访问索引的时候检查筛选字段在索引中的 where 条件，如果索引元组中的数据不满足推送的索引条件，那么就过滤掉该条数据记录。 ICP（优化器）尽可能的把 index condition 的处理从 server 层下推到存储引擎层。 存储引擎使用索引过滤不相关的数据，仅返回符合 index condition 条件的数据给 server 层。也是说数据过滤尽可能存储引擎层进行，而不是返回所有数据给 server 层，然后后再根据 where 条件进行过滤。 下推过程优化器没有使用 ICP 时 数据访问和提取的过程如下： ①：MySQL Server 发出读取数据的命令，调用存储引擎的索引读或全表表读。此处进行的是索引读。 ②、③：进入存储引擎，读取索引树，在索引树上查找，把满足条件的（红色的）从表记录中读出（步骤 ④，通常有 IO）。 ⑤：从存储引擎返回标识的结果。 以上，不仅要在索引行进行索引读取（通常是内存中，速度快。步骤 ③），还要进行进行步骤 ④，通常有 IO。 ⑥：从存储引擎返回查找到的多条数据给 MySQL Server，MySQL Server 在 ⑦ 得到较多的元组。 ⑦–⑧：依据 WHERE 子句条件进行过滤，得到满足条件的数据。 注意在 MySQL Server 层得到较多数据，然后才过滤，最终得到的是少量的、符合条件的数据。 在不支持 ICP 的系统下，索引仅仅作为 data access 使用。 优化器使用ICP时 ①：MySQL Server 发出读取数据的命令，过程同图一。 ②、③：进入存储引擎，读取索引树，在索引树上查找，把满足已经下推的条件的（红色的）从表记录中读出（步骤 ④，通常有 IO）； ⑤：从存储引擎返回标识的结果。 此处，不仅要在索引行进行索引读取（通常是内存中，速度快。步骤 ③），还要在 ③ 这个阶段依据下推的条件进行进行判断，不满足条件的，不去读取表中的数据，直接在索引树上进行下一个索引项的判断，直到有满足条件的，才进行步骤 ④ ，这样，较没有 ICP 的方式，IO 量减少。 ⑥：从存储引擎返回查找到的少量数据给 MySQL Server，MySQL Server 在 ⑦ 得到少量的数据。 因此比较图一无 ICP 的方式，返回给 MySQL Server 层的即是少量的、 符合条件的数据。 在 ICP 优化开启时，在存储引擎端首先用索引过滤可以过滤的 where 条件，然后再用索引做 data access，被 index condition 过滤掉的数据不必读取，也不会返回 server 端。 举例比如： 123SELECT * FROM employees WHERE first_name='Mary' AND last_name LIKE '%man'; 在没有 ICP 时，首先通过索引前缀从存储引擎中读出所有 first_name 为 Mary 的记录，然后在 server 端用 where 筛选 last_name 的 like 条件； 而启用 ICP 后，由于 last_name 的 like 筛选可以通过索引字段进行，那么存储引擎内部通过索引与 where 条件的对比来筛选掉不符合 where 条件的记录，这个过程不需要读出整条记录，同时只返回给 server 筛选后条记录，因此提高了查询性能。 注意事项有几个关于ICP的事情要注意： ICP 只能用于二级索引，不能用于主索引； 也不是全部 where 条件都可以用 ICP 筛选，如果某 where 条件的字段不在索引中，当然还是要读取整条记录做筛选，在这种情况下，仍然要到 server 端做 where 筛选； ICP 的加速效果取决于在存储引擎内通过 ICP 筛选掉的数据的比例； 总结建索引的几大原则1、最左前缀匹配原则，非常重要的原则，MySQL 会一直向右匹配直到遇到范围查询 （&gt;、&lt;、between、like）就停止匹配； 2、= 和 in 的条件可以乱序； 3、尽量选择区分度高的列作为索引，区分度表示字段不重复的比例，比例越大我们扫描的记录数越少； 4、索引列不能参与计算，保持列「干净」。原因很简单，b+ 树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。 5、尽量的扩展索引，不要新建索引。 索引是最好的解决方案吗？ 索引不是最好的，但已经是相当好的了。 当表非常小时，没必要使用索引，直接全表查询好了； 当表是中大型时，比较适合使用索引，来快速定位目标数据； 当表是超大型时，创建和维护索引都是不小的代价，需要专业的 DBA 来分析，这种情况下可以尝试使用分表技术； 参考：https://blog.csdn.net/u012006689/article/details/73195837http://lihx8.lofter.com/post/1cc9bc99_7da03fe]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 04 为什么要使用索引？]]></title>
    <url>%2Fmysql-zhuanlan-04-index.html</url>
    <content type="text"><![CDATA[用过 MySQL 的应该都知道索引是干啥的吧，应该多少都设置过索引，但是若是问你索引是怎么实现的，你能说上来吗？ 索引是什么？ MySQL 官方对索引的定义为：索引是帮助 MySQL 高效获取数据的数据结构。 在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。 索引的出现就是为了提高查询效率，就像书的目录。其实说白了，索引要解决的就是查询问题。 查询，是数据库所提供的一个重要功能，我们都想尽可能快的获取到目标数据，因此就需要优化数据库的查询算法，选择合适的查询模型来实现索引。 另外，为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间，因为索引也要随之变动。 常见查询模型索引的实现模型有很多，这里我们先了解一下常用的查询模型。 顺序数组顺序数组是一种特殊的数组，里面的元素，按一定的顺序排列。 顺序数组在查询上有着一定的优势，因为是有序的数据，采用二分查找的话，时间复杂度是 O(log(N))。 顺序数组的优点就是查询效率非常高，但是要更新数据的话，就非常麻烦了。删除和插入元素都要涉及到大量元素位置的移动，成本很高。 因此，对于顺序数组更适合用于查询的领域，适合存储一些改动较小的静态存储引擎。 哈希索引哈希表是一种以 键-值（key-value） 存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 value。 哈希索引采用一定的哈希算法，对于每一行，存储引擎计算出了被索引字段的哈希码（Hash Code），把哈希码保存在索引中，并且保存了一个指向哈希表中的每一行的指针。 这样在检索时只需一次哈希算法即可立刻定位到相应的位置，速度非常快。 Hash 索引结构的特殊性，其检索效率非常之高，应该是 O(1) 的时间复杂度。 虽然 Hash 索引效率高，但是 Hash 索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些： 1、Hash索引仅仅能满足 =，IN 和 &lt;=&gt; 查询，如果是范围查询检索，这时候哈希索引就毫无用武之地了。 因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索； 2、Hash 索引无法利用索引完成排序，因为存放的时候是经过 Hash 计算过的，计算的 Hash 值和原始数据不一定相等，所以无法排序； 3、联合索引中，Hash 索引不能利用部分索引键查询。 Hash 索引在计算 Hash 值的时候是联合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值。 所以对于联合索引中的多个列，Hash 是要么全部使用，要么全部不使用。通过前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。 4、Hash索引在任何时候都不能避免表扫描。 前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash 运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键可能存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。 5、在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。 综上，哈希表这种结构适用于只有等值查询的场景，比如 Memcached、redis 及其他一些 NoSQL 引擎。 二叉搜索树索引二叉搜索树的每个节点都只存储一个键值，并且左子树（如果有）所有节点的值都要小于根节点的值，右子树（如果有）所有节点的值都要大于根节点的值。 当二叉搜索树的所有非叶子节点的左右子树的节点数目均保持差不多时（平衡），这时树的搜索性能逼近二分查找；并且它比连续内存空间的二分查找更有优势的是，改变树结构（插入与删除结点）不需要移动大段的内存数据，甚至通常是常数开销。 特殊情况下，根节点的左右子树的高度相差不超过 1 时，这样的二叉树被称为平衡二叉树；与之相对的是，二叉搜索树有可能退化成线性树。 下图展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。 为了加快 Col2 的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在 O(log2n) 的复杂度内获取到相应数据。 B树看得出来，二叉树在查询和修改上做到了一个平衡，都有着不错的效率，但是现实是很少有数据库引擎使用二叉树来实现索引，为什么呢？ 数据库存储大多不适用二叉树，数据量较大时，树高会过高。 你可以想象一下一棵 100 万节点的平衡二叉树，树高 20，每个叶子结点就是一个块，每个块包含两个数据，块之间通过链式方式链接。 树高 20 的话，就要遍历 20 个块才能得到目标数据，索引存储在磁盘时，这将是非常耗时的。 因此，为了减少磁盘的读取，查询时就要尽量少的遍历数据块，因此一般使用 N 叉树。 这里就有了 B树（Balanced Tree）。 究竟什么是 B 树？ 我们先看一个例子： 从上图你能轻易的看到，一个内结点 x 若含有 n[x] 个关键字，那么 x 将含有 n[x]+1 个子女。如含有 2 个关键字 D H 的内结点有 3 个子女，而含有 3 个关键字 Q T X 的内结点有 4 个子女。 B 树的特性 普及一些概念： 节点的度：一个节点含有的子树的个数称为该节点的度；树的度：一棵树中，最大的节点的度称为树的度；叶节点或终端节点：度为零的节点；非终端节点或分支节点：度不为零的节点； 首先定义两个变量：d 为大于 1 的一个正整数，称为 B 树的度。h 为一个正整数，称为 B 树的高度。 B 树是满足下列条件的数据结构： 1、每个非叶子节点由 n-1 个 key 和 n 个指针组成，其中 d&lt;=n&lt;=2d。 2、每个叶子节点最少包含一个 key 和两个指针，最多包含 2d-1 个 key 和 2d 个指针，叶节点的指针均为 null 。 3、除根结点和叶子结点外，其它每个结点至少有 [ceil(m / 2)] 个孩子（其中 ceil(x) 是一个取上限的函数）； 4、所有叶节点具有相同的深度，等于树高 h，且叶子结点不包含任何关键字信息。 5、key 和指针互相间隔，节点两端是指针。 6、一个节点中的 key 从左到右非递减排列。 7、每个指针要么为 null，要么指向另外一个节点。 8、每个非终端结点中包含有 n 个关键字信息： (n，P0，K1，P1，K2，P2，……，Kn，Pn)。 其中：a) Ki (i=1…n) 为关键字，且关键字按顺序升序排序 K(i-1)&lt; Ki。b) Pi 为指向子树根的接点，且指针 P(i-1) 指向子树种所有结点的关键字均小于 Ki，但都大于 K(i-1)。c) 关键字的个数 n 必须满足： [ceil(m / 2)-1]&lt;= n &lt;= m-1。 B 树查找过程 由于 B 树的特性，在 B 树中按 key 检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的 data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到 null 指针，前者查找成功，后者查找失败。 如上图所示，我们来模拟下查找文件 29 的过程： 1、根据根结点指针找到文件目录的根磁盘块 1，将其中的信息导入内存。【磁盘 IO 操作 1 次】 2、此时内存中有两个文件名 17、35 和三个存储其他磁盘页面地址的数据。根据算法我们发现：17&lt;29&lt;35，因此我们找到指针 p2； 3、根据 p2 指针，我们定位到磁盘块 3，并将其中的信息导入内存。【磁盘 IO 操作 20次】 4、此时内存中有两个文件名 26，30 和三个存储其他磁盘页面地址的数据。根据算法我们发现：26&lt;29&lt;30，因此我们找到指针 p2； 5、根据 p2 指针，我们定位到磁盘块 8，并将其中的信息导入内存。【磁盘 IO 操作 3 次】； 6、此时内存中有两个文件名 28，29。根据算法我们查找到文件名 29，并定位了该文件内存的磁盘地址。 分析上面的过程，发现需要 3 次磁盘 IO 操作和 3 次内存查找操作。关于内存中的文件名查找，由于是一个有序表结构，可以利用折半查找提高效率。 B+ 树B+ 树：是应文件系统所需而产生的一种 B 树的变形树。 一棵 m 阶的 B+ 树和 m 阶的 B 树的异同点在于： 1、每个节点的指针上限为 2d 而不是2d+1。 2、所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。（B 树的叶子节点并没有包括全部需要查找的信息） 3、所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字，不存储 data。（B 树的非终节点也包含需要查找的有效信息） 为什么说 B+ 树比 B 树更适合做数据库索引？ 1）B+ 树的磁盘读写代价更低 B+ 树的内部结点并没有存储关键字具体信息。因此其内部结点相对 B 树更小。 如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说 IO 读写次数也就降低了。 2) B+ 树的查询效率更加稳定 由于非终端结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，进而每一个数据的查询效率相当。 几种树的对比 以上，为了介绍索引内容，我们花费了大量的篇幅介绍了几种数据结构模型，特别是树的相关概念。 另外，涉及到树的添加和删除元素，操作更加复杂，本文篇幅有限（其实是小编也搞不太明白），这里就不再展开。 有兴趣的，强烈建议钻研下参考链接里的内容。 好了，下面我们来看 MySQL 中的 InnoDB 引擎的索引是如何实现的。 MySQL 的索引模型说了这么多，终于到索引出场了。 索引就是这种神奇伟大的存在。索引相当于数据库的表数据之外新建的数据结构，该数据结构的数据段中存储着字段的值以及指向实际数据记录的指针。 数据库表的索引从数据存储方式上可以分为聚簇索引和非聚簇索引（又叫二级索引）两种。 1、聚簇索引 表数据按照索引的顺序来存储的，也就是说索引项的顺序与表中记录的物理顺序一致。 对于聚簇索引，叶子结点即存储了真实的数据行，不再有另外单独的数据页。 在一张表上最多只能创建一个聚集索引，因为真实数据的物理顺序只能有一种。 聚簇集是指实际的数据行和相关的键值都保存在一起。 注意：数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。 如果主键不是自增 id，那么可以想象，它会干些什么，不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但，如果是自增的，那就简单了，它只需要一页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。 聚簇索引的二级索引：叶子节点不会保存引用的行的物理位置,而是保存了行的主键值 2、非聚集索引 表数据存储顺序与索引顺序无关。对于非聚集索引，叶结点包含索引字段值及指向数据页数据行的逻辑指针，其行数量与数据表行数据量一致。 聚簇索引是对磁盘上实际数据重新组织以按指定的一个或多个列的值排序的算法。特点是存储数据的顺序和索引顺序一致。一般情况下主键会默认创建聚簇索引，且一张表只允许存在一个聚簇索引。 这两个名字虽然都叫做索引，但这并不是一种单独的索引类型，而是一种数据存储方式。 下面，我们可以看一下 MYSQL 中 MyISAM 和 InnoDB 两种引擎的索引结构。 MyISAM索引实现MyISAM 引擎使用 B+ 树作为索引结构，叶节点的 data 域存放的是数据记录的地址，就是非聚集索引。 下图是 MyISAM 索引的原理图： 在 MyISAM 中，主键索引和辅助索引（Secondary key）在结构上没有任何区别，只是主键索引要求 key 是唯一的，而辅助索引的 key 可以重复。 InnoDB索引实现虽然 InnoDB 也使用 B+ 树作为索引结构，但具体实现方式却与 MyISAM 截然不同。 第一个重大区别是 InnoDB 的数据文件本身就是索引文件。 在 InnoDB 中，表数据文件本身就是按 B+ 树组织的一个索引结构，这棵树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。 另外，第二个与 MyISAM 索引的不同是 InnoDB 的辅助索引 data 域存储相应记录主键的值而不是地址。 对于聚簇索引存储来说，行数据和主键 B+ 树存储在一起，辅助索引只存储辅助键和主键，主键和非主键 B+ 树几乎是两种类型的树。 对于非聚簇索引存储来说，主键 B+ 树在叶子节点存储指向真正数据行的指针，而非主键。 为了更形象说明这两种索引的区别，我们假想一个表如下图存储了 4 行数据。其中 Id 作为主索引，Name 作为辅助索引。图示清晰的显示了聚簇索引和非聚簇索引的差异。 对于聚簇索引，若使用主键索引进行查询，where id = 14 这样的条件查找主键，则按照 B+ 树的检索算法即可查找到对应的叶节点，之后获得行数据。 若使用辅助索引进行查询，对 Name 列进行条件搜索，则需要两个步骤： 1、第一步在辅助索引 B+ 树中检索 Name，到达其叶子节点获取对应的主键。2、第二步根据主键在主索引 B+ 树种再执行一次 B+ 树检索操作，最终到达叶子节点即可获取整行数据。这个过程称为回表。 聚簇索引的优势在哪？1、由于行数据和叶子节点存储在一起，这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键 Id 来组织数据，获得数据更快。 2、辅助索引使用主键作为指针而不是使用地址值作为指针的好处是，减少了当出现行移动或者数据页分裂时辅助索引的维护工作。 使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是 InnoDB 在移动行时无须更新辅助索引中的这个指针。 也就是说行的位置会随着数据库里数据的修改而发生变化，使用聚簇索引就可以保证不管这个主键 B+ 树的节点如何变化，辅助索引树都不受影响。 小结这次内容比较多，涉及到了一些数据结构的内容，我也是翻了很多博客才搞懂那么一点点。主要是要搞懂，为什么要用索引，以及索引的查询流程。 希望对你有用。 参考：http://blog.codinglabs.org/articles/theory-of-mysql-index.htmlhttps://blog.csdn.net/v_JULY_v/article/details/6530142]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 03 - 谁动了我的数据：浅析MySQL的事务隔离级别]]></title>
    <url>%2Fmysql-zhuanlan-03-isolation.html</url>
    <content type="text"><![CDATA[使用过关系型数据库的，应该都事务的概念有所了解，知道事务有 ACID 四个基本属性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability），今天我们主要来理解一下事务的隔离性。 声明：MySQL专栏学习系列，基本上是本人学习极客时间《MySQL实战45讲》专栏内容的笔记，并在专栏基础上进行知识点挖掘。侵删。本人也不是什么 DBA，所以有些错误的地方请大家指正，相互交流，共同进步！ 什么是事务？ 数据库事务（简称：事务）是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。—— 维基百科 事务的概念看上去不难，但是需要注意以下几个点： 1、首先，事务就是要保证一组数据库操作，要么全部成功，要么全部失败； 2、在 MySQL 中，事务支持是在引擎层实现的； 3、并不是所有引擎都支持事务，如 MyISAM 就不支持，InnoDB 就支持； 今天，我们的主角是隔离性，隔离性是指当多个用户并发操作数据库时，数据库为每一个用户开启不同的事务，这些事务之间相互不干扰，相互隔离。 为什么需要隔离性？如果事务之间不是互相隔离的，可能将会出现以下问题。 1、脏读脏读（dirty read），简单来说，就是一个事务在处理过程中读取了另外一个事务未提交的数据。 这种未提交的数据我们称之为脏数据。依据脏数据所做的操作肯能是不正确的。 还记得上节中我们提到的 dirty page 吗？这种临时处理的未提交的，都是「脏」的。 举例 时间点 事务A 事务B 1 开启事务A 2 开启事务B 3 查询余额为100 4 余额增加至150 5 查询余额为150 比如，你给小编赞赏 1 分钱，整个事务需要两个步骤：①给小编账号加一分钱，这时小编看到了，觉得很欣慰；②你的账号减一分钱； 但是，若该事务未提交成功，最终所有操作都会回滚，小编看到的一分钱也只是镜花水月。 2、不可重复读不可重复读（non-repeatable read），是指一个事务范围内，多次查询某个数据，却得到不同的结果。 在第一个事务中的两次读取数据之间，由于第二个事务的修改，第一个事务两次读到的数据可能就是不一样的。 举例 时间点 事务A 事务B 1 开启事务A 2 开启事务B 3 查询余额为100 4 余额增加至150 5 查询余额为100 6 提交事务 7 查询余额为150 接着上一个例子，假设你真给小编打赏了一分钱，小编乐得屁颠屁颠地去准备提现，一查，发现真多了一分钱。 在这同时，在我还没有提现成功之前，小编的老婆已经提前将这一分钱支走了，小编此时再次查账，发现一分钱也没了。 脏读和不可重复读有点懵逼？ 二者的区别是，脏读是某一事务读取了另外一个事务未提交的数据，不可重复读是读取了其他事务提交的数据。 其实，有些情况下，不可重复读不是问题，比如，小编提现期间，一分钱被老婆支走了，这不是问题！ 而脏读，是可以通过设置隔离级别避免的。 3、幻读幻读（phantom read），是事务非独立执行时发生的一种现象。 例如事务 T1 对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务 T2 又对这个表中插入了一行数据项为“1”的数据，并且提交给数据库。 而操作事务 T1 的用户如果再查看刚刚修改的数据，会发现数据怎么还是 1？其实这行是从事务 T2 中添加的，就好像产生幻觉一样，这就是发生了幻读。 举例 时间点 事务A 事务B 1 开启事务A 2 开启事务B 3 查询id&lt;3的所有记录，共3条 4 插入一条记录id=2 5 提交事务 6 查询id&lt;3的所有记录，共4条 其实上面的解释已经是一个例子了，但是还是要举个例子。 比如，小编准备提取你打赏的一分钱，提取完了，这时又有其他热心网友打赏了一分钱，小编一看，明明已经取出了，怎么又有一分钱！？ 小编此时以为像做梦一样，我觉得也可以叫「梦读」，哈哈。 幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。 事务的隔离级别为了解决上面可能出现的问题，我们就需要设置隔离级别，也就是事务之间按照什么规则进行隔离，将事务隔离到什么程度。 首先，需要明白一点，隔离程度越强，事务的执行效率越低。 ANSI/ISO SQL 定义了 4 种标准隔离级别： ① Serializable（串行化）：花费最高代价但最可靠的事务隔离级别。 “写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 事务 100% 隔离，可避免脏读、不可重复读、幻读的发生。 ② Repeatable read（可重复读，默认级别）：多次读取同一范围的数据会返回第一次查询的快照，即使其他事务对该数据做了更新修改。事务在执行期间看到的数据前后必须是一致的。 但如果这个事务在读取某个范围内的记录时，其他事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行，这就是幻读。 可避免脏读、不可重复读的发生。但是可能会出现幻读。 ③ Read committed (读已提交)：保证一个事物提交后才能被另外一个事务读取。另外一个事务不能读取该事物未提交的数据。 可避免脏读的发生，但是可能会造成不可重复读。 大多数数据库的默认级别就是 Read committed，比如 Sql Server , Oracle。 ④ Read uncommitted (读未提交)：最低的事务隔离级别，一个事务还没提交时，它做的变更就能被别的事务看到。 任何情况都无法保证。 下图中是一个很好的例子，分别解释了四种事务隔离级别下，事务 B 能够读取到的结果。 看着还是有点懵逼？那我们再举个例子。 A，B 两个事务，分别做了一些操作，操作过程中，在不同隔离级别下查看变量的值： 事务A 事务B 读未提交 读已提交 可重复读 序列化 启动事务，查询变量V的值为1 启动事务 查询V的值为1 将V的值修改为2 查询V的值 2 1 1 1 提交事务B 查询V的值 2 2 1 1 提交事务A 查询V的值 2 2 2 2 隔离级别是串行化，则在事务 B 执行「将 1 改成 2」的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。 再次总结 读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。读已提交：别人改数据的事务已经提交，我在我的事务中才能读到。可重复读：别人改数据的事务已经提交，我在我的事务中也不去读。串行：我的事务尚未提交，别人就别想改数据。 这 4 种隔离级别，并行性能依次降低，安全性依次提高。 总的来说，事务隔离级别越高，越能保证数据的完整性和一致性，但是付出的代价却是并发执行效率的低下。 隔离级别的实现事务的机制是通过视图（read-view）来实现的并发版本控制（MVCC），不同的事务隔离级别创建读视图的时间点不同。 可重复读是每个事务重建读视图，整个事务存在期间都用这个视图。 读已提交是每条 SQL 创建读视图，在每个 SQL 语句开始执行的时候创建的。隔离作用域仅限该条 SQL 语句。 读未提交是不创建，直接返回记录上的最新值 串行化隔离级别下直接用加锁的方式来避免并行访问。 这里的视图可以理解为数据副本，每次创建视图时，将当前已持久化的数据创建副本，后续直接从副本读取，从而达到数据隔离效果。 隔离级别的实现我们每一次的修改操作，并不是直接对行数据进行操作。 比如我们设置 id 为 3 的行的 A 属性为 10，并不是直接修改表中的数据，而是新加一行。 同时数据表其实还有一些隐藏的属性，比如每一行的事务 id，所以每一行数据可能会有多个版本，每一个修改过它的事务都会有一行，并且还会有关联的 undo 日志，表示这个操作原来的数据是什么，可以用它做回滚。 那么为什么要这么做？ 因为如果我们直接把数据修改了，那么其他事务就用不了原先的值了，违反了事务的一致性。 那么一个事务读取某一行的数据到底返回什么结果呢？ 取决于隔离级别，如果是 Read Committed，那么返回的是最新的事务的提交值，所以未提交的事务修改的值是不会读到的，这就是 Read Committed 实现的原理。 如果是 Read Repeatable 级别，那么只能返回发起时间比当前事务早的事务的提交值，和比当前事务晚的删除事务删除的值。这其实就是 MVCC 方式。 undo logundo log 中存储的是老版本数据。假设修改表中 id=2 的行数据，把 Name=’B’ 修改为 Name = ‘B2’ ，那么 undo 日志就会用来存放 Name=’B’ 的记录，如果这个修改出现异常，可以使用 undo 日志来实现回滚操作，保证事务的一致性。 当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着 undo 链找到满足其可见性的记录。当版本链很长时，通常可以认为这是个比较耗时的操作。 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。 如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。 同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。 另外，在回滚段中的 undo log 分为: insert undo log 和 update undo log： insert undo log : 事务对 insert 新记录时产生的 undolog，只在事务回滚时需要，并且在事务提交后就可以立即丢弃。（谁会对刚插入的数据有可见性需求呢！！） update undo log : 事务对记录进行 delete 和 update 操作时产生的 undo log。不仅在事务回滚时需要，一致性读也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被 purge 线程删除。 何时删除？ 在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。 就是当系统里没有比这个回滚日志更早的 read-view 的时候。 长事务直观感觉，一个事务花费很长时间不能够结束，就是一个长的事务，简称长事务（Long Transaction）。 长事务是数据库用户经常会碰到且是非常令人头疼的问题。长事务处理需要恰当进行，如处理不当可能引起数据库的崩溃，为用户带来不必要的损失。 根据上面的论述，长事务意味着系统里面会存在很老的事务视图。 由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的 undo log 都必须保留，这就会导致大量占用存储空间。 在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。 因此，我们要尽量避免长事务。 小结这一节主要是事务的隔离级别，感觉东西有点乱，涉及了 MVCC 的东西，作者也没有展开，我能力有限，也就没有再深挖。后续，作者在涉及相关知识点时，我们再进行探讨。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 02-MySQL 如何恢复到半个月内任意一秒的状态？]]></title>
    <url>%2Fmysql-zhuanlan-02-redolog-binlog.html</url>
    <content type="text"><![CDATA[看到这个题目是不是觉得数据库再也不用担心服务器 crash 了？ 那我们需要学习为什么可以这么做？以及如何做？ 即为什么可以恢复到任意时间点？如何恢复到任意时间点？ 为什么有了 binlog 还需要 redo log？ 事务是如何提交的？事务提交先写 binlog 还是 redo log？如何保证这两部分的日志做到顺序一致性？ 为了保障主从复制安全，故障恢复是如何做的？ 上一次课我们学习了一条 select 语句的全部执行过程，那么今天我们就从一条 update 语句开始。 1mysql&gt; update T set c=c+1 where ID=2; 其实执行流程和查询流程一致，只是最后执行器执行的是找到这条数据，并进行更新。 另外，更新过程还涉及到一个重要的日志模块，即 redo log（重做日志）和 binlog（归档日志）。 我个人是只听过 binlog 的。 redo log和大多数关系型数据库一样，InnoDB 记录了对数据文件的物理更改，并保证总是日志先行。 也就是所谓的 WAL（Write-Ahead Logging），即在持久化数据文件前，保证之前的 redo 日志已经写到磁盘。 MySQL 的每一次更新并没有每次都写入磁盘，InnoDB 引擎会先将记录写到 redo log 里，并更新到内存中，然后再适当的时候，再把这个记录更新到磁盘。 这里有必要贴一下 InnoDB 的存储结构图： 如果下面看的各种空间懵逼了，建议回来看一眼这个图。 redo log 是啥当数据库对数据做修改的时候，需要把数据页从磁盘读到 buffer pool 中，然后在 buffer pool 中进行修改，那么这个时候 buffer pool 中的数据页就与磁盘上的数据页内容不一致，我们称 buffer pool 的数据页为 dirty page 脏数据。 这里也可以看出，所有的更新操作都是现在 dirty page 中进行的。 如果这个时候发生非正常的 DB 服务重启，那么这些数据还没在内存，并没有同步到磁盘文件中（注意，同步到磁盘文件是个随机 IO），也就是会发生数据丢失。 如果这个时候，能够在有一个文件，当 buffer pool 中的 dirty page 变更结束后，把相应修改记录记录到这个文件（注意，记录日志是顺序 IO），那么当 DB 服务发生 crash 的情况，恢复 DB 的时候，也可以根据这个文件的记录内容，重新应用到磁盘文件，数据保持一致。 这个文件就是 redo log ，用于记录数据修改后的记录，顺序记录。 我理解的，redo log 就是存放 dirty page 的物理空间。 log 何时产生 &amp; 释放？在事务开始之后就产生 redo log，redo log 的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入 redo log 文件中。 当对应事务的脏页写入到磁盘之后，redo log 的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。 如何写？Redo log 文件以 ib_logfile[number] 命名，并以顺序的方式写入文件文件，写满时则回溯到第一个文件，进行覆盖写。 如图所示： write pos 是当前记录的位置，一边写一边后移，写到最后一个文件末尾后就回到 0 号文件开头； checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件； write pos 和 checkpoint 之间还空着的部分，可以用来记录新的操作。 如果 write pos 追上 checkpoint，表示写满，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 Redo log 文件是循环写入的，在覆盖写之前，总是要保证对应的脏页已经刷到了磁盘。 在非常大的负载下，Redo log 可能产生的速度非常快，导致频繁的刷脏操作，进而导致性能下降。 通常在未做 checkpoint 的日志超过文件总大小的 76% 之后，InnoDB 认为这可能是个不安全的点，会强制的 preflush 脏页，导致大量用户线程 stall 住。 如果可预期会有这样的场景，我们建议调大 redo log 文件的大小。可以做一次干净的 shutdown，然后修改 Redo log 配置，重启实例。 参考：http://mysql.taobao.org/monthly/2015/05/01/ 相关配置默认情况下，对应的物理文件位于数据库的 data 目录下的 ib_logfile1、ib_logfile2。 12345innodb_log_group_home_dir 指定日志文件组所在的路径，默认./ ，表示在数据库的数据目录下。innodb_log_files_in_group 指定重做日志文件组中文件的数量，默认2# 关于文件的大小和数量，由一下两个参数配置innodb_log_file_size 重做日志文件的大小。innodb_mirrored_log_groups 指定了日志镜像文件组的数量，默认1 其他redo log 有一个缓存区 Innodb_log_buffer，默认大小为 8M，Innodb 存储引擎先将重做日志写入 innodb_log_buffer 中。 然后会通过以下三种方式将 innodb 日志缓冲区的日志刷新到磁盘： 1、Master Thread 每秒一次执行刷新 Innodb_log_buffer 到重做日志文件；2、每个事务提交时会将重做日志刷新到重做日志文件；3、当 redo log 缓存可用空间少于一半时，重做日志缓存被刷新到重做日志文件； 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。 CrashSafe 能够保证 MySQL 服务器宕机重启后： 所有已经提交的事务的数据仍然存在。 所有没有提交的事务的数据自动回滚。 binlog如前文所讲，MySQL 整体可以分为 Server 层和引擎层。 其实，redo log 是属于引擎层的 InnoDB 所特有的日志，而 Server 层也有自己的日志，即 binlog（归档日志）。 记录了什么逻辑格式的日志，可以简单认为就是执行过的事务中的 sql 语句。 但又不完全是 sql 语句这么简单，而是包括了执行的 sql 语句（增删改）反向的信息。 也就意味着 delete 对应着 delete 本身和其反向的 insert；update 对应着 update 执行前后的版本的信息；insert 对应着 delete 和 insert 本身的信息。 何时产生 &amp; 释放事务提交的时候，一次性将事务中的 sql 语句按照一定的格式记录到 binlog 中。因此，对于较大事务的提交，可能会变得比较慢一些。 binlog 的默认是保持时间由参数 expire_logs_days 配置，也就是说对于非活动的日志文件，在生成时间超过配置的天数之后，会被自动删除。 区别1、redo log 是 InnoDB 引擎特有的，binlog 是 MySQL 的 Server 层实现，所有引擎都可以使用；2、内容不同：redo log 是物理日志，记录的是在数据页上做了什么修改,是正在执行中的 dml 以及 ddl 语句；而 binlog 是逻辑日志，记录的是语句的原始逻辑，已经提交完毕之后的 dml 以及 ddl sql 语句，如「给 ID=2 的这一行的 c 字段加 1」；3、写方式不同：redo log 是循环写的，空间固定；binlog 是可以一直追加写的，一个文件写到一定大小后，会继续写下一个，之前写的文件不会被覆盖；4、作用不同：redo log 主要用来保证事务安全，作为异常 down 机或者介质故障后的数据恢复使用，binlog 主要用来做主从复制和即时点恢复时使用；5、另外，两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。 参考：http://www.importnew.com/28039.html 数据更新事务流程有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。 1、执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 2、执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 3、引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 4、执行器生成这个操作的 binlog，并把 binlog 写入磁盘； 5、执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 两阶段提交上面处理 redo log 和 binlog 看着是不是有点懵逼？ 其实这就是所谓的两阶段提交，即 COMMIT 会被自动的分成 prepare 和 commit 两个阶段。 MySQL 在 prepare 阶段会生成 xid，然后会在 commit 阶段写入到 binlog 中。在进行恢复时事务要提交还是回滚，是由 Binlog 来决定的。 由上面的二阶段提交流程可以看出，通过两阶段提交方式保证了无论在任何情况下，事务要么同时存在于存储引擎和 binlog 中，要么两个里面都不存在。 这样就可以保证事务的 binlog 和 redo log 顺序一致性。一旦阶段 2 中持久化 Binlog 完成，就确保了事务的提交。 此外需要注意的是，每个阶段都需要进行一次 fsync 操作才能保证上下两层数据的一致性。 PS：记录 Binlog 是在 InnoDB 引擎 Prepare（即 Redo Log 写入磁盘）之后，这点至关重要。另外需要注意的一点就是，SQL 语句产生的 Redo 日志会一直刷新到磁盘（master thread 每秒 fsync redo log），而 Binlog 是事务 commit 时才刷新到磁盘，如果 binlog 太大则 commit 时会慢。 参考：http://www.ywnds.com/?p=7892 如何恢复数据？当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做： 1、首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库； 2、然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。 这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。 当遇到 crash 时，恢复的过程也非常简单： 1、扫描最后一个 Binlog 文件，提取其中的 xid；2、重做检查点以后的 redo 日志，搜集处于 prepare 阶段的事务链表，将事务的 xid 与 binlog 中的 xid 对比，若存在，则提交，否则就回滚； 总结一下，基本顶多会出现下面是几种情况： 当事务在 prepare 阶段 crash，数据库 recovery 的时候该事务未写入 Binary log 并且存储引擎未提交，将该事务 rollback。 当事务在 binlog 阶段 crash，此时日志还没有成功写入到磁盘中，启动时会 rollback 此事务。 当事务在 binlog 日志已经 fsync 到磁盘后 crash，但是 InnoDB 没有来得及 commit，此时 MySQL 数据库 recovery 的时候将会读出 binlog 中的 xid，然后告诉 InnoDB 提交这些 xid 的事务，InnoDB 提交完这些事务后会回滚其它的事务，使存储引擎和二进制日志始终保持一致。 总结起来说就是如果一个事务在 prepare 阶段中落盘成功，并在 MySQL Server 层中的 binlog 也写入成功，那这个事务必定 commit 成功。 总结介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。 redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。 sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。 我还跟你介绍了与 MySQL 日志系统密切相关的「两阶段提交」。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL实战 | 01 当执行一条 select 语句时，MySQL 到底做了啥？]]></title>
    <url>%2Fmysql-zhuanlan-01-select.html</url>
    <content type="text"><![CDATA[也许，你也跟我一样，在遇到数据库问题时，总时茫然失措，想重启解决问题，又怕导致数据丢失，更怕重启失败，影响业务。 就算重启成功了，对于问题的原因仍不知所以。 本文开始，记录学习《MySQL实战45讲》专栏的过程。 也许有人会问，你记录有什么意义？直接看专栏不就行了吗？你这不是啃别人的剩骨头吗？ 是的，这个系列，我只是基于专栏学习，但是我会尽量从我的角度搞懂每一个知识点，遇到不懂得也会将知识点进行拆分。 我知道关注公众号的小伙伴也有很多购买了这个专栏的，我希望大家都能够利用好这个机会，把 MySQL 吃透！ 看大家的反馈情况吧，若有需要，可以建个小群，大家互相讨论学习！ 下面开始正文。 大家或多或少都用过 MySQL，起码 select 还是会用的吧，但是 select 执行后，MySQL 内部到底发生了什么，你知道吗？ 比如，我们有个简单的表 T，它有个 ID 字段，那么我们可以执行下面的语句： 1mysql&gt; select * from T where ID=10; 语句执行很简单，但是具体到 MySQL 内部，其实是一个完整的执行流程。 MySQL 的基本架构从下图就可以清楚地看出 MySQL 的命令执行流程： 从该图可以看出，MySQL 主要分为 server 层和存储引擎层。 server 层中包含连接器，查询缓存，分析器，优化器，执行器，大多数核心功能以及内置函数，存储过程，触发器，视图等。 存储引擎层主要负责最终数据的存储和提取，例如常用的存储引擎 InnoDB、MyISAM 等。 好了，下面开始梳理一次完整的查询流程。 1 连接首先通过连接器连接到数据库。 连接器的主要作用是建立连接，获取用户权限，维持连接，管理连接。 连接的一般命令就是我们常用的登陆数据库的命令： 1mysql -u$username -h$host -p$port -P 命令执行后，若用户名或者密码不对，或者数据库做了登录 ip 限制，都会收到异常信息。 若登陆成功，那么就代表连接成功建立。 之后连接器会维持当前连接，接下来连接器会查询出该用户的权限，后面所有的操作都会基于该权限，即使操作过程中有其他进程修改了该用户的权限。 连接完成后，若没有任何操作，连接就处于休眠状态，用命令 show processlist; 查看，就是 Sleep 状态的进程： 当然，连接器不会让你一直握着连接不动，若休眠时间超过 wait_timeout（默认为 8 小时），则会断开当前连接。 若要再用，对不起，请重新连接~ 长连接和短连接其实这里的长短连接不是 MySQL 层面的概念。 长连接：长连接是相对于短连接来说的。长连接指在一个连接上可以连续发送多个数据包，在连接保持期间，如果没有数据包发送，需要双方发链路检测包。我理解 MySQL 默认的超时时间 8 小时，就属于一个长链接。 1客户端连接--创建 socket 认证连接--维护连接--数据传输--维护连接--数据传输.....-关闭连接 短连接：是指通讯双方有数据交互时，就建立一个连接，数据发送完成后，则断开此连接，即每次连接只完成一项业务的发送。 1客户端连接--创建 socket 认证连接--维护连接--数据传输--关闭连接 长连接主要用于在少量客户端与服务端的频繁通信，因为这时候如果用短连接频繁通信常会发生 Socket 出错，并且频繁创建 Socket 连接也是对资源的浪费。 专栏中老师是建议使用长链接的，因为建立连接的过程比较复杂，应该尽量减少建立连接的动作。 长连接的管理使用长连接后，随着连接数不断增加，会导致内存占用升高，因为 MySQL 在操作过程中会占用内存来管理连接对象，只有等到连接断开后才会释放。 如果连接一直堆积，就会导致内存占用过大，被系统强行杀掉，也就是会出现 MySQL 重启。 如何解决这个问题？ 1、定期断开长连接；2、MySQL 5.7+ 的版本中提供了 mysql_reset_connection 来重新初始化连接资源，这时不需要重新连接，就可以将连接恢复到刚刚创建完时的状态； mysql_reset_connection 对于 mysql_reset_connection ，MySQL 官网的描述是这样的： 将连接重置，清空连接状态。类似于重新连接，但是不会关闭当前连接，也不会进行重新鉴权。 会产生如下影响： 1、会回滚所有活动事务，并重置自动提交模式；2、会释放所有的锁表；3、所有的临时表会被关闭并清除；4、Session 系统变量会被重新初始化为相应的全局系统变量的值；5、用户自定义变量会丢失；6、会释放 Prepared statements；7、HANDLER 变量会被关闭；8、LAST_INSERT_ID() 函数的值会被重置为 0；9、通过 GET_LOCK() 函数获得的锁会被释放； 以上影响，翻译自官方文档，有些可能不太准确，有兴趣的可以到官网自行查阅原文。 数据库连接池？ 另外，不少实际的应用框架中，大都使用连接池来维护连接数。 数据库连接池，就是服务器应用建立多个连接到数据库，还没有用的连接就放到连接池上，要的时候就向连接池取，这样比没有连接时再建立新的连接（TCP 建立连接是需要时间的）时要快很多，从而提高传输效率。 如 Spring 框架中，它实现了一个持久连接池，允许其他程序、客户端来连接，这个连接池将被所有连接的客户端共享使用，连接池可以加速连接，也可以减少数据库连接，降低数据库服务器的负载。 2 查询缓存缓存，就是提前预备好的数据，数据库查询缓存也是缓存的一种。 在解析一个查询语句之前，如果查询缓存是打开的，那么 MySQL 会优先检查这个查询是否命中查询缓存中的数据。 如果当前的查询恰好命中了查询缓存，那么在返回查询结果之前 MySQL 会检查一次用户权限。若权限没有问题，MySQL 会跳过所有其他阶段（解析、优化、执行等），直接从缓存中拿到结果并返回给客户端。 这种情况下，查询不会被解析，不用生成执行计划，不会被执行。 缓存哪里来的？查询时如果没有命中查询缓存，MYSQL 会判断该查询是否可以被缓存，而且系统中还没有对应的缓存，则会将其结果写入查询缓存。 mysql query cache 的内容为 select 的结果集，在内存中是以 HASH 结构来进行映射。 cache 会使用完整的 sql 字符串做 key，并区分大小写，空格等。即两个 sql 必须完全一致才会导致 cache 命中。 缓存何时失效？在表的结构或数据发生改变时，查询缓存中的数据不再有效。 所以查询缓存适合有大量相同查询的应用，不适合有大量数据更新的应用。 a) 一旦表数据进行任何一行的修改，基于该表相关 cache 立即全部失效，并且从缓冲区中移出；b) 为什么不做聪明一点判断修改的是否 cache 的内容？因为分析 cache 内容太复杂，服务器需要追求最大的性能。 缓存可以提高查询效率的？当有大量的查询和大量的修改时，cache 机制可能会造成性能下降。 因为每次修改会导致系统去做 cache 失效操作，这就会造成不小的开销。 另外系统 cache 的访问由一个单一的全局锁来控制，这时候大量的查询将被阻塞，直至锁释放。 所以不要简单认为设置 cache 必定会带来性能提升。 参考：https://www.cnblogs.com/duanxz/p/4385733.html 其实，在 8.0 版本开始，缓存功能被直接删除。 3 解析器词法解析词法分析的作用是将整个查询分解为多个元素。 我们输入的 MySQL 命令，不过是一串长长的字符串，MySQL 的分析器会对其进行词法解析。 1select * from T where ID=1; 比如，上述语句是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。 MySQL 从你输入的 select 这个关键字识别出来，这是一个查询语句。 它也要把字符串 T 识别成一个表名，把字符串 ID 识别成一个列。 其实，大家也可以思考一下，若让你手写一个词法分析的工具，你该如何实现呢？ 语法分析做完初步的词法分析后，就要做语法分析。 根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。 如果你的语句不对，就会收到 You have an error in your SQL syntax 的错误提醒。 解析器的最终执行结果就是解析树，提供给优化器使用。 4 优化器当你提交一个查询的时候，MySQL会分析它，看是否可以做一些优化使处理该查询的速度更快。 优化器到底干啥的？MySQL 的优化器有几个重要任务： 1、选择最合适的索引；2、选择表扫还是走索引；3、选择表关联顺序；4、优化 where 子句；5、排除管理中无用表；6、决定 order by 和 group by 是否走索引；7、尝试使用 inner join 替换 outer join；8、简化子查询，决定结果缓存；9、合并试图； MySQL 查询优化器有几个目标，但是其中最主要的目标是尽可能地使用索引，并且使用最严格的索引来消除尽可能多的数据行。 优化器试图排除数据行的原因在于它排除数据行的速度越快，那么找到与条件匹配的数据行也就越快。如果能够首先进行最严格的测试，查询就可以执行地更快。 优化器是如何工作的？到底优化器是如何进行选择的？如果每个点都展开，那都需要很长的篇幅，我再网上翻阅了一些资料，看得也是云里雾里，后面结合专栏老师的讲解再学习吧。 这里举几个优化的示例： 示例 1 假设你的查询检验了两个数据列，每个列上都有索引： 12SELECT col3 FROM mytableWHERE col1 = 'value1' AND col2 = 'value2'; 假设 col1 上的测试匹配了 900 个数据行，col2 上的测试匹配了 300 个数据行，而同时进行的测试只得到了 30 个数据行。 先测试 col1 会有 900 个数据行，需要检查它们找到其中的 30 个与 col2 中的值匹配记录，其中就有 870 次是失败了。 先测试 col2 会有 300 个数据行，需要检查它们找到其中的 30 个与 col1 中的值匹配的记录，只有 270 次是失败的，因此需要的计算和磁盘 I/O 更少。 其结果是，优化器会先测试 col2，因为这样做开销更小。 示例 2 尽可能地让索引列在比较表达式中独立。如果你在函数调用或者更复杂的算术表达式条件中使用了某个数据列，MySQL就不会使用索引，因为它必须计算出每个数据行的表达式值。 比如，下面的 WHERE 子句显示了这种情况。它们的功能相同，但是对于优化目标来说就有很大差异了： 12WHERE mycol &lt; 4 / 2WHERE mycol * 2 &lt; 4 对于第一行，优化器把表达式 4/2 简化为 2，接着使用 mycol 上的索引来快速地查找小于 2 的值。 对于第二个表达式，MySQL 必须检索出每个数据行的 mycol 值，乘以 2，接着把结果与 4 进行比较。在这种情况下，不会使用索引。数据列中的每个值都必须被检索到，这样才能计算出比较表达式左边的值。 优化器的内容还可以有很多，这个专栏老师说后续会还有讲。 5 执行器下面就到了最终的执行阶段，执行开始之前，会先判断是否有操作权限，若没有，会抛出相关异常。 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。 比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的： 1、调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；2、调用引擎接口取下一行，重复相同的判断逻辑，直到取到这个表的最后一行。3、执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 至此，这个语句就执行完成了。 对于有索引的表，执行的逻辑也差不多。第一次调用的是取满足条件的第一行这个接口，之后循环取满足条件的下一行这个接口，这些接口都是引擎中已经定义好的。 可以看出，是否有索引，执行效率区别还是很大的，没有索引需要取出所有数据，一个个进行比较；而有索引则是直接取满足条件的数据； 课后题目问题： 如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？ 答案：分析器阶段。 网友回答： 《高性能mysql》里提到解析器和预处理器。解析器处理语法和解析查询, 生成一课对应的解析树。预处理器进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过则生成新的解析树，再提交给优化器。 文中讲解分析器阶段时提到，MySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。所以应该是分析器。 我猜测应该在分析阶段，根据文章介绍分析器的作用是让mysql知道你要做什么，对语法的分析应该是第一部，语法词法分析完成后应该是解析这条sql到底要执行什么操作，插入还是更新还是建表还是查询，这时mysql应该已经知道你想操作那个表而这个表存不存在，从而才能匹配不同的优化器类 最后就作者的问题，分析为什么是分析器，因为文章中说了词法分析的时候会解析出查询的表，列等等，所以此时就应该能知道表列的存在性。而且从我个人的拙见来看，如果先一步判断出这种无法查询的错误，避免后续执行，则可以避免无谓的性能开销。而表列的数据较少，完全可以这里判断。当然，也可以在句法分析的步骤判断，个人数据库不太熟悉，只能从程序设计的角度考虑，望各位大佬真诚的评论 问：丁老师，既然在链接阶段已经通过权限表获取了这个该连接所具有的权限，那么在执行阶段再检查一次的意义何在，谢谢！作者回复：执行器阶段会碰到需要再判断权限的情况，这时候读内存中事先存好的权限，而这个权限是在连接器阶段算出来存进去的 问：长连接占用内存猛涨的情况下,您提供两种解决方案,您倾向于在生产环境使用什么方案呢? 为什么呢? 或者你评价这两种方案在生产环境有什么优劣呢? 作者回复：5.7以上就建议用mysql_reset_connection 方法，低版本就定期断开重连 另外，评论里多次提到了《高性能MySQL》一书，这里也为大家提供一个电子版，回复【005】可以获取。 好了，第一篇，学习了好几天，因为是工作党，时间都是拼凑出来的，所以后续肯定跟不上专栏老师的节奏，不过会坚持的，大家一起加油干吧！]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人人都能看懂的云计算知识科普]]></title>
    <url>%2Fwhat-is-cloud-compute.html</url>
    <content type="text"><![CDATA[双十一期间，我想很多小伙伴都被阿里云的促销活动刷屏了，大家组队组团，可以得到较为便宜的阿里云服务器。另外，Docker 也红得发紫，与之对应的 DevOps 和 NoOps 持续高温。 但是对于不少企业尤其是传统企业，云仍在天边，对于云仍感觉云里雾里。上云还是不上云，上什么云，这是个问题。我们试着用最通俗的比喻，理清云服务中最基本的那些事儿。 什么是云？先从一段对话开始。 张三：我们公司的资料不让存放到个人电脑上，一般都存到云上。 李四：别逗了，你们单位就二十几个人，两台服务器，没有虚拟化也没有分布式，能叫云？ 张三：那怎么了？几百块钱的西数 NAS 都叫云呢。 张三大概是个普通人，李四是个技术宅，对话也反映出不同人眼中不同的云。那究竟什么是云呢？ 历史上已经有不下于一百种的定义，影响力较大的是 NIST（美国国家标准与技术研究院）的定义： 云计算是一种模型，它可以实现随时随地、便捷地、随需应变地从可配置计算资源共享池中获取所需的资源（例如网络、服务器、存储、应用及服务），资源能够快速供应并释放，使管理资源的工作量和与服务提供商的交互减小到最低限度。 显然，对一般的用户来说，这并不好理解，翻译成人话大概是：让计算、存储、网络、数据、算法、应用等软硬件资源像电一样，随时随地、即插即用。这种定义，比较像张三眼中的云，我们称其为广义云计算。 技术宅李四眼中的云是指一整套虚拟化和分布式的技术体系，近几年以去 IOE（即 IBM、Oracle 和 EMC）。为嘛去人家？因为太贵！ 不过 IBM、Oracle 和 EMC 的母公司 Dell 都在积极拥抱云计算了）的低成本化为典型特点。 这种，我们称其为狭义云计算。 首先，狭义云计算过度关注底层，而忽略掉了 SaaS （软件即服务）和PaaS（平台即服务）； 其次，狭义云计算过度关注具体技术，而忽略掉服务模式、商业模式等，长期看容易低估云计算的社会推动作用。 当然，李四这么说也有一定道理，就目前来说，大部分云的底层架构确实是通过虚拟化和分布式来实现的，毕竟节省成本、容易管理，还支撑了分布式大数据处理。 什么是虚拟化和分布式？一个村，有很多人家。张三家只有一个女儿，粮食总是吃不完，相当于资源闲置。李四家有五个儿子，粮食总是不够用，相当于资源紧缺。这还不算，王五家时不时来一大堆客人，粮食够不够用谁也说不准，相当于计算波动大。 于是，张三家添了几双筷子几个碗，可以让别人来吃，相当于一台物理机虚拟出更多台虚机。谁家有多少粮食、几张桌子、几双筷子、几个碗，村长记在自己的小本本上，相当于统一调度，形成了资源池。 李四和王五家不够吃的时候，拿小板凳去张三家，相当于分布式。有同学就问了，张三岂不是亏了？别入戏太深，张三只是一台服务器！还有同学说，我为嘛嗅到了共产主义的味道？没错，虚拟化和分布式就是要在计算、存储和网络上实现共产主义！ 虚拟化和分布式在共同解决一个问题，就是物理资源重新配置形成为逻辑资源（在 IT 领域称为解耦，也就是你用的东西跟实际物理的东西是两码事，一如李四和王五的午饭其实是在张三家解决的）。其中虚拟化做的是造一个资源池，而分布式做的是用一个资源池。 虚拟化包括计算虚拟化、网络虚拟化和存储虚拟化。 计算虚拟化通常做的是一虚多，即一台物理机虚拟出多台虚拟机，以榨干实际的物理资源，其包括全虚拟化、超虚拟化、硬件辅助虚拟化、半虚拟化和操作系统虚拟化。 类似于计算虚拟化，网络虚拟化同样解决的是网络资源占用率不高、手动配置安全策略过于麻烦的问题，采用的思路同样是把物理的网络资源抽象成一个资源池，然后动态获取，网络虚拟化目前有控制转发分离、控制面开放、虚拟逻辑网络和网络功能虚拟化等不同的思想路线。 存储虚拟化通常做的是多虚一，除了解决弹性、扩展问题外，还解决备份的问题。 公有云、私有云、混合云和社区云是什么东东？张三、李四、王五住一栋楼，楼下一个大规模的饭店。张三一直在家做饭，这是私有云，厨房是自建机房。李四一直在饭店吃，这是公有云，饭店是云数据中心。王五牛叉，在饭店有个固定包间，包间不对外人开放，这是托管型私有云（有的厂商将其定义为专有云），包间是云数据中心中的托管服务器。 张三家有天来了十多个客人，这是业务突增。家里装不开，要去饭店，这是私有云转公有云。张三妈妈省吃俭用，对张三说，你们去吧，我和你爸在家吃，对张三家来说这是混合云。如果饭店仅对某个特定人群比如学生开放，这就相当于社区云。 当然，举例不十分恰当，毕竟饭还是买的，而云是租的，此点切记。 私有云私有云是为某个特定用户/机构建立的，只能实现小范围内的资源优化，因此并不完全符合云的本质——社会分工，所以 Openstack 等开源软件带来的私有云繁荣可能只是暂时的，会有越来越多的客户发现廉价的硬件和免费的软件并不是打造私有云的充分条件，精细的管理、7×24 运维所耗去的总成本（TOC）不比公有云低，而且随着公有云厂商运营能力的进步，这种趋势会越来越明显。 托管型私有云在一定程度上实现了社会分工，但是仍无法解决大规模范围内物理资源利用效率的问题。 公有云公有云是为大众建的，所有入驻用户都称租户，不仅同时有很多租户，而且一个租户离开，其资源可以马上释放给下一个租户，一如饭店里一桌顾客走了马上迎来下一桌顾客。 公有云是最彻底的社会分工，能够在大范围内实现资源优化，因此，不管道路如何曲折，前途总是光明的。当然公有云尤其是底层公有云构建，不是一般人能玩的了的，就像开个三五桌的饭店谁都能行，开个三五万桌的饭店就要看资金和本事了。 很多客户担心公有云的安全问题，敏感行业、大型客户可以考虑，但一般的中小型客户，不管是数据泄露的风险，还是停止服务的风险，公有云都远远小于自己架设机房。 社区云社区云是介于公有、私有之间的一个形式，每个客户自身都不大，但自身又处于敏感行业，上公有云在政策和管理上都有限制和风险，所以就多家联合做一个云平台。 混合云混合云*是以上几种的任意混合，这种混合可以是计算的、存储的，也可以两者兼而有之。在公有云尚不完全成熟、而私有云存在运维难、部署实践长、动态扩展难的现阶段，混合云是一种较为理想的平滑过渡方式，短时间内的市场占比将会大幅上升。 并且，不混合是相对的，混合是绝对的。在未来，即使不是自家的私有云和公有云做混合，也需要内部的数据与服务与外部的数据与服务进行不断的调用（PaaS 级混合）。并且还有可能，一个大型客户把业务放在不同的公有云上，相当于把鸡蛋放在不同篮子里，不同篮子里的鸡蛋自然需要统一管理，这也算广义的混合。 Iaas、PaaS 和 SaaS 又是什么东东？ IaaS，Infrastructure as a Service，基础设施即服务； PaaS，Platform as a Service，平台即服务； SaaS，Software as a Service，软件即服务。 还是不太好理解？没关系，张三李四王五登场。 张三卖小麦，相当于 IaaS；李四卖面粉，相当于 PaaS；王五卖馒头，相当于 SaaS。 张三觉得卖小麦不挣钱且不能打品牌，向下游延伸，也卖起了面粉，相当于 IaaS 企业也逐渐做 PaaS 业务；王五馒头卖得好，一天几万个，面粉需求量非常大，不希望被李四控制，也做起了面粉，相当于 SaaS 企业做 PaaS，所以 IaaS、PaaS 和 SaaS 只是分析师和投资人津津乐道的，从业者并不关注，天下熙熙，皆为利来，啥赚钱搞啥。 张三卖面粉后，与李四就形成了竞争关系，但是李四还经常从自己这里买小麦，相当于又有合作，这种既竞争又合作的关系就叫竟合。 赵六嘴叼，馒头满足不了，非自己包饺子吃，直接从张三那里买小麦或李四那里买面粉，相当于直接利用 PaaS 平台做软件或订制 SaaS，这种嘴叼的一般都是土豪，对应的就是大客户。 有没有发现，越是在城市里，越是发达，种小麦的、买小麦的、买面粉的就越少，买馒头的越多？那就对了，这是社会分工的结果。而云计算同样会向着高度分工的方向进化。 还有同学问，存储到底算是哪一层呢？这就相当于你觉得能灌溉能和面还能直接喝的水是哪一层呢？自然是出现在不同场景时对应不同层：常说的块存储、对象存储一般是指 IaaS 层，而网盘一般是指 SaaS 层。 IaasIaaS 提供的一般是通用计算、存储和网络三大基础资源，前面提到的虚拟化、分布式等大多集中在本层，少量「流亡」于 PaaS 层。 一般认为，IaaS 始于亚马逊的 EC2 和 S3 两款产品。近两年，我们说的云计算快速落地，其实主要指 IaaS 的迅速落地，因为原来的公有云确实不稳定，而客户也都在观望。当然，有 IaaS 公司提出自己是「企业级 IaaS」，这就有点噱头了，试问，哪个 IaaS 不是冲着企业级这一目标去的？给开发者玩儿的吗？ PaasPaaS 定义比较复杂，早年提供的是部署了数据库和开发环境的平台，被称为 XAE（X：企业名首字母；AE：Application engine），XAE 常用于个人建站，商用程度并不高，在中国尤其如此，后来要么转型要么解体了； 后来 PaaS 转为提供某种细分能力，如图像识别、语音识别、推送、通信等，常以 API 或 SDK 进行交付；近两年 Docker 风生水起，成为 PaaS 新秀。 此时回头看原来 PaaS 的各种定义，都不太恰当了，因此比较准确的描述应是：PaaS 提供除计算、存储和网络三大基础资源之外的其他能力（如通用开发能力，细分能力，业务交付能力），但并不对终端用户提供成熟产品。 SaasSaaS 涵盖的就广了，邮箱是、网盘是、几乎常见的网站都是！但一般所谓的 SaaS 是指：具有一定复杂度的，通常应该在 C/S 架构下主要通过 C 端完成的软件服务，在 B/S 架构下完成了。 当然这个复杂度，在不同的时期有不同的定义，十几年前，邮箱可能都算复杂了，而现在随着 HTML5 技术的成熟，大部分的 Office 操作都可以在浏览器完成。当然，放企业级市场里，SaaS 比较好界定，指以云的方式取代了的原来企业软件系统的服务。 SaaS 始于上世纪九十年代末 Salesforce 等公司，随着移动互联网和 HTML5 的发展而蓬勃发展，强调的是瘦终端。但是，到底多瘦才算瘦，各种应用不再用 APP 而以微信小程序的形式出现算瘦吗？或许，SaaS 的终极进化是纯「裸机」，也就是「桌面云」，当然这只是一种理想，因为不仅关乎软硬件技术，还关乎用户习惯。须知，到现在还有不少用户喜欢把电影放到移动硬盘里，抽屉里一塞，那感觉，踏实！ SaaS 最接近于终端用户，是一个巨大的市场。但是，SaaS 是对软件开发水平和服务水平的综合考验，拼得往往不仅是技术本身，还包括对用户的理解、以及设计水平和创意。 如果原来就是卖不出去的软件，没有任何改进包装一下放到云上改为服务也不会有人买单，原来最起码还不用对宕机这种事情负责呢，放云上只是增加了 SaaS 服务商自身的风险。 所以，SaaS 绝不是单机软件到云上的简单迁移，而是自始至终都应贯穿服务的思想和云的思想，比如多屏同步、多人协同等。也所以，我们虽然看好整体市场，但是并不看好很多 SaaS 领域一堆堆的无价值企业，资本寒冬，最先倒下的往往是他们。 云计算有什么价值？成本更低、运维成本更低、服务更好、弹性扩展、部署更快、不用采购硬件，云计算的好处总能说出一大堆。 但，这些点往往只反映云计算的一个侧面，有的还不完全正确：比如成本低，客户会发现，如果租用高性能云主机且保证 99.99% 的可用服务时，成本往往并不比自建机房低，在需要的主机（物理机或虚机）量比较大时，尤其明显。 其实，云计算的本质就是社会分工，社会分工所产生的价值云计算都能产生，比如规模化、精细化所产生的成本降低与效率提高等； 而社会分工中产生的问题，云计算也都会面对，比如节省下来的成本到底是买家受益还是卖家受益，再比如垄断。 还是拿蒸馒头举例子，在城市中，大多数家庭不自己蒸馒头而去馒头房买，这是社会分工，节省了社会总体成本，但是买馒头并不比自己蒸更便宜，说明节省了的成本进入了卖家而非买家的腰包。 再比如，当一个城市只剩一家馒头房而大多数家庭又丧失了蒸馒头的能力时，馒头房便有可能提价，这就是垄断。 理解了云计算是一次社会分工的本质，便不会过分夸大其优点，更不会对之回避认为其只不过是一时风潮。从狩猎到农耕、再到工业社会，从一只羊换两把斧子到贝壳、金属货币、纸币、虚拟货币，从生产方式到价值交换方式，你会发现，人们所做的一切都是在朝着社会分工或促进社会分工的方向发展。 所以，对于云，逃也没用，躲也没用，时代总会来临。果断拥抱，理性选择，踏实落地，即是未来。]]></content>
      <categories>
        <category>闲扯系列</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑马/传智播客最新第 24 期 C/C++ 全栈教程]]></title>
    <url>%2Fresource-heima-c-c%2B%2B.html</url>
    <content type="text"><![CDATA[双十一，没啥大奖送给大家，送大家一份 C/C++ 的视频吧，视频是黑马的，按以往 Python 的惯例，黑马的质量应该都是还说的过去的。 视频内容包括： 想要的关注下方公众号后，回复【004】即可获取。]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>c/c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教你用 Python 实现抖音热门表白软件]]></title>
    <url>%2Fpython-douyin-biaobai.html</url>
    <content type="text"><![CDATA[之前在群里看到有人发了一个抖音上很火的小视频，就是一个不正经的软件，运行后问你是不是愿意做我的朋友，但你没法点击到「不同意」！并且没办法直接关闭窗口！ 很不正经，很流氓，有点适合我。 效果大概是这样的： 我要做一个高仿版的！ 实现思路首先我想到的就是 pygame 实现，因为之前很多人都用它「打过飞机」，不对，是做「打飞机」的游戏，因此多少有些熟悉。 其实思路很简单，就是探测鼠标位置，当鼠标跑到按钮上面时，随机改变按钮的位置。 剩下的就是组件的布局样式了！ 这里我在网上找了一个小图片，放在左方，然后中间位置放置两行文字，下方放置两个按钮，最终布局如下： 主要实现逻辑实现流程大致如下： 主要的逻辑就是鼠标移动到按钮上时，按钮的位置进行随机的变动。 如何判断鼠标在按钮上？看下出自灵魂画手的示意图： 代码实现也很简单： 1234567891011121314151617# 生成随机的位置坐标def get_random_pos(): x, y = random.randint(20, WIDTH-20), random.randint(20, HEIGHT-20) return x, y# 获取鼠标位置# 若鼠标位置位于按钮区域内# 则随机生成按钮位置进行显示mouse_pos = pygame.mouse.get_pos()if mouse_pos[0] &lt; unlike_pos_x+unlike_pos_width and mouse_pos[0] &gt; unlike_pos_x and\ mouse_pos[1] &lt; unlike_pos_y+unlike_pos_height and mouse_pos[1] &gt; unlike_pos_y: while True: unlike_pos_x, unlike_pos_y = get_random_pos() if mouse_pos[0] &lt; unlike_pos_x+unlike_pos_width and mouse_pos[0] &gt; unlike_pos_x and\ mouse_pos[1] &lt; unlike_pos_y+unlike_pos_height and mouse_pos[1] &gt; unlike_pos_y: continue break 看着有点乱，但其实就是上图的公式。 实现效果最终实现效果： 最后，把我们的程序打包成 exe，当然，需要附上图片和字体文件。 不会代码打包的可以参考之前的文章： 1、 使用 PyInstaller 打包 Python 程序2、 [使用 py2exe 打包 Python 程序][7] 程序和最终的 exe 文件，关注下方公众号，回复【表白】即可获取。 [7]: https://hoxis.github.io/python-py2exe.html**strong text**]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World 程序究竟从何而来？]]></title>
    <url>%2Fwhere-hello-world-come-from.html</url>
    <content type="text"><![CDATA[Hello World，这是一个最著名的程序。 对每一位程序员来说，这个程序几乎是每一门编程语言中的第一个示例程序。那么，这个著名的程序究竟从何而来呢？ 实际上，这个程序的功能只是告知计算机显示 Hello World 这句话。传统意义上，程序员一般用这个程序测试一种新的系统或编程语言。对程序员来说，看到这两个单词显示在电脑屏幕上，往往表示他们的代码已经能够编译、装载以及正常运行了，这个输出结果就是为了证明这一点。 这个测试程序在一定程度上具有特殊的象征意义。在过去的几十年间，这个程序已经渐渐地演化成为了一个久负盛名的传统。 几乎所有的程序员，无论是在你之前，或在你之后，当第一次实现与计算机成功沟通之后，在某种程度上，他们的肾上腺素就会急剧上升（激动不已）。以下就是这个著名程序的诞生故事。 Hello World 究竟从何而来？Hello, World 最早是由 Brian Kernighan 创建的。 1978年，Brian Kernighan 写了一本名叫《C 程序设计语言》的编程书，在程序员中广为流传。他在这本书中第一次引用的 Hello World 程序，源自他在1973年编写的一部讲授 B 语言的编程教程： 12345678main()&#123;extrn a,b,c;putchar(a); putchar(b); putchar(c); putchar('!*n');&#125;a 'hell';b 'o, w';c 'orld'; 但是非常不幸的是，当 Forbes India 杂志采访他的时候，他自己对这段传奇故事中一些记忆已经有点儿模糊了。当他被问及为什么选择『Hello, World!』时，他回答说，『我只记得，我好像看过一幅漫画，讲述一枚鸡蛋和一只小鸡的故事，在那副漫画中，小鸡说了一句『Hello World』。 鉴于 Hello World 这个计算机程序的广泛流行程度，这个起因看起来还是蛮合适的。 那个时候，无论是 Kernighan，还是他的同事 Dennis Ritchie - C 语言之父，都无法想象 C 语言以及这本教程书将会在今天如此之流行。他们所做的工作只是贝尔实验室的一个研究项目，而在当时，贝尔实验室也只是美国电话电报公司（AT&amp;T）的技术研究与开发机构而已。 尽管没人能够科学地解释为什么 Hello World 如此地流行，但是，Hello, World 程序的确在计算机发展历史上成为了一个具有重要意义的里程碑。 也许有很多不同的基本程序可供初学者动手尝试，但是截至目前为止，Hello World 则是其中最为著名的一个。每一位程序员都曾记得他们的第一个 Hello World 程序，因为对他们来说，这就是一个重大事件。 也许有些人还没有意识到这一点，但是，当一名新程序员清除完一些障碍顺利抵达 Hello World 时，他的内心体验到的不仅仅是一种成功的喜悦，更重要的是，他正在亲身经历一个跨越历史的时刻。]]></content>
      <categories>
        <category>闲扯系列</category>
      </categories>
      <tags>
        <tag>闲扯系列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从 0 开始学微服务]]></title>
    <url>%2Flearn-microservice-from-0.html</url>
    <content type="text"><![CDATA[分享专栏「从 0 开始学微服务」的学习总结。主要是文章截图、文章音频、以及个人学习记录。 文章截图较大，所以这里不会直接显示。 01 到底什么是微服务？文章截图到底什么是微服务？ 个人整理https://mubu.com/doc/kSAAJUY5UG 02 从单体应用走向服务化文章截图从单体应用走向服务化 个人整理https://mubu.com/doc/7CxiBTch0G 03 初探微服务架构文章截图初探微服务架构 个人整理https://mubu.com/doc/CGDDevNSwG 04 如何发布和引用服务？文章截图04 如何发布和引用服务？ 个人整理https://mubu.com/doc/qSZIg9rV0G 05 如何注册和发现服务？文章截图05 如何注册和发现服务？ 个人整理https://mubu.com/doc/gUbghFylwG 06 如何实现RPC远程服务调用？文章截图06 如何实现RPC远程服务调用？ 个人整理https://mubu.com/doc/5HCdxIblkG 07 如何监控微服务调用？文章截图07 | 如何监控微服务调用？ 个人整理https://mubu.com/doc/kiGZMCKdYG 08 如何追踪微服务调用？文章截图08 如何追踪微服务调用？ 个人整理https://mubu.com/doc/d0cOqQo1yG 09 微服务治理的手段有哪些？文章截图如何追踪微服务调用？ 个人整理https://mubu.com/doc/nb3GCm1TqG 10 Dubbo框架里的微服务组件文章截图10 Dubbo框架里的微服务组件 个人整理https://mubu.com/doc/tQkevcr1MG 课程音频以上传到网盘，关注下方微信号，回复【微服务】即可获取。]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给软件工程师的一些职业建议]]></title>
    <url>%2Fcareer-advices.html</url>
    <content type="text"><![CDATA[原文链接：http://www.ruanyifeng.com/survivor/startup/advices.html作者：阮一峰 什么样的人适合当软件工程师？ 下面的职业建议分别来自台湾的侯捷老师，以及美国的著名程序员尼古拉斯.泽卡斯（Nicholas C. Zakas）。 我觉得这些建议非常好，不仅适合 IT 行业，也适合其他行业。 其中一些也许你不一定认同，但我想你会得到启发， 1、兴趣虽然很多人在选择职业时受到家庭、环境等方面因素的影响，不一定能从事自己非常感兴趣的工作，但是如果可能的话，一定要以兴趣为要。这样在工作时会很开心，在个人发展方面也会取得很好的成就。 因为只有兴趣才能使你乐在其中，乐在其中你才会产生热情，充满热情才能使你做到卓越。 2、认知认知影响态度，态度决定一切。 侯捷老师认为，一个人在选择发展道路时，尤其重要的是要对自己有一个正确的认知。 每个人的兴趣可能会变，有些人看到某个行业有发展，有前途，因此对这个行业、这条路产生很大兴趣，这是非常可能的。但是每个人的本质基本不变，你是否甘于寂寞，是否能够与寂寞为伍？你的抗压性怎样？你的毅力强不强？你的心理素质如何？这些特质都是不易改变的，而且只有你自己才能给出这些问题的准确答案。 只有对自己有了正确的认知后，才能决定往哪个方向发展。 他认为，做 IT 产业非常寂寞，也非常辛苦，大家可能在周末的晚上都要加班，这就要求从事该产业的人必须甘于寂寞，具备一定的忍耐力。 侯捷先生在年轻的时候非常努力，曾被称为部门的「门神」，通常都是最早来，最晚走。 他认为如果一个人喜欢交际应酬，喜欢公关，就应该尽早离开这个行业，因为选择道路一定要忠实于你的本质、你的兴趣。 我补充一点，软件工程师主要跟机器打交道，而不是跟人打交道。有时，你会整整一天坐在电脑屏幕前，不说一句话，全神贯注地调试软件。所以，如果你特别喜欢社交场合，喜欢跟人互动，你可能不适合当软件工程师。 3、EQ（情商）有能力读完大学的人，聪明才智基本上处于同一水平，没有人可以凭借聪明就可以取得成功。 尤其是在进入社会后聪明才智已经退为次要位置，人们更重视 EQ 方面的东西，包括你的人际关系能力、沟通表达能力，抗压性、处理危机的能力等等。 4、学技术要掌握本质我们在学习技术时应该注意掌握技术的本质性、不变性和可复用性。本质的东西不易变，不易变就可复用，这三者是一体的。 在接触先进的技术时，如果我们能将它的底层结构、本质性的东西搞清楚，会给我们带来莫大的帮助。 本质性、结构性的东西属于基础建设方面的问题，它对我们做项目可能不会带来直接的帮助，但在无形中会带来很大的影响，无形的通常是最宝贵的！世界上没有万变不变的手法，只有万变不变的宗旨。 5、刻苦修炼内功学武的人都必须从最基本的马步、吐纳等内功方面学起，招术很重要，但如果没有内功方面的基础，招术也只能停留在基本的层面，不会到达很高的成就。 在技术追求方面也一样，我们有时候会太热心于学习业界的新技术，每一样都想沾一点。其实不必太急，基本功的东西更重要，研究得扎实一些，招术就比较容易创作了。 6、唯坚持得成功。坚持、毅力对一个人的成功是最重要的。有一句话说：在大树底下站久了，树阴就是你的。 侯捷老师自认才能平庸，但很能坚持。他的这个个性在朋友之间是被称道的。 虽然有时坚持并不代表一定成功，但只有坚持才能有成功的机会。 年轻时尽量刻苦一些，使肉体承受最大的痛苦，年龄稍大一些的时候才能享受成果。有一句话「退一步海阔天空」，但侯捷先生更希望大家「撑一下海阔天空」，一试再试做不成，再试一下。 7、不要别人点什么，就做什么尼古拉斯.泽卡斯的第一份工作，只干了8个月，那家公司就倒闭了。他问经理，接下来他该怎么办，经理说： 小伙子，千万不要当一个被人点菜的厨师，别人点什么，你就烧什么。不要接受那样一份工作，别人下命令你该干什么，以及怎么干。你要去一个地方，那里的人肯定你对产品的想法，相信你的能力，放手让你去做。 他从此明白，单单实现一个产品是不够的，你还必须参与决定怎么实现。好的工程师并不仅仅服从命令，而且还给出反馈，帮助产品的拥有者改进它。 8、推销自己泽卡斯进入雅虎公司以后，经理有一天跟他谈话，觉得他还做得不够。 你工作得很好，代码看上去不错，很少出 Bug。但是，问题是别人都没看到这一点。为了让其他人相信你，你必须首先让别人知道你做了什么。你需要推销自己，引起别人的注意。 他这才意识到，即使做出了很好的工作，别人都不知道，也没用。 做一个角落里静静编码的工程师，并不可取。你的主管会支持你，但是他没法替你宣传。 公司的其他人需要明白你的价值，最好的办法就是告诉别人你做了什么。一封简单的 Email：「嗨，我完成了 XXX，欢迎将你的想法告诉我」，就很管用。 9、学会带领团队工作几年后，已经没人怀疑泽卡斯的技术能力了，大家知道他能写出高质量的可靠代码。有一次，他问主管，怎么才能得到提升，主管说： 当你的技术能力过关以后，就要考验你与他人相处的能力了。 于是，他看到了，自己缺乏的是领导能力，如何带领一个团队，有效地与其他人协同工作，取到更大的成果。 10、生活才是最重要的有一段时间，泽卡斯在雅虎公司很有挫折感，对公司的一些做法不认同，经常会对别人发火。 他问一个同事，后者怎么能对这种事情保持平静，同事回答： 你要想通，这一切并不重要。有人提交了烂代码，网站下线了，又怎么样？工作并不是你的整个生活。它们不是真正的问题，只是工作上的问题。真正重要的事情都发生在工作以外。我回到家，家里人正在等我，这才重要啊。 从此，他就把工作和生活分开了，只把它当作“工作问题”看待。这样一来，对工作就总能心平气和，与人交流也更顺利了。 11、自己找到道路泽卡斯被提升为主管以后，不知道该怎么做。他请教了上级，上级回答： 以前都是我们告诉你做什么，从现在开始，你必须自己回答这个问题了，我期待你来告诉我，什么事情需要做。 很多工程师都没有完成这个转变，如果能够做到，可能就说明你成熟了，学会了取舍。 你不可能把时间花在所有事情上面，必须找到一个重点。 12、把自己当成主人泽卡斯每天要开很多会，有些会议根本无话可说。他对一个朋友说，我不知道自己为什么要参加这个会，也没有什么可以贡献，朋友说： 不要再去开这样的会了。你参加一个会，那是因为你参与了某件事。如果不确定自己为什么要在场，就停下来问。如果这件事不需要你，就离开。不要从头到尾都静静地参加一个会，要把自己当成负责人，大家会相信你的。 从那时起，他从没有一声不发地参加会议。他确保只参加那些需要他参加的会议。]]></content>
      <categories>
        <category>闲扯系列</category>
      </categories>
      <tags>
        <tag>职业</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是短连接，如何用 Python 生成短连接？]]></title>
    <url>%2Fpython-short-url.html</url>
    <content type="text"><![CDATA[在编辑微信文章时，发现微信页面插入一个网址会变的非常丑陋，稍微长一些的显示效果都不好。 比如这样： 对于读者来说，由于微信里不能插入外链，读者要想访问一个网址，不能点击，只能手输。 WTF，那么长的一个网址！ 于是我想到了短网址。 什么是短链接 ?短网址，很简单，就是把普通网址，转换成比较短的网址。 短网址服务是随着 Twitter 和微博这样短小的互联网内容的兴起而出现的，因为这些社交网站的 140 字字数限制，如果网址不用什么办法来缩短的话，会很容易占据一条消息的绝大部分篇幅，甚至使得消息无法发出。 常见的就是微博的短网址，比如：http://t.cn/EZXC3rf 。短网址在微博这些限制字数的应用里，好处不言而喻。短、字符少、美观、便于发布、传播。 新浪、百度等等，很多都有提供短网址转换服务。 短网址的原理当我们在浏览器里输入 http://t.cn/EZXC3rf 时 1、DNS 首先解析获得 http://t.cn 的 IP 地址；2、当 DNS 获得 IP 地址以后（比如：116.211.169.137），会向这个地址发送 HTTP GET 请求，查询短码 EZXC3rf；3、http://t.cn 服务器会通过短码 EZXC3rf 获取对应的长 URL；4、请求通过 HTTP 301 转到对应的长 URL。 实现短网址服务是需要短网址服务器的，这里我们不再重复造轮子。 百度、新浪等短网址服务都有相应的 API 接口可以直接调用。 短网址接口新浪短网址接口的稳定性和跳转速度还是很给力的，但是接口使用时需要进行鉴权先，那就有点麻烦了，这里我们就不再演示。 百度的呢，百度的倒是不用鉴权，但是在转换我的博客地址时，居然报异常！ 于是，又找到了一个小众的接口：http://suo.im/。 使用也很简单： TXT格式短网址 API 接口 接口：http://suo.im/api.php?url=urlencode(&#39;要缩短的网址‘)例如：http://suo.im/api.php?url=http%3a%2f%2fwww.baidu.com返回：http://suo.im/baidu JSON格式短网址API接口 说明：format为json例如：http://suo.im/api.php?format=json&amp;url=http%3a%2f%2fwww.baidu.com返回：{“url”:”http://suo.im/baidu&quot;,&quot;err&quot;:&quot;&quot;} 代码实现有接口，代码实现就很简单了： 12345678910import requestslong_url = "https://hoxis.github.io/learn-microservice-from-0.html"querystring = &#123;"url":long_url&#125;url = "http://suo.im/api.php"response = requests.request("GET", url, params=querystring)print(response.text) 运行完，就能生成自定义网址的短网址啦！ 12$ python suo.pyhttp://suo.im/51ckP5 再也不用担心公众号里插入链接了！ 参考： http://t.cn/RYUf0PW]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小米、锤子，这是要一起「搞机」？]]></title>
    <url>%2Fxiaomi-chuizi.html</url>
    <content type="text"><![CDATA[昨天，我想很多人的朋友圈或者群里，都被下面这张「官宣」图刷屏了： 没错，就是雷军和罗永浩在微头条相互示好，让人浮想联翩。 1、小米近来日子并不好过，虽然刚刚上市，但是股价一度跌破 12.12 港元，相距开盘后的 21.55，跌去了将近一半的市值。 另外，最近受 P2P 跑路门影响，小米的声誉也受到了不小的损伤。 2、小米手机的情况呢？我想也不能让雷军乐观，虽然小米 8 刚刚突破 600 万台的出货量，但是一直甩不掉「性价比」的标签。之前想靠 note 系列冲击高端价位，无奈折戟。 反观竞争对手 ov、华为，慢慢在消费者心中堆砌堆砌出了高大上的产品形象，特别是华为，刚发布的 mata20，是直逼三星的地位。 3、了解小米的应该能感受到，小米手机的设计最近有所乏力，虽说 Mix 让人眼前一亮，但之后并没有拿出让消费者心动的设计，不知道过几天将要发布的 Mix3 能否为小米扳回一城。 而锤子呢？ 我想老罗更没有资格坐得住。 锤子最近很不稳，负面消息不断。 1、之前过了一把瘾的子弹短信，当时仿佛一夜爆红，一路领跑各大 App 下载榜单，几天内激活用户数就超过了 400 万。可是过眼瘾后呢？我们知道，子弹短信下架了，这并没有成为老罗的一张稳稳当当的船票。 2、子弹短信的风波还未平息，锤子有要开始面临「裁员」传闻，有网友爆料称，锤子科技正在裁员，且规模不小。还有消息称，锤子科技成都分公司面临解散。 3，还有 TNT，基本上成了大家的笑柄，当时发布会后，大家动不动就开玩笑说，小声点，吵到我用 TNT 了。 不得不说，锤子手机的设计还是挺令人满意的，很心动，但是手机的品控一直令人担忧，要是让我拿来作为主力机，又会望而却步。 还有就是锤子的一些「微创新」，比如闪念胶囊、一步、锤子便签等等，这都是小而美的东西。但是，这些都不足以转换成购买力，不足以让老罗实现他收购苹果的梦想。 那么，今天这张图到底意味着什么呢？ 锤子收购小米，为收购苹果的计划打下坚实的基础？ 不过，这条新闻已经被证实是「乌龙」了，只是微头条在同步微博内容时出了 bug： 今日头条有一个功能，可以同步你在微博发的内容过去，但是他们的同步有时候很及时，有时候又慢一拍，而且只能自动同步帐号主人发的内容，无法同步转发内容~所以就把两个老板两天发的心~给心到一起去了，都散了吧~ 不过，我打心底还是希望两家拿出各自的优势进行合作，为米粉和锤粉带来一款较为完美的手机产品！ P.S. 第一次写这种文章，大家觉得怎样？ 1024 福利预告：1024，我为大家准备了 6 本书，具体的大家可以关注明天的推文。]]></content>
      <categories>
        <category>闲扯系列</category>
      </categories>
      <tags>
        <tag>趣文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[资源分享 | 2018 年最新传智播客黑马 WEB 前端 36 期全套（赠1000套HTML模板+前端面试题汇总）]]></title>
    <url>%2Fresource-heima-qianduan.html</url>
    <content type="text"><![CDATA[周末了，放松下，分享一波资源给大家~ 教程千千万万，坚持寥寥几人。以前没人教，但肯坚持。现在有人教，没人坚持。保存 100TB，实际是摆设。大吉大利，今晚吃鸡？ 视频+笔记+案例+素材适用人群：零基础Web前端开发 课程内容 获取方式关注下方微信后，回复【002】即可获取。]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 转义字符中没有这个 「\e」 ！]]></title>
    <url>%2Fpython-escape-character-e.html</url>
    <content type="text"><![CDATA[问题来源于技术交流群里： 常见的转义字符 \n、\t 之类的我们都知道什么意思，但是这个 \e 是什么意思呢？ 抱着一股钻研的精神，我搜了一把。 结果，所有的页面里都是只有一句简单的 \e 代表转义。 然后呢？ 不要举个例子吗？ 他们不给例子，那我们自己做个总可以吧！ 于是，打开 Python 交互页面，做了一些简单的实验： 123456789&gt;&gt;&gt; print '\e123'\e123&gt;&gt;&gt; print 'eee\e123'eee\e123&gt;&gt;&gt; print 'eee\e\t123'eee\e 123&gt;&gt;&gt; print 'eee\e\n123'eee\e123 结果发现，\e 根本没有任何影响！ 那这个 \e 到底是个啥？ 于是，我想到了要找官方文档。 Python3.7 的官方文档中列出的所支持的转义字符如下： 可以发现，并没有 \e ！！！ 那我们搜出来的文档里的 \e 都是哪里来的？ 我也不知道。 也许我理解的有问题，有技术大佬懂的话，欢迎留言指导啊！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[资源分享 | 网易云课堂价值 399 的 office 三合一自学教程]]></title>
    <url>%2Fresource-office-qiuye.html</url>
    <content type="text"><![CDATA[上次分享了 PS 资源后，又有小伙伴后台留言想要 office 相关学习资源，今天我就找了一份价值 399 的网易云课堂的自学教程，免费送给大家！ 这位小伙伴是在博客里留言的： 资源介绍网易云秋叶 office、Word、PPT 三合一免费自学教程，标价 399。 适用人群： 急需一门课贯通Word、Excel、PPT办公应用核心技能，想学 Office 却无从下手！ 课程概述： 1 课贯通 Word、Excel、PPT 三大技能； 精选办公实战案例，场景化教学，无缝衔接办公应用； 3 大模块，34 章，520 课时，全面覆盖 Office 核心知识点； 新手必学 + 高手必会 + 疑难速查，全面覆盖你的需求； 完整的知识地图，提供给你学习攻略，科学安排学习路径，分级教学，让高手之路更加轻松，助你成为 Office 三剑客 课程简介：http://study.163.com/course/introduction.htm?courseId=1005105013 获取方式关注下方公众号后，回复【001】即可获取下载链接。]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>office</tag>
        <tag>资源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 博客 busuanzi_count 失效解决方法]]></title>
    <url>%2Fhexo-next-busuanzi.html</url>
    <content type="text"><![CDATA[有一天突然发现还正常的使用不蒜子统计功能失效了，一脸懵逼，以为是自己的配置哪里出问题了，因为我经常瞎鼓捣。 今天心血来潮，到不蒜子官网一看： 原来是牛牛牛牛牛牛牛的域名被强制过期了，官网也提供了解决方案，就是更改域名。 博客使用的是 next 主题，配置文件位置为： themes\next\layout\_third-party\analytics\busuanzi-counter.swig 找到如下代码： 1&lt;script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt; 修改为： 1&lt;script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt; 重新部署即可：]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好物分享 | 在线脑图工具：百度脑图]]></title>
    <url>%2Fgood-things-naotu-baidu.html</url>
    <content type="text"><![CDATA[背景：【好物分享】系列主要分享本人工作学习过程中用到的一些效率工具。因为本人有个「坏毛病」，用某个东西前，在能力范围内，会把相关类似的所有产品都试用一遍，然后挑出一个最喜欢的持续使用。 不过，有时会出现无法挑出的情况，比如 A 的颜值高，B 的功能全，我恨不得自己做一个把 A、B 的优点合并一起，哈哈~ 这种情况下，我只能先挑一个用着，然后时不时回去看另外一个有没有更新。 举个例子，我现在用印象笔记，还是时不时看有道云笔记更新了啥功能。 下面开始正文。 群里总是有小伙伴问 xmind 文件怎么打开，能不能分享下软件？ 其实我个人是非常喜欢在线工具的，主要是不需安装，还可以云端保存，适合多终端进行工作。 好了，下面介绍今天的主角：百度脑图。 虽说大家印象中的百度是一个经常「作恶」的公司，但是今天推荐的百度脑图确实是一个不错的在线工具。 优点 无需安装 这有点废话了，既然是在线工具，当然无需安装。 不过这一点也很关键，有时候思维导图软件的安装问题就难倒了一大批小伙伴。 但百度脑图就非常方便，不用安装，直接登陆 http://www.naotu.baidu.com 就可以开始画思维导图了。 容易上手 相对于普通的思维导图软件，百度脑图非常简单，基本上能够满足一般脑图的制作。 方便储存 只要你拥有一个百度账号，你就能将思维导图保存在云端，非常非常方便。 功能简介 管理页面 可以方地对脑图文件进行管理，可以按目录梳理文件： 编辑页面 主题插入、标记等脑图常用功能都有： 导出 支持导出为图片、xmind 格式文件、km 格式文件等。 本地文件上传 还支持本地文件上传编辑，不知道怎么打开 xmind 格式文件的小伙伴，看到这里是不是应该知道了？ 分享 还可以把脑图分享给其他小伙伴查看，但是不能多人编辑。 总结加上之前分享的幕布，我们已经分享了两个在线脑图工具了，这里简单说下它们的区别。 个人觉得，百度脑图偏向于图形化的脑图工具，可以直接编辑脑图；幕布主要是文字编排，根据文字的层级来生成脑。 好了，介绍到这也差不多了，小伙伴们有兴趣的可以试用起来了。]]></content>
      <categories>
        <category>好物分享</category>
      </categories>
      <tags>
        <tag>脑图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我一般是这么爬虫的]]></title>
    <url>%2Fmy-spider-steps.html</url>
    <content type="text"><![CDATA[首先，爬虫不是我的本职工作，我爬虫一般是为了一些有意思的东西，获取一些信息，或者是实现一些可以自动化完成的任务，比如签到。 一般我的爬虫流程是这样的： 1、浏览器访问待爬网页，并提前打开开发者工具（F12），选中 Nework 选项卡，这样就可以看到网络交互信息； 或者，右键查看网页源代码，查找目标信息。 2、在网络交互信息流中筛选出自己需要的，然后在 postman 中模拟请求，看是否仍然可以获取到想要的信息； postman 除了可以进行请求测试外，还有一个优势就是，代码可以直接生成，这样就可以方便得进行最终的整合了。 3、数据解析，从请求的响应中解析出我们的目标数据，至于得到数据后如何处理，那就是你的事情了。 下面就以大家耳熟能详（landajie）的豆瓣电影 TOP250 为例。 实例分析请求梳理首先，我们要访问待爬取的网页：https://movie.douban.com/top250。 一般情况下，我都是直接按下 F12 调出 DevTools，点击 Network 选项卡： 有时请求已经加载完成了，可以把数据全部 clear 掉，然后重新刷新网页，这时候请求流会重新加载。 这里有几个点需要注意，主要是下图圈红的几个： 1、有些网页请求会有自动跳转，这是请求流会重新加载，这是勾选了 Preserve log 的话，数据就会持续打印，不会被冲掉； 2、勾选 Disable cache 可以禁用缓存； 3、请求流的筛选：XHR 是 XMLHttpRequest 的意思，大多数情况下只要点击 XHR 就行了，但是若此时发现没有想要的请求数据，那么就要点击 All 展示所有请求流。 比如豆瓣的这个，XHR 中是没有我们的目标请求的。 请求模拟通过上面的步骤，我们能够确定通过哪些请求能够得到我们的目标数据，然后把这些请求放到 postman 中进行模拟。 比如，我们在 postman 中访问豆瓣的网站： 这里的请求比较简单，直接 get url 就能获取到目标数据。 其实大部分情况下，都是需要添加一些访问参数的，这是我们可以在 Headers 里添加。 另外，postman 还支持其他请求，如 post、delete 等等： 生成代码 点击右侧的 code 按钮，就可以获取到对应的代码： 支持生成多种语言的代码： 比如，我们这里选择 Python Requests，就可以得到如下代码： 123456789101112import requestsurl = "https://movie.douban.com/top250"headers = &#123; 'cache-control': "no-cache", 'postman-token': "d2e1def2-7a3c-7bcc-50d0-eb6baf18560c" &#125;response = requests.request("GET", url, headers=headers)print(response.text) 这样我们只要把这些代码合并到我们的业务逻辑里就行了，当然其中的 postman 相关的参数是不需要的。 数据解析下面要做的就是从响应中解析目标数据。 有些响应是返回 HTML，有些是返回 json 数据，有的还是返回 XML，当然也有其他的，这就需要不同的解析逻辑。 具体如何解析，这里我们不再赘述，之前的爬虫文章中都有涉及，有兴趣的可以翻一翻。 总结本来打算写 postman 的使用的，但是写来写去，成了我的一般爬虫流程梳理。 本文涉及的爬虫都是比较初级的，至于 ip 代理、验证码解析等高端功能，后面有时间再单独说。 不知道你的一般流程是什么样的，不妨留言分享下。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 系统 MySQL yum 升级到 5.6]]></title>
    <url>%2Flinux-mysql-5.6-to-5.6.html</url>
    <content type="text"><![CDATA[在服务器上使用 MySQL 时，发现不支持 --set-gtid-purged 参数，查阅资料，原来从 MySQL5.6 才有这个参数，于是需要在线将 MySQL5.5 升级到 MySQL5.6。 去网站下载mysql的yum源，地址如下：http://repo.mysql.com/ 在 Linux 上先查看系统的版本号，根据版本号对应下载： 12345678# more /etc/redhat-release# rpm -Uvh http://repo.mysql.com/mysql-community-release-el6-5.noarch.rpm# yum -y upgrade mysql# mysql --versionmysql Ver 14.14 Distrib 5.6.41, for Linux (x86_64) using EditLine wrapper 升级成功！]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[骚操作 | 一行命令生成动态二维码]]></title>
    <url>%2Fpython-myqr.html</url>
    <content type="text"><![CDATA[当我看到别人的二维码都做的这么炫酷的时候，我心动了！ 我也想要一个能够吸引眼球的二维码，今天就带大家一起用 Python 来做一个炫酷的二维码！ 首先要安装工具 myqr： 1pip install myqr 安装完成后，就可以在命令行中输入 myqr 查看下使用帮助： 1$ myqr --help 可以看出 myqr 有着丰富的参数支持，这里就不再一一解释，后面使用到会再细说。 简单用法首先我们生成一个普通二维码： 1234$ myqr "http://weixin.qq.com/r/PnUmPg7E8lONrUpd9yAs"line 16: mode: byteSucceed!Check out your 2-H QR-code: /mnt/d/code/Python/learn/myqr/qrcode.png 这时就会在当前目录下生成一个名称为 qrcode.png 的二维码。 如果 myqr 后面传入的是普通字符串，那么扫描后会现在字符串。若是一个网址，扫描后会自动跳转。 大家可以扫描下看看，是不是我们设置的字符串。 需要注意的时，这里的字符串不能指定中文，否则会抛出 ValueError(‘Wrong words! Make sure the characters are supported!’) 的异常。 1、使用 -d 可以控制输出的文件路径； 2、使用 -n 控制文件名称，格式可以是 .jpg、.png、.bmp、.gif； 3、使用 -l 可以控制二维码的纠错等级，范围是L、M、Q、H，从左到右依次升高； 4、使用 -v 控制二维码的边长，范围是 1 至 40，数字越大边长越大。 生成带图片的二维码光是二维码，是否太单调了呢？没关系，我们能加上我们想要的图片，使二维码更具辨识度！ 我们可以使用 -p 参数指定图片，将二维码与该图片结合在一起。 想要将上面的图片结合到二维码中，可以使用下面的命令来生成： 1myqr "http://weixin.qq.com/r/PnUmPg7E8lONrUpd9yAs" -p developer.png 黑白的，似乎不是那么好看，彩色的如何呢？ 实现彩色也非常简单。 如果想要生成彩色的，可以加上参数 -c。 另外，如果想要图片的对比度和亮度，可以使用参数 -con 控制图片对比度，1.0 表示原始图片，更小的值表示更低对比度，更大反之。默认为 1.0； 使用参数 -bri 用来调节图片的亮度，其余用法和取值与 -con 相同。 生成动态二维码其实生成动态二维码，并没有想象的那么复杂。 方式与上面的带图片的二维码的生成方式没有区别，只是将原始图片换成 .gif 即可! 1myqr "http://weixin.qq.com/r/PnUmPg7E8lONrUpd9yAs" -p who.gif -c 总结myqr 使用非常简单，一行代码就可以生成我们想要的二维码。另外，还有在 Python 代码中调用的方式生成，这里就不再赘述。 大家快试试生成自己的专属炫酷二维码吧！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>骚操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[资源分享 | 敬伟 PS 教程 ABCD 四套全集]]></title>
    <url>%2Fresource-ps-jingwei.html</url>
    <content type="text"><![CDATA[昨天，我说有需要资源的后台联系我，于是，就真的有小伙伴在后台跟我留言了，说要 PS 视频。 咱说出去的话，就要说到做到，说尽量肯定会尽量帮你找！ 于是，我和官方合作平台【谷歌】进行了全网的资源盘点，下载了好几拨资源，每个都下载下来进行试听，最终锁定到了：敬伟 PS 教程。 敬伟 PS 教程全集，讲得特别好，特别详细，声音和画面都很清晰！！！ 本资源分为 ABCD 四套教程，全部无密码，在网上很难找到这么全乎的哦~ 部分目录： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175============基础篇===============A01-PS是什么 怎么学PSA02-PS安装与启动A03-PS主界面认识A04-PS新建文档A05-PS图像大小A06-PS打开与保存/tA07-PS设置 PSA08-PS图层教程 A09-PS平移和缩放A10-PS移动工具详解A11-PS选区和选框工具 A12-PS选框工具全解 A13-PS套索与魔法工具 A14-PS选区编辑调整A15-PS历史工具 A16-PS画笔工具A17-PS修复工具A18-PS填充颜色和图案A19-PS自由变换A20-PS通道和蒙版A21-图层进阶知识A22-色彩基础大课A23-亮度与色阶看懂直方图-1A23-亮度与色阶看懂直方图-2A24-曲线和色彩平衡调色-1A24-曲线和色彩平衡调色-2A24-曲线和色彩平衡调色-3A25-万能的钢笔！制图抠图必学！-part1A25-万能的钢笔！制图抠图必学！-part2A25-万能的钢笔！制图抠图必学！-part3A25-万能的钢笔！制图抠图必学！-part4A25-万能的钢笔！制图抠图必学！-part5A25-万能的钢笔！制图抠图必学！-part6A26-PS的文字处理工具A27-PS各种实用的辅助工具A28-批量处理大量的图像A29-用PS做3D图像特效A30-用PS做视频动画-part1A30-用PS做视频动画-part2==============B掌握篇=============B01-01初阶抠图-调整边缘介绍B01-02初阶抠图-调整边缘抠头发B01-03初阶抠图-图层修边知识B01-04初阶抠图-钢笔无损抠图B01-05初阶抠图-蒙版的利用B02-01制图操作-排布照片B02-02制图操作-自动生成全景照B02-03制图操作-服装操控变形B02-04制图操作-内容识别比例调图B02-05制图操作-画笔高级设置B02-06制图操作-复制技术B03-01图层样式-图层样式基础B03-02图层样式-混合选项-红蓝3DB03-03图层样式-斜面浮雕水晶按钮B03-04图层样式-描边发光按键B03-05图层样式-文字图层样式B03-06图层样式-图标设计B03-07图层样式-网页网店导航店招B03-08图层样式-制作动画特效B04-01工具介绍-智能对象B04-02工具介绍-标尺与计数工具B04-03工具介绍-切片工具B04-04工具介绍-宝贝描述的动静切片B04-05更多工具-多彩的混合器画笔B05-01混合模式-了解混合模式B05-02混合模式-车灯炫光和星云B05-03混合模式-变暗模式B05-04混合模式-正片叠底B05-05混合模式-颜色加深B05-06混合模式-线性加深B05-07混合模式-深色模式B05-08混合模式-变亮模式B05-09混合模式-滤色模式B05-10混合模式-其他变亮型B05-11混合模式-叠加模式B05-12混合模式-柔光模式B05-13混合模式-强光模式B05-14混合模式-亮光模式B05-15混合模式-线性光模式B05-16混合模式-点光模式B05-17混合模式-实色混合模式B05-18混合模式-色差型水墨中国风B05-19混合模式-调色型系列混合模式B05-20混合模式-黑白照片上色B05-21混合模式-穿透模式B05-22混合模式-颜色混合带合成B06-01调色课程-位图网点特效B06-02调色课程-索引颜色B06-03调色课程LAB模式B06-04调色课程-LAB调色(敬伟色)B06-05调色课程-玩转饱和度B06-06调色课程-照片滤镜矫偏色B06-07调色课程-通道调出青色调B06-08调色课程-通道混合器巧变色B06-09调色课程-颜色查找快捷调色B06-10调色课程-CMYK通道混合色调B06-11调色课程-强大的可选颜色B06-12调色课程-可选颜色的彩色范围B06-13调色课程-可选颜色黑白灰范围B06-14调色课程-可选颜色范围关联性B06-15调色课程-薰衣草变白花B06-16调色课程-反相和反向B06-17调色课程-色调分离分色B06-18调色课程-阈值磨皮去斑B06-19调色课程-渐变映射调色B06-20调色课程-转化黑白图B06-21调色课程-匹配颜色调色B06-22调色课程-替换颜色B06-23调色课程-颜色替换工具B06-24调色课程-色调均化B06-25调色课程-自动调整图像B06-26调色课程-应用图像命令B06-27调色课程-Lab应用图像调色B06-28调色课程-启用BridgeB06-29调色课程-合并HDR ProB06-30调色课程-HDR特殊色调B06-31调色课程-阴影高光老人沧桑皮肤B06-32调色课程-了解ACRawB06-33调色课程-ACR超便捷调色B06-34调色课程-无损操作B07-01高级抠图-色彩范围抠毛发B07-02高级抠图-通道抠火焰B07-03高级抠图-计算命令详解B07-04高级抠图-通道抠头发B07-05高级抠图-复杂头发的抠图B07-06高级抠图-抠复杂背景的头发B07-07高级抠图-抠复杂背景的婚纱B07-08高级抠图-玻璃的抠图与合成B07-09高级抠图-黑白命令巧抠图B07-10高级抠图-玻璃瓶抠图合成B07-11高级抠图-水花抠图合成练习B07-12高级抠图-高阶抠图作业布置B08-01滤镜系列-滤镜基础知识B08-01滤镜系列-滤镜入门知识B08-02滤镜系列-滤镜快捷键操作B08-03滤镜系列-强大的智能滤镜B08-04滤镜系列-滤镜库B08-05滤镜系列-滤镜库应用B08-06滤镜系列-插画和水彩效果实例B08-07滤镜系列-玻璃与塑料B08-08滤镜系列-照片变水墨画B08-09滤镜系列-真人变雕塑B08-10滤镜系列-广角镜头校正B08-11滤镜系列-液化滤镜B08-12滤镜系列-液化高级选项B08-13滤镜系列-消失点妙用B08-13滤镜系列-液化美容B08-15滤镜系列-风格化滤镜B08-16滤镜系列-模糊画廊B08-17滤镜系列-普通模糊类滤镜B08-18滤镜系列-模糊类滤镜B08-19滤镜系列-镜头模糊效果B08-20滤镜系列-波浪B08-21滤镜系列-波纹实例B08-22滤镜系列-水波实例B08-23滤镜系列-扭曲滤镜做易拉罐B08-24滤镜系列-极坐标特效B08-25滤镜系列-置换滤镜特效B08-26滤镜系列-从云到爆炸B08-27滤镜系列-光照特效系统B08-28滤镜系列-减少杂色美化皮肤B08-29滤镜系列-添加杂色变老照片B08-30滤镜系列-像素化效果B08-31滤镜系列-锐化模糊变清晰B08-32滤镜系列-高反差保留B08-33滤镜系列-位移滤镜做图案B09-01三维练习-3D立体倒影B09-02三维练习-海报3D立体字B10-01视频动画-视频转GIF动态图B10-02视频动画-文字炫光动画B10-03视频动画-卷轴动画效果 官方价格 50 块： 今天，全部免费送！ 关注下方公众号后，后台回复【ps】即可获取！希望喜爱 PS 的朋友能够喜欢~]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>资源</tag>
        <tag>ps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好物分享 | Gif 录制工具：Screen2Gif]]></title>
    <url>%2Fgood-things-screen2gif.html</url>
    <content type="text"><![CDATA[后台有小伙伴问我演示的动图是怎么做的，其实是借助于 Gif 录制工具，录制屏幕动作，生成的动图。 我之前试用过很多 Gif 录制工具，今天就推荐一个我最终选用的 Screen2Gif。 ScreenToGif 是一个 Gif 动态图片录制软件，它可以直接帮我们在屏幕上的操作输出成 Gif 动画，而且操作相当简单。 软件界面友好，并且易操作，软件占用资源很小，录制起来不会造成机器速度变慢。 录影时时会有个取景用的方框，我们可以任意移动方框的位置，只要在方框内的就会被录影下来，随时按键盘上指定的快速键即可随时录影、暂停、停止。 录影完成后，还可一步一步检视被录下来的画面，如果哪些画面你不要的话，还可个别删除掉，相当简单且方便。 无需安装即可使用 该软件是无需安装的就可直接运行使用的，如图： 直接点击该 exe 文件即可使用。 自动吸附窗口 按住窗口的「⊕」按钮，还可以吸附窗口，不用再小心翼翼地拖拉窗口了。 逐帧操作 且提供了友善的逐帧编辑的页面： 添加水印 还可以添加水印： 关注后，回复【gif】即可获取本软件。]]></content>
      <categories>
        <category>好物分享</category>
      </categories>
      <tags>
        <tag>gif</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术学得好，老婆加班少！]]></title>
    <url>%2Fpython-weixin-api-test.html</url>
    <content type="text"><![CDATA[国庆本来打算好好休息下的，没想到第一天就被领导的电话叫醒，说微信服务挂了，抓紧修复。 mmp 这就是我老婆的第一天假期，问题修复后，老婆心有余悸，一直手动在那测试微信服务，就是往他们公众号发个消息，看是不是能够正常返回。 我看着心疼，立志要用技术手段实现微信接口的巡检。 我先捋了下思路，技术实现的话，大概需要解决如下几个问题： 1、微信后台接口如何测试？2、如何用 Python 实现？3、如何及时获取测试结果？4、如何定时执行测试？ 下面开始！ 1 微信接口如何测试？最开始，我比较闹心的就是微信接口怎么测，因为之前基本没有接触过。 我先去他们微信后台找到了配置的服务接口信息，然后又再往上各种找如何测试。 最后，找到的一个竟然是官网提供的：https://mp.weixin.qq.com/debug/cgi-bin/apiinfo?t=index&amp;type=%E6%B6%88%E6%81%AF%E6%8E%A5%E5%8F%A3%E8%B0%83%E8%AF%95&amp;form=%E6%96%87%E6%9C%AC%E6%B6%88%E6%81%AF 于是我打开了浏览器开发者工具，查看后台请求信息： 然后，我用我们熟悉的 Postman 进行接口测试，果然，OK！ 能够得到我们想要的数据。 返回数据长这样： 2 Python 如何实现接口测试？经过上面的分析，如何测试接口，流程已经很清晰，我们接下来要做的就是数据解析。 由上图可见，返回的其实是一个 HTML，我们想要的数据在其中的 resultData 变量中。 resultData 变量对应的是一个 json 数据，其中的 body 是我们最想要的内容，它还是一个 XML 格式的数据。 resultData 对应的数据如下（已经过 UrlDecode）： 123456789101112&#123; "status_line": "200\tOK", "header": ["Cache-Control: private", "Date: Tue, 02 Oct 2018 07:50:50 GMT", "X-Powered-By: ASP.NET", "Set-Cookie: ASPSESSIONIDCCRCTCTQ=DPFLKAJBFOJLDAFAFNOCDDFI; path=\/", "Server: WWW Server\/1.1", "Content-Type: text\/html; Charset=utf-8", "Content-Length: 270"], "body": "&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[xxx]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[xxx]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;2018/10/2 15:50:50&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt;&lt;Content&gt;&lt;![CDATA[您所查询的数码不存在，请仔细确认，谨防假冒。]]&gt;&lt;/Content&gt;&lt;/xml&gt;", "hint": "请求成功"&#125; 因此，主要需要做的工作就是： 1、从返回数据中解析出 resultData 对应的数据；2、从 body 数据中解析出 &lt;Content&gt; 标签对应的内容； ## 解析 resultData 本来打算用 BeautifulSoup 解析返回的 HTML 数据，但是 resultData 其实是其中 js 代码中的一个变量，我不知道怎么处理，于是想到了用正则直接解析字符串。 需要做的就是用正则匹配出 resultData = 和 } 之间的内容。 参考正则：匹配两个字符串 A 与 B 中间的字符串包含 A 但是不包含 B： 表达式: A.*?(?=B) 写出来我们的正则就是： 1pattern = re.compile(r'(?&lt;=resultData = ).*?&#125;') 看着有点懵吧，正则的一大头疼问题就是难看，难懂！ body 内容的解析resultData 对应数据解析完成后，我们得到了一个 json 数据，然后很容易可以获取到 body 数据。 接下来就是解析 body 对应的 xml 数据了。 这里，我们使用的是 xml.etree.ElementTree，解析 xml 非常简单： 12xml_data = ET.fromstring(body)text = xml_data.find('Content').text 这个组件在之前的文章 《Python 助你填写高考志愿》也有用过，有兴趣的可以点击查阅。 重要信息我们都获取到了，下面我们就要想怎么把接口结果发出去了。 3 如何及时获取测试结果？这里，我首先想到的还是之前用过的 pushbear 的微信推送服务，因为实现很简单，而且也不是正式场合使用。 123def send_wechat(tiele, text): url = "https://pushbear.ftqq.com/sub?sendkey=xxx5&amp;text=&#123;&#125;&amp;desp=&#123;&#125;".format(tiele, text) resp = requests.get(url) 通过上面的函数，就可以将信息推送到微信了，不懂得可以参考之前的文章：1 行代码，实现微信消息发送。 4 如何定时执行接口测试？接口测试代码也有了，消息推送也有了，下面就是如何定时执行接口测试了，比如半小时执行一次？ 一种方案是使用 Linux 系统自带的 crontab 模块。 还有就是 Python 也有定时任务的模块，我找到了一个轻量级的定时任务调度的库：schedule。 12345678910111213141516import scheduleimport time def job(): print("I'm working...") schedule.every(10).minutes.do(job)schedule.every().hour.do(job)schedule.every().day.at("10:30").do(job)schedule.every(5).to(10).days.do(job)schedule.every().monday.do(job)schedule.every().wednesday.at("13:15").do(job) while True: schedule.run_pending() time.sleep(1) 这个栗子简单到我不需要怎么解释。而且，通过这个栗子，我们也可以知道，schedule 其实就只是个定时器。 在 while True 死循环中，schedule.run_pending() 是保持 schedule 一直运行，去查询上面那一堆的任务，在任务中，就可以设置不同的时间去运行。跟 crontab 是类似的。 我们只要把我们的测试接口方法放在上面的 job() 方法里，然后通过 schedule.every(30).minutes.do(job) 就可以实现半小时一次执行啦！ 总结至此，我的任务基本完毕，虽然功能简单，也没有什么高级的架构。 但是涉及的东西还是挺多的，网络交互、XML 解析、JSON 解析、正则表达式、微信推送、定时任务等。 这次，就到这吧，大家节日快乐~]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好物分享 | 在线脑图神器-幕布]]></title>
    <url>%2Fgood-things-mubu.html</url>
    <content type="text"><![CDATA[今天给大家分享一款常用的思维脑图工具：幕布。 地址：https://mubu.com/ 最近用的比较多的一个工具，个人整理有如下特点： 编辑页面看着很舒服； 可以将树形结构笔记转化为思维导图； 待办事项功能； 可以将自己的文件进行共享，对微信支持的还不错； 有自己的文档发布平台：幕布精选； 收费版有更多功能，如思维导图高级风格、文档高级样式等； 页面简洁清爽进入自己的文件列表是这样的，有没有很清爽的感觉？ 操作简单 注册登录以后，进入非常简洁的文档管理界面，点击“新建”即可建立一个新文档。记录笔记的时候给笔记分层极为简便： tab 和 tab+shift 分别控制层次的升降。 enter 新建主题 就这么简单的笔记操作，几乎是可以立刻上手。除此以外，他还有大量的快捷键可以操作，在笔记过程中，随时可以呼叫出快捷键列表帮助自己应用操作。 转换为思维导图： 分享及多格式导出完成幕布笔记以后，如果没有人能看到，那么自己的出色作品、认真思考则毫无价值。幕布这款软件在共享和导出方面，也做得颇为厚道： 支持复制链接分享的方式：自己的笔记点击开始分享的按钮，就可以立刻生成链接，发送给其他人。 生成思维导图以后，可以以图片或 Xmind 支持的格式保存并分享给他人，后者可以在 Xmind 的软件上进行修改。 还支持导出成 word、pdf、html 等多种格式，方便人们查看和使用。 看着不错吧，扫描下方二维码注册，可以免费获赠 15 天幕布高级版。]]></content>
      <categories>
        <category>好物分享</category>
      </categories>
      <tags>
        <tag>脑图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谁说 HTTP GET 就不能通过 Body 来发送数据呢？]]></title>
    <url>%2Fhttp-get-with-body.html</url>
    <content type="text"><![CDATA[当我们被问及 HTTP 的 GET 与 POST 两种请求方式的区别的时候，很多答案是说 GET 的数据须通过 URL 以 Query Parameter 来传送，而 POST 可以通过请求体来发送数据，所以因 URL 的受限，往往 GET 无法发送太多的字符。 这个回答好比在启用了 HTTPS 时，GET 请求 URL 中的参数仍然是明文传输的一样。 GET 果真不能通过 Request Body 来传送数据吗？ 非也。 如此想法多半是因循着网页中 form 的 method 属性只有 get 与 post 两种而来。因为把 form 的 method 设置为 post，表单数据会放在 body 中，而 method 为 get(默认值) 时，提交时浏览器会把表单中的字符拼接到 action 的 URL 后作为 query parameter 传送。 于是乎就有了这么一种假像：HTTP GET 必须通过 URL 的查询参数来发送数据。 其实 HTTP 规范并未规定说 GET 就不能发送 body 数据，在 RFC GET 中只是说： The GET method means retrieve whatever information (in the form of an entity) is identified by the Request-URI. 只是说 GET 意味着通过 URI 来识别资源。 测试我也是本着传统上对 GET 与 POST 区别的误解很多年，今天突然意识到 GET 应该可以使用 body，况且 HTTP 本身是一个纯文本的协议。没有测试就没有 100% 的发言权，所以做了如下的测试。 在一个 Spring Boot Web 项目中创建的 GET 请求 API： 12345678@RestControllerpublic class DemoController &#123; @RequestMapping(value = "/", method = RequestMethod.GET) public String getRequest(@RequestParam("id") String id, @RequestBody String body) &#123; return id + ": " + body; &#125;&#125; 上而创建的 GET 请求，URL 是 /?id=something，然后希望通过 request body 来获得请求数据。 再来一个测试用例，给 GET 请求发送 body 数据： 1234567891011121314@RunWith(SpringRunner.class)@WebMvcTestpublic class DemoControllerTest &#123; @Autowired private MockMvc mockMvc; @Test public void shouldReturnDefaultMessage() throws Exception &#123; this.mockMvc.perform(get("/?id=100").content("Hello, Get Body")) .andDo(print()) .andExpect(content().string(is("100: Hello, Get Body"))); &#125;&#125; 上面的单元测试顺利通过，说明对于 GET 请求我们同样可以使用 Request Body 来发送数据，而且 Spring 的测试框架也支持 GET 发送 body 数据。 再作一个验证，curl 命令, 需要用 -X 指定为 GET 请求，否则 curl 在使用 -d 发送 body 数据时自动切换为 POST 请求： 通过 curl -v 可以看到详细的请求响应数据，两个请求的 Content-Length 都是 8，即 “Get Body” 的长度，它们确实是在 Request Body 中，服务端接送 GET 来的 body 数据也没有半点问题。 下面是通过 Wireshark 捕获到的数据包的样子： 其他工具的支持情况如果说通过 Spring 的测试用例以及 curl 命令还有所疑问的话，看上面那张图片就分明的告诉我们是在使用 GET 发送 body 数据的。 但确实有些工具或类库不让我们发送 GET 请求时设置 Body。 Postman如著名的 Postman，在选择 GET 时 Body 标签是灰色不可用的： 而且从目前最新的 Apache Http Client 4.5 组件，它的 HttpGet 也不支持设置 Request Body, 因为 HttpGet 没有像 HttpPost 那样的 setEntity(entity) 方法。 OkHttpClient另一个 OkHttpClient 库也不支持 GET 发送 Request Body，当执行下面的代码时： 1234new Request.Builder() .url("http://localhost:8080/?id=100") .method("GET", RequestBody.create(MediaType.parse("application/json"), "hello body")) .build(); 直接告诉我: java.lang.IllegalArgumentException: method GET must not have a request body AsyncHttpClient最后再试一个 AsyncHttpClient 库： 123456Dsl.asyncHttpClient() .prepareGet("http://localhost:8080/?id=100") .setBody("Get Body") .execute() .toCompletableFuture() .thenAccept(System.out::println).join(); 输出 “100: Get Body”, 证明 AsyncHttpClient 是可以 GET 时发送 Body 数据的。 小结一下Apache Http Client 和 OkHttpClient 都不支持 GET 请求发送 Body 数据，而 AsyncHttpClient 是可以的。 那么回过头来想想为什么 HTTP 并未规定不可以 GET 中发送 Body 内容，但却不少知名的工具不能用 GET 发送 Body 数据，所以大致的讲我们仍然不推荐使用 GET 携带 Body 内容，还有可能某些应用服务器也会忽略掉 GET 的 Body 数据（???，猜的）。 我想更主要是 GET 被设计来用 URI 来识别资源，如果让它的请求体中携带数据，那么通常的缓存服务便失效了，URI 不能作为缓存的 Key。 但另一方面，如果仅仅是为了读取资源，而需要使用 Body 发送一大批数据时，改用 POST 请求却与 RESTFul 的 POST 语义不相符。这时候或许可以 GET + BODY, 但是不能对该请求以 URI 作为 Key 进行缓存了。 转载自：https://yanbin.blog/why-http-get-cannot-sent-data-with-reuqest-body/,作者：隔叶黄莺 Yanbin Blog]]></content>
      <categories>
        <category>网络相关</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 py2exe 打包 Python 程序]]></title>
    <url>%2Fpython-py2exe.html</url>
    <content type="text"><![CDATA[上回在《使用 PyInstaller 打包 Python 程序》中，我们介绍了使用 PyInstaller 对 Python 程序进行打包，今天带大家认识一个新的工具：py2exe。 接下来将从这几个方面进行介绍：基本使用方法、高级参数、注意点等。 简介 &amp; 安装py2exe 是一个将 python 脚本转换成 Windows 上的可独立执行的可执行程序（*.exe）的工具，这样，你就可以不用装 python 而在 Windows 系统上运行这个可执行程序。 安装 123pip install py2exe# 或者python -m pip install py2exe 基本用法看一个简单的例子：先写一个简单的脚本，文件名：helloworld.py： 123456789#!/usr/bin/env python # -*- coding: utf-8 -*- def say_hello(name): print("Hello, " + name) if __name__ == "__main__": name = input("What's your name：") say_hello(name) 下面还需要个用于发布程序的设置脚本：mysetup.py，在其中的 setup 函数前插入语句 import py2exe。 1234from distutils.core import setupimport py2exesetup(console=["helloworld.py"]) 然后按下面的方法运行 mysetup.py: 1python mysetup.py py2exe 运行生成的文件： 需要注意，这里需要在 Windows 环境下运行！否则可能会出现以下异常： 上面的命令执行后将产生一个名为 dist 的子目录，其中包含了 helloworld.exe、python24.dll、library.zip 等等文件： dist 子目录中的文件包含了程序所必须的东西，你需要将该目录中的所有内容一起发布。 默认情况下，py2exe 会在 dist 下创建以下这些文件： 1、一个或多个 exe 文件；2、几个 .pyd 文件，它们是已编译的扩展名，是 exe 文件所需要的；3、python**.dll，加上其它的 .dll 文件，这些 .dll 是 .pyd 所需要的；4、一个 library.zip 文件，它包含了已编译的纯的 python 模块如 .pyc 或 .pyo； 扩展setup 优化我们可以看到生成的 dist 目录中文件很多，那么是不是可以进行优化呢？ 123456789101112131415161718192021222324252627282930# mysetup.py# from distutils.core import setup# import py2exe# setup(console=["helloworld.py"])# -*- encoding:utf-8 -*-from distutils.core import setupimport py2exeINCLUDES = []options = &#123; "py2exe" : &#123; "compressed" : 1, # 压缩 "optimize" : 2, "bundle_files" : 1, # 所有文件打包成一个 exe 文件 "includes" : INCLUDES, "dll_excludes" : ["MSVCR100.dll"] &#125;&#125;setup( options=options, description = "this is a py2exe test", zipfile=None, console = [&#123;"script":'helloworld.py'&#125;]) options 可以用来指定一些编译的参数，譬如是否压缩，是否打包为一个文件等。 再次运行后，发现所有内容打包进了一个 helloworld.exe 程序中。 指定额外的文件一些应用程序在运行时需要额外的文件，诸如配置文件、字体、图标。py2exe 并不会自动把他们打包到 dist 目录，不过可以通过配置参数来打包。 可以在安装脚本中用 data_files 可选项指定了那些额外的文件，那么 py2exe 能将这些文件拷贝到 dist 子目录中。 格式如下：data_files=[(“目的文件夹”,[“文件名”,]), (“目的文件夹”,[“文件名”,]), (“目的文件夹”,[“文件名”,]),]。 比如，我们的程序中有一个名为 images 的目录放置了程序需要的图片， 那么我们就需要在 setup 函数中配置参数 data_files，这个参数包含一个元组列表 (target_dir,files)，其中 target_dir 是指定文件存放的目标路径，files 是这些额外文件的一个列表。 示例如下： 12345678from distutils.core import setupimport py2exe setup( windows = ['hello.py], data_files = [('images',['images\*.jpg'])] ) 上面的示例中，会把 images 目录中所有的 jpg 文件打包到 dist/images 子目录中。 注意点1、py2exe 新版本只支持 python3.3 以上，可以使用 pip install py2exe_py2 来安装兼容 python2 版本；2、若在 python3.6 版本下运行报错，请切换到 python3.4 尝试；3、python3 如果是 64 位，生成的 exe 只能在 64 位操作系统下运行，使用 32 位 python 可以解决； 4、从 Python 3.3，Windows 在构建 Python 时使用的是 Visual Studio 2010，因此生成后，需要手动将 msvcr100.dll 拷到生成目录下（dist目录），否则最终的文件运行时可能会报错； 或者通过 data_files=[(&quot;&quot;,[&quot;MSVCR100.dll&quot;])], 打包其中； 比如，我在 Win10 下打的包，拷贝到 Win7 上，运行出错： 出现类似确实 dll 文件的情况，都可以参考这种方法进行解决； 总结对于 pyinstaller 和 py2exe 两种把 Python 文件打包成 exe 的可执行文件的方法，都有各自的优缺点。但是最终目的都是为了在没有 Python 环境下的普通 Windows 系统的电脑中可直接运行，这点还是很不错的。 大家根据自己的需要，择优选择就行了。 参考：1、http://irootlee.com/Py2exe/2、https://www.jianshu.com/p/afc56b647866]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>打包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 PyInstaller 打包 Python 程序]]></title>
    <url>%2Fpython-pyinstaller.html</url>
    <content type="text"><![CDATA[有不少订阅本公众号的朋友都不是玩 Python，甚至都不是计算机相关专业的，当我给他们一个 Python 程序时，他们是完全不知道该怎么运行的。 于是我想是不是可以将我的程序打包成可执行文件，直接运行？ 就像这样： Python 程序都是脚本的方式，一般是在解析器里运行，如果要发布出去，需要提前安装解析器才可以运行，为了在 Windows 里方便发布，只要点击一个 EXE 文件运行，并且打包所需要库文件，这样发布给用户使用就会更方便。 PyInstallerPyInstaller 是一个十分有用的第三方库，可以用来打包 python 应用程序，打包完的程序就可以在没有安装 Python 解释器的机器上运行了。 它能够在 Windows、Linux、 Mac OS X 等操作系统下将 Python 源文件打包，通过对源文件打包， Python 程序可以在没有安装 Python 的环境中运行，也可以作为一个 独立文件方便传递和管理。 PyInstaller 支持 Python 2.7 / 3.4-3.7。可以在 Windows、Mac OS X 和 Linux 上使用，但是并不是跨平台的，而是说你要是希望打包成 .exe 文件，需要在 Windows 系统上运行 PyInstaller 进行打包工作。 下面我们以 Windows 为例来进行程序的打包工作。 安装123pip install pyinstaller# 或者python -m pip install pyinstaller 安装成功： 使用1pyinstaller -F helloworld.py 其中，-F 表示打包成单独的 .exe 文件，这时生成的 .exe 文件会比较大，而且运行速度回较慢。仅仅一个 helloworld 程序，生成的文件就 5MB 大。 另外，使用 -i 还可以指定可执行文件的图标；-w 表示去掉控制台窗口，这在 GUI 界面时非常有用。不过如果是命令行程序的话那就把这个选项删除吧！ PyInstaller 会对脚本进行解析，并做出如下动作： 1、在脚本目录生成 helloworld.spec 文件；2、创建一个 build 目录；3、写入一些日志文件和中间流程文件到 build 目录；4、创建 dist 目录；5、生成可执行文件到 dist 目录； 执行流程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445$ pyinstaller -F helloworld.py838 INFO: PyInstaller: 3.4839 INFO: Python: 3.4.3841 INFO: Platform: Windows-8-6.2.9200842 INFO: wrote d:\code\Python\pyinstaller\helloworld.spec858 INFO: UPX is not available.885 INFO: Extending PYTHONPATH with paths['d:\\code\\Python\\pyinstaller', 'd:\\code\\Python\\pyinstaller']886 INFO: checking Analysis887 INFO: Building Analysis because Analysis-00.toc is non existent888 INFO: Initializing module dependency graph...890 INFO: Initializing module graph hooks...899 INFO: Analyzing base_library.zip ...6225 INFO: Processing pre-find module path hook distutils11387 INFO: running Analysis Analysis-00.toc12012 INFO: Caching module hooks...12022 INFO: Analyzing d:\code\Python\pyinstaller\helloworld.py12027 INFO: Loading module hooks...12028 INFO: Loading module hook "hook-encodings.py"...12395 INFO: Loading module hook "hook-xml.py"...13507 INFO: Loading module hook "hook-pydoc.py"...13508 INFO: Loading module hook "hook-distutils.py"...13606 INFO: Looking for ctypes DLLs13662 INFO: Analyzing run-time hooks ...13677 INFO: Looking for dynamic libraries13894 INFO: Looking for eggs13895 INFO: Using Python library C:\WINDOWS\system32\python34.dll13895 INFO: Found binding redirects:[]13915 INFO: Warnings written to d:\code\Python\pyinstaller\build\helloworld\warn-helloworld.txt14035 INFO: Graph cross-reference written to d:\code\Python\pyinstaller\build\helloworld\xref-helloworld.html14287 INFO: checking PYZ14287 INFO: Building PYZ because PYZ-00.toc is non existent14288 INFO: Building PYZ (ZlibArchive) d:\code\Python\pyinstaller\build\helloworld\PYZ-00.pyz15836 INFO: Building PYZ (ZlibArchive) d:\code\Python\pyinstaller\build\helloworld\PYZ-00.pyz completed successfully.15883 INFO: checking PKG15884 INFO: Building PKG because PKG-00.toc is non existent15884 INFO: Building PKG (CArchive) PKG-00.pkg18528 INFO: Building PKG (CArchive) PKG-00.pkg completed successfully.18536 INFO: Bootloader D:\program\Python34\lib\site-packages\PyInstaller\bootloader\Windows-64bit\run.exe18537 INFO: checking EXE18537 INFO: Building EXE because EXE-00.toc is non existent18538 INFO: Building EXE from EXE-00.toc18538 INFO: Appending archive to EXE d:\code\Python\pyinstaller\dist\helloworld.exe18548 INFO: Building EXE from EXE-00.toc completed successfully. 生成文件： 注意事项1、直接运行最终的 .exe 程序，可能会出现一闪而过的情况，这种情况下要么是程序运行结束（比如直接打印的 helloWorld），要么程序出现错误退出了。 这种情况下，建议在命令行 cmd 下运行 .exe 文件，这时就会有文本输出到窗口； 2、-i 是改变图标的，但是我发现是有些 bug 的，客官请看： 放大过程中，图标才变成了我们设置的图标。 3、写代码的时候应当有个良好的习惯，用什么函数导什么函数，不要上来 import 整个库，最后你会发现你一个 100KB 的代码打包出来有 500MB； 4、当你的代码需要调用一些图片和资源文件的，这是不会自动导入的，需要你自己手动复制进去才行。不然 exe 文件运行时命令窗口会报错找不到这个文件。 导入方法： 假设程序中需要引入一个 test.txt 文件，首先我们运行： 1pyi-makespec -F helloworld.py 此时会生成一个 .spec 文件，这个文件会告诉 pyinstaller 如何处理你的脚本，pyinstaller 创建一个 exe 的文件就是依靠它里面的内容进行执行的。 正常情况下你不需要去修改这个 spec 文件，除非你需要打包一个 dll 或者 so 文件或者其他数据文件。 那么我们就需要修改这个 spec 文件： 1234a = Analysis(['helloworld.py'], pathex=['/home/test'], binaries=[], datas=[], ### &lt;------- 改 修改为： 1234a = Analysis(['helloworld.py'], pathex=['/home/test'], binaries=[], datas=[('test.txt','.')], ## &lt;---- 修改此处添加外部文件 然后在生成 exe 文件： 1pyinstaller helloworld.spec 然后生成的文件就可以正常引入外部文件了。 总结本文只是使用 PyInstaller 打包流程进行简单的介绍，更多内容可以参见官方文档：https://pyinstaller.readthedocs.io。 欢迎留言交流。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>打包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好物分享 | 一个在线阅读技术书籍的网站]]></title>
    <url>%2Fpython-jike-wiki.html</url>
    <content type="text"><![CDATA[之前很多人分享一些电子书籍，大部分是 pdf 版本的，但是有些人喜欢看在线的，这样就不用下载，符合现在「云化」的理念，偷笑。 今天，就给大家分享一个在线阅读技术类书籍的网站，堪称「程序员的藏经阁」。 这个网站就是极客学院的 wiki：https://wiki.jikexueyuan.com/。 P.S. 这里不是广告…纯个人推荐 该网站提供了大量的技术文档，有些是电子书的在线版本，有些是技术大佬共享的资料。 内容涉及前后端、移动开发、数据库等多个方面： 感觉就是个人资料的书签收藏夹了~ 比如，Python 方面的： 其中也有些书籍支持 pdf、epub、mobi 等格式的离线下载。 喜欢的小伙伴抓紧试下吧。]]></content>
      <categories>
        <category>好物分享</category>
      </categories>
      <tags>
        <tag>好物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Katalon Recorder 自动录制 Selenium 爬虫脚本]]></title>
    <url>%2Fpython-katalon-recorder.html</url>
    <content type="text"><![CDATA[相信很多小伙伴都用过 Selenium 来完成爬虫工作，今天就给大家带来一个神器，可以录制你的浏览器动作，然后直接生成 Selenium 脚本，是不是心动了？ 1 Selenium 简介Selenium 是为了测试而出生的。但是没想到到了爬虫的年代，它摇身一变，变成了爬虫的好工具。 让我试着用一句话来概括 Seleninm：它能控制你的浏览器，有模有样地学人类「看」网页。 那么你什么时候会要用到 Selenium 呢？当你： 1、发现用普通方法爬不到想要的内容；2、网站跟你玩「捉迷藏」，包含太多的 JavaScript 内容；3、需要像人一样浏览的爬虫； 好了，Selenium 的其他这里不再赘述，本公众号已与 Google 达成战略协议，Google 可以免费提供 Selenium 的其他信息！ 2 Katalon RecorderKatalon Recorder 能够记录你使用浏览器的操作。 相信很多小伙伴都知道一个叫「按键精灵」的东西，它帮我做了很多重复性的工作，这个 Katalon Recorder 插件 + Selenium 就和按键精灵是一个意思，记录你的操作，然后你可以让电脑重复上千遍。 2.1 安装谷歌应用商店和火狐插件均可下载安装。 安装完成后，右上角会出现插件图标： 2.2 使用点击图标，会出现单独的 Katalon Recorder 窗口： 其中：① 工具栏② 用例管理器③ 用例详情④ Log/Reference/Variable 点击窗口上的 Record，下面就会开始录制浏览器操作了。 这里我们打开拉勾网首页，并搜索「Python」，然后点击下一页。 进入网站时的这个动作也可以录制： 每当点击的时候，插件就会记录下你这些点击。 录制完成后，点击「Play」还可以进行动作回放，会重新自动执行刚刚录制的动作。 最后神奇的事情将要发生你可以点击 Export 按钮： 可以根据录制的事件生成代码，这里不单单可以生成 Python 代码，Java、C#、Ruby 等，都不在话下。 这里的脚本应该是自动化测试使用的，我们爬虫时只要截取其中的 selenium、driver 部分的即可。 12345678driver.get("https://www.lagou.com/")driver.find_element_by_link_text(u"全国站").click()driver.find_element_by_id("search_input").click()driver.find_element_by_id("search_input").click()driver.find_element_by_id("search_input").clear()driver.find_element_by_id("search_input").send_keys("python")driver.find_element_by_id("search_button").click()driver.find_element_by_xpath(u"(.//*[normalize-space(text()) and normalize-space(.)='下一页'])[1]/following::span[5]").click() 3 总结使用 Katalon Recorder 可以完成以下脚本的自动生成，但有时会不太好使，比如上面的下一页的点击，我运行代码时就不管用，还需要后续进行微调。 Katalon Recorder 还有很多其他方面的功能，其实人家是用来录制自动化测试脚本的，有兴趣的同学快试试吧~]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你使用频率最高的 Linux 命令是什么？]]></title>
    <url>%2Flinux-top10-command.html</url>
    <content type="text"><![CDATA[你使用的命令可以反映出你的工作内容，你的工作习惯等信息。 使用下面的命令可以统计出你最近使用频率最高的 10 条命令： 1history | awk '&#123;CMD[$2]++;count++;&#125; END &#123; for (a in CMD )print CMD[ a ]" " CMD[ a ]/count*100 "% " a &#125;' | grep -v "./" | column -c3 -s " " -t |sort -nr | nl | head -n10 命令的细节并不是非常重要，它就是将 history 命令的输出进行总计，并告诉你十大命令是什么以及每个命令的使用频率。你也可以对代码段进行一些修改以获得更长的列表，或稍微更改格式。 下面是我在我的一个常用服务器上的使用命令情况： 12345678910 1 215 21.5% sudo 2 157 15.7% python 3 152 15.2% cd 4 149 14.9% ll 5 88 8.8% git 6 35 3.5% vim 7 25 2.5% pip 8 22 2.2% celery 9 20 2% exit10 19 1.9% ansible 这些数字并不是非常大，我在这个环境下使用的是普通用户，所以 sudo 成了第一名。 我又在其他几个虚拟机上运行了相同的命令，得到了截然不同的结果，这是因为几个机器的用途不同造成的。 在虚拟机中，systemctl 和 docker 都出现在列表，当我需要花费大量时间编辑配置文件时，vim 爬到了榜首。 常用命令多少能够反映出你的一些特征。比如你是开发人员吗？高级用户？你在远程系统上工作很多吗？你最喜欢的文本编辑器是什么？ 如果你愿意，请在下面的留言区中分享出你的命令 TOP10。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 张脑图带你了解微服务]]></title>
    <url>%2Fknow-microservice-with-9-photos.html</url>
    <content type="text"><![CDATA[本文脑图分享自微博技术专家：胡忠想，是在《从 0 开始学微服务》专栏的微信群里分享的，经过允许，现在分享给大家。 微服务基础原理 服务发布与引用 微服务注册与发现 服务框架 服务监控 服务追踪 服务治理 微服务、容器化与 DevOps 下一代微服务架构 以上内容均分享自极客时间专栏《从 0 开始学微服务》，想深入学习的同学可以扫描下方二维码加入，和我一起学习微服务吧~ ![专栏][11]]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 爬虫闯关（第五关）]]></title>
    <url>%2Fpython-crawler_ex04.html</url>
    <content type="text"><![CDATA[这次我们来到了第五关，也是最后一关了，之后黑板客上就没再更新关卡。 且闯且珍惜吧~ 相较于之前的关卡，本关多了验证码识别的功能，也就是需要对图片验证码进行自动识别。 第五关地址：http://www.heibanke.com/lesson/crawler_ex04/，页面如下： 思路其实基本和第三关类似，主要是多了验证码的处理。 可以看出，验证码都是英文大写，并且位置不正，歪扭七八的，这给验证码识别带来了难度。 解题思路先来看一眼请求数据： username csrfmiddlewaretoken password captcha_0 captcha_1 根据之前的闯关经验，1、2 两项我们都知道。password 我们也只能按照第 2、3 关密码 0~30 尝试。captcha_0 是登录页面上一个隐藏的值，对应的应该是验证码在服务器的 uuid。captcha_1 即验证码。 目前验证码处理仍然是一个比较困难的问题，处理方法一般可以分为自动识别和手动识别。 手动处理：就是通过验证码链接将验证码图片下载到本地，然后手动敲入完成信息录入。 自动识别：指使用一些高级的算法技术来完成的，如 OCR 文字识别，机器学习进行识别训练等。一般免费的文字识别算法识别率并不高，收费的识别效率还是可以接受的。 我们先体验一把自动处理，知道处理效果后，再考虑是不是用手动处理。 自动识别验证码处理流程如下： 这里我们打算使用 Tesseract 进行自动图片识别的尝试。 tesseract-ocr 是一个做图形识别必须用到第一个软件，不仅可以处理验证码，也可以识别图片上的文字等等。其他的这里不再赘述，请自行 Google。 安装可以参考官方文档：https://github.com/tesseract-ocr/tesseract/wiki 试用下准备好待识别的图片 1234# tesseract test.png result -l engTesseract Open Source OCR Engine v3.04.01 with Leptonica# cat result.txtUZUM 可以看出，识别成功，难道识别率这么好吗？ 安装其他依赖组件123pip install PILpip install Pillowpip install pytesseract Pytesseract 是一个 python 的第三方的包，主要作用就是用来连接操作 tesseract-ocr 工具。为我们用 python 来处理图形打好了基础。 Pillow 包是 python 的图形处理库，用来处理调整图形的各种内容。 实现准备工作差不多了，下面就动手写代码吧！ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def getImage(): # 获取登录页面 response = requests.get(url, cookies=cookies) soup = bs4.BeautifulSoup(response.text, "html.parser") # 解析获取图片地址 image_url = 'http://www.heibanke.com' + soup.select('img[class="captcha"]')[0]['src'] # 获取图片 image_response = requests.get(image_url) if image_response.status_code != 200: print('get image fail: ' + image_url) image = image_response.content # 保存图片 with open('./crawler_ex04.png', 'wb') as f: f.write(image) return Image.open('./crawler_ex04.png')if __name__ == '__main__': url = 'http://www.heibanke.com/lesson/crawler_ex04/' login_url = 'http://www.heibanke.com/accounts/login' login_data = &#123;'username':'liuhaha', 'password':'123456'&#125; cookies = login() playload = &#123;'username':'liuhaha', 'password':'1'&#125; playload['csrfmiddlewaretoken'] = cookies['csrftoken'] for i in range(31): # 识别验证码 optCode = pytesseract.image_to_string(getImage(), lang="eng", config="-psm 7") # 验证码的准确率是个问题啊 print(u'验证码为：' + optCode) playload['captcha_1'] = optCode playload['password'] = i # print(u'传入参数为：' + str(playload)) r = requests.post(url, data=playload, cookies=cookies) soup = bs4.BeautifulSoup(r.text, "html.parser") # print(u'执行结果：' + str(r.status_code)) if r.status_code == 200: if u"成功" in r.text: print(u'闯关成功！密码为：' + str(i)) break else: print(u'请继续') else: print(u'Failed') break 这里我对一些乱码进行了过滤，不过识别结果还是惨不忍睹啊！获取了 447 次，最后终于成功。 数据训练识别率很差，但是 tesseract 是可以自行训练的，这样也许能够提升识别率。 训练过程很漫长，这里就不再展开，有兴趣的可以参考 https://www.cnblogs.com/zhongtang/p/5555950.html 中的方法进行训练。 这里只说下训练结果。 刚开始使用 100 张图片进行训练，但是结果还是不能令人满意，识别的正确率大概只有 10% 左右。 于是我又拉了 500 张图片，并用上次训练的结果再进行训练，这次后很少出现特殊字符了，说明还是有一点效果的，我只能这么安慰自己。 但是正确率还是很低！ 也许还可以用 TensorFlow 来试一把，我现在实在没力气折腾了，有兴趣的搞一下看看？ 另外，百度、腾讯等也有免费的图像识别服务，后面有兴趣我会进行测试，与大家分享。 手动识别手动识别其实就是通过验证码链接将验证码图片下载到本地，然后手动敲入完成信息录入。 12345678910111213141516171819def getImage(): # 获取登录页面 response = requests.get(url, cookies=cookies) soup = bs4.BeautifulSoup(response.text, "html.parser") # 解析获取图片地址 image_url = 'http://www.heibanke.com' + soup.select('img[class="captcha"]')[0]['src'] # print(soup.select('img[class="captcha"]')[0]['src'].split('/')[-2]) # 获取图片 image_response = requests.get(image_url) # if image_response.status_code != 200: # print('get image: ' + image_url) image = image_response.content # 保存图片 with open('./crawler_ex04.png', 'wb') as f: f.write(image) code_typein = input('请根据下载图片 crawler_ex04.png 输入验证码：') return soup.select('img[class="captcha"]')[0]['src'].split('/')[-2], code_typein 需要每次运行时手动输入验证码，运行结果如下： 还好运行到 3 就成功了。 总结本关的难点就是验证码的处理，用自动识别方法，识别率不高，当然这里我只用了一种方法，有做这方面工作的同学可以尝试用 TensorFlow 来试一把，记得来分享~ 后续，我会测试下 百度、腾讯、阿里的图像识别接口，看下它们的识别情况是否能够让人满意，到时再给大家分享。 到这里，爬虫闯关系列就结束了，一共 5 关。通过这 5 关，我们大致了解了爬虫的一般流程，其中涉及了 cookie 处理、验证码处理、多线程爬虫等知识点，当然不能完全覆盖爬虫所有的知识点，但是我觉得足以应对一般网站的爬取了。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫闯关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员是如何从复杂的代码里找到 bug 的？]]></title>
    <url>%2Fhow-programmer-find-bug.html</url>
    <content type="text"><![CDATA[我曾经做了两年大型软件的维护工作，那个项目有 10 多年了，大约 3000 万行以上的代码，参与过开发的有数千人，代码 checkout 出来有大约 5 个 GB，而且 bug 特别多，open 的有上千，即使最高优先级的 showstopper 也有上百。分享下我的 debug 的经验。 1. 优先解决那些可重现的可重现的 bug 特别好找，反复调试测试就好了，先把好解决的干掉，这样最节约时间。 2. 问下老员工对于某些 bug 没有头绪或者现象古怪不知道从哪里下手，找有经验的同事问一下思路，因为在那种开发多年的大型系统里，经常会反复出现同样原因的 bug，原因都类似，改了一处，过一阵子另外一处又冒出来，而且无法根治。 比如：我那个系统里有个特别危险的 API，接口参数比较难用，一旦有人用错了某些情况下就会出诡异的现象，解决很简单，找到调用这个 API 的地方把调用方式写对就好了。为什么不根治呢？因为要保持兼容性不能改接口了。Windows 系统里就好多这种烂 API。问下老员工吧，说不定他们都遇到过好多次了。 3. 放大现象有些 bug 现象不太明显，那么就想办法增大它的破坏性，把现象放大。这只是个思路，具体怎么放大只能根据具体的代码来定。比如：美剧《豪斯医生》里有一集，怀疑病人心肺有问题，就让病人去跑步机上跑步，加重心肺负担，从而放大症状。 4. 二分法定位把程序逻辑一点点注释掉，看看还会不会出问题，类似二分查找的方法，逐步缩小问题范围。 5. 模拟现场有时候我会问自己，如果我要实现 bug 描述的现象我要怎么写代码才行？比如：我遇到一个死锁问题，但是检查代码发现所有的锁都是配对的，没有忘记解锁的地方，而且锁很简单就是一个普通的临界段，保护几行赋值语句而已。这样的代码怎么写才能让他死锁呢？我想如果让我故意制造这样一个现象，只有在上锁的时候强制杀掉线程了。既然这样就可以去看看有谁强杀线程了没有。 6. 制作工具针对某些 bug 编写一些调试辅助工具。比如，我那个系统没有完善的崩溃报告，虽然也有 dump，但是分析出来的 callstack 经常不准。于是我为解决崩溃问题编写了个工具，会自动扫描代码，在每个函数入口和出口插入 log，以此来定位崩溃点。 7. 掩盖问题虽然这样做有点不厚道，但是有时不得不这么做。有些 bug 找不到真正的 root cause，但是又要在规定时间内解决，那么我们就可以治疗症状而不去找病因。比如用 try catch 掩盖一些奇怪的崩溃。不到万不得已不要这么干，未来可能会付出更大代价。 后记：对于大部分转行的人来说，找机会把自己的基础知识补齐，边工作边补基础知识，真心很重要。 via：https://www.zhihu.com/question/23019630/answer/23369396]]></content>
      <categories>
        <category>闲扯系列</category>
      </categories>
      <tags>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible 实现批量建立互信]]></title>
    <url>%2Fansible-ssh-copy.html</url>
    <content type="text"><![CDATA[什么是 ssh 互信？说白了，就是在目标机器上，预先设置好经过认证的 key 文件，当需要访问目标机器时，目标机器通过 key 文件，对访问者进行自动认证，从而实现互信。 当管理大量机器时，使用 ssh-copy-id 方法一个个建立互信有些费时，那么使用 ansible 是否可以批量建立互信呢？ 生成密钥对1ssh-keygen -t rsa 一路回车即可。 建立互信格式： ssh-copy-id -i ~/.ssh/id_rsa.pub username@[ip,hostname] 1ssh-copy-id -i ~/.ssh/id_rsa.pub username@192.168.1.2 根据提示完成操作即完成了互信。 批量建立互信机器多的情况下，使用 ssh-copy-id 方法有些费时，使用 ansible-playbook 推送 ymal，这里使用到了 authoried_keys 模块，可以参考官方文档：http://docs.ansible.com/authorized_key_module.html 建立如下 playbook： 1234567--- - hosts: test # 互信用户 user: hoxis tasks: - name: ssh-copy authorized_key: user=hoxis key="&#123;&#123; lookup('file', '/home/hoxis/.ssh/id_rsa.pub') &#125;&#125;" 默认，已在 Ansible 资产文件中配置待互信机器信息。 执行： 123456789101112# ansible-playbook pushssh.yamlPLAY [test] *****************TASK [Gathering Facts] ******ok: [client]TASK [ssh-copy] *************changed: [client]PLAY RECAP ******************client : ok=2 changed=1 unreachable=0 failed=0 执行完毕，若没有报错，则证明互信建立成功。 测试：执行 ssh 登录，若无需再输入密码，则证明互信建立成功！]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 行代码，实现微信消息发送]]></title>
    <url>%2Fpython-serverchan.html</url>
    <content type="text"><![CDATA[还是接食行生鲜签到的问题，之前我们讲到，将签到结果通过短信发送到手机，但是我发现 twilio 有些不稳定，为了防止漏签，我在服务器上设置了两次定时任务，通常情况下第一个收不到短信，第二个才会收到。 看到最近好多大神写操作微信的文章，于是，我又想，是不是可以将消息发送到微信上？ 微信发送消息有如下几个思路： itchat 模块 使用个人公众号 使用其他公众号封装好的发送消息的功能； itchat大部分人操作个人微信都是使用这个模块。 itchat 是一个开源的微信个人接口，它可以模拟网页端的微信登陆，从而用 Python 脚本或命令行模式来使用个人微信号，达到推送各种通知到微信上的目的。 项目主页：https://github.com/littlecodersh/ItChat 其实是基于网页版微信，通过 HTTP 交互来实现微信的一些操作，被封的风险其实在于，当检测到账号异常时，账号的网页版登录权限会被腾讯禁掉，这种情况下 itchat 就不好使了。另外，据说新申请的账号直接没有网页版登录权限了。 itchat 的使用已经有其他很多大神讲了，网上也有很多教程，这里我们不再赘述，有兴趣的自行 Google，也可以后台找我，一起来研究下~ 个人公众号接口微信提供了丰富的公众号接口，可以实现消息收发、关注用户信息获取等等。 BUT！大部分接口（包括发送消息接口）只开放给认证用户，而个人号又无法认证，所以这条路断了！ 据说以前个人是可以认证的，反正权限的口子越来越小了。 别人家的公众号正所谓「它山之石，可以攻玉」，此处不留爷，爷就去他处！今天的主角登场！ 还好我们找到了提供收发消息功能的公众号 API，我们只要集成他们的接口即可。 它就是「Server酱」！ Server 酱Server 酱，英文名字 ServerChan，地址：http://sc.ftqq.com 使用方法： 登入：用 GitHub 账号登入网站，就能获得一个 SCKEY（在「发送消息」页面）； 绑定：点击「微信推送」，扫码关注同时即可完成绑定； 发消息：往 http://sc.ftqq.com/SCKEY.send 发 GET 请求，就可以在微信里收到消息啦； 来个示意图： 代码示例： 12&gt;&gt;&gt; import requests&gt;&gt;&gt; requests.get("https://sc.ftqq.com/your-SCKEY.send?text=&#123;&#125;&amp;desp=&#123;&#125;".format('测试标题','哈哈')) 微信端效果： 是不是很简单！1 行代码就搞定了微信消息推送，再也不用其他任何复杂的步骤！ 另外，显示发现发件人是Server酱，另外点进去有推广，毕竟是免费的接口，还要啥自行车！ 还有就是发送消息是有一些限制的： 每人每天发送上限 500 条，相同内容 5 分钟内不能重复发送，不同内容一分钟只能发送 30 条。主要是防止程序出错的情况。 对于我这种需求肯定够了。 PushBearServerChan 只能推送到一个微信上，若果想一对多发送信息，并且向自定义发件人，那么可以使用 PushBear。 PushBear 地址：https://pushbear.ftqq.com 无需注册，直接扫码登入； 创建消息通道，获得订阅二维码； 通过 API 向关注了该二维码的用户推送消息； PushBear 可以自定义发件人信息，通过微信登录后，创建一个通道，会生成一个 sendkey 和一个订阅二维码， 可以通过「订阅消息API」发送微信给所有扫描过此二维码的人。 代码示例： 12import requestsrequests.get("https://pushbear.ftqq.com/sub?sendkey=your-sendkey&amp;text=&#123;&#125;&amp;desp=&#123;&#125;".format('pushbear', '哈哈')) 微信端效果： 发现发件人是我们自己设置的「不正经程序员」了！ 使用限制： 推送消息存储 72 小时、5 分钟内不可发布重复消息、普通用户每天 1000 条上限、请勿用于发送广告和有害信息。 综上，若要完成签到成功后的通知，我们只要使用 ServerChan 或者 PushBear 的接口封装成发送消息的函数即可！ 食行生鲜签到系列也可以到此结束了，回复【食行生鲜】可以获取最终代码。 总结也许还有其他微信的使用方法，但是 ServerChan 是我找到的最简单的一个了，1 行代码搞定，简单高效，很 pythonic！ 当然，作为个人发送一些通知 ServerChan 是绰绰有余的，但是，若是企业级的应用还是用自己的微信订阅号来开发接口吧~]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo next 配置 DaoVoice 实现在线聊天功能]]></title>
    <url>%2Fhexo-next-daovoice.html</url>
    <content type="text"><![CDATA[DaoVoice 可以提供在线联系的功能，我们可以借助于此在自己的站点上接入了此功能。 我们先看下设置后的效果： 看着还不错吧，可以在线留言，作者会收到邮件，如果绑定了微信，作者还会收到微信通知。 下面就开始设置吧。 注册首先需要注册一个 DaoVoice，点击注册。 注册成功后，进入后台控制台，进入到 应用设置--&gt;安装到网站 页面，可以得到一个 app_id： 设置下面就进行主题中的一些设置。 以 next 主题为例，打开 themes/next/layout/_partials/head.swig 文件中添加如下代码，位置随意： 123456789&#123;% if theme.daovoice %&#125; &lt;script&gt; (function(i,s,o,g,r,a,m)&#123;i["DaoVoiceObject"]=r;i[r]=i[r]||function()&#123;(i[r].q=i[r].q||[]).push(arguments)&#125;,i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)&#125;)(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice") daovoice('init', &#123; app_id: "&#123;&#123;theme.daovoice_app_id&#125;&#125;" &#125;); daovoice('update'); &lt;/script&gt;&#123;% endif %&#125; 在主题配置文件 _config.yml，添加如下代码： 123# Online contact daovoice: truedaovoice_app_id: 这里输入前面获取的app_id next 主题下聊天的按钮会和其他按钮重叠到一起，可以到聊天设置，修改下按钮的位置: 位置可以在 hexo s 调试模式下进行调试，效果满意后部署就可以看到最终效果啦！ 最后到右上角选择管理员，微信绑定,可以绑定你的微信号，关注公众号后打开小程序，就可以实时收发消息，有新的消息也会通过微信通知，设置页面如下：]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo next 新增阅读排行页面]]></title>
    <url>%2Fhexo-next-read-rank.html</url>
    <content type="text"><![CDATA[新增一个阅读排行页面，可以现在本站文章的阅读排行榜，基于 leancloud 的数据实现。 新建页面hexo n page top 新建页面，会生成 top 目录，编辑其中自动生成的 index.md 文件，将其中的代码替换如下： 12345678910111213141516171819202122232425&lt;div id="top"&gt;&lt;/div&gt;&lt;script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"&gt;&lt;/script&gt;&lt;script&gt;AV.initialize("leancloud_appid", "leancloud_appkey");&lt;/script&gt;&lt;script type="text/javascript"&gt; var time=0 var title="" var url="" var query = new AV.Query('Counter'); query.notEqualTo('id',0); query.descending('time'); query.limit(1000); query.find().then(function (todo) &#123; for (var i=0;i&lt;1000;i++)&#123; var result=todo[i].attributes; time=result.time; title=result.title; url=result.url; // var content="&lt;a href='"+"https://hoxis.github.io"+url+"'&gt;"+title+"&lt;/a&gt;"+"&lt;br&gt;"+"&lt;font color='#fff'&gt;"+"阅读次数："+time+"&lt;/font&gt;"+"&lt;br&gt;&lt;br&gt;"; var content="&lt;p&gt;"+"&lt;font color='#1C1C1C'&gt;"+"【文章热度:"+time+"℃】"+"&lt;/font&gt;"+"&lt;a href='"+"https://hoxis.github.io"+url+"'&gt;"+title+"&lt;/a&gt;"+"&lt;/p&gt;"; document.getElementById("top").innerHTML+=content &#125; &#125;, function (error) &#123; console.log("error"); &#125;);&lt;/script&gt; 并将其中的 leancloud_appid、leancloud_appkey 和页面链接替换为你的。 配置菜单显示编辑主题配置文件 themes\next\_config.yml，添加 top： 123menu: home: / || home top: /top/ || signal 新增菜单栏的显示名称 hexo/theme/next/languages/zh-Hans.yml，同样新增 top 对应的中文： 123456789101112menu: home: 首页 archives: 归档 categories: 分类 tags: 标签 about: 关于 search: 搜索 schedule: 日程表 sitemap: 站点地图 commonweal: 公益404 resources: 资源 top: 阅读排行 最后，hexo d -g 部署后可以显示。]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo next 主题修改底部版权信息]]></title>
    <url>%2Fhexo-next-copyright.html</url>
    <content type="text"><![CDATA[感觉底部版权信息不够丰富，打算新增一些内容。 设置前的效果： 修改文件：themes/next/layout/_macro/post-copyright.swig 修改前： 1234567891011121314&lt;ul class="post-copyright"&gt; &lt;li class="post-copyright-author"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.author') + __('symbol.colon') &#125;&#125;&lt;/strong&gt; &#123;&#123; post.author | default(config.author) &#125;&#125; &lt;/li&gt; &lt;li class="post-copyright-link"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.link') + __('symbol.colon') &#125;&#125;&lt;/strong&gt; &lt;a href="&#123;&#123; post.url | default(post.permalink) &#125;&#125;" title="&#123;&#123; post.title &#125;&#125;"&gt;&#123;&#123; post.url | default(post.permalink) &#125;&#125;&lt;/a&gt; &lt;/li&gt; &lt;li class="post-copyright-license"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.license_title') + __('symbol.colon') &#125;&#125; &lt;/strong&gt; &#123;&#123; __('post.copyright.license_content', theme.post_copyright.license_url, theme.post_copyright.license) &#125;&#125; &lt;/li&gt;&lt;/ul&gt; 修改后： 1234567891011121314151617&lt;ul class="post-copyright"&gt; &lt;li class="post-copyright-author"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.author') + __('symbol.colon') &#125;&#125;&lt;/strong&gt; &#123;&#123; post.author | default(config.author) &#125;&#125; | 微信公众号【不正经程序员】 &lt;/li&gt; &lt;li class="post-copyright-link"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.link') + __('symbol.colon') &#125;&#125;&lt;/strong&gt; &lt;a href="&#123;&#123; post.url | default(post.permalink) &#125;&#125;" title="&#123;&#123; post.title &#125;&#125;"&gt;&#123;&#123; post.url | default(post.permalink) &#125;&#125;&lt;/a&gt; &lt;/li&gt; &lt;li class="post-copyright-license"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.license_title') + __('symbol.colon') &#125;&#125; &lt;/strong&gt; &#123;&#123; __('post.copyright.license_content', theme.post_copyright.license_url, theme.post_copyright.license) &#125;&#125; &lt;/li&gt; &lt;li class="post-copyright-license"&gt; 并保留本声明和上方二维码。感谢您的阅读和支持！ &lt;/li&gt;&lt;/ul&gt; 主要是新增了一些文字描述。 设置后的效果： 大公高成！]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo next 主题修改底部微信二维码显示尺寸]]></title>
    <url>%2Fhexo-next-wechat-code.html</url>
    <content type="text"><![CDATA[打算把底部微信二维码换成长方形带简介的那种，无奈原来是正方形的，展示出来就是很小的一个，本文记录适配方法。 设置前的效果： 显示效果很差，一点点一个图片在那！ 修改文件：themes/next/layout/_macro/wechat-subscriber.swig 修改前： 1234&lt;div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center"&gt; &lt;img id="wechat_subscriber_qcode" src="&#123;&#123; theme.wechat_subscriber.qcode &#125;&#125;" alt="&#123;&#123; theme.author &#125;&#125; wechat" style="width: 200px; max-width: 100%;"/&gt; &lt;div&gt;&#123;&#123; theme.wechat_subscriber.description &#125;&#125;&lt;/div&gt;&lt;/div&gt; 修改后： 1234&lt;div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center"&gt; &lt;img id="wechat_subscriber_qcode" src="&#123;&#123; theme.wechat_subscriber.qcode &#125;&#125;" alt="&#123;&#123; theme.author &#125;&#125; wechat" style="width: auto; height:250px; max-width: 100%;"/&gt; &lt;div&gt;&#123;&#123; theme.wechat_subscriber.description &#125;&#125;&lt;/div&gt;&lt;/div&gt; 主要是修改了第二行，图片的 style 属性，设置了高度为 200，并将宽度设置为了自动。 设置后的效果：]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅地使用 rm 防止误删除？]]></title>
    <url>%2Flinux-rm-2-mv.html</url>
    <content type="text"><![CDATA[IT 界的有一个老梗，一次某论坛的数据库管理员抱怨自己老板一直虐待他，结果他一气之下就删库跑路了…… 于是… 据新华社北京 8 月 20 日电 ，北京一软件工程师徐某离职后因公司未能如期结清工资，便利用其在所设计的网站中安插的后门文件将网站源代码全部删除。记者 20 日从北京市丰台区人民法院获悉，徐某破坏计算机信息系统罪成立，获刑五年。 我在服务器维护的时候不小心执行了 rm -rf 命令……现在整台服务器被我删光了肿么办？？？ 好吧，现在先来介绍一下 rm。 rm -rf 的威力rm 是 linux 系统下删除文件的命令，-r 代表删除这个下面的一切，一切的一切那种的一切。f 表示不需要用户确认，直接执行。 通常这个命令都是指定文件夹用的，比如 1rm -rf /home/test/ 就是删除 /home/test/ 这个文件夹下面的所有东西。 但是如果后面的文件夹路径没有加对， rm -rf / 在服务器上也就意味着… 俗话说的好：常在河边走， 哪能不湿鞋。 那该怎么避免这种悲剧的发生呢？ 如何避免再次跑路？一个方案就是重定向 rm 命令以嫁接为 mv 命令， 相当于给 Linux 系统定制了一个回收站。 实现方式如下： 1234567891011121314151617181920212223242526272829303132333435363738394041### 重定义rm命令 #### 定义回收站目录trash_path='~/.trash'# 判断 $trash_path 定义的文件是否存在，如果不存在，那么就创建 $trash_path.if [ ! -d $trash_path ]; then mkdir -p $trash_pathfi# 定义别名：使用 rm 就调用 trashalias rm=trash# 使用 rl 就调用 'ls ~/.trash' # 如果更改上面的回收站目录这里的目录也需要修改alias rl='ls ~/.trash'# 使用 unrm 就调用 restorefile，需要在删除目录的父目录下执行alias unrm=restorefile# 使用 rmtrash 就调用 claearteashalias rmtrash=cleartrash# 恢复文件的函数restorefile()&#123; mv -i ~/.trash/$@ ./&#125; # 删除文件的函数trash()&#123; mv $@ ~/.trash/&#125; # 清空回收站的函数cleartrash()&#123; read -p "确定要清空回收站吗?[y/n]" confirm [ $confirm == 'y' ] || [ $confirm == 'Y' ] &amp;&amp; /bin/rm -rf ~/.trash/*&#125; 最后将上述脚本写入 /etc/bashrc，并立即执行命令 source /etc/bashrc 即刻生效。 使用这个脚本定义了几个命令： rl：查看回收站下的文件 unrm 文件名或目录：恢复到当前的路径下 rmtrash：清空回收站，不过会友好提示。 执行 rm 不会真正删除，而是使用 mv 移动到我们指定的回收站。 实在真的想删除可以 /bin/rm 来进行删除。 另外，需要注意的时，之前 rm 指令的一些参数可能不再使用，因为 rm 现在其实是 mv 了。 123456789101112131415161718192021222324252627# touch hoxistest# touch 1# mkdir haha# ls1 haha hoxistest# rm 1# lshaha hoxistest# 查看回收站文件# rl1 myftp1# 恢复已删除文件# unrm 1[root@CESHI-CLM-10-254-4-48 test]# ls1 haha hoxistest# rm haha/# rm hoxistest# rlhaha hoxistest# 情况回收站# rmtrash确定要清空回收站吗?[y/n]y# rl 效果看着应该还可以吧。 例行总结看着是还可以，但是也有一些问题，比如删除文件不能重名，若重名了会提示你是否进行覆盖。那就需要再进行特殊处理了，比如删除时加个时间戳什么的，有兴趣的动手实现下吧。 via：https://www.cloudbility.com/club/6981.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible 进阶 | 动态 Inventory]]></title>
    <url>%2Fansible-dynamic-inventory.html</url>
    <content type="text"><![CDATA[在之前的文章中，我们提到 Ansible 是通过 inventory 文件来管理资产的，但是一般情况下，一个配置管理系统往往会将资产存储在一个软件系统里，这种情况下该如何处理呢？ 其实，Ansible Inventory 是包含静态 Inventory 和动态 Inventory 两部分的，静态 Inventory 指的是在文件中指定的主机和组，动态 Inventory 指通过外部脚本获取主机列表，并按照 ansible 所要求的格式返回给 ansilbe 命令的。这部分一般会结合 CMDB 资管系统、云计算平台等获取主机信息。由于主机资源一般会动态的进行增减，而这些系统一般会智能更新。我们可以通过这些工具提供的 API 或者接入库查询等方式返回主机列表。 比如为了结合资产管理系统（CMDB），所以要使用到动态获取 inventory 的方法，这样可以省去配置 ansible 服务端的 hosts，所有的客户端 IP、帐号、密码、端口都可以从 CMDB 中获取到。 只要你的脚本输出格式是满足要求的 JSON，这样就可以成为一个动态的资产生成器。 脚本规约用于生成 JSON 的脚本对实现语言没有要求，它可以是一个可执行脚本、二进制文件，或者其他任何可以运行文件，但是必须输出为 JSON 格式，同时必须支持两个参数：--list 和 --host &lt;hostname&gt;。 --list：用于返回所有的主机组信息，每个组所包含的主机列表 hosts、所含子组列表 children、主机组变量列表 vars 都应该是字典形式的，_meta 用来存放主机变量。 示例如下： 123456789101112131415161718192021222324&#123; "group1": &#123; "hosts": [ "192.168.28.71", "192.168.28.72" ], "vars": &#123; "ansible_ssh_user": "johndoe", "ansible_ssh_private_key_file": "~/.ssh/mykey", "example_variable": "value" &#125;, "children":['group2'] &#125;, "_meta": &#123; "hostvars": &#123; "192.168.28.71": &#123; "host_specific_var": "bar" &#125;, "192.168.28.72": &#123; "host_specific_var": "foo" &#125; &#125; &#125;&#125; --host &lt;hostname&gt;：返回指定主机的变量列表，或者返回一个空的字典 如： 123&#123; "host_specific_var": "foo"&#125; 脚本实现一个参考实现框架如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/usr/bin/env python3#coding:utf8import jsonimport sys def all(): info_dict = &#123; "all":[ "10.10.0.109", "10.10.0.112"] &#125; print(json.dumps(info_dict,indent=4)) def group(): host1 = ['10.10.0.112'] host2 = ['10.10.0.112','10.10.0.109'] group1 = 'test1' group2 = 'test2' hostdata = &#123; group1:&#123;"hosts":host1&#125;, group2:&#123;"hosts":host2&#125; &#125; print(json.dumps(hostdata,indent=4)) def host(ip): info_dict = &#123; "10.10.0.112": &#123; "ansible_ssh_host":"10.10.0.112", "ansible_ssh_port":22, "ansible_ssh_user":"root", "ansible_ssh_pass":"123457" &#125;, "10.10.0.109": &#123; "ansible_ssh_host":"10.10.0.109", "ansible_ssh_port":22, "ansible_ssh_user":"root", "ansible_ssh_pass":"xxxx" &#125; &#125; print(json.dumps(info_dict,indent=4)) if len(sys.argv) == 2 and (sys.argv[1] == '--list'): group()elif len(sys.argv) == 3 and (sys.argv[1] == '--host'): host(sys.argv[2])else: print("Usage: %s --list or --host &lt;hostname&gt;" % sys.argv[0]) sys.exit(1) 使用使用方法和静态 inventory 类似： 1234567891011# 可以指定组$ ansible -i dynamic_investory.py all --list-hosts hosts (3): 127.0.0.1 10.10.0.112 10.10.0.109# 可以指定主机$ ansible -i dynamic_investory.py 127.0.0.1 --list-hosts hosts (1): 127.0.0.1 参考： https://www.jeffgeerling.com/blog/creating-custom-dynamic-inventories-ansible https://adamj.eu/tech/2016/12/04/writing-a-custom-ansible-dynamic-inventory-script/ https://pynet.twb-tech.com/blog/ansible/dynamic-inventory.html http://www.ywnds.com/?p=11701 http://www.linuxyw.com/749.html]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Python 发送短信？]]></title>
    <url>%2Fpython-twilio.html</url>
    <content type="text"><![CDATA[上回我们说到怎么把签到结果发出来，于是就找到了 Twilio。 Twilio 是一个位于加利福尼亚的云通信（PaaS）公司，致力于为开发者提供通讯模块的 API。由于 Twilio 为试用帐户提供了免费电话短信服务，我们可以在申请需要短信验证的国外免费资源时，使用 Twilio 在线实时收取验证短信。下面，本站就详细介绍一下 Twilio 的申请及短信发送过程。 注册及设置访问 http://twilio.com/ 并填写注册表单。注册了新账户后，你需要验证一个手机号码，短信将发给该号码。还需要做一个人机验证，证明你是一个人！ 注册成功后，需要新建一个 Project，进入 Project 界面后可以看到有 SID 和 TOKEN 信息，后面代码中会用到： 你需要激活一个电话号码，就是让 Twilio 分配一个，分配成功后，就可以用它来发短信了。在 Project 页面 Phone Numbers 下操作即可： 想要使用 Twilio 号码发送短信，需要先验证收信方的手机号码。在 Phone Numbers 选项卡中选择 Verified Caller IDs，进入号码验证页面，选择使用短信验证。 输入手机验证码，确认后即完成了接收方的手机验证。 下面，我们就可以使用代码来发送短信了。 使用首先，要安装，很简单： 1pip install twilio 其实 Twilio 官方文档提供了各种代码发送短信的方式，如 Python： 12345678910111213141516# Download the helper library from https://www.twilio.com/docs/python/installfrom twilio.rest import Client# Your Account Sid and Auth Token from twilio.com/consoleaccount_sid = 'AC4e30ba292bcf6fc97ca656aa71b34bc6'auth_token = 'your_auth_token'client = Client(account_sid, auth_token)message = client.messages.create( from_='+15017122661', body='body', to='+15558675310' )print(message.sid) 这里，需要 Twilio 提供的试用账户包括一个电话号码，它将作为短信的发送者。还需要两个信息：你的账户 SID 和 TOKEN，Python 中，这些值将作为你的 Twilio 用户名和密码。 另外，to 的手机号需要是已经验证过的！ 发送效果： 由于是试用账号，所以带有一些 Twilio 试用字样。也许在哪里设置可以去掉，有兴趣的可以研究下。 上次食行签到领积分里我们说过是不是有办法提醒签到成功，这里就可以操作了，定义一个发送短信的函数，将签到信息发送到指定号码上就行啦： 1234567891011def send_sms(text): account_sid = 'your_sid' auth_token = 'your_auth_token' client = Client(account_sid, auth_token) message = client.messages.create( from_='your_from_num', body=text, to='your_to_num' ) print(message.sid) 完整代码后台回复「食行生鲜」即可获取。 总结Twilio 的使用还是很简单的，另外官方的文档也很赞，都提供了示例代码。这里我们仅仅演示了发送短信的功能，有兴趣的还可以试一下接收短信、拨打电话等功能。 如果 Twilio 的注册过程比较懵，可以参考下这篇：http://uuxn.com/twilio-toll-free-sms]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 实现「食行生鲜」签到领积分]]></title>
    <url>%2Fpython-shsx.html</url>
    <content type="text"><![CDATA[用过食行生鲜的同学应该知道，每天可以在食行生鲜签到，签到可以领到 20 积分，在购物时可以抵 2 毛钱。钱虽少，但是积少成多，买菜时可以抵扣一两块钱还是不错的。 今天我们就用 Python 来实现自动签到，省得我每天打开 APP 来操作了。 分析要自动签到，最简单的是打开页面分析请求，然后我们用脚本实现请求的自动化。但是发现食行没有页面，只有 APP，这不是一个好消息，这意味着需要抓包处理了。 不过还好，我们有微信。 在微信里面，我们发现也可以登录食行，这时选择在浏览器中打开页面，~哎~ ，柳暗花明了，我们找到了一个可用的网页地址：wechatx.34580.com 下面的操作就好办了，在电脑端的浏览器打开网址，按下 F12，开始起飞~ 登录分析点击签到后，会跳转到用户登录页面：https://wechatx.34580.com/mart/#/sign/in，输入登录信息后，点击登录，同时关注开发调试栏的网络交互信息。 可以发现，登录的请求地址是：https://wechatx.34580.com/sz/Sign/SignInV2，并且会在请求时带着登录信息： 1234567&#123; "SourceType": "9", "Phone": "18800000000", "PassWord": "98a53578bd74e150", "ZhuGeDeviceMd5": "164edd53b71674-02922cef4808a-47e1039-e1000-164edd53b7222e", "DeviceId": ""&#125; 现在，还无法确定哪些字段是必填的，哪些是可以不传的。 有一个问题是，密码是经过加密的，我在页面输入的 000000，这里变成了 98a53578bd74e150。这里我找了半天是如何加密的，也没有找到，若是有大神有办法，还请留言告知！ 不过还好，加密方式是固定的，也就是 000000 一直对应的是 98a53578bd74e150，我们只要记下这个加密后的密码，在登录时，传入后台即可。 登录成功后，请求会响应一些 token 数据： 123456789&#123; "Error": 0, "Message": "返回正确", "Data": &#123; "CustomerGuid": "d8cd7c84-xxxx-4369-xxxx-b1e86c027407", "Phone": "18800000000", "AccessToken": "73c7b5fxxxxxxx" &#125;&#125; 只要 Error 字段为 0，就代表登录成功！ 签到分析登录成功后，页面会自动跳转到首页，我们可以看到签到图标，点击它，进入签到页面： 发现进来还是一个签到按钮，套娃啊！再点它！ 终于签到成功！ 发现签到的请求：https://wechatx.34580.com/sz/SignUp/CustomerSignUp 签到请求中有两个重要的参数，accesstoken 和 customerguid，这两个参数就是登陆后返回的。 签到请求响应： 12345678&#123; "Error": 0, "Message": "返回正确", "Data": &#123; "GetPoints": 5, "SumGetPoints": 840 &#125;&#125; 返回说这次签到获得了 5 个积分，其实连续签到 4 天后，每天就可以获得 20 积分了！ 实现通过上面的分析，我们的签到流程也很清晰了，首先就是登陆获取 accesstoken 和 customerguid，然后再去签到就可以了！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import requests, json, sysdef login(Phone, PassWord): url = "https://wechatx.34580.com/sz/Sign/SignInV2" payload = &#123; 'SourceType': 9, 'Phone': Phone, 'PassWord': PassWord &#125; # 测试下来发现，连 header 都不需要 response = requests.post(url, data=json.dumps(payload)) data = json.loads(response.text) is_error = data['Error'] # 登录失败直接退出 if is_error: print('登录失败：&#123;&#125;'.format(data['Message'])) sys.exit(1) else: print('登录成功！') return data['Data']['CustomerGuid'], data['Data']['AccessToken']def signin(customerguid, accesstoken): url = "https://wechatx.34580.com/sz/SignUp/CustomerSignUp" querystring = &#123;"accesstoken": accesstoken, "customerguid": customerguid, "sourcetype": "9"&#125; # 这次不需要 body 中的传入数据 response = requests.post(url, params=querystring) data = json.loads(response.text) is_error = data['Error'] if is_error: print(data['Message']) else: print("签到成功，获取到 &#123;&#125; 个积分".format(data['Data']['GetPoints']))if __name__ == "__main__": Phone = input('请输入账号：') PassWord = input('请输入密码：') customerguid, accesstoken = login(Phone.strip(), PassWord.strip()) signin(customerguid, accesstoken) 运行： 12345$ python shsx.py请输入账号：188xxxxxxxx请输入密码：98a53578bd74e150登录成功！签到成功，获取到 20 个积分 最后，怎么自动执行？把登录信息写死到代码里，然后放到 Linux 下的 crontab 里，每天早上执行一次就行啦~ 总结这里还有一个遗留问题，就是登录密码的获取，现在还只能通过 F12 查看请求获取到，然后记下来。 但是，登录密码是怎么加密的，由于本人 js 方面比较薄弱，有能力有兴趣的同学要是能看出来可以留言分享下啊~ 另外，怎么知道是不是签到成功了呢，总不能去看定时任务的执行日志吧，是不是可以发送短信通知或者微信通知？这个且看后续分解。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交互式 shell 玩转 Python]]></title>
    <url>%2Fpython-shell.html</url>
    <content type="text"><![CDATA[Python 编程语言已经成为 IT 中使用的最流行的语言之一。成功的一个原因是它可以用来解决各种问题。从网站开发到数据科学、机器学习到任务自动化，Python 生态系统有丰富的框架和库。本文将介绍 Ubuntu 软件包集合中提供的一些有用的 Python shell 来简化我们的开发。 Python ShellPython Shell 即原生的 Python 交互环境，可以让你以交互模式使用 Python 解释器。这在测试代码或尝试新库时非常有用。在 Ubuntu 中，你可以通过在终端会话中输入 python 来调用默认的 shell。 123456$ pythonPython 3.5.2 (default, Nov 23 2017, 16:37:01)[GCC 5.4.0 20160609] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; print('hi')hi IPythonIPython 为 Python shell 提供了许多有用的增强功能。例如包括 tab 补全，对象内省，可以调用系统 shell 访问和命令历史检索。 安装和运行 IPython1234$ pip install ipython$ ipython --version6.5.0 自动补全 在 ipython 环境下就可以使用 tab 补全啦，当遇到使用不熟悉的库时，此功能会派上用场。 内省 如果不熟悉某个库的某个方法，可以输入 ? 命令来查看文档。对此的更多详细信息，也可以使用 ??命令。这就叫做对象的内省。 shell命令 另一个很酷的功能是使用 ! 字符执行系统 shell 命令的能力。然后还可以在 IPython shell 中引用该命令的结果。 IPython 完整的功能列表可在官方文档中找到。 crtl+r 可以搜索历史命令： bpythonbpython 并不能像 IPython 做那么多，但它却在一个简单的轻量级包中提供了一系列有用功能。除其他功能之外，bpython 提供： 内嵌语法高亮显示 在你输入时提供自动补全建议 可预期的参数列表，bpython可以在调用函数时显示参数列表。 能够将代码发送或保存到 pastebin 服务或文件中 安装和运行 bpython12345$ pip install bpython$ bpython --versionbpython version 0.17.1 on top of Python 3.5.2 /usr/bin/python(C) 2008-2016 Bob Farrell, Andreas Stuehrk, Sebastian Ramacher, Thomas Ballinger, et al. See AUTHORS for detail. 在你输入的时候，bpython 为你提供了选择来自动补全你的代码。 当你调用函数或方法时，会自动显示需要的参数和文档字符串。 有关配置和功能的更多细节，请参考 bpython 官方文档。 总结使用增强的 Python shell 是提高生产力的好方法。它为你提供增强的功能来编写快速原型或尝试新库。 你在使用增强的 Python shell 吗？来留言分享吧~ 参考: https://fedoramagazine.org/enhance-python-interactive-shell/]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible 进阶 | facts 缓存]]></title>
    <url>%2Fansible-facts-cache.html</url>
    <content type="text"><![CDATA[什么是 Ansible factsAnsible facts 是远程系统的信息，主要包含IP地址，操作系统，以太网设备，mac 地址，时间/日期相关数据，硬件信息等信息。 Ansible facts 对于需要根据远程主机的信息作为执行条件操作的场景非常有用。例如，根据远程服务器使用的操作系统版本，可以安装不同版本的软件包。或者也可以显示与每台远程计算机相关的一些信息，例如每台设备上有多少 RAM 可用。 如何获取 Ansible facts默认情况下，在使用 Ansible 对远程主机执行任何一个 playbook 之前，总会先通过 setup 模块获取 facts，并暂存在内存中，直至该 playbook 执行结束。 这意味着，想要在 playbook 中引用主机变量，至少先与该主机通信一次，以便 Ansible 能够访问其 facts，尽管有时候只需要来自该主机的少量信息。 Ansible 提供了 setup 模块来收集主机的系统信息，这些 facts 信息可以直接以变量的形式使用。 如果想查看 setup 模块获取到的数据，可以在命令行上通过调用 setup 模块命令查看： 1ansible all -m setup 将会返回一大大堆数据，文章篇幅有限，这里就不再展示。 获取这么多数据是非常耗时的，通过 time 指令可以看出，获取一台主机的 facts 数据就用了 3 秒多时间： 12345time ansible localhost -m setupreal 0m3.321suser 0m1.797ssys 0m0.205s 在被控主机较少的情况下，收集信息还可以容忍，如果被控主机数量非常大，收集 facts 信息会消耗掉非常多时间。 那怎么办呢？优化 Ansible 运行速度，最简单的莫过于设置 facts 缓存了。 设置 facts 缓存我们可以设置 gather_facts: no 来禁止 Ansible 收集 facts 信息，但是有时候又需要使用 facts 中的内容，这时候可以设置 facts 的缓存。 例如，我们可以在空闲的时候收集 facts，缓存下来，在需要的时候直接读取缓存进行引用。 Ansible 1.8 版本开始，引入了 facts 缓存功能。 Ansible 的配置文件中可以修改 gathering 的值为 smart、implicit 或者 explicit。 smart 表示默认收集 facts，但 facts 已有的情况下不会收集，即使用缓存 facts； implicit 表示默认收集 facts，要禁止收集，必须使用 gather_facts: False； explicit 则表示默认不收集，要显式收集，必须使用 gather_facts: Ture。 在使用 facts 缓存时（即设置为 smart），Ansible 支持两种 facts 缓存：redis 和 jsonfile。 使用 redis 缓存1234567gathering = smartfact_caching_timeout = 86400fact_caching = redisfact_caching_connection = 127.0.0.1:6379# 若 redis 设置了密码# fact_caching_connection = localhost:6379:0:admin 在使用 redis 缓存后，出现异常（若未出现，请忽略）：TypeError: the JSON object must be str, not &#39;bytes&#39;，加上 -vvv 打印出调试信息后，定位到 /usr/local/lib/python3.5/dist-packages/ansible-2.5.0-py3.5.egg/ansible/plugins/cache/redis.py 文件中的 第 90 行： 1self._cache[key] = json.loads(value) 将其修改为如下即可： 1self._cache[key] = json.loads(value.decode('utf-8')) 使用 json 文件环境123# 使用 json 文件缓存fact_caching = jsonfilefact_caching_connection = /tmp/mycachedir 注意：这个目录需要是一个可读写的目录。 效果测试随便新建一个剧本，这里我们随便执行一个 command 指令： 12345---- hosts: 192.168.9.21 tasks: - name: test ping command: whoami 未使用 facts 缓存的耗时： 1234567891011121314# time ansible-playbook ping.ymlPLAY [10.254.9.21] **********************************************************************************************************************************************************TASK [Gathering Facts] ******************************************************************************************************************************************************ok: [10.254.9.21]TASK [test ping] ************************************************************************************************************************************************************changed: [10.254.9.21]PLAY RECAP ******************************************************************************************************************************************************************10.254.9.21 : ok=2 changed=1 unreachable=0 failed=0real 0m15.870suser 0m2.766ssys 0m0.938s 使用缓存的耗时： 123456789101112# time ansible-playbook ping.ymlPLAY [10.254.9.21] **********************************************************************************************************************************************************TASK [test ping] ************************************************************************************************************************************************************changed: [10.254.9.21]PLAY RECAP ******************************************************************************************************************************************************************10.254.9.21 : ok=1 changed=1 unreachable=0 failed=0real 0m3.037suser 0m1.469ssys 0m0.813s 可以发现，速度提升很多，由 15s 减少到只有 3s！ 运行结束后，在 redis 中可以看到有如下数据： 1234$ redis-cli127.0.0.1:6379&gt; keys *1) "ansible_facts10.254.9.21"2) "ansible_cache_keys" 若使用的是 json 缓存，配置的目录中会生成如下文件： 12345$ tree facts_cache/facts_cache/└── 10.254.9.210 directories, 1 file 其中存放的就是主机的 facts 信息。 总结不同网络环境下的耗时肯定是不同的，但是设置缓存是肯定可以加快 Ansible 运行速度的，特别是 playbook 的运行。 另外，可以在空闲时间手动进行 facts 缓存的更新，从而避免执行真正的任务时再去更新缓存。 当然，优化 Ansible 运行速度还有其他方法，后面我再继续给大家分享。]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 常用静态代码检查工具]]></title>
    <url>%2Fpython-static-check.html</url>
    <content type="text"><![CDATA[对于我这种习惯了 Java 这种编译型语言，在使用 Python 这种动态语言的时候，发现错误经常只能在执行的时候发现，总感觉有点不放心。 而且有一些错误由于隐藏的比较深，只有特定逻辑才会触发，往往导致需要花很多时间才能将语法错误慢慢排查出来。其实有一些错误是很明显的，假如能在写程序的时候发现这些错误，就能提高工作效率。 这时候 Python 静态语法检查工具就出现了。 本文使用之前文章Python 助你填写高考志愿中的代码作为测试代码。另外有些输出过长的，进行了截取。 pep8/pycodestyle相信大家多多少少都见过 PEP 8，那 PEP 8 到底是个啥？ 其实 PEP 8 是一种 Python 代码规范指南，可以参阅官网：https://www.python.org/dev/peps/pep-0008/，其目的是为了保持代码的一致性、可读性。 检查自己代码是否符合 PEP 8 规范，一个简单的工具就是：pep8。 安装1$ pip install pep8 在使用时发现 pep8 给出了一个警告： 1234567891011$ pep8 gkcx.py/usr/local/lib/python3.5/dist-packages/pep8.py:2124: UserWarning:pep8 has been renamed to pycodestyle (GitHub issue #466)Use of the pep8 tool will be removed in a future release.Please install and use `pycodestyle` instead.$ pip install pycodestyle$ pycodestyle ... '\n\n' 意思是 pep8 已被 pycodestyle 替代！ 使用基本使用方法：$ pycodestyle [file name or directory name] 1234567891011$ pycodestyle gkcx.pygkcx.py:11:80: E501 line too long (135 &gt; 79 characters)gkcx.py:14:1: E302 expected 2 blank lines, found 1gkcx.py:15:80: E501 line too long (94 &gt; 79 characters)...省略部分gkcx.py:67:1: E305 expected 2 blank lines after class or function definition, found 1gkcx.py:71:80: E501 line too long (100 &gt; 79 characters)gkcx.py:82:25: E231 missing whitespace after ','gkcx.py:82:29: E231 missing whitespace after ','gkcx.py:84:1: W293 blank line contains whitespacegkcx.py:84:1: W391 blank line at end of file 参数 --statistics -qq ：对结果进行汇总 12345678910$ pycodestyle gkcx.py --statistics -qq3 E203 whitespace before ':'1 E225 missing whitespace around operator16 E231 missing whitespace after ':'3 E302 expected 2 blank lines, found 11 E305 expected 2 blank lines after class or function definition, found 16 E501 line too long (135 &gt; 79 characters)1 W291 trailing whitespace1 W293 blank line contains whitespace1 W391 blank line at end of file 参数 --show-source：更详细的输出 1234567891011121314$ pycodestyle gkcx.py --show-sourcegkcx.py:14:1: E302 expected 2 blank lines, found 1def get_school_id(school_name):^gkcx.py:15:80: E501 line too long (94 &gt; 79 characters) Referer = "https://gkcx.eol.cn/soudaxue/queryschool.html?&amp;keyWord1=&#123;&#125;".format(school_name) ^gkcx.py:18:19: E203 whitespace before ':' "messtype" : "jsonp", ^gkcx.py:19:12: E231 missing whitespace after ':' "_":"1530074932531", ^...省略部分 参数 --ignore：忽略指定输出 1234567891011$ pycodestyle gkcx.py --ignore=E225,E501,E231gkcx.py:14:1: E302 expected 2 blank lines, found 1gkcx.py:18:19: E203 whitespace before ':'gkcx.py:20:19: E203 whitespace before ':'gkcx.py:21:19: E203 whitespace before ':'gkcx.py:32:1: E302 expected 2 blank lines, found 1gkcx.py:41:1: E302 expected 2 blank lines, found 1gkcx.py:55:15: W291 trailing whitespacegkcx.py:67:1: E305 expected 2 blank lines after class or function definition, found 1gkcx.py:84:1: W293 blank line contains whitespacegkcx.py:84:1: W391 blank line at end of file 错误码含义 E...：错误 W...：警告 100 型：缩进问题 200 型：空格问题 300 型：空行问题 400 型：导入问题 500 型：行长度问题 600 型：已弃用 700 型：声明问题 900 型：语法错误 Pyflakes一个用于检查 Python 源文件错误的简单程序。 Pyflakes 分析程序并且检查各种错误。它通过解析源文件实现，无需导入它，因此在模块中使用是安全的，没有任何的副作用。 不会检查代码风格 由于它是单独检查各个文件，因此它也相当的快，当然检测范围也有一定的局限 安装1pip install pyflakes 使用$ pyflakes [ file name or directory name] 123$ pyflakes gkcx.pygkcx.py:3: 'bs4.BeautifulSoup' imported but unusedgkcx.py:6: 're' imported but unused PylintPyLint 是 Python 源代码分析器，可以分析 Python 代码中的错误，查找不符合代码风格标准和有潜在问题的代码，是一个可以用于验证多个文件的模块和包的工具。 缺省情况下，PyLint 启用许多规则。它具有高度可配置性，从代码内部处理程序控制它。另外，编写插件添加到自己的检查中是可能的。 安装1234567$ pip install pylint$ pylint --versionpylint 2.0.0astroid 2.0.1Python 3.5.2 (default, Nov 23 2017, 16:37:01)[GCC 5.4.0 20160609] 使用基本使用：pylint [options] module_or_package 1234567891011121314151617$ pylint gkcx.py************* Module gkcxgkcx.py:11:0: C0301: Line too long (135/100) (line-too-long)gkcx.py:25:47: C0326: Exactly one space required after comma response = requests.request("GET", data_url,headers=headers,params=params) ^ (bad-whitespace)gkcx.py:36:0: C0301: Line too long (113/100) (line-too-long)gkcx.py:1:0: C0111: Missing module docstring (missing-docstring)gkcx.py:10:0: C0103: Constant name "headers" doesn't conform to UPPER_CASE naming style (invalid-name)...省略部分gkcx.py:14:18: W0621: Redefining name 'school_name' from outer scope (line 68) (redefined-outer-name)gkcx.py:32:0: C0111: Missing function docstring (missing-docstring)gkcx.py:33:4: W0622: Redefining built-in 'id' (redefined-builtin)gkcx.py:32:12: W0621: Redefining name 'school' from outer scope (line 72) (redefined-outer-name)------------------------------------------------------------------Your code has been rated at 3.33/10 (previous run: 3.33/10, +0.00) 发现 Pylint 还会给代码整体打一个分数，我们就可以根据提示一步步调优，提高分数！10 分满分。 如果运行两次 Pylint，它会同时显示出当前和上次的运行结果，从而可以看出代码质量是否得到了改进。 错误代码含义 C：惯例，违反了编码风格标准 R：重构，代码非常糟糕 W：警告，某些 Python 特定的问题 E：错误，很可能是代码中的错误 F：致命错误，阻止 Pylint 进一步运行的错误 flake8Flake8 是由 Python 官方发布的一款辅助检测 Python 代码是否规范的工具，相对于目前热度比较高的 Pylint 来说，Flake8 检查规则灵活，支持集成额外插件，扩展性强。Flake8 是对下面三个工具的封装： PyFlakes：静态检查 Python 代码逻辑错误的工具。 Pep8： 静态检查 PEP8 编码风格的工具。 NedBatchelder’s McCabe ：静态分析 Python 代码复杂度的工具。 不光对以上三个工具的封装，Flake8还提供了扩展的开发接口。 官方文档：https://pypi.python.org/pypi/flake8/ 安装1234$ pip install flake8 $ flake8 --version3.5.0 (mccabe: 0.6.1, pycodestyle: 2.3.1, pyflakes: 1.6.0) CPython 3.5.2 on Linux 使用基本使用方法：flake8 [file name or directory name] 1234567891011$ flake8 gkcx.pygkcx.py:3:1: F401 'bs4.BeautifulSoup' imported but unusedgkcx.py:6:1: F401 're' imported but unusedgkcx.py:11:80: E501 line too long (135 &gt; 79 characters)gkcx.py:14:1: E302 expected 2 blank lines, found 1...省略部分gkcx.py:71:80: E501 line too long (100 &gt; 79 characters)gkcx.py:82:25: E231 missing whitespace after ','gkcx.py:82:29: E231 missing whitespace after ','gkcx.py:84:1: W293 blank line contains whitespacegkcx.py:84:1: W391 blank line at end of file PyFlakes 和 Pep8 的输出将合并起来一起返回。可以看出 flake8 不止检查代码错误，还会对代码规范不对的地方进行检查，比如：一行代码过长。 Flake8 提供一个扩展选项：–max-complexity，如果函数的 McCabe 复杂度比给定的值更高将发出一个告警。该功能对于发现代码过度复杂非常有用，根据 Thomas J. McCabe, Sr 研究，代码复杂度不宜超过 10，而 Flake8 官网建议值为 12。 McCabe 复杂度默认情况下是不会输出的，需要通过 --max-complexity 指定： 1234567891011$ flake8 gkcx.py --max-complexity=5gkcx.py:3:1: F401 'bs4.BeautifulSoup' imported but unusedgkcx.py:6:1: F401 're' imported but unused...省略部分gkcx.py:67:1: E305 expected 2 blank lines after class or function definition, found 1gkcx.py:67:1: C901 'If 67' is too complex (6)gkcx.py:71:80: E501 line too long (100 &gt; 79 characters)gkcx.py:82:25: E231 missing whitespace after ','gkcx.py:82:29: E231 missing whitespace after ','gkcx.py:84:1: W391 blank line at end of filegkcx.py:84:1: W293 blank line contains whitespace 可以通过 --ignore 忽略指定输出： 1234567891011$ flake8 gkcx.py --ignore E501,E231,E203gkcx.py:3:1: F401 'bs4.BeautifulSoup' imported but unusedgkcx.py:6:1: F401 're' imported but unusedgkcx.py:14:1: E302 expected 2 blank lines, found 1gkcx.py:32:1: E302 expected 2 blank lines, found 1gkcx.py:38:22: E225 missing whitespace around operatorgkcx.py:41:1: E302 expected 2 blank lines, found 1gkcx.py:55:15: W291 trailing whitespacegkcx.py:67:1: E305 expected 2 blank lines after class or function definition, found 1gkcx.py:84:1: W391 blank line at end of filegkcx.py:84:1: W293 blank line contains whitespace 通过 --select 参数设置只展示指定输出： 123$ flake8 gkcx.py --select F401gkcx.py:3:1: F401 'bs4.BeautifulSoup' imported but unusedgkcx.py:6:1: F401 're' imported but unused 错误码含义Flake8 基础错误返回码一共有三类： E***/W***：PEP8 中的 error 和 warning。 F***：通过 PyFlakes 检测出的 error，其实 PyFlakes 本身是不提供错误返回码的，flake8 对 pyflakes 返回的错误消息进行了分类。 C9**：通过 McCabe 检测出的代码复杂度。 总结Python 静态代码检查工具不止这几个，大家可以挑选合适的进行使用。本人也没有进行深入地探究，有兴趣进行高阶使用的可以参照官网。 另外，各个工具应该都有对应的插件，比如 vim、vscode、eclipse、pycharm 上应该都能集成上述工具，大家可以网上找下适合自己 ide 的插件进行安装。 有些人估计看到那么多异常也会烦，但是毕竟是可以培养大家代码规范的，后续工作后，肯定也有相应的代码规范，建议大家养成习惯。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你肯定不知道还可以这样创建「类」]]></title>
    <url>%2Fpython-namedtuple.html</url>
    <content type="text"><![CDATA[我们都知道，标准的元组 tuple 是使用数字索引来访问其中的成员的，但是在使用时要记住要哪一个数字索引对应哪一个成员值是有点困难的，往往会引发错误，特别是在元组包含了较多的成员时。 这个时候，我们的主角要登场了：namedtuple，它会为每个成员分配一个索引的同时，再分配一个名称，使用起来就像一个「类」。 namedtuple 主要用来产生可以使用名称来访问元素的数据对象，通常用来增强代码的可读性。 namedtuple 继承自 tuple，但是它有更多更酷的特性，正所谓「青出于蓝」。namedtuple 创建一个和 tuple 类似的对象，而且对象拥有可以访问的属性。这对象更像带有数据属性的类，不过数据属性是只读的。 定义和使用namedtuple 创建时会需要使用构造函数 namedtuple()，参数是创建类的名称，以及包含元素名称的字符串。 1234567891011&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; Person = namedtuple('Person','name age gender')&gt;&gt;&gt; type(Person)&lt;class 'type'&gt;&gt;&gt;&gt; hoxis = Person('hoxis',18,'male')&gt;&gt;&gt; print(hoxis)Person(name='hoxis', age=18, gender='male')&gt;&gt;&gt; hoxis.name'hoxis'&gt;&gt;&gt; hoxis[0]'hoxis' 从上面例子可以看出，我们可以通过 . 来访问成员（obj.attr），同时也可以使用数字索引访问。同时，还内置了 repr() 函数。 注意事项和元组一样，namedtuple 也是不可变的，不能直接改变其成员： 1234567# hoxis 只能是 18 岁，变不了&gt;&gt;&gt; hoxis.age18&gt;&gt;&gt; hoxis.age = 28Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: can't set attribute 若非要改变，可以使用 _replace() 方法，但是这时其实是生成了一个新的 namedtuple，原来的还是没有改变，不信你看： 123456# hoxis 还是 18 岁&gt;&gt;&gt; hoxis_2 = hoxis._replace(age=28)&gt;&gt;&gt; hoxisPerson(name='hoxis', age=18, gender='male')&gt;&gt;&gt; hoxis_2Person(name='hoxis', age=28, gender='male') 其实这里和其他不可变对象类似，若要改变只会返回一个新的数据给你，原来的还是原来的，your daye still your daye。 还有一点，不能使用 Python 自带关键字作为成员名称，如 class，这时会抛出 ValueError 异常： 123456&gt;&gt;&gt; Person = namedtuple('Person','name age gender class')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/usr/lib/python3.5/collections/__init__.py", line 403, in namedtuple 'keyword: %r' % name)ValueError: Type names and field names cannot be a keyword: 'class' 成员名称也不能重复： 123456&gt;&gt;&gt; Person = namedtuple('Person','name age gender age')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/usr/lib/python3.5/collections/__init__.py", line 410, in namedtuple raise ValueError('Encountered duplicate field name: %r' % name)ValueError: Encountered duplicate field name: 'age' 若非要死皮赖脸说，我就要用 class，那你需要设置 rename=True 属性： 1234&gt;&gt;&gt; Person = namedtuple('Person','name age gender class', rename=True)&gt;&gt;&gt; hoxis = Person('hoxis',18,'male','三年二班')&gt;&gt;&gt; hoxisPerson(name='hoxis', age=18, gender='male', _3='三年二班') 其实成员名称被重命名了，class 你还是没用上，死皮赖脸也没用。。。 扩展有没有发现，namedtuple 和 dict 有点像？ 其实 namedtuple 有一个内置的方法 ._asdict()，可以生成一个 dict： 123456789&gt;&gt;&gt; hoxis = Person('hoxis',18,'male')&gt;&gt;&gt; hoxis_dict = hoxis._asdict()&gt;&gt;&gt; hoxis_dictOrderedDict([('name', 'hoxis'), ('age', 18), ('gender', 'male')])&gt;&gt;&gt; hoxis_dict['age']18&gt;&gt;&gt; hoxis_dict['age'] = 28&gt;&gt;&gt; hoxis_dictOrderedDict([('name', 'hoxis'), ('age', 28), ('gender', 'male')]) 转换成 dict 后，属性就可以改变了。 当然，dict 也可以转换为 namedtuple，其实是用 dict 生成一个 namedtuple： 123&gt;&gt;&gt; hoxis = Person(**hoxis_dict)&gt;&gt;&gt; hoxisPerson(name='hoxis', age=28, gender='male') 总结相比 tuple 和 dictionary，namedtuple 略微有点综合体的意味：直观、使用方便，你不必使用整数索引来访问一个命名元组，这让你的代码更易于维护。而且，namedtuple 的每个实例没有对象字典，所以它们很轻量，并不需要更多的内存，这使得它们比字典更快。 建议大家在合适的时候尝试使用 namedtuple，你会回来点赞的~]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你还在用 format 格式化字符串？]]></title>
    <url>%2Fpython-fstring.html</url>
    <content type="text"><![CDATA[Python 3.6 提供了一种新的字符串格式化方法：f-strings，不仅比其他格式化方式更易读，更简洁，更不容易出错，而且它们也更快！ 看完本文后，你将了解如何以及为何要使用 f-strings。 首先，我们先了解下现有的字符串格式化方法。 在 Python 3.6 之前，字符串格式化方法主要有两种：%格式化 和 str.format()。下面我们简单看下它们的使用方法，以及局限。 1 %-格式化% 格式化方法从 Python 刚开始时就存在了，堪称「一届元老」，但是 Python 官方文档中并不推荐这种格式化方式： 这里描述的格式化操作容易表现出各种问题，导致许多常见错误（例如无法正确显示元组和字典）。使用较新的格式化字符串文字或 str.format() 可以有助于避免这些错误。这些替代方案还提供了更强大，灵活和可扩展的格式化文本方法。 1.1 如何使用 %格式化一般使用方式，要插入多个变量的话，必须使用元组： 1234&gt;&gt;&gt; name = "hoxis"&gt;&gt;&gt; age = 18&gt;&gt;&gt; "hello, %s. you are %s ?" %(name, age)'hello, hoxis. you are 18 ?' 1.2 %格式化的缺陷上面的代码示例看起来还能读，但是，一旦开始使用多个参数和更长的字符串，你的代码将很快变得不那么容易阅读： 123456&gt;&gt;&gt; name = "hoxis"&gt;&gt;&gt; age = 18&gt;&gt;&gt; country = "China"&gt;&gt;&gt; hair = "black"&gt;&gt;&gt; "hello, %s. you are %s ?. Your country is %s, and your hair is %s" %(name, age, country,hair)'hello, hoxis. you are 18 ?. Your country is China, and your hair is black' 可以看出，这种格式化并不是很好，因为它很冗长并且容易导致错误，比如没有正确显示元组或字典。 不过还好我们还有 str.format()。 2 str.format()Python 2.6 中引入了 str.format() 格式化方法：https://docs.python.org/3/library/stdtypes.html#str.format。 2.1 str.format() 的使用str.format() 是对 %格式化 的改进，它使用普通函数调用语法，并且可以通过 __format__() 方法为对象进行扩展。 使用 str.format() 时，替换字段用大括号进行标记： 12&gt;&gt;&gt; "hello, &#123;&#125;. you are &#123;&#125;?".format(name,age)'hello, hoxis. you are 18?' 并且可以通过索引来以其他顺序引用变量： 12&gt;&gt;&gt; "hello, &#123;1&#125;. you are &#123;0&#125;?".format(age,name)'hello, hoxis. you are 18?' 或者可以这样： 12&gt;&gt;&gt; "hello, &#123;name&#125;. you are &#123;age1&#125;?".format(age1=age,name=name)'hello, hoxis. you are 18?' 从字典中读取数据时还可以使用 **： 123&gt;&gt;&gt; person = &#123;"name":"hoxis","age":18&#125;&gt;&gt;&gt; "hello, &#123;name&#125;. you are &#123;age&#125;?".format(**person)'hello, hoxis. you are 18?' 确实，str.format() 比 %格式化高级了一些，但是它还是有自己的缺陷。 2.2 str.format() 的缺陷在处理多个参数和更长的字符串时仍然可能非常冗长，麻烦！看看这个： 12&gt;&gt;&gt; "hello, &#123;&#125;. you are &#123;&#125; ?. Your country is &#123;&#125;, and your hair is &#123;&#125;".format(name, age, country,hair)'hello, hoxis. you are 18 ?. Your country is China, and your hair is black' 3 f-Strings还好，现在我们有了 f-Strings，它可以使得字符串格式化更加容易。 f-strings 是指以 f 或 F 开头的字符串，其中以 {} 包含的表达式会进行值替换。 下面从多个方面看下 f-strings 的使用方法，看完后，我相信你会对「人生苦短，我用 Python」有更深地赞同~ 3.1 f-Strings 使用方法123456&gt;&gt;&gt; name = 'hoxis'&gt;&gt;&gt; age = 18&gt;&gt;&gt; f"hi, &#123;name&#125;, are you &#123;age&#125;"'hi, hoxis, are you 18'&gt;&gt;&gt; F"hi, &#123;name&#125;, are you &#123;age&#125;"'hi, hoxis, are you 18' 是不是很简洁？！还有更牛叉的！ 因为 f-strings 是在运行时计算的，那么这就意味着你可以在其中放置任意合法的 Python 表达式，比如： 运算表达式 12&gt;&gt;&gt; f"&#123; 2 * 3 + 1&#125;"'7' 调用函数 还可以调用函数： 123456&gt;&gt;&gt; def test(input):... return input.lower()...&gt;&gt;&gt; name = "Hoxis"&gt;&gt;&gt; f"&#123;test(name)&#125; is handsome."'hoxis is handsome.' 也可以直接调用内置函数： 12&gt;&gt;&gt; f"&#123;name.lower()&#125; is handsome."'hoxis is handsome.' 在类中使用 123456789101112131415161718&gt;&gt;&gt; class Person:... def __init__(self,name,age):... self.name = name... self.age = age... def __str__(self):... return f"&#123;self.name&#125; is &#123;self.age&#125;"... def __repr__(self):... return f"&#123;self.name&#125; is &#123;self.age&#125;. HAHA!"...&gt;&gt;&gt; hoxis = Person("hoxis",18)&gt;&gt;&gt; f"&#123;hoxis&#125;"'hoxis is 18'&gt;&gt;&gt; f"&#123;hoxis!r&#125;"'hoxis is 18. HAHA!'&gt;&gt;&gt; print(hoxis)hoxis is 18&gt;&gt;&gt; hoxishoxis is 18. HAHA! 多行 f-string 1234567891011&gt;&gt;&gt; name = 'hoxis'&gt;&gt;&gt; age = 18&gt;&gt;&gt; status = 'Python'&gt;&gt;&gt; message = &#123;... f'hi &#123;name&#125;.'... f'you are &#123;age&#125;.'... f'you are learning &#123;status&#125;.'... &#125;&gt;&gt;&gt;&gt;&gt;&gt; message&#123;'hi hoxis.you are 18.you are learning Python.'&#125; 这里需要注意，每行都要加上 f 前缀，否则格式化会不起作用： 123456&gt;&gt;&gt; message = &#123;... f'hi &#123;name&#125;.'... 'you are learning &#123;status&#125;.'... &#125;&gt;&gt;&gt; message&#123;'hi hoxis.you are learning &#123;status&#125;.'&#125; 4 速度对比其实，f-string 里的 f 也许可以代表 fast，它比 %格式化方法和 str.format() 都要快： 12345678910111213from timeit import timeitprint(timeit("""name = "hoxis"age = 18'%s is %s.' % (name, age)""", number = 10000))print(timeit("""name = "hoxis"age = 18'&#123;&#125; is &#123;&#125;.'.format(name, age)""", number = 10000))print(timeit("""name = "hoxis"age = 18f'&#123;name&#125; is &#123;age&#125;.'""", number = 10000)) 运行结果： 1234$ python3.6 fstring.py0.0022380000154953450.0040680000092834230.0015349999885074794 很明显，f-string 是最快的，并且语法是最简洁的，是不是迫不及待地要试试了？ 5 注意事项5.1 引号的处理可以在字符串中使用各种引号，只要保证和外部的引号不重复即可。 以下使用方式都是没问题的： 12345678&gt;&gt;&gt; f"&#123;'hoxis'&#125;"'hoxis'&gt;&gt;&gt; f'&#123;"hoxis"&#125;''hoxis'&gt;&gt;&gt; f"""hoxis"""'hoxis'&gt;&gt;&gt; f'''hoxis''''hoxis' 那如果字符串内部的引号和外部的引号相同时呢？那就需要 \ 进行转义： 12&gt;&gt;&gt; f"You are very \"handsome\""'You are very "handsome"' 5.2 括号的处理若字符串中包含括号 {}，那么你就需要用双括号包裹它： 12345&gt;&gt;&gt; f"&#123;&#123;74&#125;&#125;"'&#123;74&#125;'&gt;&gt;&gt; f"&#123;&#123;&#123;74&#125;&#125;&#125;"'&#123;74&#125;' 可以看出，使用三个括号包裹效果一样。 当然，你可以继续增加括号数目，看下有什么其他效果： 123456&gt;&gt;&gt; f"&#123;&#123;&#123;&#123;74&#125;&#125;&#125;&#125;"'&#123;&#123;74&#125;&#125;'&gt;&gt;&gt; f"&#123;&#123;&#123;&#123;&#123;74&#125;&#125;&#125;&#125;&#125;"'&#123;&#123;74&#125;&#125;'&gt;&gt;&gt; f"&#123;&#123;&#123;&#123;&#123;&#123;74&#125;&#125;&#125;&#125;&#125;&#125;"'&#123;&#123;&#123;74&#125;&#125;&#125;' 额，那么多括号，看着有点晕了… 5.3 反斜杠上面说了，可以用反斜杠进行转义字符，但是不能在 f-string 表达式中使用： 12345&gt;&gt;&gt; f"You are very \"handsome\""'You are very "handsome"'&gt;&gt;&gt; f"&#123;You are very \"handsome\"&#125;" File "&lt;stdin&gt;", line 1SyntaxError: f-string expression part cannot include a backslash 你可以先在变量里处理好待转义的字符，然后在表达式中引用变量： 123&gt;&gt;&gt; name = '"handsome"'&gt;&gt;&gt; f'&#123;name&#125;''"handsome"' 5.4 注释符号不能在表达式中出现 #，否则会报出异常； 12345&gt;&gt;&gt; f"Hoxis is handsome # really"'Hoxis is handsome # really'&gt;&gt;&gt; f"Hoxis is handsome &#123;#really&#125;" File "&lt;stdin&gt;", line 1SyntaxError: f-string expression part cannot include '#' 总结经过以上的讲解，是不是发现 f-string 非常简洁实用、可读性高，而且不易出错，可以尝试切换到 f-string 喽~ f-string 也体现出了 Python 的奥义： 12345678910111213141516171819202122&gt;&gt;&gt; import thisThe Zen of Python, by Tim PetersBeautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.Special cases aren't special enough to break the rules.Although practicality beats purity.Errors should never pass silently.Unless explicitly silenced.In the face of ambiguity, refuse the temptation to guess.There should be one-- and preferably only one --obvious way to do it.Although that way may not be obvious at first unless you're Dutch.Now is better than never.Although never is often better than *right* now.If the implementation is hard to explain, it's a bad idea.If the implementation is easy to explain, it may be a good idea.Namespaces are one honking great idea -- let's do more of those!]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 玩转 Excel]]></title>
    <url>%2Fpython-openpyxl.html</url>
    <content type="text"><![CDATA[在前面抓取高考分数线的文章中，我们用到了 openpyxl 模块来存储数据到 Excel，今天带大家学习一下该模块的详细使用。 根据官方文档，openpyxl 是一个用来处理 xlsx/xlsm/xltx/xltm 格式 Excel 文件的 Python 代码库，同时支持 Pandas 和 NumPy 等包，能够绘制图表，并且同样支持格式控制等，详细文档可以参考： https://openpyxl.readthedocs.io/。 openpyxl 用起来非常简单，对照文档就可以解决一些基本需求，比如常见的都写操作。 现在还有很多人在用 Excel 2003 版本，即 xls 格式，那么 xls 和 xlsx 有什么区别呢？ xls 是一个特有的二进制格式，其核心结构是复合文档类型的结构，而 xlsx 的核心结构是 XML 类型的结构，采用的是基于 XML 的压缩方式，使其占用的空间更小。xlsx 中最后一个 x 的意义就在于此。 1 基本概念在 openpyxl 中，主要用到三个概念：Workbook，Sheet，Cell： Workbook：就是一个 excel 工作簿，其中包含多个 sheet； Sheet：工作簿中的一张表页； Cell：就是简单的一个单元格，用来存储数据对象； openpyxl 的主要操作就是围绕着这三个概念进行的，无怪乎：打开 Workbook，定位 Sheet，操作 Cell。下面就分别介绍 openpyxl 几个常见的方法。 2 安装openpyxl 的安装很简单，使用 pip 直接安装即可。 1pip install openpyxl 3 基本操作提前新建一个测试 Excel： 导入模块 1&gt;&gt;&gt; import openpyxl 3.1 Workbook 相关 读取已存在的 xlsx 1&gt;&gt;&gt; wb = openpyxl.load_workbook("test.xlsx") openpyxl.load_workbook() 函数接受文件名，返回一个 Workbook 数据类型的值。这个 Workbook 对象代表这个 Excel 文件，有点类似 File 对象代表一个打开的文本文件。 以只读模式读取 1&gt;&gt;&gt; wb = openpyxl.load_workbook("test.xlsx", read_only=True) 保存 Workbook 在对 Workbook 进行了相关操作后，可以调用 save(filename) 方法进行保存。 另外，在只读模式下保存时，会报 Workbook is read-only 异常。 123456&gt;&gt;&gt; wb.save('test.xlsx')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/usr/local/lib/python3.5/dist-packages/openpyxl/workbook/workbook.py", line 363, in save raise TypeError("""Workbook is read-only""")TypeError: Workbook is read-only 3.2 Sheet 相关 获取 Workbook 中的 sheet 列表 返回一个 sheet 的 list。 1&gt;&gt;&gt; sheet = wb.worksheets 获取 sheet 页的名称列表 12&gt;&gt;&gt; wb.sheetnames['各专业历年录取分数线', '测试页'] 读取 sheet 页 12345# 根据名称读取&gt;&gt;&gt; sheet = wb['测试页']# 通过索引 index 读取&gt;&gt;&gt; sheet = wb.worksheets[1] 获取当前正在使用的 sheet 页 1&gt;&gt;&gt; sheet = wb.active sheet 页属性 12345678910&gt;&gt;&gt; sheet.title'测试页'# 最大列数&gt;&gt;&gt; sheet.max_column4# 最大行数&gt;&gt;&gt; sheet.max_row13 新建 sheet 页 123456789&gt;&gt;&gt; wb.create_sheet('test2')&lt;Worksheet "test2"&gt;&gt;&gt;&gt; wb.sheetnames['各专业历年录取分数线', '测试页', 'test2']# 在指定索引处新建&gt;&gt;&gt; sheet = wb.create_sheet('test2',1)&gt;&gt;&gt; wb.sheetnames['各专业历年录取分数线', 'test21', 'test2', '测试页'] 若 sheet 页重名，会自动进行重命名。 修改 sheet 页名称 1234&gt;&gt;&gt; sheet = wb['test2']&gt;&gt;&gt; sheet.title = 'test3'&gt;&gt;&gt; wb.sheetnames['各专业历年录取分数线', '测试页', 'test3'] 删除 sheet 页 要先获取到 sheet 页才能删除，不能直接用 sheet 页的名称删除 1234567&gt;&gt;&gt; sheet = wb['test3']&gt;&gt;&gt; wb.remove(sheet)&gt;&gt;&gt; wb.sheetnames['各专业历年录取分数线', '测试页']# 也可以使用 del 进行删除&gt;&gt;&gt; del wb['test2'] 3.3 行和列 获取指定行/列 12345678910# 获取第 1 行&gt;&gt;&gt; sheet[1](&lt;Cell '测试页'.A1&gt;, &lt;Cell '测试页'.B1&gt;, &lt;Cell '测试页'.C1&gt;, &lt;Cell '测试页'.D1&gt;)# 获取第 1 列&gt;&gt;&gt; sheet['A'](&lt;Cell '测试页'.A1&gt;, &lt;Cell '测试页'.A2&gt;, &lt;Cell '测试页'.A3&gt;, &lt;Cell '测试页'.A4&gt;, &lt;Cell '测试页'.A5&gt;, &lt;Cell '测试页'.A6&gt;, &lt;Cell '测试页'.A7&gt;, &lt;Cell '测试页'.A8&gt;, &lt;Cell '测试页'.A9&gt;, &lt;Cell '测试页'.A10&gt;, &lt;Cell '测试页'.A11&gt;, &lt;Cell '测试页'.A12&gt;, &lt;Cell '测试页'.A13&gt;) 对行/列切片获取 1234567891011&gt;&gt;&gt; sheet[2:3]((&lt;Cell '测试页'.A2&gt;, &lt;Cell '测试页'.B2&gt;, &lt;Cell '测试页'.C2&gt;, &lt;Cell '测试页'.D2&gt;), (&lt;Cell '测试页'.A3&gt;, &lt;Cell '测试页'.B3&gt;, &lt;Cell '测试页'.C3&gt;, &lt;Cell '测试页'.D3&gt;))&gt;&gt;&gt; sheet['A:B']((&lt;Cell '测试页'.A1&gt;, &lt;Cell '测试页'.A2&gt;, &lt;Cell '测试页'.A3&gt;, &lt;Cell '测试页'.A4&gt;, &lt;Cell '测试页'.A5&gt;, &lt;Cell '测试页'.A6&gt;, &lt;Cell '测试页'.A7&gt;, &lt;Cell '测试页'.A8&gt;, &lt;Cell '测试页'.A9&gt;, &lt;Cell '测试页'.A10&gt;, &lt;Cell '测试页'.A11&gt;, &lt;Cell '测试页'.A12&gt;, &lt;Cell '测试页'.A13&gt;), (&lt;Cell '测试页'.B1&gt;, &lt;Cell '测试页'.B2&gt;, &lt;Cell '测试页'.B3&gt;, &lt;Cell '测试页'.B4&gt;, &lt;Cell '测试页'.B5&gt;, &lt;Cell '测试页'.B6&gt;, &lt;Cell '测试页'.B7&gt;, &lt;Cell '测试页'.B8&gt;, &lt;Cell '测试页'.B9&gt;, &lt;Cell '测试页'.B10&gt;, &lt;Cell '测试页'.B11&gt;, &lt;Cell '测试页'.B12&gt;, &lt;Cell '测试页'.B13&gt;)) 获取所有行/列 返回的是一个 Generator 对象，它包含该区域中的 Cell 对象。里面是每一行（列）的数据，每一行（列）又由一个 tuple 包裹。 123456789&gt;&gt;&gt; rows = sheet.rows&gt;&gt;&gt; rows&lt;generator object Worksheet._cells_by_row at 0x7f778a7978e0&gt;&gt;&gt;&gt; columns = sheet.columns&gt;&gt;&gt; for row in sheet.rows:... for cell in row:... print(cell.value) 因为 sheet.rows 是生成器类型，不能直接使用索引，需要先转换成 list 之后才行，如 list(sheet.rows)2 这样就获取到第三行的 tuple 对象。 添加一行值 12&gt;&gt;&gt; sheet.append(row)&gt;&gt;&gt; row = [1,2,3,4,5,6] 3.4 Cell 相关 读取 Cell 12&gt;&gt;&gt; cell = sheet['B2']&gt;&gt;&gt; cell = sheet.cell(2,1) 需要注意的是：openpyxl 中 row 和 column 为了和 Excel 中的表达方式一致，并不和编程语言的习惯以 0 表示第一个值，而是 1 开始。 Cell 属性 123456789101112131415# 所在列&gt;&gt;&gt; cell.column'A'# 所在行&gt;&gt;&gt; cell.row2# 所属坐标&gt;&gt;&gt; cell.coordinate'A2'# 对应的值&gt;&gt;&gt; cell.value'A2' 写入 Cell 12345# 直接给单元格赋值&gt;&gt;&gt; cell.value = 'test'# 这里可以不写 value？&gt;&gt;&gt; sheet['A1'] = 'kk'&gt;&gt;&gt; sheet.cell(1,1).value = 'ff' 写入公式 123456789# 写入和值&gt;&gt;&gt; sheet['A14'] = "=SUM(B14:D14)"&gt;&gt;&gt; sheet['A14'].value'=SUM(B14:D14)'# 写入平均值&gt;&gt;&gt; sheet['A14'] = "=AVERAGE(B14:D14)"&gt;&gt;&gt; sheet['A14'].value'=AVERAGE(B14:D14)' 这里可发现，在读取的时候，返回的是公式本身 &#39;=AVERAGE(B14:D14)&#39;，而不是计算结果。若要返回计算结果，只有手动打开 test.xlsx 文件，然后点击保存更改。 单元格合并与拆分 12&gt;&gt;&gt; sheet.merge_cells('A1:A3')&gt;&gt;&gt; sheet.merge_cells('B1:D2') 如果这些要合并的单元格都有数据，只会保留左上角的数据，其他则丢弃。 分解类似： 12&gt;&gt;&gt; sheet.unmerge_cells('A1:A3')&gt;&gt;&gt; sheet.unmerge_cells('B1:D2') 单元格样式 123456789101112from openpyxl.styles import Font, colors, Alignment# 设置字体: 等线 24 号加粗斜体，字体颜色红色bold_itatic_24_font = Font(name="等线", size=24, italic=True, color=colors.RED, bold=True)sheet["B1"].font = bold_itatic_24_font# 对齐方式: B1 中的数据垂直居中和水平居中sheet["C1"].alignment = Alignment(horizontal="center", vertical="center")# 设置行高和列宽sheet.row_dimensions[2].height = 40sheet.column_dimensions["C"].width = 30 设置后的效果： openpyxl 模块的使用就到这里，完整使用示例可以参考我的上篇：Python 助你填写高考志愿。 其实还有很多高级用法，但个人觉得用的较少，有兴趣的可以参考官网：https://openpyxl.readthedocs.io/en/stable/]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 助你填写高考志愿]]></title>
    <url>%2Fpython-gaokao-2018.html</url>
    <content type="text"><![CDATA[最近一周一直在帮家里小弟看高考志愿，所以更新的没那么频繁了，请大家见谅。 在看各高校的往年分数时，忍不住手痒，想着能不能给它爬下来？哈哈，说干就干！ 1 流程分析之前无意中在这个网站发现有各个高校的历年录取分数线：https://gkcx.eol.cn。 我们的目标是用 Python 将下面页面的数据导出到 Excel： 这个页面的 URL 是：https://gkcx.eol.cn/schoolhtm/schoolTemple/school160.htm，显然是需要一个 school_id 拼接而成的，那么如何获取这个 school_id 呢？ 除非想办法爬取到所有院校的 school_id，这里我想着是从上面图中的搜索框进入： 这样，整体的业务流程我们就理清楚了： 先调用搜索的 URL 获取到高校的 school_id，拼接到高校的详情访问地址 访问详情地址，抓取目标数据 处理目标数据，存储到 Excel 中 2 获取 school_id按下 F12，可以看出搜索调用的 URL 是：https://gkcx.eol.cn/soudaxue/queryschool.html?&amp;keyWord1=南京邮电大学，但是我们发现该请求的 response 里并没有高校列表，所以猜测这里是有二次数据请求获取到高校的列表，然后解析显示到页面的。 顺着请求流，我们看到了这么一个请求： 并且它的 response 刚好是一个包含高校信息的 json，到这里应该还是顺利的，我们只要从这个 json 里解析出我们想要的东西，然后继续后面的步骤就可以了。要注意该请求的 Referer。 但是在解析这个 json 时会遇到一个小问题，返回的数据格式是这样的： 12345678(&#123; "totalRecord": &#123;"num": "2"&#125;, "school": [ &#123; "schoolid": "160", "schoolname": "南京邮电大学",...&#125;); 它是被 (); 包围着的，不是一个合法的 json 数据，这里需要对其进行处理后才能解析 json： 123# 返回数据包含 ();，需要特殊处理text = ((response.text).split(');',1)[0]).split('(',1)[1]j = json.loads(text) 3 分数线获取学校的详情页面是：https://gkcx.eol.cn/schoolhtm/schoolTemple/school160.htm，同样的套路，在点击后 response 里并没有分数线数据，我想也是二次请求吧，果然在请求流里找到了这个： 这里的两个请求刚好将高校的每年分数线和各专业的分数线以 XML 的格式返回，Very Good！ 下面要做的就是 XML 解析啦。 4 XML 解析这里我们使用 xml.etree.ElementTree 来解析 XML： 12345678910&lt;areapionts&gt; &lt;areapiont&gt; &lt;year&gt;2017&lt;/year&gt; &lt;specialname&gt;软件工程（嵌入式培养）&lt;/specialname&gt; &lt;maxfs&gt;369&lt;/maxfs&gt; &lt;varfs&gt;366&lt;/varfs&gt; &lt;minfs&gt;364&lt;/minfs&gt; &lt;pc&gt;一批&lt;/pc&gt; &lt;stype&gt;理科&lt;/stype&gt; &lt;/areapiont&gt; 由于数据比较规整，解析也很简单： 1234areapionts = ET.fromstring(response.text)for areapiont in areapionts: print(areapiont.find('year').text) print(areapiont.find('specialname').text) 5 Excel 写入Excel 的写入需要借助于 openpyxl 模块。 openpyxl 简单使用示例 12345678910111213141516171819202122&gt;&gt;&gt; import openpyxl&gt;&gt;&gt; wb = openpyxl.Workbook()# 初始时会生成一个 sheet 页&gt;&gt;&gt; wb.sheetnames['Sheet']# 创建 sheet 页&gt;&gt;&gt; wb.create_sheet(index=0,title='First')&lt;Worksheet "First"&gt;# 获取所有 sheet 页&gt;&gt;&gt; wb.sheetnames['First', 'Sheet']# 删除 sheet 页&gt;&gt;&gt; wb.remove(wb['Sheet'])&gt;&gt;&gt; wb.sheetnames['First']&gt;&gt;&gt; sheet = wb['First']# 设置单元格&gt;&gt;&gt; sheet['A1'] = '省份'&gt;&gt;&gt; sheet['B1'] = '学校'# 设置指定的单元格&gt;&gt;&gt; sheet.cell(1,3).value='test'&gt;&gt;&gt; wb.save('test.xlsx') XML 解析写入 Excel 1234567891011121314151617181920212223def gen_excel(school,xml,wb): sheet = wb.create_sheet(title='各专业历年录取分数线') sheet.column_dimensions['B'].width = 40 sheet['A1'] = '年份' sheet['B1'] = '专业' sheet['C1'] = '最高分' sheet['D1'] = '平均分' sheet['E1'] = '最低分' sheet['F1'] = '批次' sheet['G1'] = '录取批次' areapionts = ET.fromstring(xml) column = 1 for areapiont in areapionts: column += 1 sheet.cell(column,1).value = areapiont.find('year').text sheet.cell(column,2).value = areapiont.find('specialname').text sheet.cell(column,3).value = areapiont.find('maxfs').text sheet.cell(column,4).value = areapiont.find('varfs').text sheet.cell(column,5).value = areapiont.find('minfs').text sheet.cell(column,6).value = areapiont.find('pc').text sheet.cell(column,7).value = areapiont.find('stype').text wb.save('&#123;&#125;.xlsx'.format(school['schoolname'])) 执行效果1234$ python gkcx.pyPlease the school name：南京邮电大学共检索到 2 个高校：['南京邮电大学', '南京邮电大学通达学院']数据获取完成，已下载到脚本目录 结果看着还可以，但是还是有问题的，因为各省的分数线肯定是不一样的，这里默认检索出的是学校所在省的分数线，因此若要获取在其他省的分数线，还需要进一步处理，有兴趣的同学不妨动手试一下。后台回复「高考」可以获取源码。 福利预告 随着公众号的壮大，最近开始有出版社找到我进行赠书的合作活动，我会在最近几天将活动发出，有兴趣的不妨关注下本公众号，等待福利降临！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 实现京东自动签到领京豆]]></title>
    <url>%2Fpython-jd-beans.html</url>
    <content type="text"><![CDATA[今天带大家进行模拟京东登录，并进行签到获取京豆，1000 个京豆 = 10 元，毕竟「苍蝇也是肉」，每天用脚本可以获取大概 n 个京豆，是不是一个发现了一个「发家致富」的好路子？ 废话不多说，下面开始正题。 整体流程如下： 1 模拟登录首先我们需要的就是模拟京东登录，只有登录了才能进行签到领京豆等操作。模拟登录其实就是通过 HTTP 的 POST 请求讲用户的登录信息发送给服务器进行认证的过程。 1.1 登录数据分析登录过程表面上看着挺简单，我们只要在浏览器里输入用户名、密码，有时还需要输入一些连开发者都分辨不出的验证码。其实背后是浏览器帮忙做了很多工作（浏览器表示挺累的），因此我们要模拟登录，就要搞清楚浏览器在背后做了什么。 同样的套路，进入到京东的登录页面：https://passport.jd.com/uc/login?ltype=logout，按下 F12，页面输入登录信息后，点击登录（可以尝试输入一个错误的密码，因为登录后页面直接跳转到了主页面，看不到我们要的数据了），可以看到一个 POST 请求： 这里可以看到，浏览器发送了一个 POST 请求到 https://passport.jd.com/uc/loginService，然后在请求头上面带上了一些基本的参数，其中有一个 FormData，这里就是浏览器向服务器提交的表单信息。 看上去是不是一脸蒙蔽了，其实，这些信息大部分是可以在登录页面的源代码里找到的，源码中有一个 id 为 formlogin 的表单，其内容有： 1234567891011&lt;form id="formlogin" method="post" onsubmit="return false;"&gt; &lt;input type="hidden" id="sa_token" name="sa_token" value="B68C442BE64..." /&gt; &lt;input type="hidden" id="uuid" name="uuid" value="cde6e309-9fed-4511-b517-4ffd7777d31f" /&gt; &lt;input type="hidden" name="eid" id="eid" value="" class="hide" /&gt; &lt;input type="hidden" name="fp" id="sessionId" value="" class="hide" /&gt; &lt;input type="hidden" name="_t" id="token" value="_t" class="hide" /&gt; &lt;input type="hidden" name="loginType" id="loginType" value="f" class="hide" /&gt; &lt;input type="hidden" name="main_flag" id="main_flag" value="main_flag" class="hide" /&gt; &lt;input type="hidden" name="pubKey" id="pubKey" value="MIGfMA0GCSq..." class="hide" /&gt; &lt;input type="hidden" name="qHPHrmjSKm" value="YKsoe" /&gt;&lt;/form&gt; 可以看到一批 hidden，其实这些都是浏览器后台「偷偷」传给服务器的参数，只不过它们是被隐藏了的，前端页面不可见而已。可以用 BeautifulSoup 获取这些登录信息： 1234567sa_token = soup.find(id='sa_token')['value']uuid = soup.find(id='uuid')['value']loginType = soup.find(id='loginType')['value']pubKey = soup.find(id='pubKey')['value']_t = soup.find(id='token')['value']fp = soup.find(id='sessionId')['value']eid = soup.find(id='eid')['value'] 1.2 验证码的处理普通登陆的情况下验证码 authcode 只要为空即可，但是若京东认为有安全风险问题时，会出现验证码，那这个验证码如何处理呢？ 目前验证码处理仍然是一个比较困难的问题，处理方法一般可以分为自动识别和手动识别。 手动处理：就是通过验证码链接将验证码图片下载到本地，然后手动敲入完成信息录入。 自动识别：指使用一些高级的算法技术来完成的，如 OCR 文字识别，机器学习进行识别训练等。一般免费的文字识别算法识别率并不高，收费的识别效率还是可以接受的。 本文就采用手动录入验证码的方式。 首先，如何判断页面是否需要输入验证码？ 调试时，可以看到有这么一个请求：https://passport.jd.com/uc/showAuthCode： 其返回值是： 1(&#123;"verifycode":true&#125;) 显然，这个地址是用来判断是否该账号是否需要验证码的。 点击一下「换一张图片」，可以看到验证码的请求地址是：https://authcode.jd.com/verify/image?a=1&amp;acid=36f24f99-f86d-4e1b-957e-bd51cd3257a4&amp;uid=36f24f99-f86d-4e1b-957e-bd51cd3257a4&amp;yys=1529922165515。 同时，在登录页面源码中可以得到图片的地址信息：src2=”//authcode.jd.com/verify/image?a=1&amp;acid=37fe7934-fbc9-413d-b0a8-e0492e1d01b7&amp;uid=37fe7934-fbc9-413d-b0a8-e0492e1d01b7”，显然图片的获取地址是由 http: + src2 + yys= + Unix时间戳 拼接组成: 12auth_code_url = soup.find(id='JD_Verification1').get('src2')auth_code_url = 'http:&#123;&#125;&amp;yys=&#123;&#125;'.format(url, str(int(time.time()*1000))) 这样我们就能得到图片的下载地址，将其下载到本地，然后根据图片内容输入验证码即可。 1.3 会话保持假设我们已经登录成功，那该如何保持会话呢？也就是我们切换到其他网页后，如何保持会话状态，不用再次登录。 其实在后续访问其他页面时只要在 header 中包含用户 cookie 的话，不需用户名密码即可登录。 这里就要用到会话对象 requests.Session，会话对象让你能够跨请求保持某些参数。它也会在同一个 Session 实例发出的所有请求之间保持某些参数，比如 cookies，并且 requests 模块每次会自动处理 cookies，不需要我们手动来处理 cookie，是不是很方便！ 所以如果你向同一主机发送多个请求，底层的 TCP 连接将会被重用，从而也可以带来显著的性能提升。其高级用法可以参考文档：http://docs.python-requests.org/zh_CN/latest/user/advanced.html。 2 获取京豆通过上面的分析，我们解决了京东的登录问题，下面要做的就是京豆的领取啦。 领取京豆店铺签到的地址：http://bean.jd.com/myJingBean/list 分析店铺签到的页面源码（这里仅列出部分源码）： 12345&lt;ul class="bean-shop-list"&gt; &lt;li&gt; &lt;div class="s-bean"&gt;店内签到最多可领&lt;span class="ftc03"&gt;1京豆&lt;/span&gt;&lt;/div&gt; &lt;a href="http://misney.jd.com" target="_blank" class="s-btn" clstag="pageclick|keycount|myJingBean_201707111|18"&gt;去签到&lt;/a&gt; &lt;/li&gt; 可以看出，店铺列表是被 class=&quot;bean-shop-list&quot; 包裹的 li 组成，其中有店铺的超链接，我们需要访问这些链接地址进入到店铺主页进行签到。 随便访问一个签到店铺，查看签到的源码是一个地址：https://mall.jd.com/shopSign-1000006984.html，发现是由 固定地址 + 店铺 id 拼接而成的，那我们主要的工作就是获取店铺 id 了。 另外，在访问店铺时，在其 response 是包含 shop_id 的： 1&lt;input type="hidden" id="shop_id" value="1000003179" /&gt; 那我们就可以直接使用 BeautifulSoup 获取，然后拼接成签到地址： 1234# 获取店铺 idshop_id = soup.find(id='shop_id')['value']# 拼接签到地址sign_url = 'https://mall.jd.com/shopSign-&#123;&#125;.html'.format(shop_id) 这样就可以直接访问签到地址进行签到啦~ 运行12345678910$ python jd_beans.py请输入京东账号：xxxx请输入京东密码：xxxx请根据下载图片 authcode.jpg 输入验证码：et3r1. 获取登录信息成功2. 登录成功签到失败：http://sjhpchaju.jd.comHTTPConnectionPool(host='sjhpchaju.jd.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7f0bd105cf60&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))签到失败：http://huliuxiang.jd.comHTTPConnectionPool(host='huliuxiang.jd.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7f0bd0a2d0b8&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)) 由于网络原因，部分店铺签到失败。 P.S. 签到后，在京东记录页面好像没找到京东增加的记录，泪奔，不过我们是来学技术的，不要在乎这些蝇头小利。 3 总结本文的难点在于京东的登录过程，涉及到了 验证码、cookie 的处理，业务逻辑也稍微有些绕，需要判断是否需要验证码、是否登录成功等。其实，主要的就是在 HTTP 交互过程中抽取我们所要的目标数据。 另外，验证码处理部分还是有些问题，比如前面判断出登录不需要验证码，但是在登录时仍返回「请输入验证码」。还有，有兴趣的同学也可以进行扩展，比如秒杀、抢购等。 获取源码可以关注下面的公众号，回复「京东」即可。 参考： https://segmentfault.com/a/1190000013170936]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 语法糖之「列表推导式」]]></title>
    <url>%2Fpython-list-comprehension.html</url>
    <content type="text"><![CDATA[有时候一些普遍的设计模式应用得非常广泛，慢慢的就形成了一种语法，或者叫 语法糖，Python 中的列表推导式 就是其中的典型代表。列表推导式是一种可以让代码更简洁，并且可以增加可读性和执行效率的方法，但是要掌握好这个语法则有些难。 下面就带你好好认识下 列表推导式，学完之后你就知道这个语法糖有多「甜」。 1 从一个例子开始事情的起因是这样的，在交流群里，一个小伙伴问如何把下面这种数据： 12[&#123;'city': '北京北京', 'max_temp': '35', 'min_temp': '23'&#125;, &#123;'city': '北京海淀', 'max_temp': '36', 'min_temp': '23'&#125;] 转换成这种： 1[('北京北京', '35'), ('北京海淀', '36')] 即把一个 dict 组成的 list，从中抽取目标数据，转换成另外一个 list。 部分人的第一想法就是用 for 循环遍历 list，对每个元素进行处理： 1234old_list = [&#123;'city': '北京北京', 'max_temp': '35', 'min_temp': '23'&#125;, &#123;'city': '北京海淀', 'max_temp': '36', 'min_temp': '23'&#125;]new_list = []for item in old_list: new_list.append((item['city'], item['max_temp'])) 其实，这种时候就可以用列表推导式： 1new_list = [(item['city'], item['max_temp']) for item in old_list] 是不是更加优雅，简洁？ 2 到底什么是列表推导式通过上面的例子，我们可以看出列表解析式是将一个列表（实际上适用于任何可迭代对象）转换成另一个列表的工具。 并且在转换过程中，可以指定元素必须符合一定的条件，才能添加至新的列表中，这样每个元素都可以按需要进行转换。 可迭代对象：以直接作用于 for 循环的数据类型有以下几种： 集合数据类型，如 list、 tuple、 dict、 set、 str 等； generator，包括生成器和带 yield 的 generator function。 这些可以直接作用于 for 循环的对象统称为可迭代对象： Iterable。可以使用 isinstance() 判断一个对象是否是 Iterable 对象，如：isinstance([1,2,3], Iterable) 3 基本语法1new_list = [expression(i) for i in old_list if condition(i)] 翻译成 for 循环就是： 1234new_list = []for i in old_list: if (condition): new_list.append(expression(i)) 4 使用示例4.1 list 元素的简单处理123456789101112&gt;&gt;&gt; x = [i for i in range(10)]# 对每个元素求平方&gt;&gt;&gt; print([i**2 for i in x])[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]# 每个元素乘以 3&gt;&gt;&gt; print([i*3 for i in x])[0, 3, 6, 9, 12, 15, 18, 21, 24, 27]# 获取其中的偶数&gt;&gt;&gt; print([i for i in x if i%2==0])[0, 2, 4, 6, 8] 4.2 for 的嵌套语法如下： 1234[ expression for x in X [if condition1 if condition2] for y in Y [if condition] ... for n in N [if condition] ] 12345&gt;&gt;&gt; print([ (x, y) for x in range(10) if x % 2 if x &gt; 3 for y in range(10) if y &gt; 7 if y != 8 ])[(5, 9), (7, 9), (9, 9)]&gt;&gt;&gt; [(x,y) for x in range(3) for y in range(3)][(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)] 理论上可以嵌套多层，不过一般两层，不会超过三层。 4.3 对字符串操作123456789&gt;&gt;&gt; words = ["this","is","a","list","of","words"]# 取每个单词的首字母&gt;&gt;&gt; print( [word[0] for word in words])['t', 'i', 'a', 'l', 'o', 'w']# 对字符串列表中的单词取小写&gt;&gt;&gt; [x.lower() for x in ["A","b","Ca"]]['a', 'b', 'ca'] 4.4 对 dict 操作12345678910111213&gt;&gt;&gt; d = &#123;'a':1,'b':2,'c':3&#125;# 筛选 value 值&gt;&gt;&gt; print([i for i in d.values() if i &gt;1])[2, 3]# 获取 key 值列表，并且可以加 if 判断&gt;&gt;&gt; print([i for i in d.keys()])['b', 'a', 'c']# 在 value 不重复的情况下，交换 key 和 value&gt;&gt;&gt; print(&#123;(j,i) for (i,j) in d.items() &#125;)&#123;(1, 'a'), (3, 'c'), (2, 'b')&#125; 列表推导式讲到这里，相信大家应该都能理解个差不多了。从实际使用经验来看，列表推导式使用的频率是非常高的，也是相当好用的。掌握列表推导式使用时机的关键，在于不断练习识别那些看上去像列表推导式的问题。 而对于列表推导式的多层 for 循环，尤其是 3 层以上的或带复杂筛选条件的，会牺牲较多的可读性，还是建议用 for 循环实现，多几行代码就多几行吧。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 爬虫之 Beautiful Soup 模块使用指南]]></title>
    <url>%2Fpython-Beautiful-Soup-base.html</url>
    <content type="text"><![CDATA[爬取网页的流程一般如下： 选着要爬的网址（url） 使用 python 登录上这个网址（urlopen、requests 等） 读取网页信息（read() 出来） 将读取的信息放入 BeautifulSoup 使用 BeautifulSoup 选取 tag 信息等 可以看到，页面的获取其实不难，难的是数据的筛选，即如何获取到自己想要的数据。本文就带大家学习下 BeautifulSoup 的使用。 BeautifulSoup 官网介绍如下： Beautiful Soup 是一个可以从 HTML 或 XML 文件中提取数据的 Python 库，它能够通过你喜欢的转换器实现惯用的文档导航、查找、修改文档的方式，能够帮你节省数小时甚至数天的工作时间。 1 安装可以利用 pip 直接安装： 1$ pip install beautifulsoup4 BeautifulSoup 不仅支持 HTML 解析器，还支持一些第三方的解析器，如 lxml，XML，html5lib 但是需要安装相应的库。如果我们不安装，则 Python 会使用 Python 默认的解析器，其中 lxml 解析器更加强大，速度更快，推荐安装。 12$ pip install html5lib$ pip install lxml 2 BeautifulSoup 的简单使用首先我们先新建一个字符串，后面就以它来演示 BeautifulSoup 的使用。 12345678910111213html_doc = """&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Elsie&lt;/a&gt;,&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class="story"&gt;...&lt;/p&gt;""" 使用 BeautifulSoup 解析这段代码，能够得到一个 BeautifulSoup 的对象，并能按照标准的缩进格式的结构输出: 123&gt;&gt;&gt; from bs4 import BeautifulSoup&gt;&gt;&gt; soup = BeautifulSoup(html_doc, "lxml")&gt;&gt;&gt; print(soup.prettify()) 篇幅有限，输出结果这里不再展示。 另外，这里展示下几个简单的浏览结构化数据的方法： 1234567891011121314&gt;&gt;&gt; soup.title&lt;title&gt;The Dormouse's story&lt;/title&gt;&gt;&gt;&gt; soup.title.name'title'&gt;&gt;&gt; soup.title.string"The Dormouse's story"&gt;&gt;&gt; soup.p['class']['title']&gt;&gt;&gt; soup.a&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;&gt;&gt;&gt; soup.find_all('a')[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]&gt;&gt;&gt; soup.find(id='link1')&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt; 3 对象的种类Beautiful Soup 将复杂 HTML 文档转换成一个复杂的树形结构，每个节点都是 Python 对象，所有对象可以归纳为 4 种: Tag、NavigableString、BeautifulSoup、Comment 。 3.1 TagTag通俗点讲就是 HTML 中的一个个标签，像上面的 div，p，例如： 123&lt;title&gt;The Dormouse's story&lt;/title&gt; &lt;&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt; 可以利用 soup 加标签名轻松地获取这些标签的内容。 1234&gt;&gt;&gt; print(soup.p)&lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;&gt;&gt;&gt; print(soup.title)&lt;title&gt;The Dormouse's story&lt;/title&gt; 不过有一点是，它查找的是在所有内容中的第一个符合要求的标签，如果要查询所有的标签，我们在后面进行介绍。 每个 Tag 有两个重要的属性 name 和 attrs，name 指标签的名字或者 tag 本身的 name，attrs 通常指一个标签的 class。 1234&gt;&gt;&gt; print(soup.p.name)p&gt;&gt;&gt; print(soup.p.attrs)&#123;'class': ['title']&#125; 3.2 NavigableStringNavigableString：获取标签内部的文字，如，soup.p.string。 12&gt;&gt;&gt; print(soup.p.string)The Dormouse's story 3.3 BeautifulSoupBeautifulSoup：表示一个文档的全部内容。大部分时候，可以把它当作 Tag 对象，是一个特殊的 Tag。 3.4 CommentComment：Comment 对象是一个特殊类型的 NavigableString 对象，其输出的内容不包括注释符号，但是如果不好好处理它，可能会对我们的文本处理造成意想不到的麻烦。 1234567&gt;&gt;&gt; markup = "&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;"&gt;&gt;&gt; soup = BeautifulSoup(markup)&gt;&gt;&gt; comment = soup.b.string&gt;&gt;&gt; print(comment)Hey, buddy. Want to buy a used parser?&gt;&gt;&gt; type(comment)&lt;class 'bs4.element.Comment'&gt; b 标签里的内容实际上是注释，但是如果我们利用 .string 来输出它的内容，我们发现它已经把注释符号去掉了，所以这可能会给我们带来不必要的麻烦。 这时候我们可以先判断了它的类型，是否为 bs4.element.Comment 类型，然后再进行其他操作，如打印输出等。 4 搜索文档树BeautifulSoup 主要用来遍历子节点及子节点的属性，并提供了很多方法，比如获取 子节点、父节点、兄弟节点等，但通过实践来看，这些方法用到的并不多。我们主要用到的是从文档树中搜索出我们的目标。 通过点取属性的方式只能获得当前文档中的第一个 tag，例如，soup.li。如果想要得到所有的&lt;li&gt; 标签，就需要用到 find_all()，find_all() 方法搜索当前 tag 的所有 tag 子节点，并判断是否符合过滤器的条件 find_all() 所接受的参数如下： 1find_all( name , attrs , recursive , text , **kwargs ) 4.1 按 name 搜索可以查找所有名字为 name 的 tag，字符串对象会被自动忽略掉。 1234&gt;&gt;&gt; soup.find_all('b')[&lt;b&gt;The Dormouse's story&lt;/b&gt;]&gt;&gt;&gt; soup.find_all('a')[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;] 4.2 按 id 搜索如果文档树中包含一个名字为 id 的参数，其实在搜索时会把该参数当作指定名字 tag 的属性来搜索: 12&gt;&gt;&gt; soup.find_all(id='link1')[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;] 4.3 按 attr 搜索有些 tag 属性在搜索不能使用，比如 HTML5 中的 data-* 属性，但是可以通过 find_all() 方法的 attrs 参数定义一个字典参数来搜索包含特殊属性的 tag。 其实 id 也是一个 attr： 12&gt;&gt;&gt; soup.find_all(attrs=&#123;'id':'link1'&#125;)[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;] 4.4 按 CSS 搜索按照 CSS 类名搜索 tag 的功能非常实用，但标识 CSS 类名的关键字 class 在 Python 中是保留字，使用 class 做参数会导致语法错误。因此从 Beautiful Soup 的 4.1.1 版本开始，可以通过 class_ 参数搜索有指定 CSS 类名的 tag: 12&gt;&gt;&gt; soup.find_all(class_='sister')[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;] 4.5 string 参数通过 string 参数可以搜搜文档中的字符串内容。与 name 参数的可选值一样，string 参数接受字符串、正则表达式、列表、True。 12&gt;&gt;&gt; soup.find_all('a', string='Elsie')[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;] 4.6 recursive 参数调用 tag 的 find_all() 方法时，Beautiful Soup 会检索当前 tag 的所有子孙节点，如果只想搜索 tag 的直接子节点，可以使用参数 recursive=False。 4.6 find() 方法它与 find_all() 方法唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表，而 find() 方法只返回第一个匹配的结果。 4.7 get_text() 方法如果只想得到 tag 中包含的文本内容，那么可以用 get_text() 方法，这个方法获取到 tag 中包含的所有文本内容。 1234&gt;&gt;&gt; soup.find_all('a', string='Elsie')[0].get_text()'Elsie'&gt;&gt;&gt; soup.find_all('a', string='Elsie')[0].string'Elsie' 至此，Beautiful Soup 的常用使用方法已讲完，若果想了解更多内容，建议看下官方文档：https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/。 总结本篇主要带大家了解了 Beautiful Soup，结合一些小例子，相信大家对 Beautiful Soup 已不再陌生，下回会带大家结合 Beautiful Soup 进行爬虫的实战，欢迎继续关注！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手把手教你用 Python 来朗读网页]]></title>
    <url>%2Fpython-url-to-voice.html</url>
    <content type="text"><![CDATA[是不是有的时候懒得自己看新闻？那么不妨试试用 Python 来朗读给你听吧。 网页转换成语音，步骤无外乎： 网页正文识别，获取到正文的文本内容； 文本转语音，通过接口将文本转换成语音文件； 语音文件的发声，即将语音文件读出； 网页正文识别我们之所以用 Python，就是因为 Python 有着丰富的库，网页正文识别也不在话下。这里我尝试了 readability、goose-extractor、cx-extractor-python， readabilityreadability 支持 Python3，使用 pip install readability-lxml 安装即可。 readability 使用起来也很方便： 123456import requestsfrom readability import Documentresponse = requests.get('https://hoxis.github.io/run-ansible-without-specifying-the-inventory-but-the-host-directly.html')doc = Document(response.text)print(doc.title()) 但是 readability 提取到的正文内容不是文本，里面仍包含 HTML 标签。 当然也可以结合其他组件再对 HTML 进行处理，如 html2text，我们这里就不再延伸，有兴趣的可以自行尝试。 goose3Goose 本来是一个用 Java 编写的文章提取器，后来就有了 Python 实现版： goose3 。 使用起来也很方便，同时对中文支持也不错。使用 pip install goose3 即可安装。 12345678910&gt;&gt;&gt; from goose3 import Goose&gt;&gt;&gt; from goose3.text import StopWordsChinese&gt;&gt;&gt; url = 'http://news.china.com/socialgd/10000169/20180616/32537640_all.html'&gt;&gt;&gt; g = Goose(&#123;'stopwords_class': StopWordsChinese&#125;)&gt;&gt;&gt; article = g.extract(url=url)&gt;&gt;&gt; print(article.cleaned_text[:150])北京时间6月15日23:00(圣彼得堡当地时间18:00)，2018年世界杯B组一场比赛在圣彼得堡球场展开角逐，伊朗1比0险胜摩洛哥，伊朗前锋阿兹蒙半场结束前错过单刀机会，鲍哈杜兹第95分钟自摆乌龙。这是伊朗20年来首度在世界杯决赛圈取胜。本届世界杯，既相继出现替补便进球，贴补梅开二度以及东道主 可以看出网页正文提取效果还不错，基本满足我们的要求，可以使用！ 注意：goose 还有另外一个 Python2 的版本：Python-Goose，使用方法和 goose3 基本一样。 文本转语音文本转语音，百度、阿里、腾讯、讯飞等都有提供 REST API 接口，阿里和腾讯的申请相对时间较长，阿里的貌似还要收费，百度和讯飞的在线申请后即可使用，没办法，好的东西得来总是要曲折一些。其中百度的没有调用量的限制（其实默认是 200000 次/天），讯飞有每天 500 次的限制。 这里我们使用百度的 REST API 接口中的语言合成接口，一方面原因是百度的调用次数没有限制，另一方面，我大致看了下讯飞的接口文档，接口限制还是比较多的。还有就是百度提供了 REST API 的 Python 封装，使用也更方便。 baidu-aip 的使用百度提供了 Python SDK，使用 pip install baidu-aip 可以直接安装。接口的使用可以参考接口文档：http://ai.baidu.com/docs#/TTS-Online-Python-SDK/top。 使用示例如下： 123456789101112131415161718192021from aip import AipSpeech"""你的 APPID AK SK 均可在服务控制台中的应用列表中查看。"""APP_ID = '你的 App ID'API_KEY = '你的 Api Key'SECRET_KEY = '你的 Secret Key'client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)result = client.synthesis('你好，你在做什么', 'zh', 3, &#123; 'vol': 5,&#125;)# 识别正确返回语音二进制 错误则返回dict 参照下面错误码if not isinstance(result, dict): with open('auido.mp3', 'wb') as f: f.write(result) 接口参数： 参数 类型 描述 是否必须 tex String 合成的文本，使用UTF-8编码，请注意文本长度必须小于1024字节 是 lang String 语言选择,填写zh 是 ctp String 客户端类型选择，web端填写1 是 cuid String 用户唯一标识，用来区分用户，填写机器 MAC 地址或 IMEI 码，长度为60以内 否 spd String 语速，取值0-9，默认为5中语速 否 pit String 音调，取值0-9，默认为5中语调 否 vol String 音量，取值0-15，默认为5中音量 否 per String 发音人选择,0为女声，1为男声，3为情感合成-度逍遥，4为情感合成-度丫丫，默认为普通女 否 接口对单次传入的文本进行了限制，合成文本长度必须小于1024字节，如果文本长度过长，就需要进行切割处理，采用多次请求的方式，分别转换成语音文件，最后再将多个语音文件合并成一个。 文本切割可以使用如下代码将文本分割成多个长度为 500 的文本列表 12# 将文本按 500 的长度分割成多个文本text_list = [text[i:i+500] for i in range(0, len(text), 500)] 语言文件合并我们使用 pydub 来处理生成的音频文件。使用 pip install pydub 即可安装。 另外还 Ubuntu 环境需要安装依赖 sudo apt-get install libav-tools，Windows 环境需要到 https://ffmpeg.zeranoe.com/builds/ 下载 FFmpeg，并将其配置到环境变量中。 若还有问题，可以参考官网配置：https://github.com/jiaaro/pydub。 1234567891011121314151617# 合并音频文件def merge_voice(file_list): voice_dict = &#123;&#125; song = None for i,f in enumerate(file_list): if i == 0: song = AudioSegment.from_file(f,"mp3") else: # 拼接音频文件 song += AudioSegment.from_file(f,"mp3") # 删除临时音频 os.unlink(f) # 导出合并后的音频文件，格式为MP3格式 file_name = str(uuid.uuid1()) + ".mp3" song.export(file_name, format="mp3") return file_name 通过百度的接口，我们可以将文字转化成音频文件，下面的问题就是如何播放音频文件。 音频文件播放网上获取到 Python 播放 wav 文件的方式由好几种，包括 pyaudio、pygame、winsound、playsound。不过测试下来，只有 playsound 成功。其他方式有兴趣的可以试下，有问题可以留言交流。 使用 pip install playsound 安装后即可使用。 使用也很简单： 12&gt;&gt;&gt; from playsound import playsound&gt;&gt;&gt; playsound('/path/to/a/sound/file/you/want/to/play.mp3') 说明：音频的播放需要在图形化页面下运行，因为命令行模式下，没有播放声音的出口。 实现代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# encoding:utf-8import uuidimport reimport osimport argparsefrom pydub import AudioSegmentfrom aip import AipSpeechfrom playsound import playsoundfrom goose3 import Goosefrom goose3.text import StopWordsChinese""" 你的 百度 APPID AK SK """APP_ID = '11407664'API_KEY = 'GT69E8M6sgOcSnIGElrgXo1e'SECRET_KEY = 'fOCr1mwnyGOEjZg93GoonaGqzqp0paIB'# 命令行输入参数处理parser = argparse.ArgumentParser()parser.add_argument('-u', '--url', type=str, help="input the target url")# 获取参数args = parser.parse_args()URL = args.urlclient = AipSpeech(APP_ID, API_KEY, SECRET_KEY)def text_to_voice(text): file_name = str(uuid.uuid1()) + '.mp3' result = client.synthesis(text, 'zh', 3, &#123; 'vol': 5, &#125;) # 识别正确返回语音二进制 错误则返回 dict 参照下面错误码 if not isinstance(result, dict): with open(file_name, 'wb+') as f: f.write(result) return file_namedef get_text(url): g = Goose(&#123;'stopwords_class': StopWordsChinese&#125;) article = g.extract(url=url) return article.cleaned_text# 合并音频文件def merge_voice(file_list): voice_dict = &#123;&#125; song = None for i,f in enumerate(file_list): if i == 0: song = AudioSegment.from_file(f,"mp3") else: # 拼接音频文件 song += AudioSegment.from_file(f,"mp3") # 删除临时音频 os.unlink(f) # 导出合并后的音频文件，格式为MP3格式 file_name = str(uuid.uuid1()) + ".mp3" song.export(file_name, format="mp3") return file_nameif __name__ == "__main__": # url = "http://news.china.com/socialgd/10000169/20180616/32537640_all.html" text = get_text(URL) # 将文本按 500 的长度分割成多个文本 text_list = [text[i:i+500] for i in range(0, len(text), 500)] file_list = [] for t in text_list: file_list.append(text_to_voice(t)) # print(file_list) final_voice = merge_voice(file_list) print(final_voice) # 播放音频 playsound(final_voice) 运行1python page2voice.py -u "https://so.gushiwen.org/shiwenv_c244fc77f6fb.aspx" 运行后，代码就会自动解析网页并进行朗读啦。 总结至此，网页到音频的转换就结束了，当然程序没有这么完美，比如中英文混合的网页解析和转换的结果就不怎么理想，但是纯中文的新闻页面效果还是不错的。 源码已上传至 GitHub，欢迎取阅。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语音</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 爬取知识星球数据 - 词云分析]]></title>
    <url>%2Fpython-zsxq-cloud.html</url>
    <content type="text"><![CDATA[最近打算抓取知识星球的数据，分析下大家喜欢发布哪方面的主题，用词云的方式展示出来。 请求参数分析这里我们使用网页版进行爬取，首先用 Chrome 登陆知识星球，登陆成功后按下 F12 打开 Developer Tools，并进入查看网络请求窗口。 然后在页面点击一个订阅的星球，此时网络会去请求该星球的数据，肯定会有一个 topics?scope=digests&amp;count=20 的 GET 请求，点击该请求，在请求头里会有一个 Authorization 参数，将该参数对应的值记下。该参数相当于一个认证 ID，在一段时间内一直有效，后面爬虫就会一直使用该数值请求数据。 网页版星球是没有分页的，后在下拉框到底部后自动加载，此时我们可以看到请求地址是：topics?count=20&amp;end_time=2018-06-14T00%3A00%3A52.603%2B0800，是根据时间来进行请求的，这个请求应该满足我们按时段分析数据的需求。 我们来分析 帅张和他的朋友们 的星球数据，其基本 URL 是 https://api.zsxq.com/v1.10/groups/2421112121/。 数据解析用 Postman 测试接口，可以得到返回的数据是一大坨 json 数据，形如： 123456789101112131415161718192021&#123; "succeeded": true, "resp_data": &#123; "topics": [ &#123; "topic_id": 15412524852542, "group": &#123; "group_id": 2421112121, "name": "帅张和他的朋友们" &#125;, "type": "talk", "talk": &#123; "owner": &#123; "user_id": 552444151844, "name": "啊拉丁神经", "avatar_url": "https://file.zsxq.com/1d5/12/d51200c1e3a063c47b1bcc1c40dc89c08a291fadfe4cb9fa193fbcc6584cb0e9_min.jpg" &#125;, "text": "这里是主题内容" &#125;, "likes_count": 11, "comments_count": 12, 可以看出返回的数据是一个 topics 的 list，其中每个 topic 中包含着用户信息、主题内容、点赞数、评论数、评论内容、点赞者的信息、创建时间等等，我们可以使用 jsonpath 组件从返回数据中解析出我们想要的文本数据。 1jsonpath.jsonpath(result, "$..topics[*]..text") 实现准备工作 安装必要的组件：jsonpath、jieba、numpy、wordcloud 等； 准备字体文件，如本文的 fangsong_GB2312.ttf； 准备词云形状图片，如本文的 python.png； 词云展示的大致步骤如下： 读取本地的文件 使用 jieba 进行分词，并对分词的结果以空格隔开； 对分词后的文本生成词云； jieba 分词123f = open('result.txt').read()wordlist = jieba.cut(f, cut_all=True)wl_space_split = " ".join(wordlist) 这样就可以得到一个分词后的 list 结果。 其实生成词云的 generate 函数是可以对全部文本进行自动分词，但是对中文支持不好，所以这里我们使用 jieba 先进行了分词。 生成词云1234coloring = numpy.array(Image.open("python.png"))my_wordcloud = WordCloud(background_color="white", max_words=2000, mask=coloring, font_path='fangsong_GB2312.ttf', max_font_size=50, random_state=42).generate(wl_space_split)my_wordcloud.to_file('test.png') 其中参数含义如下： width,height,margin 可以设置图片属性 通过 font_path 参数来设置字体集 通过 mask 参数 来设置词云形状 另外，font_path：这个是在词云图中显示文字的字体存放的路径，特别是在显示中文的时候，这个参数尤为重要，如果缺省的话容易造成乱码，如下： 运行12345$ python zsxq_cloud.py -d "2018-06-13"Building prefix dict from the default dictionary ...Loading model from cache /tmp/jieba.cacheLoading model cost 1.000 seconds.Prefix dict has been built succesfully. 运行成功后会在当前目录生成一个 test.png 的图片： 总结可以看到，词云展示实现起来不过 10 行代码，数据的获取才是关键。这里我只是分析一天的数据生成词云，那么一个月的数据如何获取呢？大家不妨想一下。 另外，下回准备对星球数据换个方向进行分析，分析下大家喜欢在哪一天发文，在一天里的什么时候发文，且听下回分解~ 代码已上传至 GitHub，点击阅读原文下载。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 抓取豆瓣电影 TOP250]]></title>
    <url>%2Fpython-douban-top250.html</url>
    <content type="text"><![CDATA[这次要抓取的目标是豆瓣电影 TOP250，主要是要的是 BeautifulSoup，一道美味的汤啊~ &#x1f375; 解析其实简单的网络爬虫无外乎查看网页源码，从源码中获取自己想要的东西，然后对其进行处理。 通过查看页面元素代码可以看出： 电影条目是被 &lt;ol class=&quot;grid_view&quot;&gt; 所包围的； 其中每个电影条目是一个 &lt;li&gt;； 另外，每页有 25 个条目，共 10 页，这意味着需要解析多页数据。 我们来看下其中一个条目的源码： 12345678910111213141516171819202122232425262728293031&lt;li&gt; &lt;div class="item"&gt; &lt;div class="pic"&gt; &lt;em class=""&gt;1&lt;/em&gt; &lt;a href="https://movie.douban.com/subject/1292052/"&gt; &lt;img width="100" alt="肖申克的救赎" src="https://img3.doubanio.com/view/photo/s_ratio_poster/public/p480747492.webp" class=""&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="info"&gt; &lt;div class="hd"&gt; &lt;a href="https://movie.douban.com/subject/1292052/" class=""&gt; &lt;span class="title"&gt;肖申克的救赎&lt;/span&gt; &lt;span class="title"&gt;&amp;nbsp;/&amp;nbsp;The Shawshank Redemption&lt;/span&gt; &lt;span class="other"&gt;&amp;nbsp;/&amp;nbsp;月黑高飞(港) / 刺激1995(台)&lt;/span&gt;&lt;/a&gt; &lt;span class="playable"&gt;[可播放]&lt;/span&gt;&lt;/div&gt; &lt;div class="bd"&gt; &lt;p class=""&gt;导演: 弗兰克·德拉邦特 Frank Darabont&amp;nbsp;&amp;nbsp;&amp;nbsp;主演: 蒂姆·罗宾斯 Tim Robbins /... &lt;br&gt;1994&amp;nbsp;/&amp;nbsp;美国&amp;nbsp;/&amp;nbsp;犯罪 剧情&lt;/p&gt; &lt;div class="star"&gt; &lt;span class="rating5-t"&gt;&lt;/span&gt; &lt;span class="rating_num" property="v:average"&gt;9.6&lt;/span&gt; &lt;span property="v:best" content="10.0"&gt;&lt;/span&gt; &lt;span&gt;1041580人评价&lt;/span&gt;&lt;/div&gt; &lt;p class="quote"&gt; &lt;span class="inq"&gt;希望让人自由。&lt;/span&gt;&lt;/p&gt; &lt;p&gt; &lt;span class="gact"&gt; &lt;a href="https://movie.douban.com/wish/50494322/update?add=1292052" target="_blank" class="j a_collect_btn" name="sbtn-1292052-wish" rel="nofollow"&gt;想看&lt;/a&gt;&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/li&gt; 对于每个条目，我们需要解析出其中的 电影名称、评分、评价人数，及一句话点评。 标题、评分、评价解析标题是在 &lt;span class=&quot;title&quot;&gt;肖申克的救赎&lt;/span&gt; 里的，我们可以使用 1find("span", attrs=&#123;"class": "title"&#125;).getText() 获取到，但是明显这里又多个 &lt;span class=&quot;title&quot;&gt;，那我们就只获取第一个，其他的不关心。 评分和评价的解析和标题类似，用同一种解析方法解析即可。 评价人数解析评价人数这里是这样的： &lt;span&gt;1041580人评价&lt;/span&gt;，明显跟上面的不同，它没有 class 属性，这里只能通过 text 来查找了： 1find(text=re.compile('人评价$')) 这里用了正则表达式来进行匹配，即匹配以 人评价 结尾的文本。 下一页解析1234&lt;span class="next"&gt; &lt;link rel="next" href="?start=25&amp;amp;filter="/&gt; &lt;a href="?start=25&amp;amp;filter=" &gt;后页&amp;gt;&lt;/a&gt;&lt;/span&gt; 对照代码，需要从中解析出下一页的连接 ?start=25&amp;amp;filter=。 解析方法类似于标题的解析，先解析出 &lt;span class=&quot;next&quot;&gt;，然后解析其中的 &lt;a&gt; 标签。 1find("span", attrs=&#123;"class":"next"&#125;).find("a") 要解析的东西基本上就是这些，最后需要将解析结果保存到文件。 实现代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# encoding:utf-8import requests, refrom bs4 import BeautifulSoupdef download_page(url): response = requests.get(url) soup = BeautifulSoup(response.text, "lxml") return soupdef parse_soup(soup): return_list = [] # 利用 class 属性找到 grid grid = soup.find("ol", attrs=&#123;"class": "grid_view"&#125;) # 不加 attrs= 也可以 # grid = soup.find("ol", &#123;"class": "grid_view"&#125;) if grid: # 利用标签获取 list movie_list = grid.find_all("li") # 遍历 list for movie in movie_list: # 一个电影有多个名字，这里只取第一个 # getText() 方法获取到值 title = movie.find("span", attrs=&#123;"class": "title"&#125;).getText() # print(title) rating_num = movie.find("span", attrs=&#123;"class": "rating_num"&#125;).getText() inq = movie.find("span", attrs=&#123;"class": "inq"&#125;) # 利用 text 配合正则表达式匹配搜索文本 rating_p = soup.find(text=re.compile('人评价$')) # 有些暂时没有一句话评论 if not inq: inq = "暂无" else: inq = inq.getText() return_list.append(title + "，" + rating_p + "，评分：" + rating_num + "，一句话评价：" + inq) next_page = soup.find("span", attrs=&#123;"class":"next"&#125;).find("a") if next_page: return return_list, next_page["href"] else: return return_list, Noneif __name__ == "__main__": url = "https://movie.douban.com/top250" next_url = "" # 将结果保存到文件 with open("doubanMoviesTop250.txt","w+") as f: while next_url or next_url == "": soup = download_page(url + next_url) movie_list, next_url = parse_soup(soup) # 将 list 拆分成不同行 f.write("\n".join(movie_list)) 运行结果12345678910111213141516171819202122232425$ cat doubanMoviesTop250.txt肖申克的救赎，1041580人评价，评分：9.6，一句话评价：希望让人自由。霸王别姬，1041580人评价，评分：9.5，一句话评价：风华绝代。这个杀手不太冷，1041580人评价，评分：9.4，一句话评价：怪蜀黍和小萝莉不得不说的故事。阿甘正传，1041580人评价，评分：9.4，一句话评价：一部美国近现代史。美丽人生，1041580人评价，评分：9.5，一句话评价：最美的谎言。千与千寻，1041580人评价，评分：9.3，一句话评价：最好的宫崎骏，最好的久石让。泰坦尼克号，1041580人评价，评分：9.3，一句话评价：失去的才是永恒的。辛德勒的名单，1041580人评价，评分：9.4，一句话评价：拯救一个人，就是拯救整个世界。盗梦空间，1041580人评价，评分：9.3，一句话评价：诺兰给了我们一场无法盗取的梦。机器人总动员，1041580人评价，评分：9.3，一句话评价：小瓦力，大人生。三傻大闹宝莱坞，1041580人评价，评分：9.2，一句话评价：英俊版憨豆，高情商版谢耳朵。海上钢琴师，1041580人评价，评分：9.2，一句话评价：每个人都要走一条自己坚定了的路，就算是粉身碎骨。忠犬八公的故事，1041580人评价，评分：9.2，一句话评价：永远都不能忘记你所爱的人。放牛班的春天，1041580人评价，评分：9.2，一句话评价：天籁一般的童声，是最接近上帝的存在。大话西游之大圣娶亲，1041580人评价，评分：9.2，一句话评价：一生所爱。楚门的世界，1041580人评价，评分：9.1，一句话评价：如果再也不能见到你，祝你早安，午安，晚安。龙猫，1041580人评价，评分：9.1，一句话评价：人人心中都有个龙猫，童年就永远不会消失。教父，1041580人评价，评分：9.2，一句话评价：千万不要记恨你的对手，这样会让你失去理智。星际穿越，1041580人评价，评分：9.2，一句话评价：爱是一种力量，让我们超越时空感知它的存在。熔炉，1041580人评价，评分：9.2，一句话评价：我们一路奋战不是为了改变世界，而是为了不让世界改变我们。乱世佳人，1041580人评价，评分：9.2，一句话评价：Tomorrow is another day.触不可及，1041580人评价，评分：9.2，一句话评价：满满温情的高雅喜剧。无间道，1041580人评价，评分：9.1，一句话评价：香港电影史上永不过时的杰作。当幸福来敲门，1041580人评价，评分：8.9，一句话评价：平民励志片。 搞定，后面对 BeautifulSoup 的用法再进行一个详细的研究吧。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何不通过 inventory 文件，直接指定 host 运行 Ansible？]]></title>
    <url>%2Frun-ansible-without-specifying-the-inventory-but-the-host-directly.html</url>
    <content type="text"><![CDATA[使用过 ansible 的都知道，不管是运行 Ad-Hoc 还是 playbook，都需要指定一个 inventory 文件，或者使用默认的 inventory 文件。但是现在有一个主机，它尚未在 inventory 文件中配置，那么我们该如何用 ansible 对其进行操作呢？ 一般我们执行都是这样的： 12345# ansible 172.16.1.7 -m ping172.16.1.7 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125; 这时需要在 inventory 文件 /etc/ansible/hosts 中配置 172.16.1.7 信息： 12[test]172.16.1.7 那么，如果没有在 inventory 文件中配置该主机信息，又想用 ansible 对其进行操作呢？ 见证奇迹的时刻到了，这个神奇的主角就是 , 字符，使用方法如下： 123456# Host and IP addressansible all -i example.com,ansible all -i 93.184.216.119,# Requires 'hosts: all' in your playbookansible-playbook -i example.com, playbook.yml 需要注意的是，需要指定范围为 all 12345# ansible all -i 172.16.1.7, -m ping172.16.1.7 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125; 参考： https://stackoverflow.com/questions/17188147/how-to-run-ansible-without-specifying-the-inventory-but-the-host-directly]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 将图片转为字符画]]></title>
    <url>%2Fpython-picture-to-ascii.html</url>
    <content type="text"><![CDATA[字符画是一系列字符的组合，我们可以把字符看作是比较大块的像素，一个字符能表现一种颜色（暂且这么理解吧），字符的种类越多，可以表现的颜色也越多，图片也会更有层次感。 问题来了，像素是有颜色深浅的，我们如何将带有不同颜色的像素编码为对应的字符呢？我们是要转换一张彩色的图片，这么多的颜色，要怎么对应到单色的字符画上去？ 转化方法转化的整体思路就是：RGB-&gt;灰度-&gt;字符，详细来说就是： 将彩色图片转化为灰度图，根据颜色深浅的 RGB 值映射为灰度值； 根据字符集顺序及字符集长度，将灰度值映射到字符。 这里就要介绍灰度值和 RGB 的概念了。 RGB RGB 色彩模式是通过对红(R)、绿(G)、蓝(B) 三个颜色通道的变化以及它们相互之间的叠加来得到各式各样的颜色的，RGB 即是代表红、绿、蓝三个通道的颜色，这个标准几乎包括了人类视力所能感知的所有颜色。通常情况下，RGB 各有 256 级亮度，用数字表示为从 0、1、2… 到 255。 灰度图 灰度值：指黑白图像中点的颜色深度，范围一般从 0 到 255，白色为 255，黑色为 0，故黑白图片也称灰度图像 那么如何将彩色图片转为灰度呢？ 常用的公式如下，可以将像素的 RGB 值映射到灰度值： gray ＝ 0.2126 * r + 0.7152 * g + 0.0722 * b 得到灰度值后，就可以将灰度值和字符进行映射了。可以创建一个不重复的字符列表，灰度值小（暗）的用列表开头的符号，灰度值大（亮）的用列表末尾的符号。 下面是我们的字符画所使用的字符集，一共有 70 个字符，从左住右, 表示的颜色深度依次递减。字符的种类与数量可以自己根据字符画的效果反复调试。 1ascii_char = list("$@B%8&amp;WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\|()1&#123;&#125;[]?-_+~&lt;&gt;i!lI;:,\"^`'. ") 实现字符集容量为 70，一个字符对应的值：区间宽度= 256/字符集长度，即区间宽度为 256/70 = 3.6。 gray 区间和字符的对应关系1234567[0.0， 3.6) --&gt; $[3.6, 7.2) --&gt; @[7.2, 10.8) --&gt; B...[244.2, 247.8] --&gt; '[247.8, 251.4] --&gt; .[251.4, 255.0] --&gt; RGB 转字符的函数12345678910111213# 将256 灰度映射到 70 个字符上def get_char(r, g, b, alpha=256): if alpha == 0: return " " length = len(ascii_char) gray = int(0.2126*r + 0.7152*g + 0.0722*b) # 每个字符对应的 gray 值区间宽度 unit = (256.0+1)/length # gray值对应到 char_string 中的位置（索引值） index = int(gray/unit) return ascii_char[index] 完整代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import argparsefrom PIL import Image# 命令行输入参数处理parser = argparse.ArgumentParser()parser.add_argument('file') # 输入图片parser.add_argument('-o', '--output') # 输出文件parser.add_argument('--width', type=int, default=40) # 输出字符画宽度parser.add_argument('--height', type=int, default=40) # 输出字符画高度# 获取参数args = parser.parse_args()IMG = args.fileWIDTH = args.widthHEIGHT = args.heightOUTPUT = args.outputascii_char = list( "$@B%8&amp;WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\|()1&#123;&#125;[]?-_+~&lt;&gt;i!lI;:,\"^`'. ")# 将256 灰度映射到 70 个字符上def get_char(r, g, b, alpha=256): if alpha == 0: return " " length = len(ascii_char) gray = int(0.2126*r + 0.7152*g + 0.0722*b) # 每个字符对应的 gray 值区间宽度 unit = (256.0+1)/length # gray值对应到 char_string 中的位置（索引值） index = int(gray/unit) return ascii_char[index]if __name__ == "__main__": im = Image.open(IMG) im = im.resize((WIDTH, HEIGHT), Image.NEAREST) txt = "" for i in range(HEIGHT): for j in range(WIDTH): txt += get_char(*im.getpixel((j, i))) txt += '\n' print(txt) if OUTPUT: with open(OUTPUT, 'w') as f: f.write(txt) else: with open('output.txt', 'w') as f: f.write(txt) 运行结果 原图 12345678910111213141516171819202122232425262728293031323334353637383940$ python ascii.py ascii_dora.png --width=80 --height=40 $$$#kqqq#$$ $kxxxxxx( Ox "Lq$ @xxxxxxxxmf z dxx0$ @xxxxxxxxxxx# n I&#125;z ( (xxxx0 $xxxxxxxxxxc#(Ip ( COC( h pu$ @xxxxxxxxxW # C *j :kM "Opn-p kxxxxxxxu&gt; "n#n- Mkkkkk f- $ 8xxxxxxxh &#125;B&amp;C "-(nnnn- p $xxxxxxmn I-&#125;nnnOpphpz&#125; h $ oxxxxxu &#125;n &#125;OpnI f Jxxxxx# "kkkkkkka8%*aW%pn- -n &#125;CI$ Yxxxxx- nkkkkkkkkkkkkkkkkkkkkkkkkkkk* $ mxxxxx kkkkkkkkkkkkkkkkkkkkkkkkkko &gt; $xxxxx zkk8bYfcOMMkkkkkkkkkkkkkk8 &gt;$ cxxxxC nfffffffffffc#kkkkkkkkkn $ $xxxxx" Qfffffffffffukkkkkk8 $ @xxxxk&#125; hfffffffffffpkkka&gt; $ $xxxxx( "nQffffffff8&#125; -$ $uxxxxW -Cpp$%%%%%%%pn$ $xxxxc#8akkkkkkn &gt;b_ub0o&amp;W$ $8kkkWdxxxxxx# pIII[I0 $ xxxxxxxxxxxY 0IIIXIf n qxxxxxxxxxxxd h aJua" $xxxxxxxx#k&#125; (hC-" Ih$ $*(-C$ xx0qcxxxxq n n$- $ qxxxxxxxx# ( # p $xxxxxxxxc "- (I p $kkkk%$xxxxxxxxxJ -npnn- fh $ $kkkk8$xxxxxxxxxxxC "dxn C #xxxxxxxxxxxxxxdhnCW0uxxxx# O xxxxxxxxxxxxxxxxxxxxxuqB$$ 8 I$ &gt; xxxxxxxxxxxxxxxL$ ( pxxxxxxxxxxY$ Cxxxxxxuk$ &gt;OO$ $ $ $C $$Onn*$ &#x1f61c; 知识点命令行解析模块 argparse看下样例就可以： 1234567891011121314151617# 命令行输入参数处理parser = argparse.ArgumentParser()parser.add_argument('file', help='the input file') # 输入图片parser.add_argument('-o', '--output', help='the output text file') # 输出文件parser.add_argument('-w', '--width', type=int, default=40, help='the width of the output, default is 40') # 输出字符画宽度parser.add_argument('--height', type=int, default=40, help='the height of the output, default is 40') # 输出字符画高度# 获取参数args = parser.parse_args()IMG = args.fileWIDTH = args.widthHEIGHT = args.heightOUTPUT = args.output 使用： 12345678910111213$ python ascii.py --helpusage: ascii.py [-h] [-o OUTPUT] [-w WIDTH] [--height HEIGHT] filepositional arguments: file the input fileoptional arguments: -h, --help show this help message and exit -o OUTPUT, --output OUTPUT the output text file -w WIDTH, --width WIDTH the width of the output, default is 40 --height HEIGHT the height of the output, default is 40]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[执行 shell 脚本时，「source」、「. 」和「./」的区别]]></title>
    <url>%2Flinux-run-shell.html</url>
    <content type="text"><![CDATA[区别大部分人都知道，但是你试过吗？ 通过网上的查询，我们很容易知道三者的区别大致如下： source script.sh 会在当前进程下执行脚本，并且脚本中设置的变量在脚本执行完毕后会保存下来。 . script.sh 和 source script.sh 是一样的，在一些环境下有一些细微差别的，如 source 不是 POSIX 所要求的。 ./script.sh 则是会在单独的子进程中执行，脚本中设置的变量在脚本执行完毕后不会保存。但是若 script.sh 脚本不是以 #!/bin/bash 开头，那么也不会在子进程中执行。 我们可以做个简单的测试： 123456789101112131415161718# cat test.sh #! /bin/bashtest=1234# ./test.sh # echo $test# . test.sh# echo $test1234# cat test.sh #! /bin/bashtest=123# source test.shecho $test123 可以看出只有用 ./ 执行后变量没有保存在当前环境变量中。 那关于是否是在子进程运行的区别又有什么影响呢？下面我们来做另外一个测试。 下面有一个检测进程 PID 的脚本 check_process.sh，请问运行 ./check_process.sh gmond 和 source check_process.sh gmond 输出会有什么不同？（假设已存在 1 个 gmond 进程，pid 为 17255） 1234#! /bin/bashprocess=$1pid=$(ps x | grep $process | grep -v grep | awk '&#123;print $1&#125;')echo $pid 运行测试： 12345# ./check_process.sh gmond17255 25930 25931# source check_process.sh gmond17255 &#x1f631; 结果是不是有点奇怪，gmond 明明只有一个进程啊，为什么会出来三个进程 pid？ 我们在脚本里加个 sleep，然后从另外窗口看下多出的进程 pid 是谁？ &#x1f440; 12345#! /bin/bashprocess=$1pid=$(ps x | grep $process | grep -v grep | awk '&#123;print $1&#125;')echo $pidsleep 100 再运行： 123456# ./check_process.sh gmond8215 8216 17255# ps -ef|grep gmond|grep -v greproot 8215 17611 0 14:26 pts/8 00:00:00 /bin/bash ./check_process.sh gmondroot 17255 1 5 Feb02 ? 5-15:08:55 /usr/sbin/gmond 发现 pid 为 8215 的进程就是我们执行脚本本身的进程。同时也可以看到，./ 最终调用执行的是 /bin/bash。 所以，我们用 shell 脚本来获取进程 pid 时一定要对进程本身进程过滤，可以用 grep -v bash： 1234#! /bin/bashprocess=$1pid=$(ps x | grep $process | grep -v grep |grep -v bash| awk '&#123;print $1&#125;')echo $pid 遗留的问题，若脚本中不加 #! /bin/bash，又会是什么结果呢？ 123process=$1pid=$(ps x | grep $process | grep -v grep | awk '&#123;print $1&#125;')echo $pid 此时可以发现，三种运行方式的结果都是正常的 &#x1f62f; 123456# ./check_process.sh gmond17255# . check_process.sh gmond17255# source check_process.sh gmond17255]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 实现监控所有物理网卡状态]]></title>
    <url>%2Fpython-get-pic-state.html</url>
    <content type="text"><![CDATA[项目中有监控网卡的需求，但是一般的方法都需要指定某个网卡，然后返回网卡状态，另外如何从所有网卡中过滤出物理网卡也是个问题。 Linux2.6 内核中引入了 sysfs 文件系统。sysfs 文件系统整理的设备驱动的相关文件节点，被视为 dev 文件系统的替代者。同时也拥有类似 proc 文件系统一样查看系统相关信息的功能。最主要的作用是 sysfs 把连接在系统上的设备和总线组织成分级的文件，使其从用户空间可以访问或配置。 sysfs 被加载在 /sys/ 目录下，如 /sys/class/net 目录下包含了所有网络接口，我们这里就是从该目录获取到所有网卡的列表。 但是如何过滤掉虚拟网卡，只获取到物理网卡的列表呢？ 这里我们又用到了 /sys/devices/virtual/net 目录，这里又所有的虚拟网卡列表，这样我们就有办法获取到物理网卡列表了。然后再使用 ethtool 命令获取网卡状态即可。 1234567891011121314151617181920212223242526272829import commands,sys# get all virtual nicreturn_code, output = commands.getstatusoutput("ls /sys/devices/virtual/net")vnic_list = output.split('\n')# get all nic, exclude the 'bonding_masters'return_code, output = commands.getstatusoutput("ls /sys/class/net|grep -v 'bonding_masters'")nic_list = output.split('\n')# get all physical nic#pnic_list = [p_nic for p_nic in nic_list if p_nic not in vnic_list]pnic_list = list(set(nic_list) - set(vnic_list))exit_code = 0exit_list = []# use ethtool to detect the pnic link statusfor pnic in pnic_list: return_code, output = commands.getstatusoutput("ethtool " + pnic + " |grep detected") if "no" in output: exit_list.append(pnic) exit_code = 2if exit_code == 0: print("OK! all inteface is up.")else: print("CRITICAL: interface " + str(exit_list) + " is down")sys.exit(exit_code) 参考： https://www.jianshu.com/p/601bb8128fab https://blog.csdn.net/RadianceBlau/article/details/75047997]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的动态特性]]></title>
    <url>%2Fpython-dynamic-features.html</url>
    <content type="text"><![CDATA[Python 是一种动态语言，拥有动态语言的相关特性… 动态编程语言 是 高级程序设计语言 的一个类别，在计算机科学领域已被广泛应用。它是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。动态语言目前非常具有活力。例如 JavaScript 便是一个动态语言，除此之外如 PHP 、Ruby 、Python 等也都属于动态语言，而 C、C++ 等语言则不属于动态语言。 运行的过程中给实例绑定属性 运行的过程中给类绑定属性 运行的过程中给实例绑定方法 运行的过程中给类绑定方法 运行的过程中删除属性、方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Person(object): def __init__(self, name): self.name = namexiaoli = Person('小里')print(xiaoli.name)# 运行的过程中给对象绑定属性xiaoli.age = 12print(xiaoli.age)# age 属性只属于 xiaoli，Person中并没有print(dir(Person))print(dir(xiaoli))# 运行的过程中给类绑定属性Person.address = Noneprint(dir(Person))xiaoni = Person("小妮")xiaoni.address = "江苏"print(xiaoni.address)# 运行的过程中给实例绑定方法def run(self): print("%s is running" %self.name)import types# 不能直接使用 xiaoli.run = runxiaoli.run = types.MethodType(run, xiaoli)print(dir(Person))print(dir(xiaoli))xiaoli.run()# 运行的过程中给类绑定方法Person.run = runprint(dir(Person))print(dir(xiaoli))xiaoni.run()# 运行中删除类的方法delattr(Person, "run")# del Person.rundel Person.addressprint(dir(Person)) 运行结果： 1234567891011121314$ python testDynamic.py小里12['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'age', 'name']['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'address']江苏['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'address']['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'address', 'age', 'name', 'run']小里 is running['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'address', 'run']['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'address', 'age', 'name', 'run']小妮 is running['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__'] 删除的方法: del 对象.属性名 delattr(对象, “属性名”) __slots__现在我们终于明白了，动态语言与静态语言的不同： 动态语言：可以在运行的过程中，修改代码 静态语言：编译时已经确定好代码，运行过程中不能修改 如果我们想要限制实例的属性怎么办？比如，只允许对 Person 实例添加 name 和 age 属性。为了达到限制的目的，Python 允许在定义 class 的时候，定义一个特殊的 __slots__ 变量，来限制该 class 实例能添加的属性。 1234567class Person(object): __slots__ = ("name" ,"age")xi = Person()xi.name = "xixi"print(xi.name)xi.address = "China" 运行结果： 123456$ python testSlots.pyxixiTraceback (most recent call last): File "testSlots.py", line 7, in &lt;module&gt; xi.address = "China"AttributeError: 'Person' object has no attribute 'address' 使用 __slots__ 要注意，__slots__ 定义的属性仅对当前类实例起作用，对继承的子类是不起作用的 12345class Man(Person): passmi = Man()mi.address = "JS"print(mi.address) 运行结果： 123$ python testSlots.pyxixiJS]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 迭代器]]></title>
    <url>%2Fpython-iterator.html</url>
    <content type="text"><![CDATA[迭代是访问集合元素的一种方式。迭代器是一个可以记住遍历的位置的对象。 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 可迭代对象以直接作用于 for 循环的数据类型有以下几种： 集合数据类型，如 list、 tuple、 dict、 set、 str 等； generator，包括生成器和带 yield 的 generator function。 这些可以直接作用于 for 循环的对象统称为可迭代对象： Iterable。 判断是否可以迭代可以使用 isinstance() 判断一个对象是否是 Iterable 对象： 12345678910&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance(&#123;&#125;, Iterable)True&gt;&gt;&gt; isinstance([], Iterable)True&gt;&gt;&gt; isinstance('abc', Iterable)True&gt;&gt;&gt; isinstance(123, Iterable)False&gt;&gt;&gt; 而生成器不但可以作用于 for 循环，还可以被 next() 函数不断调用并返回下一个值，直到最后抛出 StopIteration 错误表示无法继续返回下一个值了。 迭代器可以被 next() 函数调用并不断返回下一个值的对象称为迭代器：Iterator。 可以使用 isinstance() 判断一个对象是否是 Iterator 对象： 123456789&gt;&gt;&gt; from collections import Iterator&gt;&gt;&gt; isinstance('abc', Iterator)False&gt;&gt;&gt; isinstance([], Iterator)False&gt;&gt;&gt; isinstance(&#123;&#125;, Iterator)False&gt;&gt;&gt; isinstance((x for x in range(10)), Iterator)True iter() 函数生成器都是 Iterator 对象，但 list、 dict、 str 虽然是 Iterable，却不是 Iterator。 把 list、 dict、 str 等 Iterable 变成 Iterator 可以使用 iter() 函数： 12345678&gt;&gt;&gt; isinstance((x for x in range(10)), Iterator)True&gt;&gt;&gt; isinstance(iter(&#123;&#125;), Iterator)True&gt;&gt;&gt; isinstance(iter([]), Iterator)True&gt;&gt;&gt; isinstance(iter('abc'), Iterator)True 总结 凡是可作用于 for 循环的对象都是 Iterable 类型； 凡是可作用于 next() 函数的对象都是 Iterator 类型 集合数据类型如 list、 dict、 str 等是 Iterable 但不是 Iterator，不过可以通过 iter() 函数获得一个 Iterator 对象。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 生成器]]></title>
    <url>%2Fpython-generator.html</url>
    <content type="text"><![CDATA[生成器也是一种迭代器，但是你只能对其迭代一次。这是因为它们并没有把所有的值存在内存中，而是在运行时生成值。 生成器保存的是算法，每次调用 next(G) ，就计算出 G 的下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出 StopIteration 的异常。当然，这种不断调用 next() 实在是太变态了，正确的方法是使用 for 循环，因为生成器也是可迭代对象。所以，我们创建了一个生成器后，基本上永远不会调用 next() ，而是通过 for 循环来迭代它，并且不需要关心 StopIteration 异常。 generator = 函数 + yield 简单说，就是一个函数，里面用到了关键字 yield，就成为了一个生成器 12345678910111213141516171819&gt;&gt;&gt; g = [x*x for x in range(5)]&gt;&gt;&gt; g[0, 1, 4, 9, 16]&gt;&gt;&gt; g = (x*x for x in range(5))&gt;&gt;&gt; g&lt;generator object &lt;genexpr&gt; at 0x7f2a07743fc0&gt;&gt;&gt;&gt; for i in g:... print(i)...014916&gt;&gt;&gt; for i in g:... print(i)...&gt;&gt;&gt; 看起来除了把 [] 换成 () 外没什么不同。但是，你不可以再次使用 for i in g，因为生成器只能被迭代一次：先计算出 0，然后继续计算 1，然后计算 4，一个跟一个的。 yield 关键字yield 是一个类似 return 的关键字，只是这个函数返回的是个生成器。 1234567891011121314151617181920212223242526&gt;&gt;&gt; def gen():... print('---1---')... mlist = range(3)... for i in mlist:... print('---2---')... yield i*i... print('---3---')...&gt;&gt;&gt; mygen = gen()&gt;&gt;&gt; next(mygen)---1------2---0&gt;&gt;&gt; next(mygen)---3------2---1&gt;&gt;&gt; next(mygen)---3------2---4&gt;&gt;&gt; next(mygen)---3---Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration 你必须要理解：当你调用这个函数的时候，函数内部的代码并不立马执行，这个函数只是返回一个生成器对象，这有点蹊跷不是吗。 那么，函数内的代码什么时候执行呢？当你使用 for 进行迭代的时候. 第一次迭代中你的函数会执行，从开始到达 yield 关键字，然后返回 yield 后的值作为第一次迭代的返回值。 然后，再次执行时从 yield 的下一跳语句开始执行，然后再次遇到 yield 后，再返回那个值，直到没有可以返回的。 如果生成器内部没有定义 yield 关键字，那么这个生成器被认为成空的。这种情况可能因为是循环进行没了，或者是没有满足 if/else 条件。 在上面的例子，我们在循环过程中不断调用 yield ，就会不断中断。当然要给循环设置一个条件来退出循环，不然就会产生一个无限数列出来。同样的，把函数改成 generator 后，我们基本上从来不会用 next() 来获取下一个返回值，而是直接使用 for 循环来迭代： 12345678910111213&gt;&gt;&gt; for i in mygen:... print(i)...---1------2---0---3------2---1---3------2---4---3--- 生成器和函数的区别 直接调用生成器，不会执行； 举个栗子：a = f() # 这里 f() 是个生成器 运行上面这句，f() 不会执行，首次执行需要使用 next(a) 或 a.send(None)，后面会细讲 每次执行，会暂时中断在 yield 关键字处，而且通过 yield 可以返回一个参数 下次再接着执行，会从上次中断的 yield 处接着执行，并可以通过 send() 传递参数，当然继续中断在下一个 yield 处 如果通过 send() 或 next() 执行 generator，而没有找到下一个 yield，会报错 next() 和 send() return = send(msg) 传递参数 msg 给 当前中断 yield 前面的变量 同时返回下一个 yield 后面的参数给 return return = next(a) 没有传递参数或者说传递参数 None 给当前中断 yield 前面的变量 同时返回下一个 yield 后面的参数给 return 12345678910111213141516171819202122232425# 生成器def f(): print('start') a = yield 1 # 可以返回参数1，并接收传递的参数给a print(a) print('middle') b = yield 2 # 可以返回参数2，并接收传递的参数给b print(b) print('next') c = yield 3 # 可以返回参数3，并接收传递的参数给c print(c) # 这里貌似永远不会执行，因为总会在上一行的yield处结束a = f() # 这里不会执行，即没有任何打印信息# a.next() #这种写法在python3里面会报错return1 = next(a) # 输出start，中断在yield 1处，返回yield后面的1给return1# return1 = a.send(None) # 效果同上一条语句# return1 = a.send('test') # 这里会报错，生成器启动时只能传入 None，因为没有变量接收传入的值， TypeError: can't send non-None value to a just-started generator# 如果首次执行generator，就传递一个非None的参数，因为第一次执行不是从一般的中断yield处执行起，所以没有yield关键字来接收传参，就会报错print(return1)return2 = next(a) # 传入参数为None，即a=None，返回2给return2print(return2)return3 = a.send('msg') # 传入参数msg，即b=msg,返回3给return3print(return3) 运行结果： 12345678start1Nonemiddle2msgnext3 总结生成器是这样一个函数，它记住上一次返回时在函数体中的位置。对生成器函数的第二次（或第 n 次）调用跳转至该函数中间，而上次调用的所有局部变量都保持不变。 生成器不仅记住了它数据状态，还记住了它在流控制构造（在命令式编程中，这种构造不只是数据值）中的位置。 生成器的特点： 节约内存 迭代到下一次的调用时，所使用的参数都是第一次所保留下的，即是说，在整个所有函数调用的参数都是第一次所调用时保留的，而不是新创建的]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 批量修改表引擎]]></title>
    <url>%2Fmysql-myisam-to-innodb.html</url>
    <content type="text"><![CDATA[在使用 mariadb galera 集群时，发现数据库数据一直不同步，刚开始一直以为是哪里配置的问题，最后才发现… 原来 MariaDB Galera Cluster 仅支持 InnoDB 存储引擎，对于 MyISAM 的支持仅是实验室性质的，不适用在生产环境，具体可见 wsrep_replicate_myisam 变量。 关于 MariaDB Galera Cluster 其他的一些限制见页面：MariaDB Galera Cluster - Known Limitations。 而我们之前初始化时导入的表很大一部分是 MyISAM 引擎的，这也就是为什么一直无法同步的原因。 &#x1f629; 那么如何批量的将 MyISAM 的表修改为 InnoDB 呢？ 可以用如下命令生成批量修改指定数据库（用 table_schema 指定）中的所有表引擎的 Alert 语句： 123SELECT CONCAT('ALTER TABLE ',table_schema,'.',table_name,' ENGINE=InnoDB;') FROM information_schema.tablesWHERE table_schema='mysql' AND ENGINE='MyISAM'; 也可以生成修改所有库中的表引擎： 123SELECT CONCAT('ALTER TABLE ',table_schema,'.',table_name,' ENGINE=InnoDB;') FROM information_schema.tablesWHERE AND ENGINE='MyISAM'; 如： 1234567891011121314151617mysql&gt; SELECT CONCAT('ALTER TABLE ',TABLE_SCHEMA,'.',table_name,' ENGINE=InnoDB;') FROM information_schema.tables WHERE table_schema='mysql' AND ENGINE='MyISAM';+----------------------------------------------------------------------+| CONCAT('ALTER TABLE ',TABLE_SCHEMA,'.',table_name,' ENGINE=InnoDB;') |+----------------------------------------------------------------------+| ALTER TABLE mysql.columns_priv ENGINE=InnoDB; || ALTER TABLE mysql.db ENGINE=InnoDB; || ALTER TABLE mysql.event ENGINE=InnoDB; || ALTER TABLE mysql.func ENGINE=InnoDB; || ALTER TABLE mysql.ndb_binlog_index ENGINE=InnoDB; || ALTER TABLE mysql.proc ENGINE=InnoDB; || ALTER TABLE mysql.procs_priv ENGINE=InnoDB; || ALTER TABLE mysql.proxies_priv ENGINE=InnoDB; || ALTER TABLE mysql.tables_priv ENGINE=InnoDB; || ALTER TABLE mysql.user ENGINE=InnoDB; |+----------------------------------------------------------------------+10 rows in set 复制生成的 Alert 语句运行即可。 参考： https://www.bbsmax.com/A/A2dmMm7qde/]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于 Keepalived + HAproxy 的 RabbitMQ 高可用配置实践]]></title>
    <url>%2Fkeepalived-haproxy-rabbitmq.html</url>
    <content type="text"><![CDATA[本文使用的高可用架构是 Keepalived + HAproxy，用 HAproxy 来做 RabbitMQ 负载均衡和高可用，用 Keepalived 来保证 HAproxy 的高可用。 RabbitMQ 集群的安装过程这里不再赘述，可以参考 https://blog.csdn.net/WoogeYu/article/details/51119101。 这里使用的三节点集群的安装方式，规划如下： 组件 IP 端口 RabbitMQ 主 192.168.151.7 5672 RabbitMQ 从 192.168.151.18 5672 RabbitMQ 从 192.168.151.19 5672 HAproxy 主 192.168.151.18 HAproxy 从 192.168.151.19 Keepalived 主 192.168.151.18 Keepalived 从 192.168.151.19 VIP 192.168.151.108 RabbitMQ 集群安装在 192.168.151.7、192.168.151.18、192.168.151.19 三个节点上分别安装配置。 安装12yum -y install rabbitmq-serverservice rabbitmq-server start 配置123456rabbitmqctl add_user admin adminrabbitmqctl set_user_tags admin administratorset_permissions -p / admin '.*' '.*' '.*'rabbitmqctl set_permissions -p / admin '.*' '.*' '.*'rabbitmq-plugins enable rabbitmq_management 局域网配置 分别在三个节点的 /etc/hosts 下设置相同的配置信息 123192.168.151.7 HRB-PCRP1-M-BCCLM-CTL7192.168.151.18 HRB-PCRP1-M-BCCLM-CTL18192.168.151.19 HRB-PCRP1-M-BCCLM-CTL19 设置不同节点间同一认证的 Erlang Cookie 采用从主节点 copy 的方式保持 Cookie 的一致性。 12# scp /var/lib/rabbitmq/.erlang.cookie 192.168.151.18:/var/lib/rabbitmq# scp /var/lib/rabbitmq/.erlang.cookie 192.168.151.19:/var/lib/rabbitmq12 使用 -detached 运行各节点 12rabbitmqctl stoprabbitmq-server -detached 查看各节点的状态 1rabbitmqctl cluster_status 创建并部署集群，以 192.168.151.7 节点为例： 1234# rabbitmqctl stop_app# rabbitmqctl reset# rabbitmqctl join_cluster rabbit@HRB-PCRP1-M-BCCLM-CTL7# rabbitmqctl start_app 查看集群状态 12345678910111213# rabbitmqctl cluster_statusCluster status of node 'rabbit@HRB-PCRP1-M-BCCLM-CTL7' ...[&#123;nodes,[&#123;disc,['rabbit@HRB-PCRP1-M-BCCLM-CTL18', 'rabbit@HRB-PCRP1-M-BCCLM-CTL19', 'rabbit@HRB-PCRP1-M-BCCLM-CTL7']&#125;]&#125;, &#123;running_nodes,['rabbit@HRB-PCRP1-M-BCCLM-CTL18', 'rabbit@HRB-PCRP1-M-BCCLM-CTL19', 'rabbit@HRB-PCRP1-M-BCCLM-CTL7']&#125;, &#123;cluster_name,&lt;&lt;"rabbit@HRB-PCRP1-M-BCCLM-CTL7"&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;'rabbit@HRB-PCRP1-M-BCCLM-CTL18',[]&#125;, &#123;'rabbit@HRB-PCRP1-M-BCCLM-CTL19',[]&#125;, &#123;'rabbit@HRB-PCRP1-M-BCCLM-CTL7',[]&#125;]&#125;] RabbitMQ 集群至此安装完成。可以通过访问各节点的 http://192.168.151.7:15672/ 管理页面查看 RabbitMQ 状态。用户名密码使用之前配置的 admin/admin。 Keepalived 监控 192.168.151.18、192.168.151.19 上的 HAproxy，利用 Keepalived 的 VIP 漂移技术，若两台服务器上的 HAprox 都工作正常，则 VIP 与优先级别高的服务器（主服务器）绑定，当主服务器当掉时，则与从服务器绑定，而 VIP 则是暴露给外部访问的 IP；HAproxy 利用 Keepalived 生产的 VIP 对多台 RabbitMQ 进行读负载均衡。 下面对上面的 RabbitMQ 集群进行高可用配置，HAproxy 和 Keepalived 的安装方法这里不再赘述。 高可用架构 其中 Keepalived 来控制 HAproxy 的高可用，HAproxy 的作用是控制下层应用的负载均衡，同时可以用来保证下层应用的高可用。 HAproxyHAproxy 是一个七层的负载均衡高度器，和 nginx 是属于一个层次上的，而 lvs 是一个四层的负载均衡高度器，它最多只能工作在 TCP/IP 协议栈上，所以对于代理转发，HAproxy 做的可以比 lvs 更细腻。 HAProxy 提供高可用性、负载均衡以及基于 TCP 和 HTTP 应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy 特别适用于那些负载特大的 web 站点，这些站点通常又需要会话保持或七层处理。HAProxy 运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中，同时可以保护你的 web 服务器不被暴露到网络上。 HAproxy 配置这里仅列出了主要内容。 123456789101112131415161718192021222324252627282930313233343536####################HAProxy配置中分成五部分内容，当然这些组件不是必选的，可以根据需要选择部分作为配置。#global ：参数是进程级的，通常和操作系统（OS）相关。这些参数一般只设置一次，如果配置无误，就不需要再次配置进行修改#defaults：配置默认参数的，这些参数可以被利用配置到frontend，backend，listen组件#frontend：接收请求的前端虚拟节点，Frontend可以根据规则直接指定具体使用后端的 backend(可动态选择)。#backend ：后端服务集群的配置，是真实的服务器，一个Backend对应一个或者多个实体服务器。#listen ：Frontend和Backend的组合体。listen rabbitmq bind 192.168.151.108:5673 balance roundrobin mode tcp option tcplog option tcpka bind-process 7 timeout client 15s timeout connect 3s timeout server 15s server HRB-PCRP1-M-BCCLM-CTL7 192.168.151.7:5672 check inter 5000 rise 2 fall 3 server HRB-PCRP1-M-BCCLM-CTL18 192.168.151.18:5672 check inter 5000 rise 2 fall 3 server HRB-PCRP1-M-BCCLM-CTL19 192.168.151.19:5672 check inter 5000 rise 2 fall 3 # weight - 调节服务器的负重 # check - 允许对该服务器进行健康检查 # inter - 设置连续的两次健康检查之间的时间，单位为毫秒(ms)，默认值 2000(ms) # rise - 指定多少次连续成功的健康检查后，可认定该服务器处于可操作状态，默认值 2 # fall - 指定多少次不成功的健康检查后，认为服务器为当掉状态，默认值 3 # maxconn - 指定可被发送到该服务器的最大并发连接数 # 配置haproxy web监控，查看统计信息 listen private_monitoring :8100 mode http option httplog stats enable #设置haproxy监控地址为http://localhost:8100/stats stats uri /stats stats refresh 5s 这里使用了一个 listen 块来同时实现前端和后端，也可以由前端（frontend）和后端（backend）配置。 最后我们打开 http://192.168.151.18:8100/stats，看一下监控页面，如果显示出正常就表明已经将 HAProxy 负载均衡配置好了！ 注意点启动 HAproxy 时可能会出现 cannot bind socket 的异常，这是因为 HAproxy 配置中使用了 VIP，但此时还没有启动 Keepalived，那么就还没有 VIP 绑定。 这时需要在 /etc/sysctl.conf 文件中配置如下内容： 12net.ipv4.ip_nonlocal_bind = 1 # 意思是启动haproxy的时候，允许忽视VIP的存在net.ipv4.ip_forward = 1 # 打开内核的转发功能 然后运行 sysctl –p 使其生效。 KeepalivedKeepalived 的作用是检测服务器的健康状态，在所有可能出现单点故障的地方为其提供高可用。如果有一台服务器死机，或工作出现故障，Keepalived 将检测到，并将有故障的服务器从系统中剔除，当服务器工作正常后 Keepalived 自动将服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的服务器。 这里使用的实现方式是单活方式，即主节点的 HAproxy 正常运行，备节点的会被停止。当主节点的出现故障时，备节点的 HAproxy 会自动启动。当主节点的恢复后，备节点的会自动停止。 当然 Keepalived 的高可用控制不止这一种，也可以有其他配置方式。 Keepalived 主节点配置123456789101112131415161718192021222324252627vrrp_script chk_haproxy &#123; script "service haproxy status" # 服务探测，返回0说明服务是正常的 interval 1 # 每隔1秒探测一次 weight -2 # 不正常时，权重-1，即haproxy上线，权重加2；下线，权重减2&#125;vrrp_instance haproxy &#123; state MASTER # 主机为MASTER，备机为BACKUP interface bond0 # 监测网络端口，用ipconfig查看 virtual_router_id 108 # 主备机必须相同 priority 100 # 主备机取不同的优先级，主机要大。 advert_int 1 # VRRP Multicast广播周期秒数 authentication &#123; auth_type PASS # VRRP认证方式 auth_pass 1234 # VRRP口令 主备机密码必须相同 &#125; track_script &#123; # 调用haproxy进程检测脚本，备节点不配置 chk_haproxy &#125; track_interface &#123; bond0 &#125; virtual_ipaddress &#123; # VIP 漂移地址 即集群IP地址 192.168.151.108/25 dev bond0 &#125;&#125; Keepalived 备节点1234567891011121314151617181920vrrp_instance haproxy &#123; state BACKUP interface bond0 virtual_router_id 108 priority 99 advert_int 1 authentication &#123; auth_type PASS auth_pass 1234 &#125; track_interface &#123; bond0 &#125; virtual_ipaddress &#123; 192.168.151.108 &#125; notify_master "/etc/keepalived/notify.sh master" # 当前节点成为master时，通知脚本执行任务，一般用于启动某服务 notify_backup "/etc/keepalived/notify.sh backup" # 当前节点成为backup时，通知脚本执行任务，一般用于关闭某服务&#125; notify.sh 脚本放在 /etc/keepalived/ 目录下，并赋予可执行权限。 1234567891011121314151617181920212223#!/bin/bashcase "$1" in master) notify master service haproxy start exit 0 ;; backup) notify backup service haproxy stop exit 0 ;; fault) notify fault service haproxy stop exit 0 ;; *) echo 'Usage: `basename $0` &#123;master|backup|fault&#125;' exit 1 ;;esac Keepalived 执行过程MASTER - 初始 priority 为 100，BACKUP - 初始 priority 为 99 模拟 MASTER 产生故障： 当检测到 chk_haproxy 执行结果为 down 时，priority 每次减少 2，变为 98；低于 BACKUP 的 priority； 此时 MASTER 变成 BACKUP； 同时 BACKUP 变成 MASTER，同时执行 notify_master 的脚本文件（启动haproxy）； 模拟 MASTER 故障恢复： 当 MASTER 节点的 HAproxy 恢复后，原 MASTER 的优先级又变为 100，高于原 BACKUP 的 priority； 此时原 MASTER 由 BACKUP 又抢占成了 MASTER； 同时原 BACKUP 由 MASTER 又变了 BACKUP，同时执行 notify_backup 的脚本文件（关闭haproxy）； 参考： http://blog.51cto.com/nmshuishui/1405486 http://www.cnblogs.com/hunttown/p/5451743.html]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis.conf 配置文件详解]]></title>
    <url>%2Fredis-conf.html</url>
    <content type="text"><![CDATA[redis 配置文件详解。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371# redis.conf# Redis configuration file example.# ./redis-server /path/to/redis.conf################################## INCLUDES ####################################这在你有标准配置模板但是每个redis服务器又需要个性设置的时候很有用。# include /path/to/local.conf# include /path/to/other.conf######################### 网络 ########################## redis 监听的端口号port 6379# 此参数确定了 TCP 连接中已完成队列（完成三次握手之后）的长度， # 当然此值必须不大于 Linux 系统定义的 /proc/sys/net/core/somaxconn 值，默认是 511，而 Linux 的默认参数值是 128。# 当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。# 该内核参数默认值一般是 128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。# 在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行 sysctl -p。tcp-backlog 511# 指定 redis 只接收来自于该 IP 地址的请求，如果不进行设置，那么将处理所有请求bind 127.0.0.1# 配置 unix socket 来让 redis 支持监听本地连接。# unixsocket /var/run/redis/redis.sock# 配置 unix socket 使用文件的权限# unixsocketperm 700# 此参数为设置客户端空闲超过 timeout，服务端会断开连接，为 0 则服务端不会主动断开连接，不能小于 0。timeout 0# 客户端空闲多少秒后关闭连接（0为不关闭）timeout 0# tcp-keepalive 设置。如果非零，则设置 SO_KEEPALIVE 选项来向空闲连接的客户端发送 ACK，用途如下：# 1）能够检测无响应的对端# 2）让该连接中间的网络设备知道这个连接还存活# 在 Linux 上，这个指定的值（单位秒）就是发送 ACK 的时间间隔。# 注意：要关闭这个连接需要两倍的这个时间值。# 在其他内核上这个时间间隔由内核配置决定# 从 redis3.2.1 开始默认值为 300 秒tcp-keepalive 0################################ GENERAL ###################################### 是否在后台执行，yes：后台运行；no：不是后台运行（老版本默认）daemonize yes# 3.2 版本里的参数，是否开启保护模式，默认开启。# 如果没有设置 bind 项的 ip 和 redis 密码的话，服务将只允许本地访问protected-mode yes# redis的进程文件pidfile /var/run/redis/redis-server.pid# 指定了服务端日志的级别。级别包括：debug（很多信息，方便开发、测试），# verbose（许多有用的信息，但是没有debug级别信息多），notice（适当的日志级别，适合生产环境），warn（只有非常重要的信息）loglevel notice# 指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的 redis 标准输出是 /dev/null。logfile /var/log/redis/redis-server.log# 是否打开记录 syslog 功能# syslog-enabled no# syslog的标识符。# syslog-ident redis# 日志的来源、设备# syslog-facility local0# 数据库的数量，默认使用的数据库是 DB 0databases 16################################ SNAPSHOTTING ################################# 快照配置# 注释掉“save”这一行配置项就可以让保存数据库功能失效# 设置 sedis 进行数据库镜像的频率。# 900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化） # 300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化） # 60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）save 900 1save 300 10save 60 10000# 当 RDB 持久化出现错误后，是否依然进行继续进行工作# yes：不能进行工作，no：可以继续进行工作，可以通过 info 中的 rdb_last_bgsave_status 了解 RDB 持久化是否有错误stop-writes-on-bgsave-error yes# 使用压缩 rdb 文件，rdb 文件压缩使用 LZF 压缩算法，yes：压缩，但是需要一些 cpu 的消耗。no：不压缩，需要更多的磁盘空间rdbcompression yes# 是否校验 rdb 文件。从 rdb 格式的第五个版本开始，在 rdb 文件的末尾会带上 CRC64 的校验和。# 这跟有利于文件的容错性，但是在保存 rdb 文件的时候，会有大概 10% 的性能损耗，所以如果你追求高性能，可以关闭该配置。rdbchecksum yes# rdb文件的名称dbfilename dump.rdb# 数据目录，数据库的写入会在这个目录。rdb、aof 文件也会写在这个目录dir /var/lib/redis################################# REPLICATION ################################## 主从同步配置。# 1) redis 主从同步是异步的，但是可以配置在没有指定 slave 连接的情况下使 master 停止写入数据。# 2) 连接中断一定时间内，slave 可以执行部分数据重新同步。# 3) 同步是自动的，slave 可以自动重连且同步数据。# slaveof &lt;masterip&gt; &lt;masterport&gt;# 如果 master 设置了 requirepass，那么 slave 要连上 master，需要有 master 的密码才行。# masterauth 就是用来配置 master 的密码，这样可以在连上 master 后进行认证。# masterauth &lt;master-password&gt;# 当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：# 1) 如果 slave-serve-stale-data 设置为 yes （默认设置），从库会继续响应客户端的请求。# 2) 如果 slave-serve-stale-data 设置为 no，除去 INFO 和 SLAVOF 命令之外的任何请求都会返回一个错误 SYNC with master in progress。slave-serve-stale-data yes# 作为从服务器，默认情况下是只读的（yes），可以修改成 NO，用于写（不建议）。# 注意：只读的 slave 不是为了暴露给互联网上不可信的客户端而设计的。它只是一个防止实例误用的保护层。# 一个只读的 slave 支持所有的管理命令比如 config,debug 等。# 为了限制你可以用 'rename-command' 来隐藏所有的管理和危险命令来增强只读 slave 的安全性。slave-read-only yes# 是否使用 socket 方式复制数据。目前 redis 复制提供两种方式，disk 和 socket。# 如果新的 slave 连上来或者重连的 slave 无法部分同步，就会执行全量同步，master 会生成 rdb 文件。# 有 2 种方式：disk 方式是 master 创建一个新的进程把 rdb 文件保存到磁盘，再把磁盘上的 rdb 文件传递给 slave。# socket 是 master 创建一个新的进程，直接把 rdb 文件以 socket 的方式发给 slave。# disk 方式的时候，当一个 rdb 保存的过程中，多个 slave 都能共享这个 rdb 文件。socket 的方式就的一个个 slave 顺序复制。# 在磁盘速度缓慢，网速快的情况下推荐用 socket 方式。repl-diskless-sync no# diskless 复制的延迟时间，防止设置为 0。一旦复制开始，节点不会再接收新 slave 的复制请求直到下一个 rdb 传输。# 所以最好等待一段时间，等更多的 slave 连上来。repl-diskless-sync-delay 5# slave 根据指定的时间间隔向服务器发送 ping 请求。时间间隔可以通过 repl_ping_slave_period 来设置，默认 10 秒。# repl-ping-slave-period 10# 同步的超时时间# 1）slave 在与 master SYNC 期间有大量数据传输，造成超时# 2）在 slave 角度，master 超时，包括数据、ping等# 3）在 master 角度，slave 超时，当 master 发送 REPLCONF ACK pings# 确保这个值大于指定的 repl-ping-slave-period，否则在主从间流量不高时每次都会检测到超时# repl-timeout 60# 是否禁止复制 tcp 链接的 tcp nodelay 参数，可传递 yes 或者 no。默认是 no，即使用 tcp nodelay。# 如果 master 设置了 yes 来禁止 tcp nodelay 设置，在把数据复制给 slave 的时候，会减少包的数量和更小的网络带宽。# 但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择 yes。repl-disable-tcp-nodelay no# 复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。# 这样在 slave 离线的时候，不需要完全复制 master 的数据，# 如果可以执行部分同步，只需要把缓冲区的部分数据复制给 slave，就能恢复正常复制状态。# 缓冲区的大小越大，slave 离线的时间可以更长，复制缓冲区只有在有 slave 连接的时候才分配内存。# 没有 slave 的一段时间，内存会被释放出来，默认 1m。# repl-backlog-size 5mb# master 没有 slave 一段时间会释放复制缓冲区的内存，repl-backlog-ttl 用来设置该时间长度。单位为秒。# repl-backlog-ttl 3600# 当 master 不可用，Sentinel 会根据 slave 的优先级选举一个 master。最低的优先级的 slave，当选 master。而配置成 0，永远不会被选举。slave-priority 100# redis 提供了可以让 master 停止写入的方式，如果配置了 min-slaves-to-write，健康的 slave 的个数小于 N，mater 就禁止写入。# master 最少得有多少个健康的 slave 存活才能执行写命令。# 这个配置虽然不能保证 N 个 slave 都一定能接收到 master 的写操作，# 但是能避免没有足够健康的 slave 的时候，master 不能写入来避免数据丢失。设置为 0 是关闭该功能。# min-slaves-to-write 3# 延迟小于 min-slaves-max-lag 秒的 slave 才认为是健康的 slave。# min-slaves-max-lag 10# 设置 1 或另一个设置为 0 禁用这个特性。# Setting one or the other to 0 disables the feature.# By default min-slaves-to-write is set to 0 (feature disabled) and# min-slaves-max-lag is set to 10.################################## SECURITY #################################### requirepass 配置可以让用户使用 AUTH 命令来认证密码，才能使用其他命令。# 这让 redis 可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户也不需要认证。# 使用 requirepass 的时候需要注意，因为 redis 太快了，每秒可以认证 15w 次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。# requirepass foobared# 把危险的命令给修改成其他名称。比如 CONFIG 命令可以重命名为一个很难被猜到的命令，这样用户不能使用，而内部工具还能接着使用。# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52# 设置成一个空的值，可以禁止一个命令# rename-command CONFIG ""################################### LIMITS ##################################### 设置能连上 redis 的最大客户端连接数量。默认是 10000 个客户端连接。# 由于 redis 不区分连接是客户端连接还是内部打开文件或者和 slave 连接等，所以 maxclients 最小建议设置到 32。# 如果超过了 maxclients，redis 会给新的连接发送 max number of clients reached，并关闭连接。# maxclients 10000# redis配置的最大内存容量。当内存满了，需要配合 maxmemory-policy 策略进行处理。# 注意 slave 的输出缓冲区是不计算在 maxmemory 内的。所以为了防止主机内存使用完，建议设置的 maxmemory 需要更小一些。# maxmemory &lt;bytes&gt;# 内存容量超过 maxmemory 后的处理策略。# volatile-lru：利用 LRU 算法移除设置过过期时间的 key。# volatile-random：随机移除设置过过期时间的 key。# volatile-ttl：移除即将过期的 key，根据最近过期时间来删除（辅以 TTL）# allkeys-lru：利用 LRU 算法移除任何 key。# allkeys-random：随机移除任何 key。# noeviction：不移除任何 key，只是返回一个写错误。# 上面的这些驱逐策略，如果 redis 没有合适的key驱逐，对于写命令，还是会返回错误。redis将不再接收写请求，只接收get请求。# 写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset # rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore # zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。# maxmemory-policy noeviction# lru 检测的样本数。使用 lru 或者 ttl 淘汰算法，从需要淘汰的列表中随机选择 sample 个 key，选出闲置时间最长的 key 移除。# maxmemory-samples 5############################## APPEND ONLY MODE ################################ 默认 redis 使用的是 rdb 方式持久化，这种方式在许多应用中已经足够用了。# 但是 redis 如果中途宕机，会导致可能有几分钟的数据丢失，根据 save 来策略进行持久化，# Append Only File 是另一种持久化方式，可以提供更好的持久化特性。# Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时 Redis 都会先把这个文件的数据读入内存里，先忽略 RDB 文件。appendonly no# aof 文件名appendfilename "appendonly.aof"# aof 持久化策略的配置# no 表示不执行 fsync，由操作系统保证数据同步到磁盘，速度最快。# always 表示每次写入都执行 fsync，以保证数据同步到磁盘。# everysec 表示每秒执行一次 fsync，可能会导致丢失这 1s 数据。appendfsync everysec# 在 aof 重写或者写入 rdb 文件的时候，会执行大量 IO，此时对于 everysec 和 always 的 aof 模式来说，# 执行 fsync 会造成阻塞过长时间，no-appendfsync-on-rewrite 字段设置为默认设置为 no。# 如果对延迟要求很高的应用，这个字段可以设置为 yes，否则还是设置为 no，这样对持久化特性来说这是更安全的选择。# 设置为 yes 表示 rewrite 期间对新写操作不 fsync，暂时存在内存中，等 rewrite 完成后再写入，默认为 no，建议 yes。# Linux 的默认 fsync 策略是 30 秒。可能丢失 30 秒数据。no-appendfsync-on-rewrite no# aof 自动重写配置。当目前 aof 文件大小超过上一次重写的 aof 文件大小的百分之多少进行重写，# 即当 aof 文件增长到一定大小的时候 Redis 能够调用 bgrewriteaof 对日志文件进行重写。# 当前 AOF 文件大小是上次日志重写得到 AOF 文件大小的二倍（设置为 100）时，自动启动新的日志重写过程。auto-aof-rewrite-percentage 100#设置允许重写的最小 aof 文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写auto-aof-rewrite-min-size 64mb# aof 文件可能在尾部是不完整的，当 redis 启动的时候，aof 文件的数据被载入内存。# 重启可能发生在 redis 所在的主机操作系统宕机后，尤其在 ext4 文件系统没有加上 data=ordered 选项（redis宕机或者异常终止不会造成尾部不完整现象。）# 出现这种现象，可以选择让 redis 退出，或者导入尽可能多的数据。# 如果选择的是 yes，当截断的 aof 文件被导入的时候，会自动发布一个 log 给客户端然后 load。# 如果是 no，用户必须手动 redis-check-aof 修复 AOF 文件才可以。aof-load-truncated yes################################ LUA SCRIPTING ################################ 如果达到最大时间限制（毫秒），redis 会记个 log，然后返回 error。当一个脚本超过了最大时限。# 只有 SCRIPT KILL和SHUTDOWN NOSAVE 可以用。第一个可以杀没有调 write 命令的东西。要是已经调用了 write，只能用第二个命令杀。lua-time-limit 5000################################ REDIS CLUSTER ################################ 集群开关，默认是不开启集群模式。# cluster-enabled yes# 集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。# 这个文件并不需要手动配置，这个配置文件有 Redis 生成并更新，每个 Redis 集群节点需要一个单独的配置文件，# 请确保与实例运行的系统中配置文件名称不冲突# cluster-config-file nodes-6379.conf# 节点互连超时的阀值。集群节点超时毫秒数# cluster-node-timeout 15000# 在进行故障转移的时候，全部 slave 都会请求申请为 master，但是有些 slave 可能与 master 断开连接一段时间了，# 导致数据过于陈旧，这样的 slave 不应该被提升为 master。# 该参数就是用来判断 slave 节点与 master 断线的时间是否过长。判断方法是：# 比较 slave 断开连接的时间和 (node-timeout * slave-validity-factor) + repl-ping-slave-period# 如果节点超时时间为三十秒，并且 slave-validity-factor 为 10，假设默认的 repl-ping-slave-period 是 10 秒，# 即如果超过 310 秒 slave 将不会尝试进行故障转移 # cluster-slave-validity-factor 10# master 的 slave 数量大于该值，slave 才能迁移到其他孤立 master 上，如这个参数若被设为 2，# 那么只有当一个主节点拥有 2 个可工作的从节点时，它的一个从节点会尝试迁移。# cluster-migration-barrier 1# 默认情况下，集群全部的 slot 有节点负责，集群状态才为 ok，才能提供服务。# 设置为no，可以在 slot 没有全部分配的时候提供服务。# 不建议打开该配置，这样会造成分区的时候，小分区的 master 一直在接受写请求，而造成很长时间数据不一致。# cluster-require-full-coverage yes################################## SLOW LOG #################################### slog log 是用来记录 redis 运行中执行比较慢的命令耗时。# 当命令的执行超过了指定时间，就记录在 slow log 中，slog log 保存在内存中，所以没有 IO 操作。# 执行时间比 slowlog-log-slower-than 大的请求记录到 slowlog 里面，单位是微秒，所以 1000000 就是 1 秒。# 注意，负数时间会禁用慢查询日志，而 0 则会强制记录所有命令。slowlog-log-slower-than 10000# 慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。# 这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存。slowlog-max-len 128################################ LATENCY MONITOR ############################### 延迟监控功能是用来监控 redis 中执行比较缓慢的一些操作，用 LATENCY 打印 redis 实例在跑命令时的耗时图表。# 只记录大于等于下边设置的值的操作。0 的话，就是关闭监视。# 默认延迟监控功能是关闭的，如果你需要打开，也可以通过 CONFIG SET 命令动态设置。latency-monitor-threshold 0############################# EVENT NOTIFICATION ############################### 键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。# 因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。# notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：##K 键空间通知，所有通知以 __keyspace@__ 为前缀##E 键事件通知，所有通知以 __keyevent@__ 为前缀##g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知##$ 字符串命令的通知##l 列表命令的通知##s 集合命令的通知##h 哈希命令的通知##z 有序集合命令的通知##x 过期事件：每当有过期键被删除时发送##e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送##A 参数 g$lshzxe 的别名#输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考http://redis.io/topics/notificationsnotify-keyspace-events ""############################### ADVANCED CONFIG ################################ 数据量小于等于 hash-max-ziplist-entries 的用 ziplist，大于 hash-max-ziplist-entries 用 hashhash-max-ziplist-entries 512# value 大小小于等于 hash-max-ziplist-value 的用 ziplist，大于 hash-max-ziplist-value 用 hash。hash-max-ziplist-value 64# 数据量小于等于 list-max-ziplist-entries 用 ziplist，大于 list-max-ziplist-entries 用 list。list-max-ziplist-entries 512# value 大小小于等于 list-max-ziplist-value 的用 ziplist，大于 list-max-ziplist-value 用 list。list-max-ziplist-value 64# 数据量小于等于 set-max-intset-entries 用 iniset，大于 set-max-intset-entries 用 set。set-max-intset-entries 512# 数据量小于等于 zset-max-ziplist-entries 用 ziplist，大于 zset-max-ziplist-entries 用 zset。zset-max-ziplist-entries 128# value大小小于等于zset-max-ziplist-value 用 ziplist，大于 zset-max-ziplist-value 用 zset。zset-max-ziplist-value 64# value 大小小于等于 hll-sparse-max-bytes 使用稀疏数据结构（sparse），大于 hll-sparse-max-bytes 使用稠密的数据结构（dense）。# 一个比 16000 大的 value 是几乎没用的，建议的 value 大概为 3000。如果对 CPU 要求不高，对空间要求较高的，建议设置到 10000 左右。hll-sparse-max-bytes 3000# Redis 将在每 100 毫秒时使用 1 毫秒的 CPU 时间来对 redis 的 hash 表进行重新 hash，可以降低内存的使用。# 当你的使用场景中，有非常严格的实时性需要，不能够接受 Redis 时不时的对请求有 2 毫秒的延迟的话，把这项配置为 no。# 如果没有这么严格的实时性要求，可以设置为 yes，以便能够尽可能快的释放内存。activerehashing yes## 对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。# 对于 normal client，第一个 0 表示取消 hard limit，第二个 0 和第三个 0 表示取消 soft limit# normal client 默认取消限制，因为如果没有寻问，他们是不会接收数据的。client-output-buffer-limit normal 0 0 0# 对于 slave client 和 MONITER client，如果 client-output-buffer 一旦超过 256mb，又或者超过 64mb 持续 60 秒，那么服务器就会立即断开客户端连接。client-output-buffer-limit slave 256mb 64mb 60# 对于 pubsub client，如果 client-output-buffer 一旦超过 32mb，又或者超过 8mb 持续 60 秒，那么服务器就会立即断开客户端连接。client-output-buffer-limit pubsub 32mb 8mb 60# redis 执行任务的频率为 1s 除以 hz。hz 10# 在 aof 重写的时候，如果打开了 aof-rewrite-incremental-fsync 开关，系统会每 32MB 执行一次 fsync。# 这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值。aof-rewrite-incremental-fsync yes]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 高可用部署方案]]></title>
    <url>%2Fredis-sentinel-ha.html</url>
    <content type="text"><![CDATA[本文主要讲解一种 redis 的高可用方案，使用的是 redis主从 + 哨兵 + VIP 的方式实现。 本次部署是在虚拟机上进行的。 原理主从复制Redis 主从复制模式可以将主节点的数据同步给从节点，从而保障当主节点不可达的情况下，从节点可以作为后备顶上来，并且可以保障数据尽量不丢失（主从复制可以保障最终一致性）。 第二，从节点可以扩展主节点的读能力，一旦主节点不能支持大规模并发量的读操作，从节点可以在一定程度上分担主节点的压力。 主从复制面临的问题： 当主节点发生故障的时候，需要手动的将一个从节点晋升为主节点，同时通知应用方修改主节点地址并重启应用，同时需要命令其它从节点复制新的主节点，整个过程需要人工干预。 主节点的写能力受到单机的限制。 主节点的存储能力受到单机的限制。 Redis Sentinel 原理 当主节点出现故障时，Redis Sentinel 能自动完成故障发现和故障转移，并通知应用方，从而实现真正的高可用。RedisSentine 是一个分布式架构，其中包含若干个 Sentinel 节点和 Redis 数据节点，每个 Sentinel 节点会对数据节点和其余 Sentinel 节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他的 Sentinel 节点进行协商，当大多数 Sentinel 节点都认为主节点不可达时，它们会选举一个 Sentinel 节点来完成自动故障转移的工作，同时会将这个变化实时通知给 Redis 应用方。整个过程是自动的，不需要人工干预，解决了Redis 的高可用问题。 Redis Sentinel 包含了若干个 Sentinel 节点，这样做也带来了两个好处： 对节点的故障判断是由多个 Sentinel 节点共同完成，这样可以有效的防止误判。 Sentinel 节点集合是由若干个 Sentinel 节点组成的，这样即使个别 Sentinel 节点不可用，整个Sentinel节点集合依然是健壮的。 Redis Sentinel 具有以下几个功能： 监控：Sentinel 会定期检测 Redis 数据节点、其余 Sentinel 节点是否可到达 通知：Sentinel 会将故障转移的结果通知给应用方。 主节点故障转移：实现从节点晋升为主节点并维护后续正确的主从关系。 配置提供者：在 RedisSentinel 结构中，客户端在初始化的时候连接的是 Sentinel 节点集合，从中获取主节点信息。 RedisSentinel 处理流程： Sentinel 集群通过给定的配置文件发现 master，启动时会监控 master。通过向 master 发送 info 信息获得该服务器下面的所有从服务器。 Sentinel 集群通过命令连接向被监视的主从服务器发送 hello 信息（每秒一次），该信息包括 Sentinel 本身的 IP、端口、id 等内容，以此来向其他 Sentinel 宣告自己的存在。 Sentinel 集群通过订阅连接接收其他 Sentinel 发送的 hello 信息，以此来发现监视同一个主服务器的其他 Sentinel；集群之间会互相创建命令连接用于通信，因为已经有主从服务器作为发送和接收 hello 信息的中介，Sentinel 之间不会创建订阅连接。 Sentinel 集群使用 ping 命令来检测实例的状态，如果在指定的时间内（down-after-milliseconds）没有回复或则返回错误的回复，那么该实例被判为下线。 当 failover 主备切换被触发后，failover 并不会马上进行，Sentinel 中的大多数 Sentinel 授权后才可以进行 failover，即进行 failover 的 Sentinel 会去获得指定 quorum 个的 Sentinel 的授权，成功后进入 ODOWN 状态。如在 5 个 Sentinel 中配置了 2 个 quorum，等到 2 个 Sentinel 认为 master 死了就执行 failover。 Sentinel 向选为 master 的 slave 发送 SLAVEOF NO ONE 命令，选择 slave 的条件是 Sentinel 首先会根据 slaves 的优先级来进行排序，优先级越小排名越靠前。如果优先级相同，则查看复制的下标，哪个从 master 接收的复制数据多，哪个就靠前。如果优先级和下标都相同，就选择进程 ID 较小的。 Sentinel 被授权后，它将会获得宕掉的 master 的一份最新配置版本号 (config-epoch)，当 failover 执行结束以后，这个版本号将会被用于最新的配置，通过广播形式通知其它 Sentinel，其它的 Sentinel 则更新对应 master 的配置。 1 到 3 是自动发现机制: 以 10 秒一次的频率，向被监视的 master 发送 info 命令，根据回复获取 master 当前信息。 以 1 秒一次的频率，向所有 redis 服务器、包含 Sentinel 在内发送 PING 命令，通过回复判断服务器是否在线。与主节点，从节点，其余 Sentinel 都建立起连接，实现了对每个节点的监控。 以 2 秒一次的频率，通过向所有被监视的 master，slave 服务器发送当前 Sentinel master 信息的消息。这个定时任务可以完成以下两个工作： 发现新的 Sentinel 节点：通过订阅主节点的 Sentinel:hello 了解其他 Sentinel 节点信息。如果是新加入的 Sentinel 节点，将该 Sentinel 节点信息保存起来，并与该 Sentinel 节点创建连接 Sentinel 节点之间交换主节点状态，作为后面客观下线以及领导者选举的依据 4 是检测机制，5 和 6 是 failover 机制，7 是更新配置机制 环境部署原则 Sentinel 节点不应该部署在一台物理机上。 部署至少三个且奇数个的 Sentinel 节点 只有一套 Sentinel，还是每个主节点配置一套 Sentinel 的讨论的建议方案是如果 Sentinel 节点集合监控的是同一个业务的多个主节点集合，那么使用方案一，否则使用方案 2。 部署架构本次使用 redis主从 + 哨兵 + VIP 的架构。 版本信息12345# uname -aLinux centos7 3.10.0-514.26.2.el7.x86_64 #1 SMP Tue Jul 4 15:04:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux# redis-server --versionRedis server v=3.2.10 sha=00000000:0 malloc=jemalloc-3.6.0 bits=64 build=c8b45a0ec7dc67c6 地址和端口规划 应用 ip 端口 Redis 主节点 192.168.31.63 6400 Redis 从从节点 192.168.31.64 6400 VIP 192.168.31.88 sentinel 本地节点 192.168.31.63 26400 sentinel 本地节点 192.168.31.64 26400 sentinel 仲裁节点 192.168.31.66 26400 部署安装 Redis在 192.168.31.63、192.168.31.64 和 192.168.31.66 节点上执行： 1yum -y install redis 配置 配置 Redis 修改 192.168.31.63 和 192.168.31.64 节点的 Redis 配置文件（/etc/redis_6400.conf）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758daemonize yes=== 以下根据实际情况修改 ===pidfile "/var/run/redis_6400.pid"port 6400tcp-backlog 65535bind 0.0.0.0notify-keyspace-events ""protected-mode norequirepass 123456logfile "/var/log/redis/redis_6400.log"dir "/data/redis/6400" # 需要提前新建好目录maxmemory 8gbmaxmemory-policy allkeys-lru#如果 master 设置了 requirepass，那 slave 要连上 master，需要有 master 的密码才行。# masterauth 就是用来配置 master 的密码，这样可以在连上 master 后进行认证。 masterauth 123456=== 以下配置采用默认配置 ===timeout 0tcp-keepalive 0loglevel noticedatabases 16save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename "dump.rdb"slave-serve-stale-data yesslave-read-only yesrepl-disable-tcp-nodelay noslave-priority 100appendonly noappendfilename "appendonly.aof"appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mblua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 128hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-entries 512list-max-ziplist-value 64set-max-intset-entries 512zset-max-ziplist-entries 128 redis 配置文件的详细讲解见：传送门 修改 sentinel 配置 在 192.168.31.63、192.168.31.64 和 192.168.31.66 节点上编写 sentinel 配置文件（/etc/redis-sentinel6400.conf） 123456789101112131415161718192021222324252627daemonize yesprotected-mode noport 26400dir "/data/redis/redis_sentinels" # 需要提前新建好目录pidfile "/var/run/redis/sentinel6400.pid"logfile "/data/redis/redis_sentinels/sentinel6400.log"# 监控的 master 的名字叫做 master6400（自定义），地址为192.168.31.63:6400# 行尾最后的一个 2 代表在 sentinel 集群中，多少个 sentinel 认为 masters 死了，才能真正认为该 master 不可用了。sentinel monitor master6400 192.168.31.63 6400 2# sentinel 会向 master 发送心跳 PING 来确认 master 是否存活# 如果 master 在「一定时间范围内」 不回应 PONG 或者是回复了一个错误消息# 那么这个 sentinel 会认为这个 master 已经不可用了 (subjectively down, 也简称为SDOWN)。# 而这个 down-after-milliseconds 就是用来指定这个「一定时间范围内」的，单位是毫秒，默认30秒。sentinel down-after-milliseconds master6400 6000# failover 过期时间，当 failover 开始后，在此时间内仍然没有触发任何 failover 操作，# 当前 sentinel 将会认为此次 failoer 失败。默认180秒，即3分钟。sentinel failover-timeout master6400 18000# sentinel 连接设置了密码的主和从sentinel auth-pass master6400 123456# 发生切换之后执行的一个自定义脚本：如发邮件、vip切换等# 仲裁节点无需添加这行配置，client-reconfig-script 参数是在 sentinel 做 failover 的过程中调用脚本漂 vip 到新的 master 上sentinel client-reconfig-script master6400 /opt/notify_master6400.sh 注意：要是参数配置的是默认值，在 sentinel 运行时该参数会在配置文件文件里被删除掉，直接不显示。也可以在运行时用命令 SENTINEL SET command 动态修改，后面说明。 很显然，只使用单个 sentinel 进程来监控 redis 集群是不可靠的，当 sentinel 进程宕掉后 （sentinel本身也有单点问题，single-point-of-failure） 整个集群系统将无法按照预期的方式运行。所以有必要将 sentinel 集群，这样有几个好处： 1：即使有一些 sentinel 进程宕掉了，依然可以进行 redis 集群的主备切换；2：如果只有一个 sentinel 进程，如果这个进程运行出错，或者是网络堵塞，那么将无法实现 redis 集群的主备切换（单点问题）;3：如果有多个 sentinel，redis 的客户端可以随意地连接任意一个 sentinel 来获得关于redis集群中的信息。 注意：当一个 master 配置为需要密码才能连接时，客户端和 slave 在连接时都需要提供密码。master 通过 requirepass 设置自身的密码，不提供密码无法连接到这 个master。slave 通过 masterauth 来设置访问 master 时的密码。客户端需要 auth 提供密码，但是当使用了 sentinel 时，由于一个 master 可能会变成一个 slave，一个 slave 也可能会变成 master，所以需要同时设置上述两个配置项，并且 sentinel 需要连接 master 和 slave，需要设置参数：sentinel auth-pass xxxxx。 撰写漂 VIP 的脚本 192.168.31.63、192.168.31.64节点上 /opt/notify_master6400.sh，并赋予可执行权限： 其中的网卡名称根据自己环境进行配置。 123456789101112131415#!/bin/bashMASTER_IP=$6LOCAL_IP='192.168.31.63' # 从库修改为 192.168.31.64VIP='192.168.31.88'NETMASK='24' INTERFACE='enp0s3' if [ $&#123;MASTER_IP&#125; = $&#123;LOCAL_IP&#125; ]; then /sbin/ip addr add $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $&#123;INTERFACE&#125; /sbin/arping -q -c 3 -A $&#123;VIP&#125; -I $&#123;INTERFACE&#125; exit 0else /sbin/ip addr del $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $&#123;INTERFACE&#125; exit 0fiexit 1 这里大概说一下这个脚本的工作原理，sentinel 在做 failover 的过程中会传出 6 个参数，分别是 &lt;master-name&gt;、 &lt;role&gt;、 &lt;state&gt;、 &lt;from-ip&gt;、 &lt;from-port&gt;、 &lt;to-ip&gt; 、&lt;to-port&gt;，其中第 6 个参数 from-ip 也就是新的 master 的 ip，对应脚本中的 MASTER_IP，下面的 if 判断大家应该都很了然了，如果 MASTER_IP=LOCAL_IP，那就绑定 VIP，反之删除 VIP。 服务启动和配置 启动redis服务 192.168.31.63、192.168.31.64 1redis-server /etc/redis_6400.conf 初始化主从 在 Redis 从节点 192.168.31.64 执行： 12# redis-cli -p 6400 -a 123456 slaveof 192.168.31.63 6400OK 绑定VIP到主库 192.168.31.63 1/sbin/ip addr add 192.168.31.88/24 dev enp0s3 启动 sentinel 服务 在 192.168.31.63、192.168.31.64 和 192.168.31.66 节点上执行： 1redis-server /etc/redis-sentinel6400.conf --sentinel redis-sentinel 日志12345678910111213141516171819202122232425+reset-master &lt;instance details&gt; -- 当master被重置时.+slave &lt;instance details&gt; -- 当检测到一个slave并添加进slave列表时.+failover-state-reconf-slaves &lt;instance details&gt; -- Failover状态变为reconf-slaves状态时+failover-detected &lt;instance details&gt; -- 当failover发生时+slave-reconf-sent &lt;instance details&gt; -- sentinel发送SLAVEOF命令把它重新配置时+slave-reconf-inprog &lt;instance details&gt; -- slave被重新配置为另外一个master的slave，但数据复制还未发生时。+slave-reconf-done &lt;instance details&gt; -- slave被重新配置为另外一个master的slave并且数据复制已经与master同步时。-dup-sentinel &lt;instance details&gt; -- 删除指定master上的冗余sentinel时 (当一个sentinel重新启动时，可能会发生这个事件).+sentinel &lt;instance details&gt; -- 当master增加了一个sentinel时。+sdown &lt;instance details&gt; -- 进入SDOWN状态时;-sdown &lt;instance details&gt; -- 离开SDOWN状态时。+odown &lt;instance details&gt; -- 进入ODOWN状态时。-odown &lt;instance details&gt; -- 离开ODOWN状态时。+new-epoch &lt;instance details&gt; -- 当前配置版本被更新时。+try-failover &lt;instance details&gt; -- 达到failover条件，正等待其他sentinel的选举。+elected-leader &lt;instance details&gt; -- 被选举为去执行failover的时候。+failover-state-select-slave &lt;instance details&gt; -- 开始要选择一个slave当选新master时。no-good-slave &lt;instance details&gt; -- 没有合适的slave来担当新masterselected-slave &lt;instance details&gt; -- 找到了一个适合的slave来担当新masterfailover-state-send-slaveof-noone &lt;instance details&gt; -- 当把选择为新master的slave的身份进行切换的时候。failover-end-for-timeout &lt;instance details&gt; -- failover由于超时而失败时。failover-end &lt;instance details&gt; -- failover成功完成时。switch-master &lt;master name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt; -- 当master的地址发生变化时。通常这是客户端最感兴趣的消息了。+tilt -- 进入Tilt模式。-tilt -- 退出Tilt模式。 至此，整个高可用方案已经搭建完成。 查看主从信息12345678910111213141516171819202122232425262728# redis-cli -h 192.168.31.63 -p 6400 -a 123456 info Replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.31.64,port=6400,state=online,offset=20290,lag=1master_repl_offset:20433repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:20432# redis-cli -h 192.168.31.64 -p 6400 -a 123456 info Replication# Replicationrole:slavemaster_host:192.168.31.63master_port:6400master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:21434slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 查看 sentinel 信息12345678# redis-cli -h 192.168.31.63 -a 123456 -p 26400 info Sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=master6400,status=ok,address=192.168.31.63:6400,slaves=1,sentinels=3 查看 VIPVIP 现在是绑定在主节点 192.168.31.63 上的。 1234# ip a|grep enp2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 inet 192.168.31.63/24 brd 192.168.31.255 scope global enp0s3 inet 192.168.31.88/24 scope global secondary enp0s3 可以看出当前 192.168.31.63 是主节点。 测试主从同步测试123456789101112131415## 在主节点设置一个 key-value# redis-cli -h 192.168.31.63 -a 123456 -p 6400 192.168.31.63:6400&gt; set test0426 ttttOK192.168.31.63:6400&gt; get test0426"tttt"## 备节点可以同步到数据# redis-cli -h 192.168.31.64 -a 123456 -p 6400 192.168.31.64:6400&gt; get test0426"tttt"## 并且备节点是只读节点，不可写192.168.31.64:6400&gt; set uuu s(error) READONLY You can't write against a read only slave. 高可用测试我们 down 掉主节点的 redis，测试下备节点是否可以升级为主节点，并且 VIP 是否可以漂移到备节点。 杀掉主节点 redis 进程 123456# ps -ef|grep redisroot 17873 1 0 13:02 ? 00:00:05 redis-sentinel *:26400 [sentinel]root 18098 1 0 13:18 ? 00:00:01 redis-server *:6400root 18238 2586 0 13:28 pts/0 00:00:00 grep --color=auto redis# kill 18098 查看 Replication 信息 主节点 redis 已无法访问，备节点已升级为主节点。 123456789101112# redis-cli -h 192.168.31.63 -a 123456 -p 6400 info ReplicationCould not connect to Redis at 192.168.31.63:6400: Connection refused# redis-cli -h 192.168.31.64 -a 123456 -p 6400 info Replication# Replicationrole:masterconnected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 查看 Sentinel 信息 同样可以看出 192.168.31.64 已升级为主节点。 12345678# redis-cli -h 192.168.31.63 -a 123456 -p 26400 info Sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=master6400,status=ok,address=192.168.31.64:6400,slaves=1,sentinels=3 查看 VIP 漂移 在 192.168.31.64 执行，可以看出 VIP 漂移成功。 1234ip a|grep enp2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 inet 192.168.31.64/24 brd 192.168.31.255 scope global enp0s3 inet 192.168.31.88/24 scope global secondary enp0s3 Sentinel 处理过程日志 192.168.31.63 节点： 12345678910111213141516171817873:X 26 Apr 13:10:10.117 # +sdown master master6400 192.168.31.63 6400 ## 进入主观不可用(SDOWN)17873:X 26 Apr 13:10:10.184 # +odown master master6400 192.168.31.63 6400 #quorum 3/2 ## 投票好了，达到了quorum，进入客观不可用(ODOWN)17873:X 26 Apr 13:10:10.184 # +new-epoch 48 ## 当前配置版本被更新17873:X 26 Apr 13:10:10.184 # +try-failover master master6400 192.168.31.63 6400 ## 达到failover条件，正等待其他sentinel的选举17873:X 26 Apr 13:10:10.207 # +vote-for-leader 500a19751ae3ae62af939699421ad53555b12b12 48 ## 选举17873:X 26 Apr 13:10:10.274 # db11c4e93efa99b49c59fc30b37b8433c43857fa voted for db11c4e93efa99b49c59fc30b37b8433c43857fa 48 ## 选举17873:X 26 Apr 13:10:10.281 # 7d031766571bc456cf087a082ff50cfa3934e1ff voted for 500a19751ae3ae62af939699421ad53555b12b12 48 ## 选举17873:X 26 Apr 13:10:10.336 # +elected-leader master master6400 192.168.31.63 6400 ## 执行failover17873:X 26 Apr 13:10:10.336 # +failover-state-select-slave master master6400 192.168.31.63 6400 ## 开始要选择一个slave当选新master17873:X 26 Apr 13:10:10.437 # +selected-slave slave 192.168.31.64:6400 192.168.31.64 6400 @ master6400 192.168.31.63 6400 ## 找到了一个适合的slave来担当新master17873:X 26 Apr 13:10:10.438 * +failover-state-send-slaveof-noone slave 192.168.31.64:6400 192.168.31.64 6400 @ master6400 192.168.31.63 6400 ## 当把选择为新master的slave的身份进行切换17873:X 26 Apr 13:10:10.528 * +failover-state-wait-promotion slave 192.168.31.64:6400 192.168.31.64 6400 @ master6400 192.168.31.63 640017873:X 26 Apr 13:10:11.391 # +promoted-slave slave 192.168.31.64:6400 192.168.31.64 6400 @ master6400 192.168.31.63 640017873:X 26 Apr 13:10:11.391 # +failover-state-reconf-slaves master master6400 192.168.31.63 6400 ## Failover状态变为reconf-slaves17873:X 26 Apr 13:10:11.479 # +failover-end master master6400 192.168.31.63 6400 ## failover成功完成17873:X 26 Apr 13:10:11.479 # +switch-master master6400 192.168.31.63 6400 192.168.31.64 6400 ## master的地址发生变化17873:X 26 Apr 13:10:11.480 * +slave slave 192.168.31.63:6400 192.168.31.63 6400 @ master6400 192.168.31.64 640017873:X 26 Apr 13:10:17.539 # +sdown slave 192.168.31.63:6400 192.168.31.63 6400 @ master6400 192.168.31.64 6400 ## 原主进入主观不可用状态 数据恢复测试在原主节点 192.168.31.63 未恢复的情况下，往 192.168.31.64 写数据，看 192.168.31.63 恢复后是否可以同步到数据。 123456789# redis-cli -h 192.168.31.64 -a 123456 -p 6400 192.168.31.64:6400&gt; set hoxis hhOK192.168.31.64:6400&gt; get hoxis"hh"# redis-cli -h 192.168.31.63 -a 123456 -p 6400 192.168.31.63:6400&gt; get hoxis"hh" 可以恢复成功，当然，数据量大时，数据同步是需要一定的时间的。 其他Leader 选举其实在 sentinels 故障转移中，仍然需要一个 Leader 来调度整个过程：master 的选举以及 slave 的重配置和同步。当集群中有多个 sentinel 实例时，如何选举其中一个 sentinel 为 leader 呢？ 在配置文件中 can-failover、quorum 参数，以及 is-master-down-by-addr 指令配合来完成整个过程。 can-failover 用来表明当前 sentinel 是否可以参与 failover 过程，如果为 YES 则表明它将有能力参与 Leader 的选举，否则它将作为 Observer ，observer 参与 leader 选举投票但不能被选举； quorum 不仅用来控制 master ODOWN 状态确认，同时还用来选举 leader 时最小「赞同票」数； is-master-down-by-addr，在上文中以及提到，它可以用来检测 ip + port 的 master 是否已经处于 SDOWN 状态，不过此指令不仅能够获得 master 是否处于 SDOWN，同时它还额外的返回当前 sentinel 本地「投票选举」的 Leader 信息 (runid); 每个 sentinel 实例都持有其他的 sentinels 信息，在 Leader 选举过程中（当为 leader 的 sentinel 实例失效时，有可能 master server 并没失效，注意分开理解），sentinel 实例将从所有的 sentinels 集合中去除 can-failover = no 和状态为 SDOWN 的 sentinels，在剩余的 sentinels 列表中按照 runid 按照「字典」顺序排序后，取出 runid 最小的 sentinel 实例，并将它「投票选举」为 Leader，并在其他 sentinel 发送的 is-master-down-by-addr 指令时将推选的 runid 追加到响应中。每个 sentinel 实例都会检测 is-master-down-by-addr 的响应结果，如果「投票选举」的 leader 为自己，且状态正常的 sentinels 实例中，赞同者的自己的 sentinel 个数不小于(&gt;=) 50% + 1,且不小与 ，那么此 sentinel 就会认为选举成功且 leader 为自己。 在 sentinel.conf 文件中，我们期望有足够多的 sentinel 实例配置 can-failovers，这样能够确保当 leader 失效时，能够选举某个 sentinel 为 leader，以便进行 failover。如果 leader 无法产生，比如较少的 sentinels 实例有效，那么 failover 过程将续。 failover 过程在 Leader 触发 failover 之前，首先 wait 数秒（随机 0~5），以便让其他 sentinel 实例准备和调整，如果一切正常，那么 leader 就需要开始将一个 salve 提升为 master，此 slave 必须为状态良好（不能处于 SDOWN/ODOWN 状态）且权重值最低（redis.conf中）的，当 master 身份被确认后，开始 failover： +failover-triggered: Leader 开始进行 failover，此后紧跟着 +failover-state-wait-start ，wait 数秒。 +failover-state-select-slave: Leader 开始查找合适的 slave +selected-slave: 已经找到合适的 slave +failover-state-sen-slaveof-noone: Leader 向 slave 发送 slaveof no one 指令，此时 slave 已经完成角色转换，此 slave 即为 master +failover-state-wait-promotition: 等待其他 sentinel 确认 slave +promoted-slave：确认成功 +failover-state-reconf-slaves: 开始对 slaves 进行 reconfig 操作。 +slave-reconf-sent: 向指定的 slave 发送 slaveof 指令，告知此 slave 跟随新的 master +slave-reconf-inprog: 此 slave 正在执行 slaveof + SYNC 过程，如过 slave 收到 +slave-reconf-sent 之后将会执行 slaveof 操作。 +slave-reconf-done: 此 slave 同步完成，此后 leader 可以继续下一个 slave 的 reconfig 操作。循环步骤 10 +failover-end: 故障转移结束 +switch-master：故障转移成功后，各个 sentinel 实例开始监控新的 master。 总结Redis-Sentinel 是 Redis 官方推荐的高可用性解决方案，Redis-sentinel 本身也是一个独立运行的进程，它能监控多个 master-slave 集群，发现 master 宕机后能进行自动切换。Sentinel 可以监视任意多个主服务器（复用），以及主服务器属下的从服务器，并在被监视的主服务器下线时，自动执行故障转移操作。 为了防止 sentinel 的单点故障，可以对 sentinel 进行集群化，创建多个 sentinel。 本文中所使用的 Redis Sentinel 集群 + VIP + 自定义脚本的优缺点： 优点： 秒级切换，在 5s 内完成整个切换操作 脚本自定义，架构可控 对应用透明，前端不用担心后端发生什么变化 缺点： 维护成本略高，Redis Sentinel 集群建议投入 3 台机器以上 使用 VIP 增加维护成本，存在 IP 混乱风险 Sentinel 模式存在短时间的服务不可用 参考： http://blog.51cto.com/navyaijm/1745569 http://www.cnblogs.com/zhoujinyi/p/5570024.html https://blog.csdn.net/sunhuiliang85/article/details/78361211 https://dbarobin.com/2017/05/27/ha-of-redis/]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 知识点拾遗]]></title>
    <url>%2Fpython-knowledge-point.html</url>
    <content type="text"><![CDATA[Python 高级知识点，如 == 和 is 的区别，位运算。 import 导入模块import 搜索路径123&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path['', '/usr/lib/python35.zip', '/usr/lib/python3.5', '/usr/lib/python3.5/plat-x86_64-linux-gnu', '/usr/lib/python3.5/lib-dynload', '/home/liuhao/.local/lib/python3.5/site-packages', '/usr/local/lib/python3.5/dist-packages', '/usr/local/lib/python3.5/dist-packages/setuptools-38.4.0-py3.5.egg', '/usr/local/lib/python3.5/dist-packages/flansible-1.0-py3.5.egg', '/usr/local/lib/python3.5/dist-packages/Flask_RESTful-0.3.6-py3.5.egg', '/usr/local/lib/python3.5/dist-packages/aniso8601-3.0.0-py3.5.egg', '/usr/local/lib/python3.5/dist-packages/ansible-2.5.0-py3.5.egg', '/usr/local/lib/python3.5/dist-packages/suitable-0.10.1-py3.5.egg', '/usr/lib/python3/dist-packages'] 路径搜索 从上面列出的目录里依次查找要导入的模块文件 &#39;&#39; 表示当前路径 新增导入路径 12sys.path.append('/home/itcast/xxx')sys.path.insert(0, '/home/itcast/xxx') #可以确保先搜索这个路径 重新导入模块模块被导入后，import module不能重新导入模块，重新导入需用 12from imp import reloadreload(test) # 重新导入模块 == 和 is123456789101112131415161718192021222324252627&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = [1,2,3]&gt;&gt;&gt; a == bTrue&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; a = 100&gt;&gt;&gt; b = 100&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; a == bTrue&gt;&gt;&gt; a = 300&gt;&gt;&gt; b = 300&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; a == bTrue&gt;&gt;&gt; a = '123'&gt;&gt;&gt; b = '123'&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; a == bTrue is 是比较两个引用是否指向了同一个对象（引用比较）也被叫做同一性运算符，这个运算符比较判断的是对象间的唯一身份标识，也就是id是否相同。 == 用来比较判断两个对象的 value （值）是否相等 类似于 Java 同样存在，比较引用还是比较真实值的问题 Python 在为数字分配内存时，按照数字的内容来分配内存，即 a = 5;b = 5时，Python 只对数字 5 分配一块内存空间，而不是对变量 a 和 b 各分配一块内存；（在 Python 交互式界面有内存池缓存机制，只适用于 -5~256，在 Python 脚本编程中则没有这个限制） 1）Python 中一切都是对象；2）Python 中 None 是唯一的； 每个对象包含3个属性，id，type，value id 就是对象地址，可以通过内置函数 id() 查看对象引用的地址。 type 就是对象类型，可以通过内置函数 type() 查看对象的类型。 value 就是对象的值。 如下脚本的输出会是什么（非 Python 交互式环境）？ 123a = 300b = 300print(a is b) 正确答案是 True。 是不是很惊喜 &#x1f60f; 位运算 &amp; 按位与 | 按位或 ^ 按位异或 ~ 按位取反 &lt;&lt; 按位左移 &gt;&gt; 按位右移 用途: 直接操作二进制、省内存、效率高 &lt;&lt; 按位左移各二进位全部左移 n 位，高位丢弃，低位补 0 注意事项： 左移 1 位相当于乘以 2，可以用于快速计算一个数乘以 2 的 n 次方（ 8&lt;&lt;3 等同于 8*2^3） 左移可能会改变一个数的正负性 &gt;&gt; 按位右移各二进位全部右移 n 位，保持符号位不变 x &gt;&gt; n，x 的所有二进制位向右移动 n 位，移出的位删掉，移进的位补符号位 右移不会改变一个数的符号 注意事项： 右移 1 位相当于除以 2 x 右移 n 位就相当于除以 2 的 n 次方，用途：快速计算一个数除以 2 的 n 次方（8&gt;&gt;3 等同于 8/2^3） &amp; 按位与全 1 才 1 否则 0 ：只有对应的两个二进位均为 1 时，结果位才为 1，否则为 0 | 按位或有 1 就 1：只要对应的二个二进位有一个为 1 时，结果位就为 1，否则为 0 ^ 按位异或不同为 1：当对应的二进位相异（不相同）时，结果为 1，否则为 0 任何数和 1 进行 &amp; 操作，得到这个数的最低位。即：数字&amp;1 = 数字的二进制形式的最低位 位运算优先级 私有化 xx：公有变量 _x：单前置下划线，私有化属性或方法，from somemodule import * 禁止导入，类对象和子类可以访问 __xx：双前置下划线，避免与子类中的属性命名冲突，无法在外部直接访问（名字重整所以访问不到） __xx__：双前后下划线，用户名字空间的魔法对象或属性。例如：__init__，不要自己发明这样的名字 xx_：单后置下划线，用于避免与 Python 关键词的冲突 1234567891011121314151617181920212223242526class Person(object): def __init__(self, age = 18): # 私有化属性，无法从外部直接获取 self.__age = age def setAge(self, age): self.__age = age def getAge(self): return self.__agep1 = Person()# print(p1.__age) # 会报错print(p1.getAge())# 获取对象的所有属性和方法print(dir(p1))# 相当于为 p1 新分配一个 __age 属性p1.__age = 20# 获取对象的所有属性和方法print(dir(p1))print(p1.__age)print(p1.getAge()) 运行结果 12345678$ python private.py18['_Person__age', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'getAge', 'setAge']# 可以看到新增了一个新的属性['_Person__age', '__age', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'getAge', 'setAge']2018 可以看到 Python 对类的私有属性进行了重整，__age 变成了 _Person__age，因此无法直接获取到。 总结 父类中属性名为 __xx 的，子类不继承，子类不能访问 如果在子类中向 __xx 赋值，那么会在子类中定义的一个与父类相同名字的属性 _xx 的变量、函数、类在使用 from xxx import * 时都不会被导入 在绑定属性时，如果我们直接把属性暴露出去，虽然写起来很简单，但是，没办法对参数进行检查，于是我们可以使用 get、set 方法来对属性进行设置和检查。 123456789101112class Money(object): def __init__(self): self.__money = 0 def getMoney(self): return self.__money def setMoney(self, money): if isinstance(money, int): self.__money = money else: print("error: 不是整型数字") 但是，上面的调用方法又略显复杂，没有直接用属性这么直接简单。 有没有既能检查参数，又可以用类似属性这样简单的方式来访问类的变量呢？ Python 内置的 @property 装饰器就是负责把一个方法变成属性调用的： 1234567891011121314class Money(object): def __init__(self): self.__money = 0 @property def xmoney(self): return self.__money @xmoney.setter def xmoney(self, money): if isinstance(money, int): self.__money = money else: print("error: 不是整型数字") @property 的实现比较复杂，我们先考察如何使用。把一个 getter 方法变成属性，只需要加上 @property 就可以了，此时，@property 本身又创建了另一个装饰器 @money.setter，负责把一个 setter 方法变成属性赋值，于是，我们就拥有一个可控的属性操作： 12345678&gt;&gt;&gt; from private import Money&gt;&gt;&gt; m = Money()&gt;&gt;&gt; m.xmoney0&gt;&gt;&gt; m.xmoney = 99&gt;&gt;&gt; m.xmoney99&gt;&gt;&gt; 注意到这个神奇的 @property，我们在对实例属性操作的时候，就知道该属性很可能不是直接暴露的，而是通过 getter 和 setter 方法来实现的。 @property 成为属性函数，可以对属性赋值时做必要的检查，并保证代码的清晰短小，主要有 2 个作用： 将方法转换为只读 重新实现一个属性的设置和读取方法，可做边界判定]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 文件操作]]></title>
    <url>%2Fpython-handle-file.html</url>
    <content type="text"><![CDATA[Python 文件操作主要包括打开文件、读文件、写文件、修改文件、关闭文件等操作，还会写一些基本操作方法。 打开文件 - open()在 python，使用 open 函数，可以打开一个已经存在的文件，或者创建一个新文件 open(文件名，访问模式) 示例如下： 1f = open('test.txt', 'w') 访问模式 说明 r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 w 打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件进行写入。 rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件进行写入。 r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 w+ 打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。 wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 关闭文件 - close()12345# 新建一个文件，文件名为test.txtf = open('test.txt', 'w')# 关闭这个文件f.close() 写文件 - write()1234&gt;&gt;&gt; f = open('text.txt', 'w')&gt;&gt;&gt; f.write('hello!')6&gt;&gt;&gt; f.close() 如果文件不存在那么创建，如果存在那么就先清空，然后写入数据 读文件 - read()使用 read(num) 可以从文件中读取数据，num 表示要从文件中读取的数据的长度（单位是字节），如果没有传入 num ，那么就表示读取文件中所有的数据。 12345&gt;&gt;&gt; f = open('text.txt', 'r')&gt;&gt;&gt; content = f.read()&gt;&gt;&gt; content'hello!'&gt;&gt;&gt; f.close() 读数据 - readlines()readlines 可以按照行的方式把整个文件中的内容进行一次性读取，并且返回的是一个列表，其中每一行的数据为一个元素。1234&gt;&gt;&gt; f = open('text.txt', 'r')&gt;&gt;&gt; result = f.readlines()&gt;&gt;&gt; result['hello!\n', 'world\n', 'haha\n'] 读数据 - readline()1234567&gt;&gt;&gt; f = open('text.txt', 'r')&gt;&gt;&gt; f.readline()'hello!\n'&gt;&gt;&gt; f.readline()'world\n'&gt;&gt;&gt; f.readline()'haha\n' 处理大文件一般的读取，readlines()、read() 等会将整个文件加载到内存中。在文件较大时，往往会引发 MemoryError（内存溢出）。本人试了用 readlines() 读取一个 2G 大小的日志文件，结果本子直接跑挂。 处理方法一般有以下几种： 逐行读取12345while True: line = f.readline() if not line: # 到 EOF，返回空字符串，则终止循环 break do_something(line) 使用 with 结构with 语句句柄负责打开和关闭文件（包括在内部块中引发异常时），for line in f 对可迭代对象 f 进行迭代遍历，会自动地使用缓冲IO（buffered IO）以及内存管理，而不必担心任何大文件的问题。 这也是较为推荐使用的方法。 123with open(filename, 'rb') as f: for line in f: &lt;do something with the line&gt; 文件的随机读写获取当前读写的位置 - tell()在读写文件的过程中，如果想知道当前的位置，可以使用 tell() 来获取。 123456789101112&gt;&gt;&gt; f = open('/mnt/d/download/catalina.out','r')&gt;&gt;&gt; str = f.read(3)&gt;&gt;&gt; str'Apr'&gt;&gt;&gt; str = f.read(30)&gt;&gt;&gt; str' 25, 2017 10:54:11 AM org.apac'&gt;&gt;&gt; f.tell()33&gt;&gt;&gt; str = f.read(200)&gt;&gt;&gt; f.tell()233 定位到某个位置 - seek()如果在读写文件的过程中，需要从另外一个位置进行操作的话，可以使用 seek()。 seek(offset, from)： offset - 偏移量 from - 方向 0 - 表示文件开头 1 - 表示当前位置 2 - 表示文件末尾 12345678910111213141516171819&gt;&gt;&gt; f = open('/mnt/d/download/catalina.out','r') &gt;&gt;&gt; f.read(30) 'Apr 25, 2017 10:54:11 AM org.a' &gt;&gt;&gt; f.tell() 30 # 把位置设置为：从文件开头，偏移6个字节&gt;&gt;&gt; f.seek(6,0) 6 &gt;&gt;&gt; f.tell() 6 # 把位置设置为：离文件末尾，20个字节处，需要已rb模式打开&gt;&gt;&gt; f = open('/mnt/d/download/catalina.out','rb')&gt;&gt;&gt; f.seek(-20,2)2238539151&gt;&gt;&gt; f.read(10)b'ged at DEB'&gt;&gt;&gt; f.read(10)b'UG level.\n' 文件重命名 - os.rename(&#39;srcFile&#39;, &#39;destFile&#39;)os 模块中的 rename() 可以完成对文件的重命名操作 删除文件 - os.remove(&#39;fileName&#39;)文件夹的相关操作 创建文件夹 - os.mkdir(&#39;dirName&#39;) 获取当前目录 - os.getcwd() 改变目录 - os.chdir(&#39;../&#39;) 获取目录列表 - os.listdir(&#39;./&#39;) 删除文件夹 - os.rmdir(&#39;dirName&#39;)，不能删除非空目录 123456789101112&gt;&gt;&gt; os.getcwd()'/mnt/d/code/Python/itcast'&gt;&gt;&gt; os.mkdir('test')&gt;&gt;&gt; os.chdir('test')&gt;&gt;&gt; os.listdir('.')[]&gt;&gt;&gt; os.chdir('../')&gt;&gt;&gt; os.listdir('./')['07day_1.py', '07day_2.py', '07day_3.py', '1_1.py', 'func.py', 'test']&gt;&gt;&gt; os.rmdir('test')&gt;&gt;&gt; os.listdir('./')['07day_1.py', '07day_2.py', '07day_3.py', '1_1.py', 'func.py']]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[emoji-cheat-sheet]]></title>
    <url>%2Femoji-cheat-sheet.html</url>
    <content type="text"><![CDATA[emoji-cheat-sheet People &#x1f604; &#x1f604; &#x1f604; :bowtie: &#x1f604; :smile: &#x1f606; :laughing: &#x1f60a; :blush: &#x1f603; :smiley: &#x263a; :relaxed: &#x1f60f; :smirk: &#x1f60d; :heart_eyes: &#x1f618; :kissing_heart: &#x1f61a; :kissing_closed_eyes: &#x1f633; :flushed: &#x1f60c; :relieved: &#x1f606; :satisfied: &#x1f601; :grin: &#x1f609; :wink: &#x1f61c; :stuck_out_tongue_winking_eye: &#x1f61d; :stuck_out_tongue_closed_eyes: &#x1f600; :grinning: &#x1f617; :kissing: &#x1f619; :kissing_smiling_eyes: &#x1f61b; :stuck_out_tongue: &#x1f634; :sleeping: &#x1f61f; :worried: &#x1f626; :frowning: &#x1f627; :anguished: &#x1f62e; :open_mouth: &#x1f62c; :grimacing: &#x1f615; :confused: &#x1f62f; :hushed: &#x1f611; :expressionless: &#x1f612; :unamused: &#x1f605; :sweat_smile: &#x1f613; :sweat: &#x1f625; :disappointed_relieved: &#x1f629; :weary: &#x1f614; :pensive: &#x1f61e; :disappointed: &#x1f616; :confounded: &#x1f628; :fearful: &#x1f630; :cold_sweat: &#x1f623; :persevere: &#x1f622; :cry: &#x1f62d; :sob: &#x1f602; :joy: &#x1f632; :astonished: &#x1f631; :scream: :neckbeard: &#x1f62b; :tired_face: &#x1f620; :angry: &#x1f621; :rage: &#x1f624; :triumph: &#x1f62a; :sleepy: &#x1f60b; :yum: &#x1f637; :mask: &#x1f60e; :sunglasses: &#x1f635; :dizzy_face: &#x1f47f; :imp: &#x1f608; :smiling_imp: &#x1f610; :neutral_face: &#x1f636; :no_mouth: &#x1f607; :innocent: &#x1f47d; :alien: &#x1f49b; :yellow_heart: &#x1f499; :blue_heart: &#x1f49c; :purple_heart: &#x2764; :heart: &#x1f49a; :green_heart: &#x1f494; :broken_heart: &#x1f493; :heartbeat: &#x1f497; :heartpulse: &#x1f495; :two_hearts: &#x1f49e; :revolving_hearts: &#x1f498; :cupid: &#x1f496; :sparkling_heart: &#x2728; :sparkles: &#x2b50; :star: &#x1f31f; :star2: &#x1f4ab; :dizzy: &#x1f4a5; :boom: &#x1f4a5; :collision: &#x1f4a2; :anger: &#x2757; :exclamation: &#x2753; :question: &#x2755; :grey_exclamation: &#x2754; :grey_question: &#x1f4a4; :zzz: &#x1f4a8; :dash: &#x1f4a6; :sweat_drops: &#x1f3b6; :notes: &#x1f3b5; :musical_note: &#x1f525; :fire: &#x1f4a9; :hankey: &#x1f4a9; :poop: &#x1f4a9; :shit: :+1: :+1: &#x1f44d; :thumbsup: :-1: :-1: &#x1f44e; :thumbsdown: &#x1f44c; :ok_hand: &#x1f44a; :punch: &#x1f44a; :facepunch: &#x270a; :fist: &#x270c; :v: &#x1f44b; :wave: &#x270b; :hand: &#x270b; :raised_hand: &#x1f450; :open_hands: &#x261d; :point_up: &#x1f447; :point_down: &#x1f448; :point_left: &#x1f449; :point_right: &#x1f64c; :raised_hands: &#x1f64f; :pray: &#x1f446; :point_up_2: &#x1f44f; :clap: &#x1f4aa; :muscle: &#x1f918; :metal: &#x1f595; :fu: &#x1f6b6; :walking: &#x1f3c3; :runner: &#x1f3c3; :running: &#x1f46b; :couple: &#x1f46a; :family: &#x1f46c; :two_men_holding_hands: &#x1f46d; :two_women_holding_hands: &#x1f483; :dancer: &#x1f46f; :dancers: &#x1f646; :ok_woman: &#x1f645; :no_good: &#x1f481; :information_desk_person: &#x1f64b; :raising_hand: &#x1f470; :bride_with_veil: &#x1f64e; :person_with_pouting_face: &#x1f64d; :person_frowning: &#x1f647; :bow: :couplekiss: :couplekiss: &#x1f491; :couple_with_heart: &#x1f486; :massage: &#x1f487; :haircut: &#x1f485; :nail_care: &#x1f466; :boy: &#x1f467; :girl: &#x1f469; :woman: &#x1f468; :man: &#x1f476; :baby: &#x1f475; :older_woman: &#x1f474; :older_man: &#x1f471; :person_with_blond_hair: &#x1f472; :man_with_gua_pi_mao: &#x1f473; :man_with_turban: &#x1f477; :construction_worker: &#x1f46e; :cop: &#x1f47c; :angel: &#x1f478; :princess: &#x1f63a; :smiley_cat: &#x1f638; :smile_cat: &#x1f63b; :heart_eyes_cat: &#x1f63d; :kissing_cat: &#x1f63c; :smirk_cat: &#x1f640; :scream_cat: &#x1f63f; :crying_cat_face: &#x1f639; :joy_cat: &#x1f63e; :pouting_cat: &#x1f479; :japanese_ogre: &#x1f47a; :japanese_goblin: &#x1f648; :see_no_evil: &#x1f649; :hear_no_evil: &#x1f64a; :speak_no_evil: &#x1f482; :guardsman: &#x1f480; :skull: &#x1f43e; :feet: &#x1f444; :lips: &#x1f48b; :kiss: &#x1f4a7; :droplet: &#x1f442; :ear: &#x1f440; :eyes: &#x1f443; :nose: &#x1f445; :tongue: &#x1f48c; :love_letter: &#x1f464; :bust_in_silhouette: &#x1f465; :busts_in_silhouette: &#x1f4ac; :speech_balloon: &#x1f4ad; :thought_balloon: :feelsgood: :finnadie: :goberserk: :godmode: :hurtrealbad: :rage1: :rage2: :rage3: :rage4: :suspect: :trollface: Nature &#x2600; :sunny: &#x2614; :umbrella: &#x2601; :cloud: &#x2744; :snowflake: &#x26c4; :snowman: &#x26a1; :zap: &#x1f300; :cyclone: &#x1f301; :foggy: &#x1f30a; :ocean: &#x1f431; :cat: &#x1f436; :dog: &#x1f42d; :mouse: &#x1f439; :hamster: &#x1f430; :rabbit: &#x1f43a; :wolf: &#x1f438; :frog: &#x1f42f; :tiger: &#x1f428; :koala: &#x1f43b; :bear: &#x1f437; :pig: &#x1f43d; :pig_nose: &#x1f42e; :cow: &#x1f417; :boar: &#x1f435; :monkey_face: &#x1f412; :monkey: &#x1f434; :horse: &#x1f40e; :racehorse: &#x1f42b; :camel: &#x1f411; :sheep: &#x1f418; :elephant: &#x1f43c; :panda_face: &#x1f40d; :snake: &#x1f426; :bird: &#x1f424; :baby_chick: &#x1f425; :hatched_chick: &#x1f423; :hatching_chick: &#x1f414; :chicken: &#x1f427; :penguin: &#x1f422; :turtle: &#x1f41b; :bug: &#x1f41d; :honeybee: &#x1f41c; :ant: &#x1f41e; :beetle: &#x1f40c; :snail: &#x1f419; :octopus: &#x1f420; :tropical_fish: &#x1f41f; :fish: &#x1f433; :whale: &#x1f40b; :whale2: &#x1f42c; :dolphin: &#x1f404; :cow2: &#x1f40f; :ram: &#x1f400; :rat: &#x1f403; :water_buffalo: &#x1f405; :tiger2: &#x1f407; :rabbit2: &#x1f409; :dragon: &#x1f410; :goat: &#x1f413; :rooster: &#x1f415; :dog2: &#x1f416; :pig2: &#x1f401; :mouse2: &#x1f402; :ox: &#x1f432; :dragon_face: &#x1f421; :blowfish: &#x1f40a; :crocodile: &#x1f42a; :dromedary_camel: &#x1f406; :leopard: &#x1f408; :cat2: &#x1f429; :poodle: &#x1f43e; :paw_prints: &#x1f490; :bouquet: &#x1f338; :cherry_blossom: &#x1f337; :tulip: &#x1f340; :four_leaf_clover: &#x1f339; :rose: &#x1f33b; :sunflower: &#x1f33a; :hibiscus: &#x1f341; :maple_leaf: &#x1f343; :leaves: &#x1f342; :fallen_leaf: &#x1f33f; :herb: &#x1f344; :mushroom: &#x1f335; :cactus: &#x1f334; :palm_tree: &#x1f332; :evergreen_tree: &#x1f333; :deciduous_tree: &#x1f330; :chestnut: &#x1f331; :seedling: &#x1f33c; :blossom: &#x1f33e; :ear_of_rice: &#x1f41a; :shell: &#x1f310; :globe_with_meridians: &#x1f31e; :sun_with_face: &#x1f31d; :full_moon_with_face: &#x1f31a; :new_moon_with_face: &#x1f311; :new_moon: &#x1f312; :waxing_crescent_moon: &#x1f313; :first_quarter_moon: &#x1f314; :waxing_gibbous_moon: &#x1f315; :full_moon: &#x1f316; :waning_gibbous_moon: &#x1f317; :last_quarter_moon: &#x1f318; :waning_crescent_moon: &#x1f31c; :last_quarter_moon_with_face: &#x1f31b; :first_quarter_moon_with_face: &#x1f314; :moon: &#x1f30d; :earth_africa: &#x1f30e; :earth_americas: &#x1f30f; :earth_asia: &#x1f30b; :volcano: &#x1f30c; :milky_way: &#x26c5; :partly_sunny: :octocat: :squirrel: Objects &#x1f38d; :bamboo: &#x1f49d; :gift_heart: &#x1f38e; :dolls: &#x1f392; :school_satchel: &#x1f393; :mortar_board: &#x1f38f; :flags: &#x1f386; :fireworks: &#x1f387; :sparkler: &#x1f390; :wind_chime: &#x1f391; :rice_scene: &#x1f383; :jack_o_lantern: &#x1f47b; :ghost: &#x1f385; :santa: &#x1f384; :christmas_tree: &#x1f381; :gift: &#x1f514; :bell: &#x1f515; :no_bell: &#x1f38b; :tanabata_tree: &#x1f389; :tada: &#x1f38a; :confetti_ball: &#x1f388; :balloon: &#x1f52e; :crystal_ball: &#x1f4bf; :cd: &#x1f4c0; :dvd: &#x1f4be; :floppy_disk: &#x1f4f7; :camera: &#x1f4f9; :video_camera: &#x1f3a5; :movie_camera: &#x1f4bb; :computer: &#x1f4fa; :tv: &#x1f4f1; :iphone: &#x260e; :phone: &#x260e; :telephone: &#x1f4de; :telephone_receiver: &#x1f4df; :pager: &#x1f4e0; :fax: &#x1f4bd; :minidisc: &#x1f4fc; :vhs: &#x1f509; :sound: &#x1f508; :speaker: &#x1f507; :mute: &#x1f4e2; :loudspeaker: &#x1f4e3; :mega: &#x231b; :hourglass: &#x23f3; :hourglass_flowing_sand: &#x23f0; :alarm_clock: &#x231a; :watch: &#x1f4fb; :radio: &#x1f4e1; :satellite: &#x27bf; :loop: &#x1f50d; :mag: &#x1f50e; :mag_right: &#x1f513; :unlock: &#x1f512; :lock: &#x1f50f; :lock_with_ink_pen: &#x1f510; :closed_lock_with_key: &#x1f511; :key: &#x1f4a1; :bulb: &#x1f526; :flashlight: &#x1f506; :high_brightness: &#x1f505; :low_brightness: &#x1f50c; :electric_plug: &#x1f50b; :battery: &#x1f4f2; :calling: &#x2709; :email: &#x1f4eb; :mailbox: &#x1f4ee; :postbox: &#x1f6c0; :bath: &#x1f6c1; :bathtub: &#x1f6bf; :shower: &#x1f6bd; :toilet: &#x1f527; :wrench: &#x1f529; :nut_and_bolt: &#x1f528; :hammer: &#x1f4ba; :seat: &#x1f4b0; :moneybag: &#x1f4b4; :yen: &#x1f4b5; :dollar: &#x1f4b7; :pound: &#x1f4b6; :euro: &#x1f4b3; :credit_card: &#x1f4b8; :money_with_wings: :e-mail: :e-mail: &#x1f4e5; :inbox_tray: &#x1f4e4; :outbox_tray: &#x2709; :envelope: &#x1f4e8; :incoming_envelope: &#x1f4ef; :postal_horn: &#x1f4ea; :mailbox_closed: &#x1f4ec; :mailbox_with_mail: &#x1f4ed; :mailbox_with_no_mail: &#x1f6aa; :door: &#x1f6ac; :smoking: &#x1f4a3; :bomb: &#x1f52b; :gun: &#x1f52a; :hocho: &#x1f48a; :pill: &#x1f489; :syringe: &#x1f4c4; :page_facing_up: &#x1f4c3; :page_with_curl: &#x1f4d1; :bookmark_tabs: &#x1f4ca; :bar_chart: &#x1f4c8; :chart_with_upwards_trend: &#x1f4c9; :chart_with_downwards_trend: &#x1f4dc; :scroll: &#x1f4cb; :clipboard: &#x1f4c6; :calendar: &#x1f4c5; :date: &#x1f4c7; :card_index: &#x1f4c1; :file_folder: &#x1f4c2; :open_file_folder: &#x2702; :scissors: &#x1f4cc; :pushpin: &#x1f4ce; :paperclip: &#x2712; :black_nib: &#x270f; :pencil2: &#x1f4cf; :straight_ruler: &#x1f4d0; :triangular_ruler: &#x1f4d5; :closed_book: &#x1f4d7; :green_book: &#x1f4d8; :blue_book: &#x1f4d9; :orange_book: &#x1f4d3; :notebook: &#x1f4d4; :notebook_with_decorative_cover: &#x1f4d2; :ledger: &#x1f4da; :books: &#x1f516; :bookmark: &#x1f4db; :name_badge: &#x1f52c; :microscope: &#x1f52d; :telescope: &#x1f4f0; :newspaper: &#x1f3c8; :football: &#x1f3c0; :basketball: &#x26bd; :soccer: &#x26be; :baseball: &#x1f3be; :tennis: &#x1f3b1; :8ball: &#x1f3c9; :rugby_football: &#x1f3b3; :bowling: &#x26f3; :golf: &#x1f6b5; :mountain_bicyclist: &#x1f6b4; :bicyclist: &#x1f3c7; :horse_racing: &#x1f3c2; :snowboarder: &#x1f3ca; :swimmer: &#x1f3c4; :surfer: &#x1f3bf; :ski: &#x2660; :spades: &#x2665; :hearts: &#x2663; :clubs: &#x2666; :diamonds: &#x1f48e; :gem: &#x1f48d; :ring: &#x1f3c6; :trophy: &#x1f3bc; :musical_score: &#x1f3b9; :musical_keyboard: &#x1f3bb; :violin: &#x1f47e; :space_invader: &#x1f3ae; :video_game: &#x1f0cf; :black_joker: &#x1f3b4; :flower_playing_cards: &#x1f3b2; :game_die: &#x1f3af; :dart: &#x1f004; :mahjong: &#x1f3ac; :clapper: &#x1f4dd; :memo: &#x1f4dd; :pencil: &#x1f4d6; :book: &#x1f3a8; :art: &#x1f3a4; :microphone: &#x1f3a7; :headphones: &#x1f3ba; :trumpet: &#x1f3b7; :saxophone: &#x1f3b8; :guitar: &#x1f45e; :shoe: &#x1f461; :sandal: &#x1f460; :high_heel: &#x1f484; :lipstick: &#x1f462; :boot: &#x1f455; :shirt: &#x1f455; :tshirt: &#x1f454; :necktie: &#x1f45a; :womans_clothes: &#x1f457; :dress: &#x1f3bd; :running_shirt_with_sash: &#x1f456; :jeans: &#x1f458; :kimono: &#x1f459; :bikini: &#x1f380; :ribbon: &#x1f3a9; :tophat: &#x1f451; :crown: &#x1f452; :womans_hat: &#x1f45e; :mans_shoe: &#x1f302; :closed_umbrella: &#x1f4bc; :briefcase: &#x1f45c; :handbag: &#x1f45d; :pouch: &#x1f45b; :purse: &#x1f453; :eyeglasses: &#x1f3a3; :fishing_pole_and_fish: &#x2615; :coffee: &#x1f375; :tea: &#x1f376; :sake: &#x1f37c; :baby_bottle: &#x1f37a; :beer: &#x1f37b; :beers: &#x1f378; :cocktail: &#x1f379; :tropical_drink: &#x1f377; :wine_glass: &#x1f374; :fork_and_knife: &#x1f355; :pizza: &#x1f354; :hamburger: &#x1f35f; :fries: &#x1f357; :poultry_leg: &#x1f356; :meat_on_bone: &#x1f35d; :spaghetti: &#x1f35b; :curry: &#x1f364; :fried_shrimp: &#x1f371; :bento: &#x1f363; :sushi: &#x1f365; :fish_cake: &#x1f359; :rice_ball: &#x1f358; :rice_cracker: &#x1f35a; :rice: &#x1f35c; :ramen: &#x1f372; :stew: &#x1f362; :oden: &#x1f361; :dango: &#x1f95a; :egg: &#x1f35e; :bread: &#x1f369; :doughnut: &#x1f36e; :custard: &#x1f366; :icecream: &#x1f368; :ice_cream: &#x1f367; :shaved_ice: &#x1f382; :birthday: &#x1f370; :cake: &#x1f36a; :cookie: &#x1f36b; :chocolate_bar: &#x1f36c; :candy: &#x1f36d; :lollipop: &#x1f36f; :honey_pot: &#x1f34e; :apple: &#x1f34f; :green_apple: &#x1f34a; :tangerine: &#x1f34b; :lemon: &#x1f352; :cherries: &#x1f347; :grapes: &#x1f349; :watermelon: &#x1f353; :strawberry: &#x1f351; :peach: &#x1f348; :melon: &#x1f34c; :banana: &#x1f350; :pear: &#x1f34d; :pineapple: &#x1f360; :sweet_potato: &#x1f346; :eggplant: &#x1f345; :tomato: &#x1f33d; :corn: Places &#x1f3e0; :house: &#x1f3e1; :house_with_garden: &#x1f3eb; :school: &#x1f3e2; :office: &#x1f3e3; :post_office: &#x1f3e5; :hospital: &#x1f3e6; :bank: &#x1f3ea; :convenience_store: &#x1f3e9; :love_hotel: &#x1f3e8; :hotel: &#x1f492; :wedding: &#x26ea; :church: &#x1f3ec; :department_store: &#x1f3e4; :european_post_office: &#x1f307; :city_sunrise: &#x1f306; :city_sunset: &#x1f3ef; :japanese_castle: &#x1f3f0; :european_castle: &#x26fa; :tent: &#x1f3ed; :factory: &#x1f5fc; :tokyo_tower: &#x1f5fe; :japan: &#x1f5fb; :mount_fuji: &#x1f304; :sunrise_over_mountains: &#x1f305; :sunrise: &#x1f320; :stars: &#x1f5fd; :statue_of_liberty: &#x1f309; :bridge_at_night: &#x1f3a0; :carousel_horse: &#x1f308; :rainbow: &#x1f3a1; :ferris_wheel: &#x26f2; :fountain: &#x1f3a2; :roller_coaster: &#x1f6a2; :ship: &#x1f6a4; :speedboat: &#x26f5; :boat: &#x26f5; :sailboat: &#x1f6a3; :rowboat: &#x2693; :anchor: &#x1f680; :rocket: &#x2708; :airplane: &#x1f681; :helicopter: &#x1f682; :steam_locomotive: &#x1f68a; :tram: &#x1f69e; :mountain_railway: &#x1f6b2; :bike: &#x1f6a1; :aerial_tramway: &#x1f69f; :suspension_railway: &#x1f6a0; :mountain_cableway: &#x1f69c; :tractor: &#x1f699; :blue_car: &#x1f698; :oncoming_automobile: &#x1f697; :car: &#x1f697; :red_car: &#x1f695; :taxi: &#x1f696; :oncoming_taxi: &#x1f69b; :articulated_lorry: &#x1f68c; :bus: &#x1f68d; :oncoming_bus: &#x1f6a8; :rotating_light: &#x1f693; :police_car: &#x1f694; :oncoming_police_car: &#x1f692; :fire_engine: &#x1f691; :ambulance: &#x1f690; :minibus: &#x1f69a; :truck: &#x1f68b; :train: &#x1f689; :station: &#x1f686; :train2: &#x1f685; :bullettrain_front: &#x1f684; :bullettrain_side: &#x1f688; :light_rail: &#x1f69d; :monorail: &#x1f683; :railway_car: &#x1f68e; :trolleybus: &#x1f3ab; :ticket: &#x26fd; :fuelpump: &#x1f6a6; :vertical_traffic_light: &#x1f6a5; :traffic_light: &#x26a0; :warning: &#x1f6a7; :construction: &#x1f530; :beginner: &#x1f3e7; :atm: &#x1f3b0; :slot_machine: &#x1f68f; :busstop: &#x1f488; :barber: &#x2668; :hotsprings: &#x1f3c1; :checkered_flag: &#x1f38c; :crossed_flags: &#x1f3ee; :izakaya_lantern: &#x1f5ff; :moyai: &#x1f3aa; :circus_tent: &#x1f3ad; :performing_arts: &#x1f4cd; :round_pushpin: &#x1f6a9; :triangular_flag_on_post: &#x1f1ef;&#x1f1f5; :jp: &#x1f1f0;&#x1f1f7; :kr: &#x1f1e8;&#x1f1f3; :cn: &#x1f1fa;&#x1f1f8; :us: &#x1f1eb;&#x1f1f7; :fr: &#x1f1ea;&#x1f1f8; :es: &#x1f1ee;&#x1f1f9; :it: &#x1f1f7;&#x1f1fa; :ru: &#x1f1ec;&#x1f1e7; :gb: &#x1f1ec;&#x1f1e7; :uk: &#x1f1e9;&#x1f1ea; :de: Symbols &#x0031;&#x20e3; :one: &#x0032;&#x20e3; :two: &#x0033;&#x20e3; :three: &#x0034;&#x20e3; :four: &#x0035;&#x20e3; :five: &#x0036;&#x20e3; :six: &#x0037;&#x20e3; :seven: &#x0038;&#x20e3; :eight: &#x0039;&#x20e3; :nine: &#x1f51f; :keycap_ten: &#x1f522; :1234: &#x0030;&#x20e3; :zero: &#x0023;&#x20e3; :hash: &#x1f523; :symbols: &#x25c0; :arrow_backward: &#x2b07; :arrow_down: &#x25b6; :arrow_forward: &#x2b05; :arrow_left: &#x1f520; :capital_abcd: &#x1f521; :abcd: &#x1f524; :abc: &#x2199; :arrow_lower_left: &#x2198; :arrow_lower_right: &#x27a1; :arrow_right: &#x2b06; :arrow_up: &#x2196; :arrow_upper_left: &#x2197; :arrow_upper_right: &#x23ec; :arrow_double_down: &#x23eb; :arrow_double_up: &#x1f53d; :arrow_down_small: &#x2935; :arrow_heading_down: &#x2934; :arrow_heading_up: &#x21a9; :leftwards_arrow_with_hook: &#x21aa; :arrow_right_hook: &#x2194; :left_right_arrow: &#x2195; :arrow_up_down: &#x1f53c; :arrow_up_small: &#x1f503; :arrows_clockwise: &#x1f504; :arrows_counterclockwise: &#x23ea; :rewind: &#x23e9; :fast_forward: &#x2139; :information_source: &#x1f197; :ok: &#x1f500; :twisted_rightwards_arrows: &#x1f501; :repeat: &#x1f502; :repeat_one: &#x1f195; :new: &#x1f51d; :top: &#x1f199; :up: &#x1f192; :cool: &#x1f193; :free: &#x1f196; :ng: &#x1f3a6; :cinema: &#x1f201; :koko: &#x1f4f6; :signal_strength: &#x1f239; :u5272: &#x1f234; :u5408: &#x1f23a; :u55b6: &#x1f22f; :u6307: &#x1f237; :u6708: &#x1f236; :u6709: &#x1f235; :u6e80: &#x1f21a; :u7121: &#x1f238; :u7533: &#x1f233; :u7a7a: &#x1f232; :u7981: &#x1f202; :sa: &#x1f6bb; :restroom: &#x1f6b9; :mens: &#x1f6ba; :womens: &#x1f6bc; :baby_symbol: &#x1f6ad; :no_smoking: &#x1f17f; :parking: &#x267f; :wheelchair: &#x1f687; :metro: &#x1f6c4; :baggage_claim: &#x1f251; :accept: &#x1f6be; :wc: &#x1f6b0; :potable_water: &#x1f6ae; :put_litter_in_its_place: &#x3299; :secret: &#x3297; :congratulations: &#x24c2; :m: &#x1f6c2; :passport_control: &#x1f6c5; :left_luggage: &#x1f6c3; :customs: &#x1f250; :ideograph_advantage: &#x1f191; :cl: &#x1f198; :sos: &#x1f194; :id: &#x1f6ab; :no_entry_sign: &#x1f51e; :underage: &#x1f4f5; :no_mobile_phones: &#x1f6af; :do_not_litter: :non-potable_water: :non-potable_water: &#x1f6b3; :no_bicycles: &#x1f6b7; :no_pedestrians: &#x1f6b8; :children_crossing: &#x26d4; :no_entry: &#x2733; :eight_spoked_asterisk: &#x2734; :eight_pointed_black_star: &#x1f49f; :heart_decoration: &#x1f19a; :vs: &#x1f4f3; :vibration_mode: &#x1f4f4; :mobile_phone_off: &#x1f4b9; :chart: &#x1f4b1; :currency_exchange: &#x2648; :aries: &#x2649; :taurus: &#x264a; :gemini: &#x264b; :cancer: &#x264c; :leo: &#x264d; :virgo: &#x264e; :libra: &#x264f; :scorpius: &#x2650; :sagittarius: &#x2651; :capricorn: &#x2652; :aquarius: &#x2653; :pisces: &#x26ce; :ophiuchus: &#x1f52f; :six_pointed_star: &#x274e; :negative_squared_cross_mark: &#x1f170; :a: &#x1f171; :b: &#x1f18e; :ab: &#x1f17e; :o2: &#x1f4a0; :diamond_shape_with_a_dot_inside: &#x267b; :recycle: &#x1f51a; :end: &#x1f51b; :on: &#x1f51c; :soon: &#x1f550; :clock1: &#x1f55c; :clock130: &#x1f559; :clock10: &#x1f565; :clock1030: &#x1f55a; :clock11: &#x1f566; :clock1130: &#x1f55b; :clock12: &#x1f567; :clock1230: &#x1f551; :clock2: &#x1f55d; :clock230: &#x1f552; :clock3: &#x1f55e; :clock330: &#x1f553; :clock4: &#x1f55f; :clock430: &#x1f554; :clock5: &#x1f560; :clock530: &#x1f555; :clock6: &#x1f561; :clock630: &#x1f556; :clock7: &#x1f562; :clock730: &#x1f557; :clock8: &#x1f563; :clock830: &#x1f558; :clock9: &#x1f564; :clock930: &#x1f4b2; :heavy_dollar_sign: &#x00a9; :copyright: &#x00ae; :registered: &#x2122; :tm: &#x274c; :x: &#x2757; :heavy_exclamation_mark: &#x203c; :bangbang: &#x2049; :interrobang: &#x2b55; :o: &#x2716; :heavy_multiplication_x: &#x2795; :heavy_plus_sign: &#x2796; :heavy_minus_sign: &#x2797; :heavy_division_sign: &#x1f4ae; :white_flower: &#x1f4af; :100: &#x2714; :heavy_check_mark: &#x2611; :ballot_box_with_check: &#x1f518; :radio_button: &#x1f517; :link: &#x27b0; :curly_loop: &#x3030; :wavy_dash: &#x303d; :part_alternation_mark: &#x1f531; :trident: :black_square: :black_square: :white_square: :white_square: &#x2705; :white_check_mark: &#x1f532; :black_square_button: &#x1f533; :white_square_button: &#x26ab; :black_circle: &#x26aa; :white_circle: &#x1f534; :red_circle: &#x1f535; :large_blue_circle: &#x1f537; :large_blue_diamond: &#x1f536; :large_orange_diamond: &#x1f539; :small_blue_diamond: &#x1f538; :small_orange_diamond: &#x1f53a; :small_red_triangle: &#x1f53b; :small_red_triangle_down: :shipit: 参考：https://gist.github.com/rxaviers/7360908#file-gistfile1-md]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>emoji</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 异常 - Template render error unexpected token]]></title>
    <url>%2Fhexo-unexpected-token.html</url>
    <content type="text"><![CDATA[在使用 Hexo 调试时，一直出现 Template render error: unexpected token: }} 的异常，显然是出现了特殊字符导致无法解析。 现象在上一篇 Python 利用 Jinja2 模版生成文件 中，每次执行 hexo s 或 hexo g，都会报错： 1234567FATAL Something's wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlTemplate render error: unexpected token: &#125;&#125; at new exports.TemplateError (E:\liuhao_data\hexo-blog\node_modules\hexo\node_modules\nunjucks\src\lib.js:51:19) at new_cls.fail (E:\liuhao_data\hexo-blog\node_modules\hexo\node_modules\nunjucks\src\parser.js:64:15) at new_cls.parsePrimary (E:\liuhao_data\hexo-blog\node_modules\hexo\node_modules\nunjucks\src\parser.js:947:18) at new_cls.parseUnary (E:\liuhao_data\hexo-blog\node_modules\hexo\node_modules\nunjucks\src\parser.js:882:25)....... 原因原文中有这句话： 先创建一个包括 {{ }}或 {% %} 等特殊符号的模板文件 出错时 Markdown 原文是这样的： 1先创建一个包括 `&#123;&#123; &#125;&#125;`或 `&#123;% %&#125;` 等特殊符号的模板文件 其中 {{ }} 和 {% %} 被当成 hexo 模板中的标签，解析出错。 解决方法Github 上给出的方法是在需要显示 {{ }} 符号的地方用如下代码包围： 123&#123;% raw %&#125;&#123;% endraw %&#125; 标记这部分不需要解析。 修改后的 Markdown 原文 1先创建一个包括 `&#123;%raw%&#125; &#123;&#123; &#125;&#125; &#123;%endraw%&#125;` 或 `&#123;%raw%&#125; &#123;% %&#125; &#123;%endraw%&#125;` 等特殊符号的模板文件 解决后的效果 先创建一个包括 {{ }} 或 {% %} 等特殊符号的模板文件 虽然有点麻烦，但也算临时解决了这个问题，这是个已知 bug ，希望后续的版本能修复吧，毕竟使用太多 hexo 专属的标签对博客以后的迁移、改版什么的来说还是很麻烦的。 补充 用 ``` 包围的代码块不需要这样特殊处理。 参考： http://lovenight.github.io/2016/09/27/Hexo%E6%8A%A5%E9%94%99Template-render-error-tag-name-expected/ https://icewing.cc/post/hexo-bug-of-quot.html]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 利用 Jinja2 模版生成文件]]></title>
    <url>%2Fpython-jinja2.html</url>
    <content type="text"><![CDATA[工作中遇到了这种场景：需要生成批量文件，文件格式一致，其中的变量根据数据库的数据生成。这里就想到了之前 Ansible 中的 template 的处理方式，可以使用 Jinja2 模版，再结合 Python 脚本进行处理生成目标文件。 Jinja2 简介Jinja2 是基于 Python 的模板引擎，功能比较类似于于 PHP 的 smarty，J2ee 的 Freemarker 和 velocity。 它能完全支持 unicode，并具有集成的沙箱执行环境，应用广泛。使用 Jinja2 的方式一般是，先创建一个包括 {{ }} 或 {% %} 等特殊符号的模板文件，然后用 Jinja 的模板对象加载，然后变量值对该模板中的变量进行赋值。 示例简单示例1234from jinja2 import Templatetemplate = Template('Hello &#123;&#123; name &#125;&#125;!')print(template.render(name='World')) 运行结果： 12$ python test.pyHello World! 结合模版文件Jinja2 使用一个名为 Environment 的中心对象。这个类的实例用于存储配 置、全局对象，并用于从文件系统或其它位置加载模板。即使你通过 Template 类的构造函数用字符串创建模板，也会为你自动创建一个环境。大多数应用在应用初始化时创建一个 Environment 对象，并用它加载模板。 项目结构： 12345678910.├── results│ ├── __init__.py│ ├── __pycache__│ │ └── __init__.cpython-35.pyc│ └── templates│ └── test.j2└── test.py3 directories, 4 files 注意点： __init__.py 是必需的，否则会出现 NotImplementedError: Can’t perform this operation for unregistered loader type 的异常。 模版文件 test.j2 需要放在 templates 目录下，否则会出现 jinja2.exceptions.TemplateNotFound 的异常 准备模版文件 12Hi, I am &#123;&#123; name &#125;&#125;, &#123;&#123; age &#125;&#125; years old.I'm from &#123;&#123; country &#125;&#125;. Jinja2 处理脚本 1234567from jinja2 import Environment, PackageLoaderenv = Environment(loader=PackageLoader('results'))template = env.get_template('test.j2')content = template.render(name='liuhao', age='18', country='China')print(content) 运行结果 123$ python test.pyHi, I am liuhao, 18 years old.I'm from China. 至此，简单的 Python 处理 Jinjia2 的逻辑基本完成，可以在此基础上进行业务逻辑的拓展，比如生成文件等。 生成文件可以参考如下代码： 123456789from jinja2 import Environment, FileSystemLoaderenv = Environment(loader = FileSystemLoader("./"))template = env.get_template("test.j2") content = template.render(name='liuhao', age='18', country='China')with open('./test.conf','w') as fp: fp.write(content) Jinja2 的高级特性可以参考官方文档，同时也有中文版。 参考： https://blog.csdn.net/wangjianno2/article/details/51044780]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitment 初始化脚本 Python 实现]]></title>
    <url>%2Fgitment-initialize.html</url>
    <content type="text"><![CDATA[之前由于 livere 评论系统加载速度慢的问题，把评论系统换成了 Gitment，但是集成后发现只能手动初始化所有文章的评论或者一个一个点开界面，作者觉得这件事情非常麻烦，所以手动抓了一下 Gitment 在初始化评论时发出的网络请求后写了一个用于自动化初始评论的脚本。 获取 token在使用该脚本之前首先要在 GitHub 创建一个新的 Personal access tokens，选择 Generate new token 后，在当前的页面中为 Token 添加所有 Repo 的权限： 在这里创建之后，点击界面最下的面 Generate token 按钮获得一个新的 token，保存好该 token，后续代码中需要。 脚本配置下面脚本的 5 个变量： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import requestsimport reimport json# 博客地址site_url = 'https://hoxis.github.io'# 博客的 sitemapsitemap_url = 'https://hoxis.github.io/sitemap.xml'# 上面步骤中获取的 tokentoken = 'token '+'xxxxx'# GitHub 用户名username = 'hoxis'# The repo you use to store Gitment commentsrepo_name = 'gitment-comments'def getHTMLText(url): try: kv = &#123;'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0'&#125; r = requests.get(url, timeout=30, headers=kv) r.raise_for_status() # 检查状态码 r.encoding = r.apparent_encoding return r.text except: return "产生异常"wb_data = getHTMLText(sitemap_url)pattern = re.compile('&lt;loc&gt;([a-zA-z]+://[^\s]*)&lt;/loc&gt;')urls = pattern.findall(str(wb_data))print(urls)for url in urls: url_data = getHTMLText(url) title_pattern = re.compile('&lt;title&gt;(.+)&lt;/title&gt;') title = title_pattern.search(url_data).group(1).replace('&amp;#39;','\'') headers = &#123; "Accept": "application/vnd.github.squirrel-girl-preview, application/vnd.github.html+json", "Accept-Encoding": "gzip, deflate, br", 'Connection': 'keep-alive', 'Host': 'api.github.com', 'Origin': site_url, "Referer": url, "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0", 'Authorization': token &#125; payload = &#123; 'title': title, 'labels': ['gitment', title.split('|')[0].strip()], 'body': url &#125; payload_json = json.dumps(payload) print(title.split('|')[0].strip()) feedback = requests.post('https://api.github.com/repos/'+username+'/'+repo_name+'/issues',headers=headers,data=payload_json) print(feedback) 配置好后，运行脚本即可： 1python comment.py 运行成功后，在设置的 repo 里会出现很多 issue，如图 ： 脚本的存放位置没有要求，只要能访问到你的博客地址和 GitHub 即可。另外，GitHub 中 issue 的可以创建但是并不能删除，所以在配置时请一定检查好所有的配置项是否正确，否则会批量创建一些无用的 issue 虽然没有什么影响，但是看起来非常头疼。 注意事项！！！上面脚本中的一段： 12345payload = &#123; 'title': title, 'labels': ['gitment', title.split('|')[0].strip()], 'body': url&#125; 即创建 issue 时的 label 如何设置，这里要与你的配置文件里的对应，否则会导致生成的 issue 无法在页面加载。 在 Next 主题中的配置文件位于 next/layout/_third-party/comments/gitment.swig 文件中： 12345&#123;% if page.comments %&#125; &lt;script type="text/javascript"&gt; function renderGitment()&#123; var gitment = new &#123;&#123;CommentsClass&#125;&#125;(&#123; id: '&#123;&#123; page.title &#125;&#125;', 这里的 id: &#39;&#39; 原来是 id: window.location.pathname，这里为了避免出现 Error: Validation Failed 的异常设置为了文章标题，因此脚本里处理时，也需要设置 label 为文章标题，若你设置的 id 为其他字段，需要做相应的修改。 参考： https://github.com/imsun/gitment/issues/88 https://draveness.me/git-comments-initialize]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 高级 -- 反射]]></title>
    <url>%2Fpython-reflection.html</url>
    <content type="text"><![CDATA[在 Java 中我们经常使用反射，而且大部分的 Java 框架都是基于反射实现的。那么 Python 中是否也有反射呢？答案是肯定的。那么 Python 中的反射如何使用呢？ 概念有时候我们会碰到这样的需求，需要执行对象的某个方法，或是需要对对象的某个字段赋值，而方法名或是字段名在编码代码时并不能确定，需要通过参数传递字符串的形式输入。举个具体的例子：需要调用的方法名是前端通过接口传入的，而在代码编写时根本无法确定前端会传入具体的那个方法名，因此无法确定调用哪个方法，这时，我们需要通过某种机制访问未知的属性。这个机制被称为反射。 反射就是通过字符串的形式，导入模块；通过字符串的形式，去模块寻找指定函数，并执行。利用字符串的形式去对象（模块）中操作（查找/获取/删除/添加）成员，是一种基于字符串的事件驱动！ 相关方法 dir([obj]): 调用这个方法将返回包含 obj 大多数属性名的列表（会有一些特殊的属性不包含在内）。obj 的默认值是当前的模块对象。 hasattr(obj, attr): 这个方法用于检查 obj 是否有一个名为 attr 的值的属性，返回一个布尔值。 getattr(obj, attr): 判断对象 obj 是否包含名为 attr 的特性，将返回 obj 中名为 attr 值的属性的值，例如如果 attr 为 bar，则返回 obj.bar。 setattr(obj, attr, val): 调用这个方法将给 obj 的名为 attr 的值的属性赋值为 val。例如如果 attr 为 bar，setattr(obj,&#39;bar&#39;,val)相当于 obj.bar = val。 delattr(obj, name) 与 setattr() 相关的一组函数，删除模块中某个变量或者函数。参数是由一个对象（记住python中一切皆是对象）和一个字符串组成的。string 参数必须是对象属性名之一。该函数删除该 obj 的一个由 string 指定的属性。delattr(bar,&#39;age&#39;) 实例1234567891011121314151617181920212223242526272829class Cat(object): def __init__(self, name="kitty"): self.name = name def sayHi(self): print(self.name, "say Hi")kit = Cat()print("name is:", kit.name)kit.sayHi()print(dir(kit))print(dir(Cat))# 判断是否方法或属性是否存在print(hasattr(kit,'sayHi'))print(hasattr(kit,'name'))# 设置 name 属性setattr(kit, 'name', 'xiaohei')print("name is:", kit.name)# 通过反射的方式调用 sayHi 方法func = getattr(kit, 'sayHi')func()# 删除属性delattr(kit, name)print("name is:", kit.name) 运行结果： 123456789101112name is: kittykitty say Hi['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'name', 'sayHi']['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'sayHi']TrueTruename is: xiaoheixiaohei say HiTraceback (most recent call last): File "reflection.py", line 28, in &lt;module&gt; delattr(kit, name)NameError: name 'name' is not defined]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 深拷贝和浅拷贝]]></title>
    <url>%2Fpython-copy-deepcopy.html</url>
    <content type="text"><![CDATA[任何变成语言中，其实都有浅拷贝和深拷贝的概念，Python 中也不例外。 浅拷贝浅拷贝是对于一个对象的顶层拷贝。通俗的理解是：拷贝了引用，并没有拷贝内容。 123456789101112131415161718&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = a&gt;&gt;&gt; id(a)140465763275080&gt;&gt;&gt; id(b)140465763275080&gt;&gt;&gt; b[1, 2, 3]&gt;&gt;&gt; a.append(2)&gt;&gt;&gt; b[1, 2, 3, 2]&gt;&gt;&gt; b.append(5)&gt;&gt;&gt; a[1, 2, 3, 2, 5] 深拷贝 - copy.deepcopy()深拷贝是对于一个对象所有层次的拷贝（递归） 123456789101112131415161718# 需要引入 copy 模块&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = copy.deepcopy(a)&gt;&gt;&gt; id(a)140465763275080&gt;&gt;&gt; id(b)140465763294408&gt;&gt;&gt; a.append(4)&gt;&gt;&gt; a[1, 2, 3, 4]&gt;&gt;&gt; b[1, 2, 3]&gt;&gt;&gt; b.append(5)&gt;&gt;&gt; a[1, 2, 3, 4]&gt;&gt;&gt; b[1, 2, 3, 5] copy.deepcopy 会递归拷贝 12345678910111213&gt;&gt;&gt; a = [1,2]&gt;&gt;&gt; b = [3,4]&gt;&gt;&gt; c = [a,b]&gt;&gt;&gt; c[[1, 2], [3, 4]]&gt;&gt;&gt; d = copy.deepcopy(c)&gt;&gt;&gt; d[[1, 2], [3, 4]]&gt;&gt;&gt; a.append(7)&gt;&gt;&gt; d[[1, 2], [3, 4]]&gt;&gt;&gt; c[[1, 2, 7], [3, 4]] copy.copy 不会递归拷贝 123456&gt;&gt;&gt; e = copy.copy(c)&gt;&gt;&gt; e[[1, 2, 7], [3, 4]]&gt;&gt;&gt; a.append(9)&gt;&gt;&gt; e[[1, 2, 7, 9], [3, 4]] 拷贝的其他方式浅拷贝对不可变类型和可变类型的 copy 不同 字典的 copy 方法可以拷贝一个字典 拷贝方式类似于 copy.copy()，即不是递归拷贝。 1234567891011121314151617&gt;&gt;&gt; l = [1,2]&gt;&gt;&gt; a = dict(name="hoxis", age=18,l=l)&gt;&gt;&gt; a&#123;'l': [1, 2], 'age': 18, 'name': 'hoxis'&#125;&gt;&gt;&gt; b = a.copy()&gt;&gt;&gt; b&#123;'l': [1, 2], 'age': 18, 'name': 'hoxis'&#125;&gt;&gt;&gt; l.append(3)&gt;&gt;&gt; a&#123;'l': [1, 2, 3], 'age': 18, 'name': 'hoxis'&#125;&gt;&gt;&gt; b&#123;'l': [1, 2, 3], 'age': 18, 'name': 'hoxis'&#125;&gt;&gt;&gt; a['age'] = 29&gt;&gt;&gt; b&#123;'l': [1, 2, 3], 'age': 18, 'name': 'hoxis'&#125;&gt;&gt;&gt; a&#123;'l': [1, 2, 3], 'age': 29, 'name': 'hoxis'&#125; 有些内置函数可以生成拷贝（list） 1234567891011&gt;&gt;&gt; a = list(range(5))&gt;&gt;&gt; a[0, 1, 2, 3, 4]&gt;&gt;&gt; b = list(a)&gt;&gt;&gt; b[0, 1, 2, 3, 4]&gt;&gt;&gt; a.append(7)&gt;&gt;&gt; a[0, 1, 2, 3, 4, 7]&gt;&gt;&gt; b[0, 1, 2, 3, 4] 拷贝不可变类型数据 使用 copy.copy() 时，它会根据拷贝对象是否是可变类型，做不同的处理。 比如处理元组时： 123456&gt;&gt;&gt; a = (1,2,3)&gt;&gt;&gt; b = copy.copy(a)&gt;&gt;&gt; id(a)140465763271376&gt;&gt;&gt; id(b)140465763271376]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杂感两则]]></title>
    <url>%2Fthink-more-2018329.html</url>
    <content type="text"><![CDATA[杂感，无他。 昨天准备带老婆去医院做个检查，刚开始打算是去小区附近的社区医院，毕竟离家近。 到了那里，发现人不是很多，但是没有一点秩序。想做个抽血检查，到那里也不知道什么流程，引导台已经有厚厚的一层灰。抱着试试看的态度问了下一楼的一个医生，说要去二楼找某某医生开抽血的单子才能抽血。于是又到二楼去找，到了二楼找人打听说抽血是在一楼啊。就这么楼上楼下的跑了几趟，最后不了了之了。 后来到了市中心的医院，才感受到该有的感觉。人虽说挺多的，但是很有秩序，该排队的排队，该就诊的就诊，不会让我有那种无助感。 这应该是大城市和小城市区别的一个缩影吧，大城市资源紧张，但是相对公平且有序，每个人都有获取到资源的机会。当然，往上走也许也有我无法看到的黑暗面，但仅仅是对今天的所想所感。 还有个想法就是感觉近代中国的发展红利基本上被城市获取了，农村得到的发展很有限。 电视节目上看到俞敏洪说在做教育公益，是帮助山区的孩子提高高考分数，他说是帮他们提高应试教育的水平。主持人说他这种做法有点大胆，因为在这个人人张口闭口都在谈「素质教育」的社会，他竟然在这说提高应试教育水平！ 我觉得这就好像经济基础和上层建筑的问题，山区或者农村的孩子，不靠应试教育靠什么？他们玩得起「素质教育」吗？他们有能力让孩子去学钢琴吗？他们现在的主要目标是走出去。也许高考就是我们这种农村孩子向上的唯一途径，或者说相对来说最为靠谱的途径。 最近看新闻，好像政府又开始课外辅导班了，同时还有取消特长生的消息，这到底是好事还是坏事？]]></content>
      <categories>
        <category>生活杂技</category>
      </categories>
      <tags>
        <tag>生活杂感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 异常：The user specified as a definer ('xxx'@'%') does not exist]]></title>
    <url>%2Fmysql-definder-and-invoker.html</url>
    <content type="text"><![CDATA[程序调用 MySQL 存储过程时出现 execute command denied to user &#39;xxx&#39;@&#39;%&#39; for routine &#39;xxx.PROCEDURE&#39; 的异常，这与 MySQL 的用户权限设置有关。 场景复现在生产环境使用之前的数据库初始化文件导入数据后，一直可以正常使用，在有一次同事做访问权限配置后，程序在不同的地方开始出现下面两种异常： 123The user specified as a definer ('cluster'@'%') does not existexecute command denied to user 'cluster'@'%' for routine 'x86.DELETE_PERFORMANCE_PROC' 同事当时是修改数据库访问权限限制为只有 &#39;cluster&#39;@&#39;172.24.%&#39; 网段的机器才能访问，但是我的机器是属于该网段的，按理说不会出现异常啊，那究竟是什么原因呢？ 原因追究definer 和 invoker首先搞清楚 definer 是个什么东西，对于我这个平时基本上只用到增删改查的小白来说，这个名字还是比较陌生的， 创建存储过程的时候可以指定 SQL SECURITY 属性，设置为 DEFINER 或者 INVOKER，用来奉告 mysql 在执行存储过程的时候，是以定义者的权限来执行，还是以调用者的权限来执行。DEFINER 表示按定义者拥有的权限来执行，INVOKER 表示用调用者的权限来执行。 默认情况下，使用 DEFINER 方式，此时调用存储过程的用户必须有存储过程的 EXECUTE 权限，并且 DEFINER 指定的用户必须是在 mysql.user 表中存在的用户。 DEFINER 模式下，默认 DEFINER=CURRENT_USER，也就是创建存储过程的执行用户，在存储过程执行时，mysql 会检查 DEFINER 定义的用户 &#39;user_name&#39;@&#39;host_name&#39; 的权限； INVOKER模式下，在存储过程执行时，会检查存储过程调用者的权限。 示例 新建一个存储过程： 1234567891011USE `test1`;DROP PROCEDURE IF EXISTS `account_count`;DELIMITER ;;USE `test1`;;CREATE DEFINER = 'root'@'localhost' PROCEDURE account_count() BEGIN SELECT 'Number of accounts:', COUNT(*) FROM mysql.user; END;;DELIMITER ; 查看存储过程的状态 12345678mysql&gt; select db, name, security_type,type, DEFINER from mysql.proc WHERE db='test1'; +-------+---------------+---------------+-----------+----------------+| db | name | security_type | type | DEFINER |+-------+---------------+---------------+-----------+----------------+| test1 | account_count | DEFINER | PROCEDURE | root@localhost |+-------+---------------+---------------+-----------+----------------+1 row in set 在这个案例中，不论哪个用户调用该存储过程，存储过程都会以 &#39;root&#39;@&#39;localhost&#39; 的权限去执行，即使这个用户没有查询 mysql.user 表的权限。 新建一个用户进行测试： 123CREATE USER 'liuhao'@'%' IDENTIFIED BY '123456'; GRANT ALL PRIVILEGES ON `test1`.* TO 'liuhao'@'%' IDENTIFIED BY '123456'; FLUSH PRIVILEGES; 1234567891011121314151617181920mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || test1 |+--------------------+2 rows in setmysql&gt; use test1;Database changedmysql&gt; call account_count();+---------------------+----------+| Number of accounts: | COUNT(*) |+---------------------+----------+| Number of accounts: | 7 |+---------------------+----------+1 row in setQuery OK, 0 rows affected 发现可以查询出来了，因为 liuhao 对存储过程 account_count 有执行的权限，虽然它依旧没有权限直接操作 mysql 库，由于我们定义的SQL SECURITY 为 DEFINER，所以在执行时是以 root 的身份执行的，所以可以正常查询出来。 虽然 liuhao 这个用户没有访问 mysql 数据库的权限，但是依然可以调用该存储过程，因为它是以定义者 root 用户的权限来调用的。 修改为 invoker 模式 用 root 用户运行： 1update mysql.proc set security_type='invoker' where db='test1' and name='account_count'; 查看存储过程状态 12345678mysql&gt; select db, name, security_type,type, DEFINER from mysql.proc WHERE db='test1'; +-------+---------------+---------------+-----------+----------------+| db | name | security_type | type | DEFINER |+-------+---------------+---------------+-----------+----------------+| test1 | account_count | INVOKER | PROCEDURE | root@localhost |+-------+---------------+---------------+-----------+----------------+1 row in set 再次用测试用户调用 1234mysql&gt; use test1;Database changedmysql&gt; call account_count();1142 - SELECT command denied to user 'liuhao'@'localhost' for table 'user' 发现系统报错查询不到了，这是因为我们在上述定义的SQL SECURITY 值为 INVOKER，存储过程执行过程中会以 liuhao 具有的权限来执行，其中调用到了 mysql 的库，而我们的 liuhao 帐户只有 test1 库的使用权限，所以会返回失败。 修改已经定义的 definer由于前期在测试库上开发的缘故，我们经常定义到的 definer 为 cluster@%，后来搬移到生产库上又得改回来，存在着大量的更新，上百个的视图、存储过程、函数等一个个改不免太麻烦并且也可能遗漏。如下为总结出的方便修改所有 definer 的方法，可以直到查漏补缺的作用。 现在在 mysql 涉及的 definer 有 view、trigger、function、procedure、event。我们一个个作介绍。 修改function、procedure的definer123select definer from mysql.proc; -- 函数、存储过程update mysql.proc set definer='root@localhost' where db='xxx'; -- 如果有限定库或其它可以加上where条件 修改 event 的 definer123select DEFINER from mysql.EVENT; -- 定时事件update mysql.EVENT set definer='root@localhost'; 修改 view 的 definer相比 function 的修改麻烦点： 123select DEFINER from information_schema.VIEWS; select concat("alter DEFINER=`user`@`localhost` SQL SECURITY DEFINER VIEW ",TABLE_SCHEMA,".",TABLE_NAME," as ",VIEW_DEFINITION,";") from information_schema.VIEWS where DEFINER&lt;&gt;'user@localhost'; 查询出来的语句再执行一遍就好了。 修改 trigger 的 definer目前还没有具体方便的方法，可以借助工具端如 HeidiSQL、sqlyog 等来一个个修改。注意改前有必要锁表，因为如果改的过程中有其它表改变而触发，会造成数据不一致。 123Flush tables with readlockUnlock tables 其他sql12345show create procedure DELETE_HOT_EVENT_PROC; -- 查询存储过程创建语句SHOW PROCEDURE STATUS; -- 查询所有存储过程的状态SHOW FUNCTION STATUS; -- 查询函数的状态 参考： http://www.cnblogs.com/zejin2008/p/4767531.html https://my.oschina.net/u/1424662/blog/485118]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 无法备份 theme 主题目录]]></title>
    <url>%2Fhexo-backup-theme-dir.html</url>
    <content type="text"><![CDATA[在使用 hexo 做博客时，我会把博客目录做一个备份，方便迁移。但是发现使用的主题目录无法备份，推送后总是下图状态： 解决方法如果你想让他正常的话，可以在博客目录运行如下命令： 12345678910111213141516$ git rm --cached themes\maupassant\rm 'themes/maupassant'$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) deleted: themes/maupassantUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) themes/maupassant/ 原因这是因为用到了 git 的子模块（git submodule）功能（你在你的 git 项目里 clone 的别人的项目）。 在你的主项目的 git 库里，子模块只是一个 HEAD 指针，指向子模块的 commit。 这个功能的意义： 在这里，如果你需要修改 next 主题（可能需要很多文件），又想保证能够随时更新最新版本，其实用子模块功能是很方便的。 只需要 clone 下来新建一个 branch，用来自己用，每次官方更新 pull 到另一个分支，merge 一下就行。 相当于把一个大项目分成多个小项目，尽可能减少项目之间的关联，方便调试和修改。 这里我偷懒直接将子模块删除，将整个仓库进行备份了。 比较优雅的做法可以参考：https://github.com/iissnan/hexo-theme-next/issues/328 参考：https://www.zhihu.com/question/63962146#/]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>备份</tag>
        <tag>theme</tag>
        <tag>主题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible - Roles的使用]]></title>
    <url>%2Fansible-roles.html</url>
    <content type="text"><![CDATA[Roles 的概念来自于这样的想法：通过 include 包含文件并将它们组合在一起，组织成一个简洁、可重用的抽象对象。这种方式可使你将注意力更多地放在大局上，只有在需要时才去深入了解细节。 Ad-Hoc 适用于临时命令的执行，Playbook 适合中小项目，而大项目一定要是有 Roles。Roles 不仅支持 Tasks 的集合，同时包括 var_files、tasks、handlers、meta、templates等。 Roles 目录结构 调用过程解析 handlers：动态变更 示例 Files：文件传输 Templates：模板替换 Roles 目录结构Roles 严重依赖目录命名规则和目录摆放，所以目录的命名和目录位置都非常重要。下面是一个案例的目录结构： 123456789101112131415161718192021222324liuhao@liuhao-pc:~/ansible$ tree fab2ansible/fab2ansible/├── group_vars│ └── all├── roles│ ├── git│ │ ├── files│ │ │ └── main.yml│ │ ├── tasks│ │ │ ├── create_dir.yml│ │ │ ├── git_checkout.yml│ │ │ ├── main.yml│ │ │ └── static_git_pull.yml│ │ └── vars│ │ └── main.yml│ └── user│ ├── tasks│ │ ├── main.yml│ │ └── user-config.yml│ └── vars│ └── main.yml└── userconf.yml9 directories, 11 files 对应的模块调用结构： 调用过程解析参考上图，下面来针对 roles 目录中的 git 模块进行剖析。 group_vars/all 文件：定义 roles 变量 1234567891011---# 以下列出的变量对所有主机和组有效，即全局有效flag: kingjavaflag: javatech: phpdamn: '-'git: gitsvn: svnpackage_dir: /srv/deploy/project_dir: /srv/www/project: cp group_vars 目录下文件定义 Roles 中调用的变量，Roles 对应调用该目录同名文件中定义的变量，文件名为 all 的文件定义的变量是全局变量，针对所有的 Roles 有效。 userconf.yml 文件：设置调用 Roles 的 git 模块。 12345678---# 该playbook用于初始化用户配置- hosts: localhost remote_user: root roles: - role: git roles 为关键字，role:git 表示调用 roles 的 git 模块。如希望同时调用图中的 user 模块，于该行下同级别对齐添加如下配置即可。 1- role: user roles/git/tasks/main.yml 文件：设置调用 git 模块实现的功能。 12345---- include: create_dir.yml- include: static_git_pull.yml- import_playbook: git_checkout.yml 通过 include 引用其他功能模块。在新版本中 ansible2.4 中，include 用 import_playbook 替换：http://docs.ansible.com/ansible/latest/playbooks_reuse_includes.html create_dir.yml、git_checkout.yml、static_git_pull.yml 文件：设置我们希望完成的具体功能。 create_dir.yml 1234567891011--- - hosts: localhost tasks: - name: create_dir file: path: "&#123;&#123; package_dir &#125;&#125;&#123;&#123; project &#125;&#125;-release-&#123;&#123; git_commit &#125;&#125;/&#123;&#123; flag &#125;&#125;-&#123;&#123; project &#125;&#125;" owner: www group: www mode: 0755 recurse: yes state: directory { { } } 在 Ansible 中表示变量引用， create_dir.yml 实现的功能是递归创建目录并设置了目录的相关属性。 static_git_pull.yml 作用是拉取指定的 git 版本至指定目录 123456789--- - hosts: localhost tasks: - name: Git pull git: repo: "&#123;&#123; repository_static &#125;&#125;" dest: "&#123;&#123; package_dir &#125;&#125;&#123;&#123; project &#125;&#125;-release-&#123;&#123; git_commit &#125;&#125;/&#123;&#123; flag &#125;&#125;-&#123;&#123; project &#125;&#125;" version: "&#123;&#123; git_commit &#125;&#125;" force: yes git_checkout.yml 实现 Git 项目初始化，Checkout 最新代码至指定目录。 1234567891011121314151617--- - hosts: localhost tasks: - name: Git init before git pull command: /usr/bin/git fetch args: chdir: "&#123;&#123; package_dir &#125;&#125;&#123;&#123; project &#125;&#125;-release-&#123;&#123; git_commit &#125;&#125;/&#123;&#123; flag &#125;&#125;-&#123;&#123; project &#125;&#125;" - name: Git reset command: /usr/bin/git reset --hard args: chdir: "&#123;&#123; package_dir &#125;&#125;&#123;&#123; project &#125;&#125;-release-&#123;&#123; git_commit &#125;&#125;/&#123;&#123; flag &#125;&#125;-&#123;&#123; project &#125;&#125;" - name: Git checkout command: /usr/bin/git checkout &#123;&#123; git_commit &#125;&#125; args: chdir: "&#123;&#123; package_dir &#125;&#125;&#123;&#123; project &#125;&#125;-release-&#123;&#123; git_commit &#125;&#125;/&#123;&#123; flag &#125;&#125;-&#123;&#123; project &#125;&#125;" handlers：动态变更Roles 不仅支持 Tasks 调用，同时支持 vars、files、handlers、meta、templates 的调用。本节介绍 Handlers 在 Roles 中的使用技巧。 Handlers 通常和 Notify 搭配使用，当（文件、进程、返回等）状态有变换时，Notify 会通过 Handlers 做指定的变更。我们通过一个功能完整的 Roles 来整体了解 Vars、Files、Handlers、Meta、Templates，然后逐步深入 Roles Handlers 用法。请看示例 example.yml： 1234567891011121314151617181920site.ymlwebservers.ymlfooservers.ymlroles/ common/ files/ templates/ tasks/ handlers/ vars/ defaults/ meta/ webservers/ files/ templates/ tasks/ handlers/ vars/ defaults/ meta/ example.yml 包含两个 Role， common 和 webservers，每个 Role 均包括 files、templates、tasks、handlers、vars、defaults、meta。在 Playbooks 中的调用方式如下： 12345--- - hosts: webservers roles: - common - webservers 了解了 Roles 支持的功能集和调用方式后，我们再来了解这些功能集的含义。 roles/x/tasks/main.yml：主函数，包括在其中的所有任务将被执行 roles/x/handlers/main.yml：所有包括在其中的 handlers 将被执行 roles/x/vars/main.yml：所有包括在其中的变量将在 roles 中生效 roles/x/meta/main.yml：roles 所有依赖将被正常登入。 roles/x/{files,templates,tasks}/(dir depends on task)：所有文件、模板都可存放在这里，不用指定绝对路径 示例当 Apache 配置文件发生变化时重启 Apache。 编排 Roles 目录结构 1234567891011.├── apache.yml└── roles └── apache ├── handlers │ └── main.yml └── tasks ├── main.yml └── restart.yml4 directories, 4 files 编辑 roles/apache/handlers/main.yml 的内容 1234--- # sleep 10s - name: restart apache service: name=httpd state=restarted 该 YML 要实现的功能非常简单：重启 Apache 进程。 编辑 roles/apache/tasks/restart.yml 内容 12345678---- name: transfer apache config lineinfile: path: /etc/httpd/conf/httpd.conf regexp: '^Listen 80' line: 'Listen 801' notify: - restart apache 该 YML 功能为更新 Apache 配置文件，如配置文件有变化则重启 Apache。 编辑 roles/apache/tasks/main.yml 内容 123---- import_tasks: restart.yml 编辑 Roles 同级目录 apache.yml 文件内容 12345--- - hosts: webserver remote_user: root roles: role: apache 该 YML 为总调度文件，完成 Apache 配置文件的变更和 Apache 的重启工作。 执行命令 ansible-playbook apache.yml，验证结果。 命令运行结果为更新 Apache 配置文件，如配置文件有更新则重启 Apache，如无错误返回为正常。 Files：文件传输Files 和 Templates 均用于 Ansible 文件处理，两者主要区别是：Files（不是 file 模块）目录下的文件无需写绝对路径即可将文件传输至远程主机；Templates 目录下的文件以 Jinja2 渲染，且传输文件至远程主机的同时支持预定义变量替换。接下来我们看 Roles 中 Files 的使用方式。 案例场景：将 example role 下的 MAGEDU.PPT 和 STANLEY.PPT 两个文件传输至远程，并修改文件名为英文小写。 编排目录结构如下 12345678910111213[root@centos7 file]# tree.├── file.yml└── roles └── example ├── files │ ├── MAGEDU.PPT │ └── STANLEY.PPT └── tasks ├── file.yml └── main.yml4 directories, 5 files 依次创建文件 MAGEDU.PPT、STANLEY.PPT，在文件中随意添加内容。 编辑 ./file.yml 1234567--- # 该playbook是整个项目的调度入口 - hosts: localhost remote_user: root gather_facts: false roles: - role: example 编辑 ./roles/example/tasks/file.yml 12345678910---- name: file change example copy: src: "&#123;&#123; item.src &#125;&#125;" dest: "/data/&#123;&#123; item.dest &#125;&#125;" owner: root group: root with_items: - &#123; src: 'MAGEDU.PPT',dest: 'magedu.ppt' &#125; - &#123; src: 'STANLEY.PPT',dest: 'stanley.ppt' &#125; 编辑 ./roles/example/tasks/main.yml 123--- - import_tasks: file.yml 执行命令 ansible-playbook file.yml，验证结果。 Roles 的 Files 功能设计主要针对业务文件传输需求，凡存放于对应的 Roles 的 Files 目录下的文件，传输时只需指定相对路径即可，这在很大程度上保证了管理机故障迁移时 Ansible 的健壮性，同时也从规则上使使用者有意规范自己的文件存放习惯。 在企业中不仅会遇到文件传输的需求，对于应用的配置文件，针对不同的主机需要进行相应的变更该怎么办呢？Templates 可以满足我们需求。 Templates：模板替换Templates 常被用作传输文件，同时支持预定义变量替换。因 Templates 由 Jinja2 渲染格式，Jinja2 官网 http://jinja.pocoo.org/ 案例场景：将 order.j2 分发至远程主机 /data// 目录下，并改名为 order.conf，且替换配置文件中变量为对应的值。 编排目录如下 123456789101112├── roles│ └── template│ ├── tasks│ │ ├── main.yml│ │ └── template.yml│ ├── templates│ │ └── order.j2│ └── vars│ └── main.yml└── template.yml5 directories, 5 files 编辑 template.yml 任务总调度文件 1234567---# 该playbook是整个项目的调度入口 - hosts: localhost remote_user: root gather_facts: false roles: - role: template 该 YML 文件是任务总调用文件，主要指定远程主机、执行用户、调用的roles等，相当于「总指挥」的角色。 编辑 roles/template/tasks/main.yml 123---- import_tasks: template.yml 编辑 roles/template/tasks/template.yml 12345---- name: template example template: src: "order.j2" dest: "/data/&#123;&#123; PROJECT &#125;&#125;/order.conf" 的变量引用文件即本节伊始提到的 Jinja2 格式。源文件是 order.j2 ，远程目录及目的文件名分别是 /data// 和 order.conf。 编辑 roles/template/templates/order.j2 定义模板文件 123project: &#123;&#123; PROJECT &#125;&#125; switch: &#123;&#123; SWITCH &#125;&#125; dbport: &#123;&#123; DBPORT &#125;&#125; 编辑 roles/template/vars/main.yml 定义变量 12345--- PROJECT: "JAVA" SWITCH: "ON" DBPORT: "3306" 执行命令并看返回及结果 1234567891011121314[root@centos7 template]# ansible-playbook template.yml PLAY [localhost] *********************************************************************************************************************TASK [template : template example] ***************************************************************************************************changed: [localhost]PLAY RECAP ***************************************************************************************************************************localhost : ok=1 changed=1 unreachable=0 failed=0 [root@centos7 template]# cat /data/JAVA/order.conf project: JAVA switch: ON dbport: 3306]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[亿级流量电商详情页系统实战视频-缓存架构+高可用服务架构+微服务架构【全集】]]></title>
    <url>%2Fresource-billion-level-traffic.html</url>
    <content type="text"><![CDATA[又到周末了，同样为大家奉上一份好资源：亿级流量电商详情页系统实战视频。 课程简介官方介绍是这样的： 深入讲解了亿级流量电商详情页系统的完整大型架构。同时最重要的是，在完全真实的大型电商详情页系统架构下，全流程实战了整套微服务架构，包含了 Spring Cloud 微服务技术、基于 DevOps 的持续交付流水线与自动化测试套件、基于 Docker 的自动化部署。此外，还包含了大型电商详情页系统架构中的多种复杂架构设计。 该课程有两个版本，现在官网有第二版，这里我们一次性分享第一版和第二版的全集！ 课程一共包括 195 节课，官网原价需要：1199！ 课程目录 资源截图第一版完整资源： 第二版完整资源： 获取方式关注下方公众号后，回复【003】即可获取。]]></content>
      <categories>
        <category>资源分享</category>
      </categories>
      <tags>
        <tag>亿级流量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我们生活在一个有意思的星球上]]></title>
    <url>%2Fwe-are-live-in-a-funny-planet.html</url>
    <content type="text"><![CDATA[我们生活在一个有意思的星球上 1、先来看看，这就是我们的地球。 2、图中圆圈里的人口比其他所有地区的总和还要多。 3、以整个地球史来看，曾活过的人类高达 1150 亿人，其中包括现存的 70 亿人口，你也是其中的一员。 上图每一个点就是 1000 万人，每年有 1.4 亿人诞生，现在有 7 亿人口，每年有 5700 万个人死亡，估计曾有 1080 亿人曾经活在地球过死去。 4、每一天，地球都有人飞来又飞去，就像下图这样： 5、这是南极州，比美国还要大！ 6、非洲比你想像的要大多了，看看一些国家塞进来的样子： 把美国、西班牙、比利时、荷兰、法国、德国、义大利、瑞士、东欧、印度、中国的一部分、英国、日本…全都放进去。 7、如果地球没有水的话，就会变成这样： 8、你知道太平洋其实比起想像得还要大吗？ 9、这是马里亚纳海沟 (Mariana Trench) 的深度，难怪还有这么多人类尚未探索到的海底生物。 可以深到 10972 公尺…或更多。 10、我们都知道有很多人造卫星，但是你知道有这么多吗？ 11、美国放到月球的话，大小比例是这样： 12、地球到月球的距离貌似很短，但是已经可以塞下太阳系的所有星球了。 有 384,400 公里那么远喔～ 13、若把火星上头的奥林帕斯山 (Olympus Mons) 拿来跟地球的高山来比较的话…地球的好像就是小儿科啊… 奥林帕斯山有 27 公里高，几乎是圣母峰的 3 倍高，也比毛纳基火山（从水底山脚计算）的 2 倍还要高。奥林帕斯山已经高耸进火星的大气层了。 它的基底有 550 公里那么宽广，意思也就是，如果你站在破火山口来看的话，它的山脚会一路绵延超过地平线。 14、而这座巨型火山，大概也跟一个法国差不多大。 15、木星的体积也不小，只是距离我们太远了。但如果木星距离我们就跟月球一样近的话，我们会看到… 心脏根本就不够用啊！仰望天空时太惊悚了吧！ 16、左是木星卫星「木卫二」(Europa) 上头的水量，右则是地球上的水量。 什么！地球的水比想像中的还要少这么多呀！ 17、每一天，都是木星让陨石的轨迹远离地球的。 虽然不知道你听不听得到，但谢谢你，木星。 18、我们都知道宇宙里头有许多彗星，但你可能对它们的大小没有什么概念。好吧，如果拿洛杉矶 (LA) 跟彗星比较的话… 19、我们的太阳系也是不断地移动，我们现在跟 2.25 亿年前的地球是在同一个位置，当时恐龙都还活着。 我们的太阳系会花上 2.25 亿年绕行银河系，上一次地球在同一个位置的时候，恐龙都还存在着。 20、仰望天空，我们都觉得其他的星星很小，但若从土星的环后方来看的话，地球也相当渺小。 21、事实上，你眼睛所能看见、人类所知道的，其实都只有在这小小的圈圈里头。 22、而在银河系当中，所有人类向宇宙广播可以触及的范围，就只有那蓝色的小点点那么多。难怪我们一直都没有找到其他高智能的生命… 23、而这是我们每年在银河系当中所发现的星球数量： 24、在我们的印象中银河系很大，但我们再来比较一下… （左到右）银河系、仙女座星系 (Andromeda)、室女A星系 (m87)、IC-1011星系。 25、看完之后，你可能跟我一样觉得自己相当渺小，但别忘了，每天有上兆的细胞在你的体内运行着。以下是白血球正在攻击寄生虫的样子： 在细分一些，这些东西都是由分子组成的，而这是其中的一个： 最后也忘了，你体内是有 7,000,000,000,000,000,000,000,000,000 个原子的，这就是你！]]></content>
      <categories>
        <category>闲扯系列</category>
      </categories>
      <tags>
        <tag>有意思</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible 进阶 | synchronise 文件同步模块]]></title>
    <url>%2Fansible-synchronise.html</url>
    <content type="text"><![CDATA[准备从远程主机上拉取文件，这时我想到了 Ansible 中的 fetch 模块，但是发现 fetch 模块支持远程文件的拉取，而不支持目录！ 于是，我就找到了 synchronise。 synchronise 模块是对 rsync 的封装，实现控制机和目标机之间的数据同步。当然，你也可以在 command 模块中直接调用 rsync 命令，但是 synchronise 对其进行了封装，提供了一些规范化的东西，使用起来更加方便、高效，还可以增量同步。 简单了解下 rsyncrsync 是一个快速且功能非常丰富的文件拷贝工具。它可以在本地和远程之间通过 shell 或 rsync 服务互相拷贝文件。它提供了大量的选项来控制它各方面功能的行为，且在指定待拷贝文件方面非常有弹性。 它以其增量拷贝算法而出名，只拷贝源和目标不同的文件部分，因此减少网络间要传输的数据。rsync 被广泛用于做备份、镜像和当作升级版拷贝命令。 rsync 同步过程中由两部分模式组成：决定哪些文件需要同步的检查模式以及文件同步时的同步模式，也就是先检查哪些要同步，然后再进行同步。 检查模式是指按照指定规则来检查哪些文件需要被同步，例如哪些文件是明确被排除不传输的。默认情况下，rsync 使用 quick check 算法快速检查源文件和目标文件的大小、mtime（修改时间）是否一致，如果不一致则需要传输。当然，也可以通过在r sync 命令行中指定某些选项来改变 quick check 的检查模式，比如 --size-only 选项表示仅检查文件大小不同的文件作为待传输文件。rsync 支持非常多的选项，其中检查模式的自定义性是非常有弹性的。 同步模式是指在文件确定要被同步后，在同步过程发生之前要做哪些额外工作。例如上文所说的是否要先删除源主机上没有但目标主机上有的文件，是否要先备份已存在的目标文件，是否要追踪链接文件等额外操作。rsync 也提供非常多的选项使得同步模式变得更具弹性。 相对来说，为 rsync 手动指定同步模式的选项更常见一些，只有在有特殊需求时才指定检查模式，因为大多数检查模式选项都可能会影响 rsync 的性能。 总之，rsync 是非常强大的，参数选项非常多，能够实现非常具有弹性的功能，关于更完整更详细的选项说明可以参考：http://www.cnblogs.com/f-ck-need-u/p/7221713.html synchronise参数说明 src：必填，源地址路径 dest：必填，目的地址路径 mode：mode=push，推送 ansible（src） -&gt; 远程主机（dest）；mode=pull，拉取，远程主机（src） -&gt; ansible（dest），默认为 push group：文件属组 owner：文件属主 archive：是否采用归档模式同步，即以源文件相同属性同步到目标地址，默认为 yes delete：是否删除源中没有而目标存在的文件（即以推送方为主），默认为 no compress：是否开启压缩，默认为 yes rsync_opts：rsync 参数部分，--exclude：忽略同步文件、目录 rsync_timeout：指定 rsync 操作的 IP 超时时间，和 rsync 命令的 --timeout 参数效果一样 简单使用本文中用两台主机进行试验：192.168.31.63（server端）、192.168.31.64（client端）。 我们现在 client 端随便新建一些文件： 123456789# pwd/tmp/client# tree.└── sync_test └── haha.t1 directory, 1 file 从远程主机 pull 文件 这时远程主机是源文件。 123456789101112# ansible test -m synchronize -a "src=/tmp/client/ dest=/tmp/server mode=pull"client | SUCCESS =&gt; &#123; "changed": true, "cmd": "/usr/bin/rsync --delay-updates -F --compress --archive --rsh=/usr/bin/ssh -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null --out-format=&lt;&lt;CHANGED&gt;&gt;%i %n%L root@client:/tmp/client/ /tmp/server", "msg": "cd+++++++++ ./\ncd+++++++++ sync_test/\n&gt;f+++++++++ sync_test/haha.t\n", "rc": 0, "stdout_lines": [ "cd+++++++++ ./", "cd+++++++++ sync_test/", "&gt;f+++++++++ sync_test/haha.t" ]&#125; 在 server 节点查看，数据已同步到 /tmp/server/ 目录下： 12345678# pwd/tmp/server# tree.└── sync_test └── haha.t1 directory, 1 file push 文件 我们在 haha.t 文件中随便输入一些内容，并新建一个文件： 1234567# lltotal 4-rw-r--r-- 1 root root 0 Aug 23 17:34 haha2.tt-rw-r--r-- 1 liuhao root 7 Aug 23 17:33 haha.t# cat haha.t hahha 需要注意的是，push 时，src 需要填本地目录，dest 填远程主机目录： 123456789101112# ansible test -m synchronize -a "src=/tmp/server/ dest=/tmp/client/"client | SUCCESS =&gt; &#123; "changed": true, "cmd": "/usr/bin/rsync --delay-updates -F --compress --archive --rsh=/usr/bin/ssh -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null --out-format=&lt;&lt;CHANGED&gt;&gt;%i %n%L /tmp/server/ root@client:/tmp/client/", "msg": ".d..t...... sync_test/\n&lt;f.st...... sync_test/haha.t\n&lt;f+++++++++ sync_test/haha2.tt\n", "rc": 0, "stdout_lines": [ ".d..t...... sync_test/", "&lt;f.st...... sync_test/haha.t", "&lt;f+++++++++ sync_test/haha2.tt" ]&#125; 单个文件冲突时 默认情况下会以 src 端的数据为准。 dest 端有多余文件时 默认情况下会保留 dest 端有，而 src 端没有的文件。可以通过 delete 参数设置为 yes 来删除 dest 端多余的文件。 12345678910# ansible test -m synchronize -a "src=/tmp/client/ dest=/tmp/server mode=pull delete=yes"client | SUCCESS =&gt; &#123; "changed": true, "cmd": "/usr/bin/rsync --delay-updates -F --compress --delete-after --archive --rsh=/usr/bin/ssh -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null --out-format=&lt;&lt;CHANGED&gt;&gt;%i %n%L root@client:/tmp/client/ /tmp/server", "msg": "*deleting sync_test/other.t\n", "rc": 0, "stdout_lines": [ "*deleting sync_test/other.t" ]&#125; 忽略文件 12345678910# ansible test -m synchronize -a "src=/tmp/server/ dest=/tmp/client/ rsync_opts='--exclude=sync_test/other.t'"client | SUCCESS =&gt; &#123; "changed": true, "cmd": "/usr/bin/rsync --delay-updates -F --compress --archive --rsh=/usr/bin/ssh -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null --exclude=sync_test/other.t --out-format=&lt;&lt;CHANGED&gt;&gt;%i %n%L /tmp/server/ root@client:/tmp/client/", "msg": ".d..t...... sync_test/\n", "rc": 0, "stdout_lines": [ ".d..t...... sync_test/" ]&#125; 源主机有多个时 比如，一个主机组下配置了两个主机，并且都有 同一个目录 /tmp/client/，我们制造一个文件冲突的现场： 主机 1： 1234567891011121314# tree.├── 21└── 230 directories, 2 files# lltotal 4-rw-r--r-- 1 root root 4 Sep 5 11:39 21-rw-r--r-- 1 root root 0 Sep 5 11:36 23# cat 21123 主机 2： 123456789101112# tree.└── 210 directories, 1 file# lltotal 4-rw-r--r-- 1 liuhao root 4 Sep 5 11:29 21# cat 21456 可以看出，文件 21，不仅文件内容不同，文件权限也不同，那我们从两台主机进行拉取时，会得到什么样的结果呢？ 执行： 123456789101112131415161718192021# ansible test -m synchronize -a "src=/tmp/client/ dest=/tmp/server/ mode=pull"主机1 | SUCCESS =&gt; &#123; "changed": true, "cmd": "/usr/bin/rsync --delay-updates -F --compress --archive --rsh=/usr/bin/ssh -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null --out-format=&lt;&lt;CHANGED&gt;&gt;%i %n%L root@主机1:/tmp/client/ /tmp/server/", "msg": ".d..t...... ./\n&gt;f.st...... 21\n", "rc": 0, "stdout_lines": [ ".d..t...... ./", "&gt;f.st...... 21" ]&#125;主机2 | SUCCESS =&gt; &#123; "changed": true, "cmd": "/usr/bin/rsync --delay-updates -F --compress --archive --rsh=/usr/bin/ssh -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null --out-format=&lt;&lt;CHANGED&gt;&gt;%i %n%L root@1主机2:/tmp/client/ /tmp/server/", "msg": ".d..t...... ./\n&gt;f..t.o.... 21\n", "rc": 0, "stdout_lines": [ ".d..t...... ./", "&gt;f..t.o.... 21" ]&#125; 然后我们看结果： 1234567891011121314# lltotal 4-rw-r--r-- 1 liuhao root 4 Sep 5 11:29 21-rw-r--r-- 1 root root 0 Sep 5 11:36 23# tree.├── 21└── 230 directories, 2 files# cat 21456 显然，后面执行的主机 2 的文件内容，覆盖了前面主机 1 的文件内容。 注意点 本地和远程系统必须安装 rsync 包，否则无法使用这个模块； 对于 synchronize 模块，本地主机是同步任务发起的主机，目标主机是同步时被连接的主机； 也可以使用 delegate_to 将本地主机更改为其他主机。这样可以在两个远程主机之间进行复制，或者在一台远程机器上执行两个目录的同步。 需要注意的是，使用 delegate_to 授权机进行 synchronize，需要保证授权机能密钥访问远程机。因为 delegate_to 时，使用的帐户权限是授权机的，而非 ansible host 的。 123456789# Synchronization of src on delegate host to dest on the current inventory host.# 同步『授权机(delegate host)』的 src 目录到远程机器# 注：需要指定 rsync_opts。# 参考 https://github.com/ansible/ansible/issues/7250- synchronize: src: /first/absolute/path dest: /second/absolute/path rsync_opts: '-e "ssh -p -i /home/delegate_host_user/.ssh/id_rsa"' delegate_to: delegate.host src 的所属用户和权限是本地主机上运行 Ansible 任务的用户和权限（如果配置了 delegate_to，那就是授权机上的 remote_user 的）； dest 的所属用户和权限是目标主机上 remote_user 的用户和权限，如果配置了 become=yes，则为 become_user的； 即使使用了 sudo, dest=~/x 也会变成 ~&lt;remote_user&gt;/x； 如果 inventory 文件中使用 ansible_ssh_pass 进行用户名密码认证，在使用 synchronize 模块时由于模块使用的是独立的 ssh 通道，因此会再次提示输入密码，在大规模文件下发场景中使用体验较差，可以考虑通过其它途径实现。 和 copy/fecth 的区别其实有点类似于 rsync 和 scp 的区别，Rsync 有着更丰富的特性，并且更快捷，当然，Rsync 使用起来相对复杂些，因为参数较多。 总结来看就是： copy 模块不支持从远端到本地的拉去操作，fetch 模块支持，但是 src 参数不支持目录递归，只能回传具体文件； copy 模块的 remote_src 参数是指定从远端服务器上往远端服务器上复制，相当于在 shell 模块中执行 copy 命令； synchronize 则支持文件下发和回传，分别对应的 push 和 pull 模式。synchronize 模块的功能依赖于 rsync，但是功能不依赖于 rsync 配置文件中定义的模块； copy 模块适用于小规模文件操作，synchronize 支持大规模文件操作。]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最常用 Git 命令列表总结]]></title>
    <url>%2Fgit-basic-command-list.html</url>
    <content type="text"><![CDATA[我几乎每天都使用 Git，但仍然无法记住很多命令。 通常，只需要记住下图中的 6 个命令就足以供日常使用。但是，为了确保使用地很顺滑，其实你应该记住 60 到 100 个命令。 Git 相关术语Git 中不可避免会遇到下面几个术语，不搞清楚它们，后面只会更懵逼。 工作区（Working Directory） 暂存区（Stage/Index） 本地历史仓库（Repository） 远程仓库（Remote） 对照下图，下面一一进行介绍。 工作区我们写代码的地方就是工作区，就是在电脑里能看到的目录，我们当前的工作空间。 暂存区暂存区（stage）就是每次 git add 时，文件的修改存放的地方。 git commit 时就是一次性把暂存区所有修改提交到分支。 本地仓库我们可以把暂存区的内容提交到我们的本地仓库，又名版本库（respository），可将其理解成一个目录，该目录下的所有文件都会被 git 管理起来，每个文件的修改、删除、git 都能跟踪，以便随时追踪历史，和还原。 .git 隐藏目录就是 git 的版本库，里面存了很多东西，最重要的就是 stage（index） 暂存区，还有第一个分支 master，以及指向 master 的 HEAD 指针。 远程仓库远程仓库其实就是找一台电脑充当服务器的角色，每天 24 小时开机，其他每个人都从这个远程仓库克隆一份到自己的电脑上，并且各自把各自的提交推送到服务器仓库里，也从服务器仓库中拉取别人的提交。 比如，GitHub、Gitlab 等都属于远程仓库。 下面，举一个形象化的例子来帮助大家理解上面几个概念： 比如我们在逛着某宝： 1、看到了心仪的物品，我们可以把商品添加到购物车（暂存区），我们可能会频繁的添加商品（add）或者移除商品（checkout），在这个过程中我们可以随便嗨，反正还没给钱； 2、接着我们挑的七七八八了，接着我们就要提交我们的订单了，点击提交订单（commit），接着会生成一个商品的订单列表（快照），我们还可以在提交的时候添加点备注信息，比如要什么颜色（commit -m “颜色”），好的，此时订单提交了，但是我们还没支付（Push），我们可以在自己的账户未支付订单列表（本地仓库）中找到我们的这个订单订单（快照），也可以看到自己以前的一些订单记录； 3、再接着我们选择这个还没付款的订单，进行支付（Push），付款完成后，商家（远程仓库）就会收到这个订单，然后发货… 其他一些重要概念HEADHEAD 就是当前活跃分支的游标，你现在在哪儿，HEAD 就指向哪儿。 HEAD 是一个指针，总是指向当前分支。仓库版本的回退和追踪都是通过操作 HEAD 指针来完成。 不过 HEAD 并非只能指向分支的最顶端（时间节点距今最近的那个），实际上它可以指向任何一个节点，它就是 Git 内部用来追踪当前位置的东东。 标签有了 commit id 为什么还要tag？因为 commit id 不好找，tag 是有意义的名字，它与 commit 绑在一起。 其他要点1、每一次 git commit，都会生成一个 commit id 记录该次提交，Git 都会将它们串成一条时间线，这条时间线就是一个分支。2、因为创建、合并、删除分支都很快，所以 git 鼓励你使用分支完成某个任务，合并后再删除分支。过程比直接在 master 分支工作更安全，且效果一样。3、分支策略：master 分支应该是非常稳定的，仅用来发布新版本，平时不能在上面干活，干活都在 dev 分支，dev 是不稳定的，到 1.0 发布时，再将 dev 合并到 master 上，由 master 发布新版本。 Git 常用命令1. 创建一个新的仓库12345678# 在当前目录新建一个 Git 仓库$ git init# 新建一个目录，并将其初始化为 Git 仓库$ git init [project-name]# 从远程下载一个仓库$ git clone [url] 2. 配置Git 的配置文件是 .gitconfig，可以放在用户的主目录（全局配置）下或项目目录下（项目配置）。 123456789# 显示当前的 Git 配置$ git config --list# 编辑 Git 配置$ git config -e [--global]# 设置用来提交代码的用户信息$ git config [--global] user.name "[name]"$ git config [--global] user.email "[email address]" 3. 添加/删除文件123456789101112131415161718192021# 将指定文件添加到暂存区中$ git add [file1] [file2] ...# 将指定目录添加到暂存区中，包括子目录$ git add [dir]# 将当前目录中的所有文件添加到暂存区中$ git add .# 在添加每个更改之前都进行确认# 对于同一个文件的多个更改，建议分开提交$ git add -p# 将指定文件从工作区删除，并将本次删除添加到暂存区$ git rm [file1] [file2] ...# 停止追踪指定的文件，不会删除文件$ git rm --cached [file]# 对指定文件进行重命名，并添加到暂存区中$ git mv [file-original] [file-renamed] 4. 代码提交相关123456789101112131415161718# 将暂存区中的文件提交到代码仓库$ git commit -m [message]# 将指定的文件从暂存区中提交到仓库$ git commit [file1] [file2] ... -m [message]# 将工作区的更改直接提交到仓库$ git commit -a# 提交前展示所有的变动$ git commit -v# 使用新提交代替上次提交# 如果代码没有任何变动，将会用于重写上次提交的提交信息$ git commit --amend -m [message]# 重做上次的提交，并将指定的文件包含其中$ git commit --amend [file1] [file2] ... 5. 分支相关123456789101112131415161718192021222324252627282930313233343536373839404142# 列出本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出本地和远程的所有分支$ git branch -a# 新建分支，并留在当前分支$ git branch [branch-name]# 新建分支，并切换到新分支$ git checkout -b [branch]# 指向某次提交新建分支$ git branch [branch] [commit]# 创建一个新分支，并与指定的远程分支建立跟踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 将本地分支与指定的远程分支建立跟踪关系$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支与当前分支$ git merge [branch]# 将指定的提交合并到本地分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 6. 标签操作1234567891011121314151617181920212223242526# 列出所有标签$ git tag# 在当前提交上创建一个新标签$ git tag [tag]# 在指定提交上创建一个新标签$ git tag [tag] [commit]# 删除本地标签$ git tag -d [tag]# 删除远程标签$ git push origin :refs/tags/[tagName]# 查看标签信息$ git show [tag]# 提交指定标签$ git push [remote] [tag]# 提交所有标签$ git push [remote] --tags# 创建一个新分支，指向特定的标签$ git checkout -b [branch] [tag] 7.查看信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 显示有变动的文件$ git status# 显示当前分支的提交历史$ git log# 显示提交历史和每次提交的文件$ git log --stat# 指定关键字搜索提交历史$ git log -S [keyword]# 显示自某次提交以来的所有更改，一次提交显示一行。$ git log [tag] HEAD --pretty=format:%s# 显示自某次提交以来的所有更改，其提交描述必须符合搜索条件。$ git log [tag] HEAD --grep feature# 显示指定文件的提交历史$ git log --follow [file]$ git whatchanged [file]# 显示与指定文件相关的每个差异$ git log -p [file]# 显示最近 5 次提交$ git log -5 --pretty --oneline# 显示所有的提交用户，已提交数目多少排名$ git shortlog -sn# 显示指定文件何时被何人修改过$ git blame [file]# 显示暂存区和工作区的文件差别$ git diff# 显示暂存区和上一次提交的差别$ git diff --cached [file]# 显示工作区和当前分支的最近一次提交的差别$ git diff HEAD# 显示指定两次提交的差别$ git diff [first-branch]...[second-branch]# 显示今天提交了多少代码$ git diff --shortstat "@&#123;0 day ago&#125;"# 显示特定提交的提交信息和更改的内容$ git show [commit]# 新手某次提交改动了哪些文件$ git show --name-only [commit]# 显示某个提交的特定文件的内容$ git show [commit]:[filename]# 显示当前分支的最新提交$ git reflog 8. 远程同步1234567891011121314151617181920212223# 从远程分支下载所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程参考的信息$ git remote show [remote]# 新建一个远程仓库，并命名$ git remote add [shortname] [url]# 检索远程存储库的更改，并与本地分支合并$ git pull [remote] [branch]# 将本地分支提交到远程仓库$ git push [remote] [branch]# 将当前分支强制提交到远程仓库，即使有冲突存在$ git push [remote] --force# 将所有分支提交到远程仓库$ git push [remote] --all 9. 撤销操作12345678910111213141516171819202122232425262728293031# 将暂存区中的指定文件还原到工作区，保留文件变动$ git checkout [file]# 将指定文件从某个提交还原到暂存区和工作区$ git checkout [commit] [file]# 将暂存区中的所有文件还原到工作区$ git checkout .# 重置暂存区中的指定文件，与先前的提交保持一致，但保持工作空间的变动不变$ git reset [file]# 重置暂存区和工作区中的指定文件，并与最近一次提交保持一致，工作空间文件变动不会保留$ git reset --hard# 重置暂存区，指向指定的某次提交，工作区的内容不会被覆盖$ git reset [commit]# 重置暂存区和工作区中的指定文件，并与指定的某次提交保持一致，工作区的内容会被覆盖$ git reset --hard [commit]# 将 HEAD 重置为指定的某次提交，保持暂存区和工作区的内容不变$ git reset --keep [commit]# 新建新提交以撤消指定的提交# All changes of the latter will be offset by the former and applied to the current branch.$ git revert [commit]# 暂存为提交的变动，并在稍后移动它们$ git stash$ git stash pop 10. 其他12# 生成用于发布的存档$ git archive 参考：1、https://juejin.im/post/5adb1720f265da0b80704fb82、https://www.cnblogs.com/tsingke/p/7350490.html3、https://www.tutorialdocs.com/article/git-basic-command-list.html]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[做IT的，不管你是运维、开发或架构师，这些安全知识你不得不懂]]></title>
    <url>%2Fit-safe.html</url>
    <content type="text"><![CDATA[以前刚接触 IT 行业，而我身为运维开发，我以为我所需要做的安全就是修改服务器密码为复杂的，ssh 端口改为非 22，还有就是不让人登录服务器就可以保证我维护的东西安全。 工作也好几年了，在这摸爬滚打中，遇到了服务器被黑，网站被人 DDOS 攻击，数据库被篡改等等。服务器也不是你说不让人上就不让人上的，所以 IT 安全这个话题还是比较沉重的，涉及的东西很多，只有你了解得更多，你才会知道你所了解的安全其实是那么少。 网络安全我们很多的公司和环境并未使用第三方审计系统，未能根据记录数据进行分形，并生成审计报表。其实审计系统是很重要的，可以进行操作溯源，这可比你一张嘴说的话有用多了。 我所在的公司其实是买了一台日志审计系统，但是然并卵，在运维方面，我搭建了 ELK，用于对服务器的操作溯源以及监控系统日志和安全日志，这个已经完全达到我想要的效果，另外的系统相关的日志，开发人员自己也有 ELK 系统，他们是用来监控 app 里面的行为操作，也是用于审计的。 下面就是我自己搭建的 ELK 系统用于监控服务器操作： 其实网络安全范围很广，还有比如说你可以将设备惊醒 ARP 绑定，那就可以避免 arp 攻击等，也可以购买入侵检测设备、入侵防御设备，防火墙等，网络设备定期修改密码，网络设备配置鉴别失败登录处理功能，配置操作超时等功能，尽量使用 https 协议加密传输。 除上述以外，应定期自检（漏洞扫描、弱口令扫描、基线配置信息等），对主机的端口、弱口令、安全漏洞进行扫描和发现，对已知业务应用漏洞进行扫描和发现，对已知木马进行扫描和发现，对扫描结果进行分析和提交，促进业务安全性管理和安全问题的解决。 主机安全在现在大多数的公司中，操作系统未安装主机入侵检测系统，未能检测到对重要服务器进行入侵的行为，能够记录攻击者的源 IP、攻击类型、攻击目标、攻击时间等，未能够在发生严重入侵事件时提供报警。 很多人说，这个需要购买硬件 WAF 或者入侵防御设备，这个的确是个不小的花销，一般的公司估计也买不起，像我们，也买不起。 但是并不是说我们毫无办法。我们可以在操作系统安装实时检测与查杀恶意代码的软件产品，对恶意代码实时检测与查杀，如 OSSEC 和 HIDS 等，这些产品都是免费开源的。 主机安全还包括系统配置安全、验证安全等等。 就比如操作系统提供身份鉴别措施、配置鉴别失败处理功能（也就是登录尝试失败次数，这个可以有效防止恶意破解）、加强口令复杂度要求，在原基础上还应不含有常用字符组合、数字组合、键盘顺序等可预测密码组合、重要服务器用使用资源强制访问控制策略（如用户、进程、文件内核级保护）、应限制默认账户的访问权限，修改这些账户的默认口令，条件允许下，应重命名默认账户； 应用安全a）、建议应用系统采用了两种或两种以上的组合机制进行用户身份鉴别； b）、建议应用系统对账号口令复杂度进行限制，口令长度限制为 8-20 位；要求口令为数字、字母字符至少两种组合，限制口令周期不大于半年； c）、建议应用系统启用登录失败处理功能，限制次数不大于 5 次，并且对登录失败用户进行帐号处理； d）、建议应用系统应启用用户身份鉴别信息复杂度要求和登录失败处理功能； e）、建议应用系统对重要信息资源设置敏感标记，系统不支持设置敏感标记的，应采用专用安全设备生成敏感标记，用以支持强制访问控制机制； f）、建议应用系统开启安全审计功能，安全审计范围覆盖到每个用户以及其相关操作； g）、建议应用系统开启安全审计功能，且审计功能不能中断和安全记录非管理员无法删除、修改或覆盖； h）、建议限制应用系统一段时间的并发会话连接数； i）、建议应用系统限制一个访问账号或一个请求进程的最大限额； j）、建议应用系统提供服务优先级设定功能，根据安全策略设定访问帐户或请求进程的优先级，根据优先级分配系统资源； 数据安全及备份恢复a）、建议提供异地数据备份功能，利用通信网络将关键数据定时批量传送到备用场地； b）、建议提供主要网络设备、通信线路和数据处理系统的硬件冗余，保证系统的高可用性； c）、数据的开发、测试环境如果要导入生产数据，则需要指定数据脱敏流程，将敏感的个人信息，如银行卡、手机号等信息做脱敏； d）、数据的访问要有严格的流程，非运维人员如要访问数据，在走完权限申请流程后，可以给予他读取的权限，但是不能给他将数据备份至本地的权限，该操作可以通过windows堡垒机进行权限限制，通过管理员将该人员的剪贴板禁用即可； e）、数据库一年要升级一次，即使你的数据库是放在内网的，但是你不能保证你们开发人员的代码不会被入侵，只要代码被入侵，或者被植入后门，就可以通过你的程序扫描到数据库。数据库的漏洞可不止一两个，基本上一年下来，一个稳定版本的数据库可以有 30 个左右的高危漏洞，50 个左右的中危漏洞，这些个漏洞，你靠打补丁的方式根本不是解决办法，最好的方式还是升级到数据库最新版本前一个稳定版； web业务安全a）、应设置合理的会话超时阀值，在合理范围内尽可能减小会话超时阀值，可以降低会话被劫持和重复攻击的风险，超过会话超时阀值后立刻销毁会话，清除会话的信息； b）、应限制会话并发连接数，限制同一用户的会话并发连接数，避免恶意用户创建多个并发的会话来消耗系统资源，影响业务可用性； c）、应确保敏感信息通信信道的安全，建议在客户端与 web 服务器之间使用 SSL。并正确配置 SSL，建议使用 SSL3.0/TLS1.0 以上版本，对称加密密钥长度不少于 128 位，非对称加密密钥长度不少于 1024 位，单向散列值位数不小于 128 位； d）、日志记录范围应覆盖到每个用户的关键操作、重要行为、业务资源使用情况等重要事件。如普通用户异常登录、发布恶意代码、异常修改账号信息等行为，以及管理员在业务功能及账号控制方面的关键操作； e）、Web 程序上线前或升级后应进行代码审计，形成报告，并对审计出的问题进行代码升级完善； f）、应禁止明文传输用户密码，建议采用SSL加密隧道确保用户密码的传输安全； g）、应对关键业务操作，例如修改用户认证鉴权信息（如密码、密码取回问题及答案、绑定手机号码等），需要经过二次鉴权，以避免因用户身份被冒用，给用户造成损失； h）、应避免认证错误提示泄露信息，在认证失败时，应向用户提供通用的错误提示信息，不应区分是账号错误还是密码错误，避免这些错误提示信息被攻击者利用； i）、应支持密码策略设置，从业务系统层面支持强制的密码策略，包括密码长度、复杂度、更换周期等，特别是业务系统的管理员密码； j）、应支持账号锁定功能，系统应限制连续登录失败次数，在客户端多次尝试失败后，服务器端需要对用户账号进行短时锁定，且锁定策略支持配置解锁时长； k）、应采取会话保护措施防止软件与服务器之间的会话不可被篡改、伪造、重放等； 本文来自 运维人生 转载请注明；本文地址：http://www.ywadmin.com/?id=75]]></content>
      <categories>
        <category>网络相关</category>
      </categories>
      <tags>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible 离线安装]]></title>
    <url>%2Finstall-ansible-offline.html</url>
    <content type="text"><![CDATA[# 需要安装 gcc、make 需要Python，若没有将下文中的安装Python过程的脚本注释打开 参考：http://blog.csdn.net/baidu_34950407/article/details/51371917https://www.jianshu.com/p/964b643ca251]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 面向对象]]></title>
    <url>%2Fpython-oop.html</url>
    <content type="text"><![CDATA[虽然 Python 是解释性语言，但是它是面向对象的，能够进行对象编程。 __init__() 方法 __init__() 方法，在创建一个对象时默认被调用，不需要手动调用 __init__(self) 中，默认有 1 个参数名字为 self，如果在创建对象时传递了2个实参，那么 __init__(self) 中出了self 作为第一个形参外还需要 2 个形参，例如 __init__(self,x,y) __init__(self) 中的 self 参数，不需要开发者传递，python 解释器会自动把当前的对象引用传递进去 所谓的self，可以理解为自己。可以把 self 当做 Java 中类里面的 this 指针一样理解，就是对象自身的意思 123456789101112131415161718192021# 定义类class Car(): # 初始化函数，用来完成一些默认的设定 # def __init__(self): # self.color = '蓝色' # self.wheelNum = 2 def __init__(self, wheelNum, color): self.color = color self.wheelNum = wheelNum def __str__(self): msg = "I'm a car. my color is " + self.color + ", and I hava " + str(self.wheelNum) + "个轮子." return msg# 创建对象Qq = Car(4, '黄色')print(Qq.color)print(Qq.wheelNum)print(Qq) 总结： 在 python 中方法名如果是 __xxxx__() 的，那么就有特殊的功能，因此叫做“魔法”方法 当使用 print 输出对象的时候，只要自己定义了 __str__(self) 方法，那么就会打印从在这个方法中return的数据 私有属性Python 中没有像 Java 中 public 和 private 这样的关键字来区别公有属性和私有属性。它是以属性命名方式来区分，如果在属性名前面加了 2 个下划线 __，则表明该属性是私有属性，否则为公有属性（方法也是一样，方法名前面加了 2 个下划线的话表示该方法是私有的，否则为公有的）。 1234567891011121314151617181920212223242526272829303132# coding=utf-8class Person: def __init__(self, name='xiaoming'): self.name = name def getName(self): return self.name def setName(self, name): self.name = nameclass Person2(object): def __init__(self, name='xiahua'): self.__name = name def getName(self): return self.__name def setName(self, name): self.__name = namexiaobi = Person()print(xiaobi.getName())print(xiaobi.name)xiaobi.name = 'xiaoci'print(xiaobi.name)xiaobi.setName('xiaodi')print(xiaobi.name)dabi = Person2()print(dabi.__name) 继承 子类在继承的时候，在定义类时，小括号 () 中为父类的名字 父类的属性、方法，会被继承给子类 私有的属性、方法，不会被子类继承，也不能被访问 一般情况下，私有的属性、方法都是不对外公布的，往往用来做内部的事情，起到安全的作用 python 中是可以多继承的，若两个父类中有名字相同的方法，会调用前面一个的。使用 类.__mro__ 可以查看调用顺序。 12345678910111213141516171819202122232425262728293031# coding=utf-8# 继承class Animal: def run(self): print('animal is running')class Cat: def __init__(self, name, color='white'): self.name = name self.color = color def run(self): print('%s -- 在跑' %self.name)# 继承自两个类class Bosi(Animal,Cat): def eat(self): print('%s -- 在吃饭' %self.name)xiaomi = Cat('xiami')xiaomi.run()huihui = Bosi('huihui', 'hui')huihui.eat()# 两个父类中有名字相同的方法，会调用前面一个的huihui.run()print(Bosi.__mro__) 重写父类方法所谓重写，就是子类中，有一个和父类相同名字的方法，在子类中的方法会覆盖掉父类中同名的方法。 这时若要调用在子类中父类的方法，需要使用 super()。 12345678910111213141516171819#coding=utf-8class Cat(object): def __init__(self,name): self.name = name self.color = 'yellow'class Bosi(Cat): def __init__(self,name): # 调用父类的__init__方法 super().__init__(name) def getName(self): return self.namebosi = Bosi('xiaohua')print(bosi.name)print(bosi.color) 多态定义时的类型和运行时的类型不一样，此时就成为多态。 123456789101112131415161718192021222324# coding=utf-8# 多态class F1(object): def show(self): print('F1.show')class S1(F1): def show(self): print('S1.show')class S2(F1): def show(self): print('S2.show')def func(obj): obj.show()if __name__ == '__main__': s1 = S1() s2 = S2() func(s1) func(s2) 类属性和实例属性类属性就是类对象所拥有的属性，它被所有类对象的实例对象所共有，在内存中只存在一个副本，这个和 Java 中类的静态成员变量有点类似。对于公有的类属性，在类外可以通过类对象和实例对象访问。 如果需要在类外修改类属性，必须通过类对象去引用然后进行修改。如果通过实例对象去引用，会产生一个同名的实例属性，这种方式修改的是实例属性，不会影响到类属性，并且之后如果通过实例对象去引用该名称的属性，实例属性会强制屏蔽掉类属性，即引用的是实例属性，除非删除了该实例属性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445# coding=utf-8# 类属性class People: name = 'Tom' # 公有的类属性 __age = 12 # 私有类属性p = People()print(p.name) # 正确print(People.name) # 正确# print(p.__age) #错误，不能在类外通过实例对象访问私有的类属性# print(People.__age) #错误，不能在类外通过类对象访问私有的类属性print('-' * 20)# 实例属性class People2: address = '山东' def __init__(self): self.name = 'sb' self.age = 22p2 = People2()print(p2.age)p2.age = 12print(p2.age)print(p2.name)print(p2.address)print(People2.address)# print(People2.name) # 错误，不能获取到实例属性# print(People2.age)p2.address = '江苏' # 会新增一个实例属性，不会影响到类属性print(p2.address) # 实例属性会屏蔽掉同名的类属性print(People2.address) # 类属性没有变化People2.address = '四川'print(p2.address) # 仍然是 江苏，因为这里引用的还是实例属性print(People2.address)del p2.address # 删除实例属性print(p2.address) # 这里引用的就是类属性 类方法和静态方法类对象所拥有的方法，需要用修饰器 @classmethod 来标识其为类方法，对于类方法，第一个参数必须是类对象，一般以 cls 作为第一个参数（当然可以用其他名称的变量作为其第一个参数，但是大部分人都习惯以 cls 作为第一个参数的名字），能够通过实例对象和类对象去访问。 需要通过修饰器 @staticmethod 来进行修饰，静态方法不需要多定义参数 从类方法和实例方法以及静态方法的定义形式就可以看出来，类方法的第一个参数是类对象 cls，那么通过 cls 引用的必定是类对象的属性和方法； 而实例方法的第一个参数是实例对象 self，那么通过 self 引用的可能是类属性、也有可能是实例属性（这个需要具体分析），不过在存在相同名称的类属性和实例属性的情况下，实例属性优先级更高。 静态方法中不需要额外定义参数，因此在静态方法中引用类属性的话，必须通过类对象来引用。 123456789101112131415161718192021222324252627282930313233343536# coding=utf-8class People: # 设置为私有属性 __address = '江苏' # 类方法，用 classmethod 来进行修饰 @classmethod def getAddress(cls): return cls.__address @classmethod def setAddress(cls, address): cls.__address = address# print(People.__address)print(People.getAddress()) # 可以通过类对象引用p = People()print(p.getAddress()) # 可以用过实例对象引用p.setAddress('湖南')print(p.getAddress())print(People.getAddress())class People2: __country = 'China' @staticmethod def getCountry(): return People2.__countryprint(People2.getCountry())p2 = People2()print(p2.getCountry()) __new__ 方法 __new__ 至少要有一个参数 cls，代表要实例化的类，此参数在实例化时由 Python 解释器自动提供 __new__ 必须要有返回值，返回实例化出来的实例，这点在自己实现 __new__ 时要特别注意，可以 return 父类 __new__ 出来的实例，或者直接是 object 的 __new__ 出来的实例 __init__ 有一个参数 self，就是这个 __new__ 返回的实例，__init__ 在 __new__ 的基础上可以完成一些其它初始化的动作，__init__ 不需要返回值 我们可以将类比作制造商，__new__ 方法就是前期的原材料购买环节，__init__ 方法就是在有原材料的基础上，加工，初始化商品环节 123456789class A(object): def __init__(self): print('This is init method.') def __new__(cls): print('This is new method.') return object.__new__(cls)A() 单例模式举个常见的单例模式例子，我们日常使用的电脑上都有一个回收站，在整个操作系统中，回收站只能有一个实例，整个系统都使用这个唯一的实例，而且回收站自行提供自己的实例。因此回收站是单例模式的应用。 确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，单例模式是一种对象创建型模式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# coding=utf-8# 创建单例-保证只有1个对象# 实例化一个单例class Singleton(object): __instance = None def __new__(cls): # 如果 __instance 没有创建 # 那么就创建一个对象，并且赋值为这个对象的引用 # 保证下次调用这个方法时，能够知道之前已经创建过对象，这样就保证了只有一个对象 if not cls.__instance: cls.__instance = object.__new__(cls) return cls.__instancea = Singleton()b = Singleton()print(id(a))print(id(b))a.age = 20print(a.age)print(b.age)# 创建单例时，只执行1次__init__方法class Singleton2(object): __instance = None __first_init = False def __new__(cls, age, name): if not cls.__instance: cls.__instance = object.__new__(cls) return cls.__instance def __init__(self, age, name): if not self.__first_init: self.age = age self.name = name Singleton2.__first_init = Truea = Singleton2(18, "dongGe")b = Singleton2(8, "dongGe")print(id(a))print(id(b))print(a.age)print(b.age)a.age = 19print(b.age)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 字符串、列表、元组、字典]]></title>
    <url>%2Fpython-string-list-tuple-dict.html</url>
    <content type="text"><![CDATA[Python 字符串、列表、元组、字典常用操作。 字符串常用操作 字符串反转 - str[::-1]，使用 -1 作为步长 123&gt;&gt;&gt; str = '12345'&gt;&gt;&gt; str[::-1]'54321' find/rfind find - 检测 str 是否包含在 mystr 中，如果是返回开始的索引值，否则返回 -1 rfind - 从右边开始查找 mystr.find(str, start=0, end=len(mystr)) 1234567&gt;&gt;&gt; str = 'hello world'&gt;&gt;&gt; str.find('mm') -1 &gt;&gt;&gt; str.find('o') 4 &gt;&gt;&gt; str.find('ll') 2 index/rindex跟 find() 方法一样，只不过如果 str 不在 mystr 中会报一个异常 mystr.index(str, start=0, end=len(mystr)) 123456&gt;&gt;&gt; str.index('ll')2&gt;&gt;&gt; str.index('mm')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: substring not found count返回 str 在 start 和 end 之间 在 mystr 里面出现的次数 mystr.count(str, start=0, end=len(mystr)) 12345678910&gt;&gt;&gt; str 'hello world' &gt;&gt;&gt; str.count('l') 3 &gt;&gt;&gt; str.count('o') 2 &gt;&gt;&gt; str.count('l', 1, 6) 2 &gt;&gt;&gt; str.count('oo') 0 replace把 mystr 中的 str1 替换成 str2,如果 count 指定，则替换不超过 count 次，不修改原字符串，返回一个新字符串。 mystr.replace(str1, str2, mystr.count(str1)) 1234567891011&gt;&gt;&gt; str = 'hello sb sb2'&gt;&gt;&gt; str.replace('sb', 'mb')'hello mb mb2'&gt;&gt;&gt; str'hello sb sb2'&gt;&gt;&gt; str2 = str.replace('sb', 'mb')&gt;&gt;&gt; str2'hello mb mb2'&gt;&gt;&gt; str2 = str.replace('sb', 'mb', 1)&gt;&gt;&gt; str2'hello mb sb2' split以 str 为分隔符切片 mystr，如果 maxsplit 有指定值，则仅分隔 maxsplit 个子字符串mystr.split(str=&quot; &quot;, 2) 12345&gt;&gt;&gt; str = 'www.sb.com.cn'&gt;&gt;&gt; str.split('.')['www', 'sb', 'com', 'cn']&gt;&gt;&gt; str.split('.', 2)['www', 'sb', 'com.cn'] join str.join(list) - list 中每个字符后面插入 str，构造出一个新的字符串 startswith/endswith检查字符串是否是以 obj 开头/结尾, 是则返回 True，否则返回 False mystr.startswith(obj) mystr.endswith(obj) 12345678&gt;&gt;&gt; www['www', 'sb', 'com', 'cn']&gt;&gt;&gt; www.join('@')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'list' object has no attribute 'join'&gt;&gt;&gt; '@'.join(www)'www@sb@com@cn' lower/upper 转化大小写 mystr.lower() mystr.upper() ljust/rjust/center 对其方式 mystr.ljust(width) - 返回一个原字符串左对齐,并使用空格填充至长度 width 的新字符串 mystr.rjust(width) - 返回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串 mystr.center(width) - 返回一个原字符串居中,并使用空格填充至长度 width 的新字符串 lstrip/rstrip/strip 去除空格 mystr.lstrip() - 删除 mystr 左边的空白字符 mystr.rstrip() - 删除 mystr 字符串末尾的空白字符 mystr.strip() - 删除mystr字符串两端的空白字符 isalpha/isdigit/isalnum/isspace/ mystr.isalpha() - 如果 mystr 所有字符都是字母 则返回 True,否则返回 False mystr.isdigit() - 如果 mystr 只包含数字则返回 True 否则返回 False mystr.isalnum() - 如果 mystr 所有字符都是字母或数字则返回 True,否则返回 False mystr.isspace() - 如果 mystr 中只包含空格，则返回 True，否则返回 False 列表相关操作添加 append/extend/insert append - 通过append可以向列表添加元素 extend - 通过extend可以将另一个集合中的元素逐一添加到列表中 insert(index, object) - 在指定位置 index 前插入元素 object 123456789101112131415&gt;&gt;&gt; list = [] &gt;&gt;&gt; list.append(2) &gt;&gt;&gt; list [2] &gt;&gt;&gt; list.append(3) &gt;&gt;&gt; list [2, 3] &gt;&gt;&gt; list.extend([6,7]) &gt;&gt;&gt; list [2, 3, 6, 7] &gt;&gt;&gt; list.insert(2,'w') &gt;&gt;&gt; list [2, 3, 'w', 6, 7] 查找 in/index/count1234567891011121314151617&gt;&gt;&gt; list[2, 3, 'b', 6, 7, 3]&gt;&gt;&gt; 2 in listTrue&gt;&gt;&gt; 5 in listFalse&gt;&gt;&gt; 5 not in listTrue&gt;&gt;&gt; list.index(3)1&gt;&gt;&gt; list.index(3, 4)5&gt;&gt;&gt; list.count(3)2 删除 del/pop/remove del - 根据下标进行删除 pop - 删除最后一个元素 remove - 根据元素的值进行删除 12345678910111213141516171819202122&gt;&gt;&gt; list[2, 3, 'b', 6, 7, 3]&gt;&gt;&gt; del list[2]&gt;&gt;&gt; list[2, 3, 6, 7, 3]&gt;&gt;&gt; list.pop()3&gt;&gt;&gt; list[2, 3, 6, 7]# 也可以删除指定元素&gt;&gt;&gt; list.pop(2)6&gt;&gt;&gt; list[2, 3, 7]&gt;&gt;&gt; list.append(3)# 删除第一个匹配到的&gt;&gt;&gt; list.remove(3)&gt;&gt;&gt; list[2, 7, 3] 排序 sort/reverse sort 方法是将 list 按特定顺序重新排列，默认为由小到大，参数 reverse=True 可改为倒序，由大到小。 reverse 方法是将 list 逆置，不是排序 1234567891011121314151617181920&gt;&gt;&gt; list[2, 7, 3]# 直接改变原list&gt;&gt;&gt; list.sort()&gt;&gt;&gt; list[2, 3, 7]&gt;&gt;&gt; list.sort(reverse=True)&gt;&gt;&gt; list[7, 3, 2]&gt;&gt;&gt; list.sort(reverse=True)&gt;&gt;&gt; list[7, 3, 2]# reverse方法只是倒置，而非排序&gt;&gt;&gt; list[7, 3, 2, 5]&gt;&gt;&gt; list.reverse()&gt;&gt;&gt; list[5, 2, 3, 7] 元组Python 的元组与列表类似，不同之处在于元组的元素不能修改。元组使用小括号，列表使用方括号。 1234567891011121314&gt;&gt;&gt; tuple = (1,2,3,3,4)&gt;&gt;&gt; tuple(1, 2, 3, 3, 4)# 访问元组&gt;&gt;&gt; tuple[4]4# index 和 count 与字符串和列表中的用法相同&gt;&gt;&gt; tuple.index(2)1&gt;&gt;&gt; tuple.count(2)1&gt;&gt;&gt; tuple.count(3)2 字典的常见操作获取元素get(key) 方法不会在 key 不存在时抛出异常。 12345678910&gt;&gt;&gt; info = &#123;'name':'班长', 'id':100, 'sex':'f', 'address':'地球亚洲中国北京'&#125;&gt;&gt;&gt; info['name']'班长'&gt;&gt;&gt; info['age']Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;KeyError: 'age'&gt;&gt;&gt; info.get('age')&gt;&gt;&gt; info.get('name')'班长' 修改元素字典的每个元素中的数据是可以修改的，只要通过 key 找到，即可修改12345&gt;&gt;&gt; info.get('id')100&gt;&gt;&gt; info['id'] = 101&gt;&gt;&gt; info.get('id')101 添加元素变量名[&#39;键&#39;] = 数据 删除元素 del / clear del 变量名[&#39;键&#39;] - 用于删除指定 key，key 不存在时会抛出异常，也可以直接删除整个字典 clear - 用于清空整个字典 123456789101112&gt;&gt;&gt; info &#123;'name': '班长', 'id': 101, 'sex': 'f', 'address': '地球亚洲中国北京', 'age': 28&#125; &gt;&gt;&gt; del info['id2'] Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; KeyError: 'id2' &gt;&gt;&gt; del info['age'] &gt;&gt;&gt; info &#123;'name': '班长', 'id': 101, 'sex': 'f', 'address': '地球亚洲中国北京'&#125; &gt;&gt;&gt; info.clear() &gt;&gt;&gt; info &#123;&#125; len() 字典数据个数123&gt;&gt;&gt; info = &#123;'name':'班长', 'id':100, 'sex':'f', 'address':'地球亚洲中国北京'&#125;&gt;&gt;&gt; len(info)4 keys() / values() / items()需要使用 list() 进行转换。 1234567891011&gt;&gt;&gt; info = &#123;'name':'班长', 'id':100, 'sex':'f', 'address':'地球亚洲中国北京'&#125;&gt;&gt;&gt; info.keys()dict_keys(['name', 'id', 'sex', 'address'])&gt;&gt;&gt; list(info.keys())['name', 'id', 'sex', 'address']&gt;&gt;&gt;&gt;&gt;&gt; list(info.values())['班长', 100, 'f', '地球亚洲中国北京']&gt;&gt;&gt; list(info.items())[('name', '班长'), ('id', 100), ('sex', 'f'), ('address', '地球亚洲中国北京')]&gt;&gt;&gt; in / not in判断字典中是否包含指定的 key。Python3 已删除 has_key() 函数。 1234567&gt;&gt;&gt; info = &#123;'name':'班长', 'id':100, 'sex':'f', 'address':'地球亚洲中国北京'&#125;&gt;&gt;&gt; 'id' in infoTrue&gt;&gt;&gt; 'age' in infoFalse&gt;&gt;&gt; 'age' not in infoTrue]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 学习笔记]]></title>
    <url>%2FPython-learning-note.html</url>
    <content type="text"><![CDATA[本文主要包括 Python 遍历方法、公共方法、异常处理、模块、列表推导式等内容。 遍历通过 for ... in ...: 的语法结构，我们可以遍历字符串、列表、元组、字典等数据结构。 字符串、列表、元组遍历12345678910111213141516171819&gt;&gt;&gt; for i in 'abc': ... print(i) ... a b c &gt;&gt;&gt; for i in [1,2,3]: ... print(i) ... 1 2 3 &gt;&gt;&gt; for i in (1,2,3): ... print(i) ... 1 2 3 &gt;&gt;&gt; 字典遍历1234567891011121314151617181920212223&gt;&gt;&gt; for key in dict.keys():... print(key)...nameage&gt;&gt;&gt; for value in dict.values():... print(value)...liuha29&gt;&gt;&gt; for item in dict.items():... print(item)...('name', 'liuha')('age', 29)&gt;&gt;&gt; for key,value in dict.items():... print('%s=%s' %(key,value))...name=liuhaage=29 enumerate()enumerate(sequence, [start=0]) - 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。 123456789101112131415161718192021222324&gt;&gt;&gt; l = ['a', 'b', 'c']&gt;&gt;&gt; list(enumerate(l))[(0, 'a'), (1, 'b'), (2, 'c')]&gt;&gt;&gt; list(enumerate(l, start=1))[(1, 'a'), (2, 'b'), (3, 'c')]&gt;&gt;&gt; list = ['a', 'b', 'c']&gt;&gt;&gt; for i,ele in enumerate(list):... print('%s=%s' %(i, ele))...0=a1=b2=c# 下标位置从1开始&gt;&gt;&gt; for i,ele in enumerate(list, start=1):... print('%s=%s' %(i, ele))...1=a2=b3=c&gt;&gt;&gt; 公共方法运算符 运算符 Python 表达式 结果 描述 支持的数据类型 + [1, 2] + [3, 4] [1, 2, 3, 4] 合并 字符串、列表、元组 * ‘Hi!’ * 4 [‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’] 复制 字符串、列表、元组 in 3 in (1, 2, 3) True 元素是否存在 字符串、列表、元组、字典 not in 4 not in (1, 2, 3) True 元素是否不存在 字符串、列表、元组、字典 Python函数相关python内置函数 方法 描述 len(item) 计算容器中元素个数 max(item) 返回容器中元素最大值 min(item) 返回容器中元素最小值 del(item) 删除变量 函数参数缺省参数调用函数时，缺省参数的值如果没有传入，则被认为是默认值。 123456# 缺省参数def printInfo(name, age=5): print('name is %s, age is %s' %(name, age))printInfo('liuha', 20)printInfo('liu2') 输出结果为：12name is liuha, age is 20name is liu2, age is 5 注意：带有默认值的参数一定要位于参数列表的最后面。否则会报错：SyntaxError: non-default argument follows default argument 不定长参数有时可能需要一个函数能处理比当初声明时更多的参数。这些参数叫做不定长参数，声明时不会命名。 基本语法如下：123def functionname([formal_args,] *args, **kwargs): function_suite return [expression] 加了 * 的变量 args 会存放所有未命名的变量参数，args 为元组；而加 ** 的变量 kwargs 会存放命名参数，即形如 key=value 的参数， kwargs 为字典。 1234567891011121314# 可变长参数def func_test(a, b=2, *args, **kwargs): print('a = %s' %a) print('b = %s' %b) print('args = ' , args) print('kwargs = ' , kwargs)func_test(1,2,3,4,k1=2,k2=3)print('-'*5)func_test(1,2,3,k1=2,k2=3)print('-'*5)func_test(1,k1=3) 输出：1234567891011121314151617181920212212[1, 2, 3][1, 2, 3]----------name is liuha, age is 20name is liu2, age is 5----------a = 1b = 2args = (3, 4)kwargs = &#123;'k1': 2, 'k2': 3&#125;-----a = 1b = 2args = (3,)kwargs = &#123;'k1': 2, 'k2': 3&#125;-----a = 1b = 2args = ()kwargs = &#123;'k1': 3&#125; 引用传参可变类型与不可变类型的变量分别作为函数参数时，会有什么不同吗？ Python中函数参数是引用传递（注意不是值传递）。对于不可变类型（string，integer，tuple），因变量不能修改，所以运算不会影响到变量自身；而对于可变类型（list，dict），函数体中的运算有可能会更改传入的参数变量。 123456789101112131415# 引用传参def add(a,b=33): a *= 2 b = b * 2a = 1b = 1add(a,b)print('a = ', a)print('b = ', b)a_list = [2,3]b_list = [2,3]add(a_list, b_list)print('a_list = ', a_list)print('b_list = ', b_list) 输出为：12345678a = 1b = 2args = ()kwargs = &#123;'k1': 3&#125;a = 1b = 1a_list = [2, 3, 2, 3]b_list = [2, 3] 注意 a *= 2 和 a = a*2 的不同，对于可变类型，a = a*2 会重新分配一个变量 a，而之前的 a 是不会变的。 匿名函数用 lambda 关键词能创建小型匿名函数。这种函数得名于省略了用 def 声明函数的标准步骤。 lambda 函数的语法只包含一个语句，如下： 1lambda [arg1 [,arg2,.....argn]]:expression lambda 函数能接收任何数量的参数但只能返回一个表达式的值。 匿名函数不能直接调用 print，因为 lambda 需要一个表达式 123&gt;&gt;&gt; sum = lambda a,b : a+b&gt;&gt;&gt; sum(1,2)3 应用场合1234567&gt;&gt;&gt; stus[&#123;'age': 18, 'name': 'zhangsan'&#125;, &#123;'age': 19, 'name': 'lisi'&#125;, &#123;'age': 17, 'name': 'wangwu'&#125;]# 对 dict 按 age 排序&gt;&gt;&gt; stus.sort(key = lambda x : x['age'])&gt;&gt;&gt; stus[&#123;'age': 17, 'name': 'wangwu'&#125;, &#123;'age': 18, 'name': 'zhangsan'&#125;, &#123;'age': 19, 'name': 'lisi'&#125;] Python 异常处理1234567891011121314151617import timetry: f = open('test.txt', 'r') try: while True: content = f.readline() if(len(content) == 0): break time.sleep(2) print(content) except: print('发生异常') finally: f.close() print('关闭文件')except (IOError,NameError) as e: print(e) 当捕获多个异常时，可以把要捕获的异常的名字，放到 except 后，并使用元组的方式仅进行存储 在 try...except... 中也是如此，即如果没有捕获到异常，那么就执行else中的事情 在程序中，如果一个段代码必须要执行，即无论异常是否产生都要执行，那么此时就需要使用 finally。 异常传递 如果 try 嵌套，那么如果里面的 try 没有捕获到这个异常，那么外面的 try 会接收到这个异常，然后进行处理，如果外边的 try 依然没有捕获到，那么再进行传递。 如果一个异常是在一个函数中产生的，例如函数 A ----&gt;函数 B ----&gt;函数 C，而异常是在函数 C 中产生的，那么如果函数 C 中没有对这个异常进行处理，那么这个异常会传递到函数 B 中，如果函数 B 有异常处理那么就会按照函数 B 的处理方式进行执行；如果函数 B 也没有异常处理，那么这个异常会继续传递，以此类推。如果所有的函数都没有处理，那么此时就会进行异常的默认处理，即通常见到的那样。 12345678910111213141516171819202122232425262728# coding=utf-8# 循环的传递def test1(): print("---test1-1---") print(num) print("---test1-2---") def test2(): print("---test2-1---") test1() print("---test2-2---")def test3(): try: print("---test3-1---") test1() print("---test3-2---") except Exception as e: print("出现异常： %s" %e) print("---test3-3---")test3()print("------华丽的分割线-----")test2() 运行结果： 注意观察执行结果图中，当调用 test3 函数时，在 test1 函数内部产生了异常，此异常被传递到 test3 函数中完成了异常处理，而当异常处理完后，并没有返回到函数 test1 中进行执行，而是在函数 test3 中继续执行 模块模块导入模块就好比是工具包，要想使用这个工具包中的工具（就好比函数），就需要导入这个模块。 import在 Python 中用关键字 import 来引入某个模块，形如： 1import module1,mudule2... 通过这种方式引入的时候，调用函数时只能给出函数名，不能给出模块名，但是当两个模块中含有相同名称函数的时候，后面一次引入会覆盖前一次引入。也就是说假如模块 A 中有函数 function()，在模块 B 中也有函数 function()，如果引入 A 中的 function 在先、B 中的 function 在后，那么当调用 function 函数的时候，是去执行模块 B 中的 function 函数。 如果想一次性引入 math 中所有的东西，还可以通过 from math import * 来实现 from…import有时候我们只需要用到模块中的某个函数，只需要引入该函数即可，此时可以用下面方法实现： 1from modname import name1[, name2[, ... nameN]] as通过 as 可以赋予引入的包一个别名： 123&gt;&gt;&gt; import math as m&gt;&gt;&gt; m.sqrt(4)2.0 模块引用顺序当你导入一个模块，Python 解析器对模块位置的搜索顺序是： 当前目录 如果不在当前目录，Python 则搜索在 shell 变量 PYTHONPATH 下的每个目录。 如果都找不到，Python 会察看默认路径。UNIX 下，默认路径一般为 /usr/local/lib/python/ 模块搜索路径存储在 system 模块的 sys.path 变量中。变量里包含当前目录，PYTHONPATH 和由安装过程决定的默认目录。 模块制作自定义模块模块在 Python 中，每个 Python 文件都可以作为一个模块，模块的名字就是文件的名字。 比如有这样一个文件 test.py，在 test.py 中定义了函数 add： 1234# coding=utf-8def add(a, b): return a+b 调用自定义模块那么在其他文件中就可以先 import test，然后通过 test.add(a,b) 来调用了，当然也可以通过 from test import add 来引入。 123&gt;&gt;&gt; import test&gt;&gt;&gt; test.add(2,3)5 测试模块在实际开中，当一个开发人员编写完一个模块后，为了让模块能够在项目中达到想要的效果，这个开发人员会自行在 py 文件中添加一些测试信息，例如： 1234567# coding=utf-8def add(a, b): return a+bresult = add(2, 3)print('int test.py file, 2+3 = %d'%result) test.py 中的测试代码，应该是单独执行 test.py 文件时才应该执行的，不应该是其他的文件中引用而执行。 可以根据 __name__ 变量的结果能够判断出，是直接执行的 python 脚本还是被引入执行的，从而能够有选择性的执行测试代码。 12345678910# coding=utf-8def add(a, b): return a+bprint(__name__)if __name__ == "__main__": result = add(2, 3) print('int test.py file, 2+3 = %d'%result) __all__ 变量python 模块中的 __all__ 属性，可用于模块导入时限制，如：from module import *。 此时被导入模块若定义了 __all__ 属性，则只有 __all__ 内指定的属性、方法、类可被导入。若没定义，则导入模块内的所有公有属性，方法和类。 因此，使用 __all__ 可以隐藏不想被 import 的默认值。 12345678910111213# coding=utf-8__all__ = ["Test", "test1"]class Test(object): def test(self): print('This is test.')def test1(): print('This is test1.')def test2(): print("This is test2.") 测试结果： 1234567891011121314151617&gt;&gt;&gt; from test import *&gt;&gt;&gt; test1()This is test1.&gt;&gt;&gt; t = Test()&gt;&gt;&gt; t.test()This is test.# __all__ 变量中没有 test2 函数，因此无法通过 import * 引入&gt;&gt;&gt; test2()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: name 'test2' is not defined&gt;&gt;&gt; from test import test2&gt;&gt;&gt; test2()This is test2. 模块发布 mymodule 目录如下： 123456789101112.├── setup.py├── suba│ ├── aa.py│ ├── bb.py│ └── __init__.py└── subb ├── cc.py ├── dd.py └── __init__.py2 directories, 7 files 编辑 setup.py 文件： py_modules 需指明所需包含的 py 文件。 12345from distutils.core import setupsetup(name="liuhao", version="1.0", description="liuhao's module", author="liuhao", py_modules=['suba.aa', 'suba.bb', 'subb.cc', 'subb.dd']) 构建模块 1python setup.py build1 构建后的目录结构： 12345678910111213141516171819202122.├── build│ └── lib│ ├── suba│ │ ├── aa.py│ │ ├── bb.py│ │ └── __init__.py│ └── subb│ ├── cc.py│ ├── dd.py│ └── __init__.py├── setup.py├── suba│ ├── aa.py│ ├── bb.py│ └── __init__.py└── subb ├── cc.py ├── dd.py └── __init__.py6 directories, 13 files 生成发布包 1python setup.py sdist 打包后，生成最终发布压缩包 liuhao-1.0.tar.gz，目录结构： 12345678910111213141516171819202122232425.├── build│ └── lib│ ├── suba│ │ ├── aa.py│ │ ├── bb.py│ │ └── __init__.py│ └── subb│ ├── cc.py│ ├── dd.py│ └── __init__.py├── dist│ └── liuhao-1.0.tar.gz├── MANIFEST├── setup.py├── suba│ ├── aa.py│ ├── bb.py│ └── __init__.py└── subb ├── cc.py ├── dd.py └── __init__.py7 directories, 15 files 模块安装和使用 找到模块的压缩包 解压 进入文件夹 执行命令 python setup.py install 如果在 install 的时候，执行目录安装，可以使用 python setup.py install --prefix=安装路径 在程序中，使用 from import 即可完成对安装的模块使用 1from 模块名 import 模块名或者* 列表推导式 基本方式 123456&gt;&gt;&gt; [x for x in range(3)][0, 1, 2]&gt;&gt;&gt; [x for x in range(3,8)][3, 4, 5, 6, 7]&gt;&gt;&gt; [x for x in range(3,8,2)][3, 5, 7] 结合 if 1234&gt;&gt;&gt; [x for x in range(3,10) if x%2 == 0][4, 6, 8]&gt;&gt;&gt; [x for x in range(3,10) if x%3 == 0][3, 6, 9] 多个 for 循环 12&gt;&gt;&gt; [(x,y) for x in range(3) for y in range(4) if x%2 ==0 if y%3 == 0][(0, 0), (0, 3), (2, 0), (2, 3)]]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 编程快速上手]]></title>
    <url>%2FPython-Programming-Quick-Start.html</url>
    <content type="text"><![CDATA[记录学习「Python 编程快速上手」一书的过程，主要涉及正则表达式、文件处理、网络爬虫等。 正则表达式 ?匹配零次或一次前面的分组。 *匹配零次或多次前面的分组。 +匹配一次或多次前面的分组。 {n}匹配 n 次前面的分组。 {n,}匹配 n 次或更多前面的分组。 {,m}匹配零次到 m 次前面的分组。 {n,m}匹配至少 n 次、至多 m 次前面的分组。 {n,m}?或*?或+?对前面的分组进行非贪心匹配。 ^spam 意味着字符串必须以 spam 开始。 spam$意味着字符串必须以 spam 结束。 .匹配所有字符，换行符除外。 \d、\w 和\s 分别匹配数字、单词和空格。 \D、\W 和\S 分别匹配出数字、单词和空格外的所有字符。 [abc]匹配方括号内的任意字符（诸如 a、b 或 c）。 [^abc]匹配不在方括号内的任意字符。 正则表达式的基本使用123456789101112131415161718&gt;&gt;&gt; import re&gt;&gt;&gt; phone = re.compile(r'\d\d\d-\d\d\d-\d\d\d\d')&gt;&gt;&gt; mo = phone.search('My number is 415-555-4242.')&gt;&gt;&gt; mo.group()'415-555-4242'&gt;&gt;&gt;# 使用括号分组&gt;&gt;&gt; phone = re.compile(r'(\d\d\d)-(\d\d\d-\d\d\d\d)')&gt;&gt;&gt; mo = phone.search('My number is 415-555-4242.')&gt;&gt;&gt; mo.group()'415-555-4242'&gt;&gt;&gt; mo.group(1)'415'&gt;&gt;&gt; mo.group(2)'555-4242'&gt;&gt;&gt; mo.groups()('415', '555-4242') findall()findall()不是返回一个 Match 对象，而是返回一个字符串列表1234567&gt;&gt;&gt; phone = re.compile(r'\d\d\d-\d\d\d-\d\d\d\d')&gt;&gt;&gt; mo = phone.search('Cell: 415-555-9999 Work: 212-555-0000')&gt;&gt;&gt; mo.group()'415-555-9999'&gt;&gt;&gt; mo = phone.findall('Cell: 415-555-9999 Work: 212-555-0000')&gt;&gt;&gt; mo['415-555-9999', '212-555-0000'] 读写文件文件路径 os.path在 Windows 上，路径书写使用倒斜杠作为文件夹之间的分隔符。但在 OS X 和Linux 上，使用正斜杠作为它们的路径分隔符。123456789&gt;&gt;&gt; import osWindows下执行&gt;&gt;&gt; os.path.join('usr','bin','test')'usr\\bin\\test'# linux下执行&gt;&gt;&gt; os.path.join('usr','bin','test')'usr/bin/test' 获取当前目录 getcwd()123456789101112131415# 获取当前目录&gt;&gt;&gt; os.getcwd()'/mnt/e/liuhao_data/OneDrive/code/Python'&gt;&gt;&gt;# 切换目录&gt;&gt;&gt; os.chdir('/mnt/e/liuhao_data/OneDrive/')&gt;&gt;&gt; os.getcwd()'/mnt/e/liuhao_data/OneDrive'# 更改的当前工作目录不存在&gt;&gt;&gt; os.chdir('/mnt/e/liuhao_data/OneDrive1/')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;FileNotFoundError: [Errno 2] No such file or directory: '/mnt/e/liuhao_data/OneDrive1/' 创建目录 makedirs()1234&gt;&gt;&gt; os.makedirs('liuhao/test/')&gt;&gt;&gt; os.chdir('/mnt/e/liuhao_data/OneDrive/code/Python/liuhao/test')&gt;&gt;&gt; os.getcwd()'/mnt/e/liuhao_data/OneDrive/code/Python/liuhao/test' os.path()模块 os.path.getsize(path) 返回 path 参数中文件的字节数 os.listdir(path) 返回文件名字符串的列表 查看文件大小和文件夹内容os.path.getsize(path) 将返回 path 参数中文件的字节数。os.listdir(path) 将返回文件名字符串的列表，包含 path 参数中的每个文件想知道这个目录下所有文件的总字节数，就可以同时使用os.path.getsize()和os.listdir()。123456&gt;&gt;&gt; totalSize = 0&gt;&gt;&gt; for file in os.listdir('/mnt/e/liuhao_data/OneDrive/code'):... totalSize += os.path.getsize(os.path.join('/mnt/e/liuhao_data/OneDrive/code', file))...&gt;&gt;&gt; print(totalSize)31180 检查路径有效性 os.path.exists(path) path 参数所指的文件或文件夹存在 os.path.isfile(path) path 参数存在，并且是一个文件 os.path.isdir(path) path 参数存在，并且是一个文件夹1234567891011121314&gt;&gt;&gt; os.path.exists('/mnt/e/liuhao_data/OneDrive/code')True&gt;&gt;&gt; os.path.exists('/mnt/e/liuhao_data/OneDrive/code2')False&gt;&gt;&gt; os.path.isfile('/mnt/e/liuhao_data/OneDrive/code')False&gt;&gt;&gt; os.path.isfile('/mnt/e/liuhao_data/OneDrive/code/xen.py')True&gt;&gt;&gt; os.path.isdir('/mnt/e/liuhao_data/OneDrive/code/xen.py')False&gt;&gt;&gt; os.path.isdir('/mnt/e/liuhao_data/OneDrive/code/')True&gt;&gt;&gt; os.path.isdir('/mnt/e/liuhao_data/OneDrive/code')True 读写文件过程在 Python 中，读写文件有 3 个步骤：1．调用open()函数，返回一个File对象。2．调用File对象的read()或write()方法。3．调用File对象的close()方法，关闭该文件。 打开并读取文件1234567&gt;&gt;&gt; sonnet = open('sonnet29.txt')&gt;&gt;&gt; sonnet.read()"When, in disgrace with fortune and men's eyes,\nI all alone beweep my outcast state,\nAnd trouble deaf heaven with my bootless cries,\nAnd look upon myself and curse my fate,\n"&gt;&gt;&gt; sonnet = open('sonnet29.txt')&gt;&gt;&gt; sonnet.readlines()["When, in disgrace with fortune and men's eyes,\n", 'I all alone beweep my outcast state,\n', 'And trouble deaf heaven with my bootless cries,\n', 'And look upon myself and curse my fate,\n'] 写入文件写模式将覆写原有的文件，从头开始，将&#39;w&#39;作为第二个参数传递给open()，以写模式打开该文件。不同的是，添加模式将在已有文件的末尾添加文本，而不是完全覆写该变量。将&#39;a&#39;作为第二个参数传递给open()，以添加模式打开该文件。1234567891011121314151617&gt;&gt;&gt; sonnet = open('sonnet29.txt', 'w')&gt;&gt;&gt; sonnet.write('test write file.\n')17&gt;&gt;&gt; sonnet.close()&gt;&gt;&gt; sonnet = open('sonnet29.txt')&gt;&gt;&gt; sonnet.read()'test write file.\n'&gt;&gt;&gt; sonnet = open('sonnet29.txt', 'a')&gt;&gt;&gt; sonnet.write('this is line 2.\n')16&gt;&gt;&gt; sonnet.close()&gt;&gt;&gt; sonnet = open('sonnet29.txt')&gt;&gt;&gt; sonnet.read()'test write file.\nthis is line 2.\n' 组织文件shutil 模块复制文件和目录 shutil.copy(sourceFile, destination) 复制文件，返回目标文件名 shutil.copytree(sourceDir, destination) 复制目录，包括它的所有文件和子文件夹，返回目录目录名 12345678910111213141516&gt;&gt;&gt; os.getcwd()'/mnt/e/liuhao_data/OneDrive/code/Python/liuhao'&gt;&gt;&gt; os.listdir()['hello.txt', 'randomQuizGen.py', 'sonnet29.txt', 'test', 'test.t']# 复制文件&gt;&gt;&gt; shutil.copy('hello.txt', 'hello.copy')'hello.copy'&gt;&gt;&gt; os.listdir()['hello.copy', 'hello.txt', 'randomQuizGen.py', 'sonnet29.txt', 'test', 'test.t']# 复制目录&gt;&gt;&gt; shutil.copytree('../liuhao', '../liuhao-bak')'../liuhao-bak'&gt;&gt;&gt; os.listdir('../liuhao-bak')['hello.copy', 'hello.txt', 'randomQuizGen.py', 'sonnet29.txt', 'test', 'test.t'] 文件和目录的移动与重命名 shutil.move(source, destination)如果destination指向一个文件夹，source文件将移动到destination中，并保持原来的文件名。12345678910111213141516171819&gt;&gt;&gt; os.listdir()['hello.copy', 'hello.txt', 'randomQuizGen.py', 'sonnet29.txt', 'test', 'test.t']# 文件重命名&gt;&gt;&gt; shutil.move('hello.copy', 'hello.bak')'hello.bak'&gt;&gt;&gt; os.listdir()['hello.bak', 'hello.txt', 'randomQuizGen.py', 'sonnet29.txt', 'test', 'test.t']# 目录重命名&gt;&gt;&gt; shutil.move('test', 'test-bak')'test-bak'&gt;&gt;&gt; os.listdir()['hello.bak', 'hello.txt', 'randomQuizGen.py', 'sonnet29.txt', 'test-bak', 'test.t']# 文件移动&gt;&gt;&gt; shutil.move('test.t', 'test-bak')'test-bak/test.t'&gt;&gt;&gt; os.listdir()['hello.bak', 'hello.txt', 'randomQuizGen.py', 'sonnet29.txt', 'test-bak'] 永久删除文件和文件夹 os.unlink(path) 删除 path 处的文件 os.rmdir(path) 删除 path 处的文件夹。该文件夹必须为空 shutil.rmtree(path) 递归删除 path 处的文件夹 123456789101112131415# 删除文件&gt;&gt;&gt; os.unlink('hello.bak')&gt;&gt;&gt; os.listdir()['hello.txt', 'randomQuizGen.py', 'sonnet29.txt', 'test-bak']# os.rmdir不能删除非空目录&gt;&gt;&gt; os.rmdir('test-bak')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;OSError: [Errno 39] Directory not empty: 'test-bak'# 递归删除目录&gt;&gt;&gt; shutil.rmtree('test-bak')&gt;&gt;&gt; os.listdir()['hello.txt', 'randomQuizGen.py', 'sonnet29.txt'] 遍历目录树 os.walk()os.walk()函数被传入一个字符串值，即一个文件夹的路径。你可以在一个for循环语句中使用os.walk()函数，遍历目录树，就像使用range()函数遍历一个范围的数字一样。os.walk()在循环的每次迭代中，返回 3 个值：1．当前文件夹名称的字符串。2．当前文件夹中子文件夹的字符串的列表。3．当前文件夹中文件的字符串的列表。 123456import osfor root, dirs, files in os.walk(".", topdown=False): for name in files: print(os.path.join(root, name)) for name in dirs: print(os.path.join(root, name)) 在子目录时，直接操作文件是有问题的，通过打印绝对路径，发现依然是处在当前路径下。需要通过os.path.join(root, name)的方式来获取文件的全路径。123456789import os, re, shutilfilereg = re.compile(r'(.jpg|.pdf)$')for foldername, subfolders, filenames in os.walk('.'): for filename in filenames: if filereg.search(filename) != None: print(os.getcwd()) print(filename) shutil.move(filename, '/mnt/e/liuhao_data/OneDrive/code/Python/') 运行结果：12345678910111213liuhao@liuhao-pc:/mnt/e/liuhao_data/OneDrive/code/Python/liuhao$ python mvfile.pyThe current folder is: .Subfolders: ['test']The current folder is: ./testSubfolders: []/mnt/e/liuhao_data/OneDrive/code/Python/liuhao1.jpgTraceback (most recent call last): File "mvfile.py", line 14, in &lt;module&gt; shutil.move(filename, '/mnt/e/liuhao_data/OneDrive/code/Python/') File "/usr/lib/python3.5/shutil.py", line 536, in move raise Error("Destination path '%s' already exists" % real_dst)shutil.Error: Destination path '/mnt/e/liuhao_data/OneDrive/code/Python/1.jpg' already exists 从 Web 抓取信息 webbrowser：是 Python 自带的，打开浏览器获取指定页面。 requests：从因特网上下载文件和网页。 Beautiful Soup：解析 HTML，即网页编写的格式。 selenium：启动并控制一个 Web 浏览器。selenium能够填写表单，并模拟鼠标在这个浏览器中点击。 webbrowser模块打开URLopen()函数可以启动一个新浏览器，打开指定的 URL。 1234567&gt;&gt;&gt; import webbrowser&gt;&gt;&gt; webbrowser.open('www.baidu.com')True# 在Linux模式下运行，因为没有开启桌面模式，所以没有正常打开&gt;&gt;&gt; webbrowser.open('www.baidu.com')False requests 模块requests.get()requests.get()函数接受一个要下载的 URL 字符串，返回一个Response对象。1234567891011121314&gt;&gt;&gt; import requests&gt;&gt;&gt; response = requests.get('http://www.gutenberg.org/cache/epub/1112/pg1112.txt')&gt;&gt;&gt; response.status_code200&gt;&gt;&gt; len(response.text)178981&gt;&gt;&gt; response.text[:100]'\ufeffThe Project Gutenberg EBook of Romeo and Juliet, by William Shakespeare\r\n\r\nThis eBook is for the us'&gt;&gt;&gt; file = open('baidu.txt', 'wb')&gt;&gt;&gt; for chunk in res.iter_content(100000):... file.write(chunk)...2381&gt;&gt;&gt; file.close() 用 BeautifulSoup 模块解析 HTMLbs4.BeautifulSoup()函数调用时需要一个字符串，其中包含将要解析的 HTML。函数返回一个BeautifulSoup对象。12345&gt;&gt;&gt; import requests,bs4&gt;&gt;&gt; res = requests.get('http://www.gutenberg.org/cache/epub/1112/pg1112.txt')&gt;&gt;&gt; noSoup = bs4.BeautifulSoup(res.text)&gt;&gt;&gt; type(noSoup)&lt;class 'bs4.BeautifulSoup'&gt; 也可以向bs4.BeautifulSoup()传递一个File对象，从硬盘加载一个 HTML 文件。1234&gt;&gt;&gt; file = open('example.html')&gt;&gt;&gt; soup = bs4.BeautifulSoup(file)&gt;&gt;&gt; type(soup)&lt;class 'bs4.BeautifulSoup'&gt; 新建测试html12345678&lt;!-- This is the example.html example file. --&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;The Website Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;Download my &lt;strong&gt;Python&lt;/strong&gt; book from &lt;a href="http://inventwithpython.com"&gt;my website&lt;/a&gt;.&lt;/p&gt;&lt;p class="slogan"&gt;Learn Python the easy way!&lt;/p&gt;&lt;p&gt;By &lt;span id="author"&gt;Al Sweigart&lt;/span&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 用select()方法查找元素 传递给 select()方法的选择器 匹配项 soup.select(&#39;div&#39;) 所有名为&lt;div&gt;的元素 soup.select(&#39;#author&#39;) 带有 id 属性为 author 的元素 soup.select(&#39;.notice&#39;) 所有使用CSS class属性名为 notice 的元素 soup.select(&#39;div span&#39;) 所有在&lt;div&gt;元素之内的&lt;span&gt;元素 soup.select(&#39;div &gt; span&#39;) 所有直接在&lt;div&gt;元素之内的&lt;span&gt;元素，中间没有其他元素 soup.select(&#39;input[name]&#39;) 所有名为&lt;input&gt;，并有一个 name 属性，其值无所谓的元素 soup.select(&#39;input[type=&quot;button&quot;]&#39;) 所有名为&lt;input&gt;，并有一个 type 属性，其值为 button 的元素 select()方法将返回一个Tag对象的列表，这是 Beautiful Soup 表示一个 HTML元素的方式。针对 BeautifulSoup 对象中的 HTML 的每次匹配，列表中都有一个Tag对象。Tag值可以传递给str()函数，显示它们代表的HTML标签。Tag值也可以有attrs属性，它将该 Tag 的所有 HTML 属性作为一个字典。 1234567891011121314151617&gt;&gt;&gt; file = open('example.html')&gt;&gt;&gt; soup = bs4.BeautifulSoup(file.read())&gt;&gt;&gt; elems = soup.select('#author')&gt;&gt;&gt; elems[&lt;span id="author"&gt;Al Sweigart&lt;/span&gt;]&gt;&gt;&gt; type(elems[0])&lt;class 'bs4.element.Tag'&gt;&gt;&gt;&gt; elems[0].getText()'Al Sweigart'&gt;&gt;&gt; elems[0]&lt;span id="author"&gt;Al Sweigart&lt;/span&gt;&gt;&gt;&gt; elems[0].attrs&#123;'id': 'author'&#125;&gt;&gt;&gt; elems = soup.select('.slogan')&gt;&gt;&gt; elems[&lt;p class="slogan"&gt;Learn Python the easy way!&lt;/p&gt;] 通过元素的属性获取数据Tag 对象的 get()方法让我们很容易从元素中获取属性值。向该方法传入一个属性名称的字符串，它将返回该属性的值。123456789101112&gt;&gt;&gt; elems = soup.select('span')&gt;&gt;&gt; elems[&lt;span id="author"&gt;Al Sweigart&lt;/span&gt;]&gt;&gt;&gt; elems = soup.select('span')[0]&gt;&gt;&gt; elems&lt;span id="author"&gt;Al Sweigart&lt;/span&gt;&gt;&gt;&gt; str(elems)'&lt;span id="author"&gt;Al Sweigart&lt;/span&gt;'&gt;&gt;&gt; elems.get('id')'author'&gt;&gt;&gt; elems.attrs&#123;'id': 'author'&#125; 抓取网站示例下载网站http://xkcd.com/所有的漫画，首页有一个Prev按钮，让用户导航到前面的漫画。手工下载每张漫画要花较长的时间，但你可以写一个脚本，在几分钟内完成这件事。代码需要做下列事情： 利用 requests 模块下载页面。 利用 Beautiful Soup 找到页面中漫画图像的 URL。 利用 iter_content()下载漫画图像，并保存到硬盘。 找到前一张漫画的链接 URL，然后重复。打开一个新的文件编辑器窗口，将它保存为 downloadXkcd.py。12345678910111213141516171819202122232425262728293031323334353637383940# --coding=utf-8--#! python3import requests, os, bs4url = 'http://xkcd.com'os.makedirs("xkcd", exist_ok=True)while not url.endswith('#'): # download the page print("Downloading page %s ..." % url) response = requests.get(url) print("the return code : " + str(response.status_code)) soup = bs4.BeautifulSoup(response.text, "lxml") # find the url of the comic image comic = soup.select('#comic img') #获取id属性为comic内的img元素 if comic == []: print('cannot get the comic image') else: imageUrl = url + (comic[0].get('src')) print("downing the image %s..." %imageUrl) response = requests.get(imageUrl) print("the return code : " + str(response.status_code)) # download the image print(os.path.basename(imageUrl)) # save the image to ./xkcd image = open(os.path.join('xkcd', os.path.basename(imageUrl)), 'wb') for i in response.iter_content(1000): image.write(i) image.close() # get the prev button'url prev = soup.select('a[rel="prev"]')[0] # 所有名为`&lt;a&gt;`，并有一个rel属性，其值为prev的元素 url = 'http://xkcd.com' + prev.get('href')print('Done.')]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫闯关 第四关]]></title>
    <url>%2F%E7%88%AC%E8%99%AB%E9%97%AF%E5%85%B3%E7%AC%AC%E5%9B%9B%E5%85%B3.html</url>
    <content type="text"><![CDATA[地址：http://www.heibanke.com/lesson/crawler_ex03/ 本关的难点是从页面解析并拼接出需要的目标密码，理解题目很重要啊~ 另外获取密码的页面加载耗时很长，也需要考虑如何处理。 解题思路首次进入题目页面，同样的跳转到了登录页面： 登录成功后，出现如下页面，发现还是猜密码。 但这次不是试出来的需要找出来，那从哪里找呢？先随便输入个密码 提示密码错误，同时给出了找密码的页面，继续访问： 初步观察，页面的表格中有两列，其中一列是密码的位置，另外一列是密码的值，猜测是将密码的值拼接成一个字符串，但是页面只有13页，每页8个数值，正好100个数，而位置数最大的出现了100，将这100个数放入到dict(location,value)里，然后再对dict的key进行排序，对value进行拼接，不就得到密码了嘛。 然而现实是残酷的，发现密码的位置中存在重复，也就是遍历完13页数据，并不能得到所有的密码值，然后我就猜想是不是对没有出现在页面的位置进行填充0处理，发现还是失败。 在多次试验中，发现每次获取到的密码的位置并不是相同的，也就是页面里的随机的意思，也就是不断的调用查询密码列表页面，总是能够获取到所有密码的值的。 实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# coding=utf-8import requests, bs4# 题目URLurl = 'http://www.heibanke.com/lesson/crawler_ex03/'# 登录URL，获取cookielogin_url = 'http://www.heibanke.com/accounts/login/?next=/lesson/crawler_ex03/'# 获取密码URLpwd_url = 'http://www.heibanke.com/lesson/crawler_ex03/pw_list/'login_data = &#123;'username':'liuhaha', 'password':'123456'&#125;# 获取默认cookieresponse = requests.get(url)if response.status_code == 200: print('Welcome')cookies = response.cookies# 登录 login_data['csrfmiddlewaretoken'] = cookies['csrftoken']login_response = requests.post(login_url, allow_redirects=False, data=login_data, cookies=cookies)if login_response.status_code == 200: print('login sucessfully')# 获取登录成功后的cookiecookies = login_response.cookies# TODO 解析最大页数payload = &#123;&#125;pwd_data = &#123;&#125;i = 0# 通过观察，密码应该有100个数字组成。# 由于每次获取到的密码会有重复，所以不是一次查询完就能获取到所有数字# 这里一直进行查询，直到获取到100个数字while len(pwd_data) &lt; 100: # 因为每一页的密码位置都是随机给出的，其实这里可以不传page参数，一直调用pwd_url也可以获取到全部密码 payload['page'] = i % 13 pwd_url = 'http://www.heibanke.com/lesson/crawler_ex03/pw_list/' print('------------------------') print('loading data from %s?page=%s ...' %(pwd_url, i%13)) pwd_response = requests.get(pwd_url, cookies=cookies, params=payload) soup = bs4.BeautifulSoup(pwd_response.text, "html.parser") # 获取表格 table = soup.select('[class="table table-striped"]') # 解析表格数据，过滤掉表头 temp_data = &#123;&#125; for tr in table[0].find_all('tr')[1:]: tds = tr.find_all('td') # 分别取出password的位置及其对应的数字 pwd_data[int(tds[0].getText())] = tds[1].getText() temp_data[int(tds[0].getText())] = tds[1].getText() # print(temp_data) i = i + 1 print('The load has run %s times and now the pwd_data length is %s' % (i, len(pwd_data))) # print(pwd_data)# print('The length of password is %s.' % len(pwd_data))# 拼接passwordpassword = ''for key in sorted(pwd_data.keys()): password = password + pwd_data[key]print(password)# 重新登录playload = &#123;'username':'liuhaha', 'password':password&#125;playload['csrfmiddlewaretoken'] = cookies['csrftoken']r = requests.post(url, data=playload, cookies=cookies)print(u'执行结果：' + str(r.status_code))if r.status_code == 200: # print(r.text) if u"成功" in r.text: print(u'闯关成功！密码为：' + password) # breakelse: print(u'Failed') # break 最终执行了62次后获取到了全部密码。 多线程版经过上面的程序，发现执行过程比较漫长，另外页面也有提示说网页会慢半拍，实验证明运行一次用时差不多1400s，将近24分钟啊！ &#x1f635; 那么也许需要一个高效率的方法进行解析，多线程？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# coding=utf-8import requests, bs4import threadingimport timedef login(): # 登录URL，获取cookie login_url = 'http://www.heibanke.com/accounts/login/?next=/lesson/crawler_ex03/' login_data = &#123;'username':'liuhaha', 'password':'123456'&#125; # 获取默认cookie response = requests.get(url) if response.status_code == 200: print('Welcome') cookies = response.cookies # 登录 login_data['csrfmiddlewaretoken'] = cookies['csrftoken'] login_response = requests.post(login_url, allow_redirects=False, data=login_data, cookies=cookies) if login_response.status_code == 200: print('login sucessfully') return login_response.cookiesdef getPassword(page): global pwd_data payload['page'] = page print(threading.currentThread().getName() + ', loading %s?page=%s ...' %(pwd_url, page)) pwd_response = requests.get(pwd_url, cookies=cookies, params=payload) soup = bs4.BeautifulSoup(pwd_response.text, "html.parser") pwd_pos = soup.findAll('td', &#123;'title':'password_pos'&#125;) pwd_value = soup.findAll('td', &#123;'title':'password_val'&#125;) for index in range(len(pwd_pos)): pwd_data[int(pwd_pos[index].getText())] = pwd_value[index].getText() print(threading.currentThread().getName() + ', now the pwd_data length is %s' % len(pwd_data)) class MyThread(threading.Thread): def __init__(self, s): threading.Thread.__init__(self) self.s = s def run(self): global pwd_data global count while len(pwd_data) &lt; 100: count += 1 print('The sub-thread has run %s times' % count) getPassword(count % 13) if __name__ == '__main__': start = time.time() payload = &#123;&#125; # 存放密码键值对 pwd_data = &#123;&#125; # 记录运行次数 count = 0 # 题目URL url = 'http://www.heibanke.com/lesson/crawler_ex03/' # 获取密码URL pwd_url = 'http://www.heibanke.com/lesson/crawler_ex03/pw_list/' # 获取登录成功后的cookie cookies = login() threads = [] for i in range(0, 5): # 线程数,可自定义 thread = MyThread(cookies) threads.append(thread) thread.start() # 等待所有线程完成 for thread in threads: thread.join() # 拼接password password = '' for key in sorted(pwd_data.keys()): password = password + pwd_data[key] print(password) # 重新登录 playload = &#123;'username':'liuhaha', 'password':password&#125; playload['csrfmiddlewaretoken'] = cookies['csrftoken'] r = requests.post(url, data=playload, cookies=cookies) print(u'执行结果：' + str(r.status_code)) if r.status_code == 200: # print(r.text) if u"成功" in r.text: print(u'闯关成功！密码为：' + password) print(u'用时 %s s' % (time.time() - start)) # break else: print(u'Failed') 多线程下，也许是网站限制，发现不管设置几个线程，运行时间总是在470s左右，不到8分钟，虽说时间仍然很长，但是比单线程版本已经有了明显提升。 &#x1f62c;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫闯关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫闯关 第三关]]></title>
    <url>%2F%E7%88%AC%E8%99%AB%E9%97%AF%E5%85%B3%E7%AC%AC%E4%B8%89%E5%85%B3.html</url>
    <content type="text"><![CDATA[地址：http://www.heibanke.com/lesson/crawler_ex02/ 本关的难点就是所谓的两层认证，需要获取处理cookie。 刚进入页面时没看懂是怎么玩，以为到这就结束了，抱着试试看的态度注册了下。 注册登录后，发现是一个记账点之类的，网页还没有跳转到题目网页，还不知道怎么玩。 重新从题目地址进入后，发现可以玩了： 使用selenium实现使用selenium实现方式好像不涉及验证之类的问题，因为完全是模拟的人类登录浏览器的过程。1234567891011121314151617181920212223242526272829303132333435363738394041424344# coding=utf-8from selenium import webdriverurl = 'http://www.heibanke.com/lesson/crawler_ex02/'browser = webdriver.Chrome()# browser = webdriver.Firefox()browser.get(url)# 登录username = browser.find_element_by_id('id_username')username.clear()username.send_keys('liuhaha')password = browser.find_element_by_id('id_password')password.clear()password.send_keys('123456')password.submit()# 重新进入问题页面browser.get(url)for i in range(31): username = browser.find_element_by_name('username') username.clear() username.send_keys('liuhaha') password = browser.find_element_by_id('id_password') password.clear() password.send_keys(i) # FireFox下异步，Chrome下同步，submit方法会等待页面加载完成后返回 # password.submit() # 两种浏览器下click()方法都会等到加载完成后返回 browser.find_element_by_id('id_submit').click() returnText = browser.find_element_by_tag_name('h3') print(returnText.text + ', password ' + str(i)) if u"成功" in returnText.text: break browser.back()browser.quit() requests实现实现思路题目中提到了两层保护，是哪两层呢？ 首先，多了账号登陆一层，还有一层是什么呢？重新登陆，打开firebug记录一下整个流程。 值得注意的一点是cookies值会存在两个地方：一个是请求标头，一个是请求正文，两者可能相同可能不同，存在请求正文的是POST请求，因此要在post data中附带上cookie值。 整个访问的详细流程： 浏览器向URL发出GET请求，得到一个302的重定向的响应，响应标头中包含了一个Location字段，告诉浏览器新的访问地址LOGIN_URL。如果之前用同样的浏览器闯过第一关或第二关，此请求的请求标头仍然会带上cookie，但并无实际作用，可忽略。 浏览器从第一步响应结果得到新的地址，并向此地址发出GET请求。响应标头中会set一个cookie，如果之前访问过该网站，那么此cookie会和请求标头的cookie一样。不管怎样，此cookie都将作为以后访问过程中的依据之一。我们将此返回的cookie记录为c1。 浏览器向再向LOGIN_URL发出POST请求，得到一个包含URL的302重定向的响应。除了请求正文中的username和password字段外，请求标头和请求正文中都附带上第二步中的cookie c1，返回的响应标头中附带上了两个新的cookie，其中一个会在下次访问的请求标头中覆盖原来的cookie c1。我们将此返回的cookies记录为c2。 向URL提交POST请求，请求标头附带的是第3步的cookie c2，请求正文是昵称密码和cookie c2的其中一个值。 其中: URL=http://www.heibanke.com/lesson/crawler_ex02/ LOGIN_URL=http://www.heibanke.com/accounts/login/?next=/lesson/crawler_ex02/ 实现代码123456789101112131415161718192021222324252627282930313233343536373839404142# coding=utf-8import requestsurl = 'http://www.heibanke.com/lesson/crawler_ex02/'login_url = 'http://www.heibanke.com/accounts/login'login_data = &#123;'username':'liuhaha', 'password':'123456'&#125;# 获取默认cookieresponse = requests.get(url)if response.status_code == 200: print('Welcome')cookies = response.cookies# 登录 login_data['csrfmiddlewaretoken'] = cookies['csrftoken']login_response = requests.post(login_url, allow_redirects=False, data=login_data, cookies=cookies)if login_response.status_code == 200: print('login sucessfully')# 获取登录成功后的cookiecookies = login_response.cookiesplayload = &#123;'username':'liuhaha', 'password':'1'&#125;playload['csrfmiddlewaretoken'] = cookies['csrftoken']for i in range(31): playload['password'] = i print(u'传入参数为：' + str(playload)) r = requests.post(url, data=playload, cookies=cookies) # print(u'执行结果：' + str(r.status_code)) if r.status_code == 200: if u"成功" in r.text: print(u'闯关成功！密码为：' + str(i)) break else: print(u'Failed') break]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫闯关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫闯关 第二关]]></title>
    <url>%2F%E7%88%AC%E8%99%AB%E9%97%AF%E5%85%B3%E7%AC%AC%E4%BA%8C%E5%85%B3.html</url>
    <content type="text"><![CDATA[题目题目地址访问http://www.heibanke.com/lesson/crawler_ex01/，如图： 使用requests实现12345678910111213141516# coding=utf-8import requestsurl = 'http://www.heibanke.com/lesson/crawler_ex01/'playload = &#123;'username': 'liuhaha', 'password': '1'&#125;for i in range(31): playload['password'] = i print(u'传入参数为：' + str(playload)) r = requests.post(url, data=playload) if u"成功" in r.text: print(u'闯关成功！') break 使用selenium实现环境：Firefox58，Chrome64。 在刚开始使用Firefox调用WebElement的submit()方法后，发现submit()方法没有等到页面重新加载完毕就返回，这就导致我们在查找页面元素时无法找到我们想要的东西。而调用提交按钮的click()方法就一切正常。 Chrome浏览器需要安装ChromeDriver - WebDriver for Chrome，下载解压后，配置到环境变量中。 12345678910111213141516171819202122232425262728293031# coding=utf-8from selenium import webdriverurl = 'http://www.heibanke.com/lesson/crawler_ex01/'# browser = webdriver.Chrome()browser = webdriver.Firefox()browser.get(url)for i in range(31): username = browser.find_element_by_name('username') username.clear() username.send_keys('liuhaha') password = browser.find_element_by_id("id_password") password.clear() password.send_keys(i) # FireFox下异步，Chrome下同步，submit方法会等待页面加载完成后返回 # password.submit() # 两种浏览器下click()方法都会等到加载完成后返回 browser.find_element_by_id('id_submit').click() returnText = browser.find_element_by_tag_name('h3') print(returnText.text + ', password ' + str(i)) if u"成功" in returnText.text: break browser.back()browser.quit()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫闯关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫闯关 第一关]]></title>
    <url>%2F%E7%88%AC%E8%99%AB%E9%97%AF%E5%85%B3%E7%AC%AC%E4%B8%80%E5%85%B3.html</url>
    <content type="text"><![CDATA[题目访问http://www.heibanke.com/lesson/crawler_ex00/，第一关是将页面出现的数字填写到当前url的尾部进行访问，然后会得到一个新的数字，再用它替换url中的尾部数字，这样不断循环往复，直到页面出现成功标识，如下图。 BeautifulSoup实现方式1234567891011121314151617181920212223# coding=utf-8import requests, bs4, reurl = 'http://www.heibanke.com/lesson/crawler_ex00/'while True: # download the page print("forward to page %s ..." % url) response = requests.get(url) print("the return code : " + str(response.status_code)) soup = bs4.BeautifulSoup(response.text, "html.parser") # get the url of the for the next page comic = soup.select('h3') # 获取页面数字 print(comic[0].getText()) number = re.findall("\d+", comic[0].getText()) if number == []: print('The end.') break; else: url = 'http://www.heibanke.com/lesson/crawler_ex00/' + number[0] # 拼接新地址 selenium实现方式selenium 模块让 Python 直接控制浏览器，实际点击链接，填写登录信息，几乎就像是有一个人类用户在与页面交互。与Requests和Beautiful Soup相比，Selenium允许你用高级得多的方式与网页交互。但因为它启动了Web浏览器，假如你只是想从网络上下载一些文件，会有点慢，并且难以在后台运行。 Selenium需要一个驱动程序来连接所选的浏览器，需要下载浏览器对应的webdriver，并配置到系统环境变量。如Firefox的需要下载geckodriver。 浏览器 驱动下载地址 Chrome https://sites.google.com/a/chromium.org/chromedriver/downloads Edge https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/ Firefox https://github.com/mozilla/geckodriver/releases Safari https://webkit.org/blog/6900/webdriver-support-in-safari-10/ 123456789101112131415161718192021222324# coding=utf-8import requests, refrom selenium import webdriverurl = 'http://www.heibanke.com/lesson/crawler_ex00/'browser = webdriver.Firefox()while True: # download the page print("Forward to page %s ..." % url) browser.get(url) elem = browser.find_element_by_tag_name('h3') # get the url of the for the next page print(elem.text) number = re.findall("\d+", elem.text) if number == []: print('The end.') browser.quit() break; else: url = 'http://www.heibanke.com/lesson/crawler_ex00/' + number[0] # 拼接新地址 更多selenium使用方法参见官方文档。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫闯关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sensu相关概念详解]]></title>
    <url>%2FSensu%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E8%AF%A6%E8%A7%A3.html</url>
    <content type="text"><![CDATA[在前文中，我们通过一个实例配置对Sensu有了初步地了解，但是对其中的一些概念只是有一个模糊的印象，本文将对Sensu中的几个重要概念或者说是术语，进行详尽的介绍。 Sensu的设计中涵盖了一些自定义的概念，比如check、event、Handler、Filter等。 CheckCheck是指在客户端运行的可执行程序，用于检测和监控客户端上的各种服务、资源和应用程序的运行状态等，比如监控HTTP的运行状态，或者收集机器的可用内存值。Check实际上是一个可执行的脚本，它的输出数据是STDOUT或者STDERR，并且在执行后会返回一个值来表示所检测内容的状态。通常使用0表示OK，1表示WARNING，2表示CRITICAL，3以及更大的值表示UNKNOWN或其他用户自定义状态。Sensu的check配置和Nagios是相同的，因此Nagios中的Check插件可以直接在Sensu中使用。 根据Check的调度方式不同，可以分为发布/订阅模式，即由服务端来调度和推送check的执行请求，发布/订阅模式下的check则是在服务器端配置，在配置的时候需要为check设置订阅主题。当要执行该check时，服务器会根据订阅主题分发执行请求，所有订阅了相应主题的客户端会收到执行的请求，从而运行check程序。同样的，执行的返回结果也会通过消息队列返回给服务器； 另外一种是Standalone模式，该模式下的check直接在客户端进行配置，不需要服务器端发出执行的请求，可以根据配置的时间间隔在客户端自主执行，每次执行后会将结果通过消息队列返回给服务器。 Check定义参数 参数名称 描述 必填 类型 默认值 示例 type Check类型，standard/metric no String standard &quot;type&quot;: &quot;metric&quot; command 执行的check命令 true（除非配置了extension） String &quot;command&quot;: &quot;check-process.rb -p cron&quot; extension 可以替换command使用，不常用 true（除非配置了command） String &quot;extension&quot;: &quot;system_profile&quot; standalone 是否是standalone模式 false Boolean false &quot;standalone&quot;: true subscribers 订阅者 true（除非配置了standalone） Array &quot;subscribers&quot;: [&quot;test&quot;] publish 是否发布 false Boolean true &quot;publish&quot;: false interval 执行周期 true（除非publish配为false，或者配置了cron） Integer &quot;interval&quot;: 60 cron 执行周期可以配置为cron表达式 true（除非publish配为false，或者配置了interval） String &quot;cron&quot;: &quot;0 0 * * *&quot; timeout 超时时间 false Integer &quot;timeout&quot;: 30 stdin 是否将检查结果写入到进程STDIN false Boolean false &quot;stdin&quot;: true auto_resolve 当Check由CRITICAL或者WARNING切换到OK状态时，是否自动清除之前产生的event，当需要手动清除时可以设置为false时 false Boolean true &quot;auto_resolve&quot;: false force_resolve 强制将event置为解决状态 false Boolean false &quot;force_resolve&quot;: true handle 是否处理Check产生的event false Boolean true &quot;handle&quot;: true handler 用来指定处理Check产生的event的handler的名称 false String &quot;handler&quot;: &quot;file&quot; handlers 可以同时指定多个handler false Array &quot;handlers&quot;: [&quot;file&quot;, &quot;email&quot; truncate_output 是否对output进行截短，对metric类型的check默认为true，其他默认为false false Boolean false &quot;truncate_output&quot;: false truncate_output_length 设置output的最大长度，超过部分会截短 false Integer 255 &quot;truncate_output_length&quot;: 1024 其他高级参数配置可以参考官方文档。 Check配置安装检测插件脚本check-process.rb可以用于检测服务进程是否在运行，可以使用下面的命令在客户端进行安装。 1sensu-install -p process-checks 发布/订阅模式示例在服务端新建文件/etc/sensu/conf.d/check_cron.json，文件内容如下：1234567891011&#123; "checks": &#123; "cron": &#123; "command": "check-process.rb -p cron", "subscribers": [ "test" ], "interval": 60 &#125; &#125;&#125; 该Check会发送到test订阅客户端上运行。在上一篇文章中已经使用了发布/订阅模式，这里基于之前搭建的系统，我们主要来讲下Standalone模式的Check。 Standalone模式示例在客户端新建文件/etc/sensu/conf.d/check_cron.json，文件内容如下：123456789&#123; "checks": &#123; "cron": &#123; "command": "check-process.rb -p cron", "standalone": true, "interval": 60 &#125; &#125;&#125; 通过配置&quot;standalone&quot;: true表明这是一个Standalone模式的Check，该Check会在客户端每60s运行一次。 不像发布/订阅模式，Standalone模式的Check在uchiwa页面是看不到的，只有在Check状态不正常时，在页面才会收到告警。 正常情况下的可以通过client端的日志查看Check的执行过程： 我们将Check中的cron进程修改为一个不存在的进程，再次观察，可以发现uchiwa页面可以收到Check告警信息： 指标采集Check还可以分为两种类型：标准采集standard和指标采集metric。 对于标准类型的check来说，Sensu不会在每次执行后都生成event，而只是在check所返回的结果为非0或者是从非0变为0的时候才会生成event。这样带来的好处是降低了负载，适用于那些只关注于非正常状态，而在正常的状态无需采取措施的监控场景。 指标采集类型的check则会在每次执行后，无论其返回的结果是什么都会生成event。此类型的check一般用于获取监控指标的信息，除了check所返回的状态值，还有一些其它的输出信息可以通过event进行收集，然后返回给Sensu服务器。 之前我们接触的一致都是standard类型的check，比如HTTP状态、cron服务状态的监控等。下面我们来配置一个metric采集的Check。 安装采集插件脚本metrics-cpu.rb用来采集和输出CPU指标，可以在客户端执行如下命令进行安装： 1sensu-install -p cpu-checks Check定义在客户端新建文件/etc/sensu/conf.d/cpu_metrics.json，内容如下：123456789101112&#123; "checks": &#123; "cpu_metrics": &#123; "type": "metric", "command": "metrics-cpu.rb", "interval": 10, "standalone": true, "truncate_output": false, "handler": "debug" &#125; &#125;&#125; 这里采用Standalone模式进行配置，另外参数truncate_output的设置为false的目的是不用截短output。因为指标采集的输出通常较长，默认会对output进行截短。也可以通过&quot;truncate_output_length&quot;: 666设置output的长度。 指标采集结果重启sensu-client服务后，可以在uchiwa页面看到指标采集结果。 Check结果Check结果结果是客户端再check执行完成后推送到Sensu transport中的JSON格式的数据，一般包含如下信息： check定义相关，如command，subscribers，interval，name等，以及check输出 客户端名称 check结果示例 12345678910111213&#123; "client": "client66", "check": &#123; "command": "/usr/lib64/nagios/plugins/check_http -I 127.0.0.1", "handler": "file", "name": "check_http", "issued": 1517317008, "executed": 1517317024, "duration": 0.006, "output": "HTTP OK: HTTP/1.1 200 OK - 289 bytes in 0.001 second response time |time=0.000647s;;;0.000000 size=289B;;;0\n", "status": 0 &#125;&#125; 其中各个字段的含义为： issued - check请求发出的时间 executed - 客户端执行check的时间 duration - 客户端执行check所耗时长 output - check命令的输出 status - check运行的退出状态码 EventSensu使用event来通知所监控内容的状态变化。比如当check执行后返回2，这表示所监控的内容出现了较为严重的问题，那么Sensu会生成event来报告这个问题，event会绑定一个或多个handler来对所报告的问题进行处理。event包含有一些上下文信息，即event data，主要包括执行check的客户端信息和check运行后的结果信息。通常event数据是以JSON格式传递的，以下是一个event的示例：123456789101112131415161718192021222324252627282930313233"event": &#123; "client": &#123; "name": "client66", "address": "192.168.2.196", "subscriptions": ["test", "client:client66"], "version": "1.2.0", "timestamp": 1517148354 &#125;, "check": &#123; "command": "/usr/lib64/nagios/plugins/check_http -I 127.0.0.1", "interval": 10, "subscribers": ["test"], "name": "check_http", "issued": 1517066088, "executed": 1517148355, "duration": 0.005, "output": "connect to address 127.0.0.1 and port 80: 拒绝连接\nHTTP CRITICAL - Unable to open TCP socket\n", "status": 2, "type": "standard", "history": ["2","2"], "total_state_change": 0 &#125;, "occurrences": 33, "occurrences_watermark": 34, "action": "create", "timestamp": 1517066088, "id": "9287299a-cebc-4708-893f-213257d105ca", "last_state_change": 1517065768, "last_ok": 1517065428, "silenced": false, "silenced_by": []&#125; 可以看到，event数据包含了Sensu客户端的基本信息，包括名称、IP等，同时也包含了所执行的check信息，客户端执行了该check并返回了状态值为2，同时输出内容HTTP CRITICAL: HTTP/1.1 503 Service Temporarily Unavailable，可以用来帮助handler对问题进行处理。 Event属性 属性 描述 类型 可取值 默认值 id event的唯一id String 任意的uuid timestamp event的发生时间 Integer action event动作 String create/resolve/flapping create occurrences 已发生次数 Integer 1 check check结果和check相关属性 Hash check.history check的历史退出状态，最多21个 Array client 客户端属性 Hash silenced 是否沉默 Boolean silenced_by 匹配该event的沉默的、条目ID列表 Array HandlerSensu handler用于处理Sensu event，例如发生告警邮件，将采集指标存放到时序数据库等。Handler在check的配置文件中指定，可以同时指定多个handler对event进行处理。Sensu包括以下几种类型的handler： Pipe handler - 最常用，将event数据通过STDIN传递给处理程序； TCP/UDP handler - 将event数据发送给一个远程的socket，如外部API； Transport handler - 将数据发送给Sensu transport（默认为RabbitMQ） Set handler - 用于组成一个event handler集合，使得能够同时管理多个特定类型的event 默认handler当check中没有指定handler时，Sensu会尝试使用default的handler，若没有定义名为default的handler，Sensu会在日志中报错。 handler配置安装插件12wget -O /etc/sensu/plugins/event-file.rb http://sensuapp.org/docs/1.2/files/event-file.rbchmod +x /etc/sensu/plugins/event-file.rb 由于event-file.rb需要Ruby运行环境，因此需要安装相关依赖：1yum install ruby ruby-devel 定义handler这里以pipe类型为例，新增文件/etc/sensu/conf.d/event_file.json，内容如下：12345678910&#123; "handlers": &#123; "file": &#123; "command": "/etc/sensu/plugins/event-file.rb", "type": "pipe", "timeout": 10, "severities": ["critical", "unknown"] &#125; &#125;&#125; TCP/UDP handler示例下面的示例定义了一个TCP handler，会将event数据转发到定义的socket上。123456789101112&#123; "handlers": &#123; "example_tcp_handler": &#123; "type": "tcp", "timeout": 30, "socket": &#123; "host": "10.0.1.99", "port": 4444 &#125; &#125; &#125;&#125; Transport handler示例该handler会将event数据推送到名为example_handler_queue的Sensu transport，其他组件可以通过订阅该消息队列来处理该event。1234567891011&#123; "handlers": &#123; "example_transport_handler": &#123; "type": "transport", "pipe": &#123; "type": "direct", "name": "example_handler_queue" &#125; &#125; &#125;&#125; Set handler示例相当于一个handler的结合，在check中引用时就可以通过notify_all_the_things来引用其中定义的多个handler。123456789101112&#123; "handlers": &#123; "notify_all_the_things": &#123; "type": "set", "handlers": [ "file", "example_tcp_handler", "example_transport_handler" ] &#125; &#125;&#125; handler属性 属性 描述 是否必须 类型 可取值 默认值 type 类型 true String pipe/tcp/udp/transport/set filter 过滤器 false String filters 可以同时配置多个过滤器 false Array severities 定义处理哪个级别的event false Array ok/warning/critical/unknown mutator 转换器 false String timeout 超时时长，只在pipe和tcp中适用 false Integer 10 handle_silenced 是否处理沉默的event false Boolean false handle_flapping 是否处理跃动状态的event false Boolean false command handler的执行命令 true（type==pipe） String FilterSensu Filter用来过滤一些Sensu event。Filter会检查event中的数据和定义的过滤规则是否匹配，然后判断是否将event发送给handler。需要注意的是filter只能针对单个的handler配置有效，在handler set配置中是无效的。 Filter处理流程 Sensu在处理event时，会检查handler的定义文件，在执行handler之前，会先执行该handler配置的filter，若配置了多个filter，会顺序执行； 将filter属性和event数据进行比较； 若filter将event删除了，那么之后就不会有的分析和处理 Filter分类Sensu filter包含两种过滤方式：Inclusive包含和Exclusive排除。 包含式：默认的处理方式，只有符合filter定义的event才会被处理，可以用个参数&quot;negate&quot;: false设置，如果同时使用多个，需要同时满足（x AND y AND z）才会处理 排除式：会过滤掉符合filter定义的event，可以用个参数&quot;negate&quot;: true设置 包含方式指定的是含有相应信息的event才会被发送至handler排除方式则相反，含有指定信息的event会被过滤掉，不会被发送到handler进行处理。值得注意的是，可以同时指定多个filter，此时event需要同时匹配所有指定的filter规则。 Filter示例Filter属性直接比较该filter会匹配数据中包含客户端属性&quot;environment&quot;: &quot;test&quot;的event。123456789101112&#123; "filters": &#123; "production_filter": &#123; "negate": false, "attributes": &#123; "client": &#123; "environment": "test" &#125; &#125; &#125; &#125;&#125; 处理状态改变的event下面定义的filter可以用来匹配状态变化的event，因为在每次event状态改变时，occurrences的数值都会被重置，或者event的action是resolve状态，因为当check结果状态由非0到0时出action会切换到resolve状态。12345678910&#123; "filters": &#123; "state_change_only": &#123; "negate": false, "attributes": &#123; "occurrences": "eval: value == 1 || ':::action:::' == 'resolve'" &#125; &#125; &#125;&#125; 重复event的处理下面的filter用来匹配check时间间隔是60s，并且occurrences!=1，即不是第一次发生（或者发生次数不能被60整除）。需要注意的是这里配置的是一个Exclusive类型的filter，即匹配的将会被过滤。即该过滤器的目的是对check间隔是60s并且在第一次发生时以及每小时进行处理。12345678910111213&#123; "filters": &#123; "filter_interval_60_hourly": &#123; "negate": true, "attributes": &#123; "check": &#123; "interval": 60 &#125;, "occurrences": "eval: value != 1 &amp;&amp; value % 60 != 0" &#125; &#125; &#125;&#125; 还有我们之前用的例子，仅处理出现次数大于5的event：123456789&#123; "filters": &#123; "recurrence": &#123; "attributes": &#123; "occurrences": "eval: value &gt; 5" &#125; &#125; &#125;&#125; 仅处理工作时间的event仅处理周一到周五9点到17点的event。12345678910&#123; "filters": &#123; "nine_to_fiver": &#123; "negate": false, "attributes": &#123; "timestamp": "eval: [1,2,3,4,5].include?(Time.at(value).wday) &amp;&amp; Time.at(value).hour.between?(9,17)" &#125; &#125; &#125;&#125; Filter配置属性 属性 描述 是否必须 类型 默认值 negate 配置是否会移除符合filter的event false Boolean false attributes 用来和event数据比较的属性 true Hash when 何时使用该filter false Hash when使用示例：123456789101112131415161718192021222324252627&#123; "filters": &#123; "offhours": &#123; "attributes": &#123; "client": &#123; "environment": "production" &#125; &#125;, "when": &#123; "days": &#123; "all": [ &#123; "begin": "5:00 PM", "end": "8:00 AM" &#125; ], "friday": [ &#123; "begin": "12:00 PM", "end": "5:00 PM" &#125; ] &#125; &#125; &#125; &#125;&#125; MutatorSensu Mutators用来转换event数据，然后将转换后的数据传递给event handler。通过使用Mutator对event数据进行处理，可以减少重复代码，简化事件处理过程。Mutator在Sensu服务器端执行，从STDIN接收JSON格式的event数据，并将转换后的数据写入STDOUT。Mutator会返回一个退出状态码用于标识转换是否成功。如果Mutator执行失败，事件将不会被handler处理，并且会将错误信息记录到日志中。 Sensu监控处理流程如图所示，Sensu的监控流程如下： Sensu Server或Sensu Client一个Service Check请求 Sensu Client来执行Service Check Service Check会发出状态信息和检测数据作为check结果 Sensu Client将check结果发送到Sensu Transport（如redis, rabbitmq） Sensu Server会对check结果进行处理，并将check的最新结果写入到Data Store，同事创建相应的event Sensu Server会通过Event Handler来处理event 通过Handler上定义的Filter对Handler进行过滤 处理Handler所绑定的Mutator 最终执行Event Handler]]></content>
      <categories>
        <category>运维监控</category>
      </categories>
      <tags>
        <tag>Sensu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sensu快速上手]]></title>
    <url>%2FSensu%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.html</url>
    <content type="text"><![CDATA[本文内容是基于上文的基础上，通过实践的方式来演示sensu的使用，初步接触check、handler、filter的相关配置。 下面将通过一个具体的实例来演示sensu的使用。主要的逻辑是使用 sensu 对节点的HTTP服务状态进行监控，每隔一段时间调用check去检查被监控机器上HTTP服务的状态。此外，我们还添加了将event信息写入文件的handler，传递给handler的event数据会被输出到文件中。最后，通过添加filter设置只有连续发生5次以上的状态才会递交给hanlder进行处理。 配置check 安装插件 定义Check 重启服务端 执行日志 安装handler 配置默认handler 安装 handler 的插件 配置 filter check结果 filter测试 配置checkSensu Check由两部分组成：检测插件和定义Check。Check插件是在客户端运行的可执行文件，Check定义文件主要用于定义何时以及如何运行插件。 Sensu中服务端和客户端都可以进程Check的调度，下面分别对这两种调度方式用实例的方式讲解。 首先我们需要一个检测HTTP服务状态的插件，并配置一个Check定义文件来执行插件，该执行过程将会由服务端调度。 安装插件在客户端安装插件：1yum -y install -y nagios-plugins-http 这里你也许会有疑问，“为什么Sensu中要安装Nagios的插件呢？” 不得不说这是一个好问题，Sensu集成了Nagios检测插件，这意味着Nagios中可以使用的检测插件在Sensu中不用做任何修改即可使用。安装成功后，可以在/usr/lib64/nagios/plugins/check_http中获取到该插件，可以手动运行看下是什么效果。 这里可以看出检测的返回结果是失败的，除此之外，Sensu会使用退出状态值（$?）来标记本次检测的最终结果是OK、WARNING、还是CRITICAL。这里返回状态值的是2，表示CRITICAL状态。 定义Check在服务端的/etc/sensu/conf.d中新建一个check_http.json文件，文件内容如下：123456789&#123; "checks": &#123; "check_http": &#123; "command": "/usr/lib64/nagios/plugins/check_http -I 127.0.0.1", "interval": 10, "subscribers": ["test"] &#125; &#125;&#125; 该文件定义了一个名为check_http的Check，执行周期是10s，订阅了test主题的客户端会收到执行该check的请求。 重启服务端在新增了Check定义文件后，需要重启Service和API来重新加载配置。12service sensu-server restartservice sensu-api restart 在重启后，就可以通过API查看到Check定义已经加载： 执行日志 服务端的执行日志也可以通过服务端的Sensu日志来查看Check的调度： 字样publishing check request表示服务端已经发出来Check请求。 客户端的执行日志 上面的日志可以看出，客户端已经收到Check请求，并且得到了执行，然后将执行结果重新返回到结果队列，以供服务端进程处理。 安装handler在客户端将Check执行结果返回后，服务端需要对结果进行处理。请求的处理可以出发多种形式的事件，本次练习中我们就配置发送邮件警告。 在Check定义文件中可以指定如何处理检查结果，由于我们的定义文件中并没有相关配置，因此会使用默认的handler进行处理。 下面通过服务端的日志来看一下默认的handler是如何处理的： 由于默认的handler没有配置，Check的执行结果实际上会被丢弃。这就意味着我们需要配置一个handler。 配置默认handler创建文件/etc/sensu/conf.d/handler_default.json，内容如下：123456789&#123; "handlers": &#123; "default": &#123; "command": "/etc/sensu/plugins/event-file.rb", "type": "pipe" ,"filter": "recurrence" &#125; &#125;&#125; 或者，不使用默认的配置，为该handler配置一个名称，并在check定义中进行引用： /etc/sensu/conf.d/handler_default.json 123456789&#123; "handlers": &#123; "file": &#123; "command": "/etc/sensu/plugins/event-file.rb", "type": "pipe" ,"filter": "recurrence" &#125; &#125;&#125; /etc/sensu/conf.d/check_http.json 12345678910&#123; "checks": &#123; "check_http": &#123; "command": "/usr/lib64/nagios/plugins/check_http -I 127.0.0.1", "interval": 60, "subscribers": ["test"] ,"handler": "file" &#125; &#125;&#125; 安装 handler 的插件在Sensu服务器端/etc/sensu/plugin/目录下安装handler的插件：event-file.rb：1wget -O /etc/sensu/plugins/event-file.rb http://sensuapp.org/docs/1.2/files/event-file.rb 配置 filter添加一个filter，用于过滤掉重复出现次数小于5的事件。这样可以避免被监控节点上的误报。Filter在handler的配置文件中指定，可以看到，我们通过名称recurrence在my_handler.json中指定了使用该filter，即大于5次时才会交由handler处理。 同样的，在服务器端/etc/sensu/config.d/目录下添加filter配置文件my_filter.json：123456789&#123; "filters": &#123; "recurrence": &#123; "attributes": &#123; "occurrences": "eval: value &gt; 5" &#125; &#125; &#125;&#125; check结果 从上图可以看到，history中连续出现了21个返回值为2，这表示连续21次 check 返回CRITICAL状态，从而通过了filter筛选条件，由hanlder进行处理。 在/tmp目录中也有相应的文件生成，这表明handler成功的处理了event。 filter测试下面把客户端的HTTP服务恢复到正常状态，并将之前handler生成的文件删除，然后再停止HTTP状态，看下filter是如何处理的。 此时页面已经出现警告，通过history可以看出已经出现1次CRITICAL状态。但此时并没有生成文件，这就表明handler没有处理，表示过滤器生效。 当重复次数&gt;5时，文件生成。 参考https://www.ibm.com/developerworks/cn/cloud/library/1607-sensu-monitoring-platform/index.htmlhttps://sensuapp.org/docs/latest/quick-start/learn-sensu-basics.html]]></content>
      <categories>
        <category>运维监控</category>
      </categories>
      <tags>
        <tag>Sensu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sensu简介和安装]]></title>
    <url>%2FSensu%E7%AE%80%E4%BB%8B%E5%92%8C%E5%AE%89%E8%A3%85.html</url>
    <content type="text"><![CDATA[本文主要介绍运维监控软件Sensu，主要包括Sensu的组成，事件处理流程，以及Sensu的安装过程。 Sensu 简介Sensu是由 Sonian 公司开发的一种监控框架，主要用于基础设施和应用的监控和检测。Sensu可以为基础设施、服务、应用运行状况以及业务的监控提供一个框架。Sensu专门设计用于解决现代基础设施平台在规模（即公共，私有和混合云）中混合使用静态，动态和短暂基础设施所带来的监控挑战。 Sensu的优势 可以监控服务器、服务、应用运行状态 可以发送告警和通知 支持客户端的动态注册 基于分布式的设计，能够轻松的动态伸缩规模 支持通过插件的形式自定义检查的内容，拥有丰富的插件库 内置的集成工具，可用于和其它系统集成，如 Graphite、Email等 提供丰富的API接口，支持通过API调用访问事件和客户端信息，触发检测等 Sensu 的组成部分数据传输部分Sensu使用消息总线（如RabbitMQ）来互信通信，Sensu的这种消息总线通信已被抽象为Sensu Transport。Sensu服务需要通过访问Sensu Transport实例（例如RabbitMQ群集）才能运行。Sensu检查请求和Check Results会作为消息发布到Sensu Transport，相应的Sensu服务可以通过订阅的方式来接收这些消息。 数据存储在Sensu体系中，只有Sensu Server、API和dashboard才需要访问数据存储。通过将数据存储在Redis中，Sensu服务本身可以保持无状态。主要存储以下数据： 客户端注册表 Check历史 事件注册表 Stashes（Sensu API提供的一个key-value形式的存储） Check执行调度Sensu可以通过服务端或者客户端来调度Check。服务端通过发布/订阅模型将Check请求发送给客户端，客户端会处理相应的Check，Sensu会确保在相应的系统上执行相应的Check。 监控客户端Sensu客户端提供了以下功能： 动态自助注册 客户订阅（用于监控通过发布/订阅模式配置的Check） 本地Check执行调度 用于监控本地系统、服务 可以接收来自外部服务的信息输入 事件处理器Sensu Server是一个可伸缩的事件处理器，用于处理事件并采取行动。Sensu的事件处理功能包括： 注册和注销客户 处理检查结果 使用filters，mutators，handlers处理监视事件 尽管事件处理程序由Sensu Server在本地执行，但可以运行Sensu Server的多个实例而无需任何其他配置。Sensu提供了内置的任务选择算法以避免Sensu服务器之间的调度冲突，并且Sensu可以通过循环算法将检查结果分发到不同的Sensu Server实例以进行处理，从而实现负载平衡。 RESTful APISensu通过RESTful HTTP JSON API提供对监控数据和核心功能的访问，包括： Clients API - 用于访问client数据，以及添加/删除client Checks API - 用于访问Check配置数据和发布Check请求 Events API - 用于访问event数据和处理event Results API - 用于访问Check Results数据并发布Check Results Aggregates API - 用于访问汇总过的Check Results数据，并可以删除汇总数据 Stashes API - 用于对Redis基础键值功能的读/写 生产过程中Sensu主要由服务端、客户端、RabbitMQ、Redis和API五个部分构成。如图所示，RabbitMQ用于组件之间的通信，Redis用于持久化Sensu服务器和Sensu API的数据。因为客户端都是通过文件进行配置，并且不需要在服务器端配置客户端的信息，所以可以很轻易的增加和减少客户端的数量。从图中可以看到，为了解耦服务器和客户端，通信都是通过RabbitMQ进行的，如果只有单节点的RabbitMQ，这可能会带来通信上的瓶颈问题，不过可以通过RabbitMQ官方提供的集群部署解决方案来解决这个问题。 Sensu 的安装与配置下面介绍针对单节点的情况的安装与配置。安装环境是Centos7。 RabbitMQ 和 Redis 的安装与配置安装 RabbitMQ安装准备 安装 epel 源 1yum -y install epel-release 安装 erlang 1yum -y install erlang 过程较长。 测试是否安装成功 123456[root@centos7 home]# erlErlang R16B03-1 (erts-5.10.4) [source] [64-bit] [async-threads:10] [hipe] [kernel-poll:false]Eshell V5.10.4 (abort with ^G)1&gt; 1+2.3 安装 RabbitMQ这里安装的是最新版本3.6.15，可以通过访问http://www.rabbitmq.com/releases/rabbitmq-server/获取。12rpm --import http://www.rabbitmq.com/rabbitmq-signing-key-public.ascrpm -Uvh http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.15/rabbitmq-server-3.6.15-1.el7.noarch.rpm 验证是否安装成功 12345[root@centos7 home]# service rabbitmq-server statusRedirecting to /bin/systemctl status rabbitmq-server.service● rabbitmq-server.service - RabbitMQ broker Loaded: loaded (/usr/lib/systemd/system/rabbitmq-server.service; disabled; vendor preset: disabled) Active: inactive (dead) 配置 RabbitMQ1234567891011[root@centos7 home]# chkconfig rabbitmq-server on[root@centos7 home]# service rabbitmq-server start[root@centos7 home]# rabbitmqctl add_vhost /sensuCreating vhost "/sensu"[root@centos7 home]# rabbitmqctl add_user sensu secretCreating user "sensu"[root@centos7 home]# rabbitmqctl set_permissions -p /sensu sensu ".*" ".*" ".*"Setting permissions for user "sensu" in vhost "/sensu" 安装 Redis123yum -y install redis/sbin/chkconfig redis onservice redis start Sensu 服务器和客户端的安装与配置Sensu服务器和客户端的安装过程是一致的，都是使用sensu的yum源进行安装。 安装 sensu配置 sensu 的 yum 源1234567# echo '[sensu]name=sensubaseurl=https://sensu.global.ssl.fastly.net/yum/$releasever/$basearch/gpgcheck=0enabled=1' | sudo tee /etc/yum.repos.d/sensu.repo# yum -y install sensu 配置 sensu 服务器端 添加/etc/sensu/conf.d/api.json文件： 123456&#123; "api": &#123; "host": "localhost", "port": 4567 &#125;&#125; 添加redis配置/etc/sensu/conf.d/redis.json 123456&#123; "redis": &#123; "host": "192.168.31.63", "port": 6379 &#125;&#125; 添加rabbitmq配置/etc/sensu/conf.d/rabbitmq.json 123456789&#123; "rabbitmq": &#123; "host": "192.168.31.63", "port": 5672, "vhost": "/sensu", "user": "sensu", "password": "secret" &#125;&#125; 添加开机自启动 12chkconfig sensu-server onchkconfig sensu-api on 配置 sensu 客户端 添加rabbitmq配置/etc/sensu/conf.d/rabbitmq.json 123456789&#123; "rabbitmq": &#123; "host": "192.168.31.63", "port": 5672, "vhost": "/sensu", "user": "sensu", "password": "secret" &#125;&#125; 此外，还需添加描述客户端信息的配置文件，在客户端节点/etc/sensu/conf.d/目录下添加client.json文件：1234567&#123; "client": &#123; "name": "client66", "address": "192.168.31.66", "subscriptions": ["test"] &#125;&#125; 添加开机自启动 1chkconfig sensu-client on Uchiwa 的安装与配置Uchiwa是 sensu 的用户管理界面，主要包含查看客户端和 check 相关信息的功能。下面简要介绍uchiwa的安装与配置。12wget http://dl.bintray.com/palourde/uchiwa/uchiwa-1.1.1-1.x86_64.rpmrpm -Uvh uchiwa-0.10.2-1.x86_64.rpm 配置/etc/sensu/uchiwa.json 文件：12345678910111213&#123; "sensu": [&#123; "name": "sensu31", "host": "192.168.31.63", #API服务IP地址。 "port": 4567, #API服务的端口。 "timeout": 5 &#125;], "uchiwa": &#123; "host": "192.168.31.63", "port": 3000, "interval": 5 &#125;&#125; 启动相关服务并验证是否安装成功123456789101112131415[root@centos7 etc]# service sensu-server startRedirecting to /bin/systemctl start sensu-server.service[root@centos7 etc]# service sensu-server statusRedirecting to /bin/systemctl status sensu-server.service● sensu-server.service - sensu server Loaded: loaded (/usr/lib/systemd/system/sensu-server.service; enabled; vendor preset: disabled) Active: active (running) since 五 2018-01-26 13:59:13 CST; 4s ago Main PID: 15189 (sensu-server)[root@centos7 sensu]# service uchiwa startuchiwa started.[root@centos7 sensu]# service uchiwa statusuchiwa is running 此时，uchiwa页面也可以成功启动访问192.168.31.63:3000： 至此，sensu的简单介绍和安装就完成了，后续结合实践对check、handler和filter等概念进行详细介绍。 参考https://www.ibm.com/developerworks/cn/cloud/library/1607-sensu-monitoring-platform/index.html]]></content>
      <categories>
        <category>运维监控</category>
      </categories>
      <tags>
        <tag>Sensu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ansible学习】- 常用系统模块之service/systemd/ping模块]]></title>
    <url>%2Fansible-system-modules.html</url>
    <content type="text"><![CDATA[service模块简介service模块用于控制远程主机的服务，说白了，就是Linux下的service命令。支持的init系统包括BSD init，OpenRC，SysV，Solaris SMF，systemd，upstart。 模块参数 名称 必选 默认值 可选值 备注 arguments no 如果打开这个标记，backrefs会改变模块的一些操作：insertbefore和insertafter参数会被忽略。当regexp不匹配文件中的任何行时，文件不会做任何修改，否则 使用扩展的line参数 替换 最后一个匹配正则表达式的行 enabled no yes/no 服务是否开机自动启动。enabled和state至少要有一个被定义 name yes 服务名称 pattern no 如果服务没有响应，则ps查看是否具有指定参数的进程，有则认为服务已经启动 sleep no EOF EOF/*regex* 如果服务被重新启动，则睡眠多少秒再执行停止和启动命令 state no started,stopped,restarted,reloaded service最终操作后的状态 示例启动/停止/重启/重载服务123456789101112131415161718192021222324252627[root@centos7 ~]# ansible test -m service -a "name=httpd state=started"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "started", &#125;[root@centos7 ~]# ansible test -m service -a "name=httpd state=stopped"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "stopped", &#125;[root@centos7 ~]# ansible test -m service -a "name=httpd state=restarted"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "started", &#125;[root@centos7 ~]# ansible test -m service -a "name=httpd state=reloaded"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "started", &#125; 设置服务开机自启动1234567[root@centos7 ~]# ansible test -m service -a "name=httpd enabled=yes"192.168.31.66 | SUCCESS =&gt; &#123; "changed": false, "enabled": true, "name": "httpd", 。。。&#125; systemd模块简介systemd模块用于控制远程主机的systemd服务，说白了，就是Linux下的systemd命令。需要远程主机支持systemd。 用法和service模块基本相同。 模块参数 名称 必选 默认值 可选值 备注 daemon_reload no yes/no 在执行任何其他操作之前运行守护进程重新加载，以确保systemd已经读取其他更改 enabled no yes/no 服务是否开机自动启动。enabled和state至少要有一个被定义 masked no yes/no 是否将服务设置为masked状态，被mask的服务是无法启动的 name yes 服务名称 no_block no yes/no 不要同步等待操作请求完成 state no started,stopped,restarted,reloaded service最终操作后的状态 user no yes/no 使用服务的调用者运行systemctl，而不是系统的服务管理者 示例启动/停止/重启/重载服务1234567891011121314151617181920212223242526272829[root@centos7 ~]# ansible test -m systemd -a "name=httpd state=started"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "started", "status": &#123;。。。[root@centos7 ~]# ansible test -m systemd -a "name=httpd state=stopped"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "stopped", "status": &#123;。。。[root@centos7 ~]# ansible test -m systemd -a "name=httpd state=restarted"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "started", "status": &#123;。。。[root@centos7 ~]# ansible test -m systemd -a "name=httpd state=reloaded"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "started", 设置服务masked状态123456789101112131415161718192021222324252627282930313233343536373839# 先将服务停止[root@centos7 python_code]# ansible test -m systemd -a "name=httpd state=stopped"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "stopped", 。。。&#125;[root@centos7 python_code]# ansible test -m systemd -a "name=httpd masked=yes"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd",。。。&#125;# 服务已无法启动[root@centos7 python_code]# ansible test -m systemd -a "name=httpd state=started"192.168.31.66 | FAILED! =&gt; &#123; "changed": false, "msg": "Unable to start service httpd: Failed to start httpd.service: Unit is masked.\n"&#125;# 撤销mask[root@centos7 python_code]# ansible test -m systemd -a "name=httpd masked=no"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", 。。。&#125;# 可以成功启动[root@centos7 python_code]# ansible test -m systemd -a "name=httpd state=started"192.168.31.66 | SUCCESS =&gt; &#123; "changed": true, "name": "httpd", "state": "started", 。。。&#125; ping模块简介用于确认和对象机器之间是否能够ping通，正常情况会返回pong。它在剧本中没有任何意义，但从/usr/bin/ansible可以验证主机是否可以登录。 参数 名称 必选 默认值 可选值 备注 data no pong 数据返回的ping返回值。如果此参数设置为crash ，模块将导致异常。 实例12345678910111213141516171819202122# 默认返回是pong[root@centos7 python_code]# ansible test -m ping192.168.31.66 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125;# 设置返回值是haha[root@centos7 python_code]# ansible test -m ping -a "data=haha"192.168.31.66 | SUCCESS =&gt; &#123; "changed": false, "ping": "haha"&#125;[root@centos7 python_code]# ansible test -m ping -a "data=crash"192.168.31.66 | FAILED! =&gt; &#123; "changed": false, "module_stderr": "Shared connection to 192.168.31.66 closed.\r\n", "module_stdout": "Traceback (most recent call last):\r\n File \"/tmp/ansible_P3uPly/ansible_module_ping.py\", line 82, in &lt;module&gt;\r\n main()\r\n File \"/tmp/ansible_P3uPly/ansible_module_ping.py\", line 72, in main\r\n raise Exception(\"boom\")\r\nException: boom\r\n", "msg": "MODULE FAILURE", "rc": 0&#125; selinux模块简介selinux模块用于配置SELinux状态，需要客户端安装libselinux-python。 参数 名称 必选 默认值 可选值 备注 conf no /etc/selinux/config SELinux配置文件的路径 policy no SELinux所使用的的策略，如targeted。若state不是disabled，该配置是必需的 state yes enforcing,permissive,disabled SELinux的最终状态 实例123456789101112131415161718192021222324252627282930313233[root@centos7 sensu]# ansible test -m selinux -a "state=enforcing policy=targeted" [WARNING]: Reboot is required to set SELinux state to enforcing192.168.2.196 | SUCCESS =&gt; &#123; "changed": true, "configfile": "/etc/selinux/config", "msg": "Config SELinux state changed from 'disabled' to 'enforcing'", "policy": "targeted", "reboot_required": true, "state": "enforcing"&#125;[root@centos7 sensu]# ansible test -m selinux -a "state=permissive policy=targeted" [WARNING]: Reboot is required to set SELinux state to permissive192.168.2.196 | SUCCESS =&gt; &#123; "changed": true, "configfile": "/etc/selinux/config", "msg": "Config SELinux state changed from 'enforcing' to 'permissive'", "policy": "targeted", "reboot_required": true, "state": "permissive"&#125;[root@centos7 sensu]# ansible test -m selinux -a "state=disabled"192.168.2.196 | SUCCESS =&gt; &#123; "changed": true, "configfile": "/etc/selinux/config", "msg": "Config SELinux state changed from 'permissive' to 'disabled'", "policy": "targeted", "reboot_required": false, "state": "disabled"&#125;]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ansible学习】- 常用文件操作模块之lineinfile模块]]></title>
    <url>%2Fansible-files-modules-lineinfile.html</url>
    <content type="text"><![CDATA[简介 该模块用于确保一个特定的行在一个文件中，或者使用一个正则表达式替换一个现有的行。 如果想要改变文件中相似的多行，可以使用replace模块。如果想要插入/更新/删除一个行块，可以使用blockinfile模块。 模块参数 名称 必选 默认值 可选值 备注 backrefs no no yes/no 如果打开这个标记，backrefs会改变模块的一些操作：insertbefore和insertafter参数会被忽略。当regexp不匹配文件中的任何行时，文件不会做任何修改，否则 使用扩展的line参数 替换 最后一个匹配正则表达式的行 backup no no yes/no 用于创建一个包含时间戳信息的备份文件。以便在错误的修改了文件的时候，能够找回原始的文件 create no no yes/no 与state=present一起使用。如果指定了这个参数，当要修改的文件不存在的时候，会创建它。否则会报错。 group no 设置文件/目录的所属组 insertafter no EOF EOF/*regex* 当regexp不匹配文件中的任何行的时候，会将新行插入到其所指定的正则表达式匹配的行中的最后一行的后面。insertafter也支持一个特殊的值：EOF（代表文件的末尾）。若没有匹配的行，那么就会插入EOF insertbefore no BOF/*regex* 当regexp不匹配文件中的任何行的时候，会将line参数所指定的行，插入到insertbefore所指定的正则表达式匹配的行中的最后一行的前面，当insertbefore所指定的正则表达式不匹配任何行时，会插入到文件的末尾，同时insertbefore还可以是一个特殊的值：BOF（代表文件的开始）；否则，会使用line参数所指定的行替换regexp所匹配的行中的最后一行。 line no 要插入或者替换的行。如果设置了backrefs参数，那么line中可以包含位置分组或命名分组，lineinfile模块会使用regexp捕获的分组填充它们 mode no 设置文件权限，模式实际上是八进制数字（如0644），少了前面的零可能会有意想不到的结果。从版本1.8开始，可以将模式指定为符号模式（例如u+rwx或u=rw,g=r,o=r） others no file模块的其他参数可以在这里使用 owner no 设置文件/目录的所属用户 path yes 要修改的文件，也可以使用dest,destfile,name regexp no 用于搜索文件中的每一行的正则表达式。对于state=present，这个正则表达式所匹配的行中的最后一行会被替换；对于state=present，会删除所有匹配的行 state no present present/absent 用于设置 新增或替换一行，还是删除行 unsafe_writes no yes/no 是否以不安全的方式进行，可能导致数据损坏 validate no None 复制前是否检验需要复制目的地的路径 示例文本替换将/etc/selinux/config文件中所有匹配^SELINUX=正则表达式的行中的最后一行使用SELINUX=disabled替换；如果regexp不匹配文件中的任何一行，则将line所指定的行插入到文件的末尾。12345678910111213141516171819202122[root@centos7 templates]# ansible test -m lineinfile -a "path=/etc/selinux/config regexp='^SELINUX=' line='SELINUX=disabled'"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": true, "msg": "line replaced"&#125;# 查看结果[root@centos7 templates]# ansible test -m command -a "cat /etc/selinux/config"172.20.21.121 | SUCCESS | rc=0 &gt;&gt;# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled# SELINUXTYPE= can take one of three two values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection.SELINUXTYPE=targeted 删除行将/tmp/test.sh文件中所有匹配^pwd的行删除12345678910111213141516[root@centos7 templates]# ansible test -m lineinfile -a "path=/tmp/test.sh regexp='^pwd' state=absent"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": true, "found": 3, "msg": "3 line(s) removed"&#125;# 再次运行，没有匹配行[root@centos7 templates]# ansible test -m lineinfile -a "path=/tmp/test.sh regexp='^pwd' state=absent"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": false, "found": 0, "msg": ""&#125; 替换行并设置文件权限123456[root@centos7 ~]# ansible test -m lineinfile -a "path=/etc/hosts regexp='^127.0.0.1' line='127.0.0.1 localhost' owner=root group=root mode=0644"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": true, "msg": "line replaced"&#125; insertafter和insertbefore当文件中没有匹配正则表达式^Listen80的行时，会将Listen 80插入到^#Listen所匹配的最后一行的后面。1234567891011121314[root@centos7 ~]# ansible test -m lineinfile -a "path=/etc/httpd/conf/httpd.conf regexp='^Listen80' insertafter='^#Listen' line='Listen 80'"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": true, "msg": "line added"&#125;# insertbefore的使用方法类似[root@centos7 ~]# ansible test -m lineinfile -a "path=/etc/httpd/conf/httpd.conf regexp='^#Listen80' insertbefore='^Listen 80' line='#Listen 80'"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": true, "msg": "line added"&#125; 为文件新增一行直接在文件中新增一行（如果line不存在则会插入），而不通过正则表达式进行匹配。1234567891011121314[root@centos7 ~]# ansible test -m lineinfile -a "path=/root/test.sh line='liuhao test'"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": true, "msg": "line added"&#125;# 再次执行[root@centos7 ~]# ansible test -m lineinfile -a "path=/root/test.sh line='liuhao test'"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": false, "msg": ""&#125; backrefs用法 backrefs为no时，如果没有匹配，则添加一行line。如果匹配了，则把匹配内容替被换为line内容。 backrefs为yes时，如果没有匹配，则文件保持不变。如果匹配了，把匹配内容替被换为line内容。 123456789101112[root@centos7 ~]# ansible test -m lineinfile -a "path=/root/test.sh line='liuhao test1' regexp='^liuhao' backrefs=yes"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": true, "msg": "line replaced"&#125;[root@centos7 ~]# ansible test -m lineinfile -a "path=/root/test.sh line='liuhao test1' regexp='^liuhao2' backrefs=yes"172.20.21.121 | SUCCESS =&gt; &#123; "backup": "", "changed": false, "msg": ""&#125;]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Codewars每日一题】- Simple Pig Latin]]></title>
    <url>%2FCodewars-Simple-Pig-Latin.html</url>
    <content type="text"><![CDATA[题目题目地址 Move the first letter of each word to the end of it, then add “ay” to the end of the word. Leave punctuation marks untouched. Examples12pig_it('Pig latin is cool') # igPay atinlay siay oolcaypig_it('Hello world !') # elloHay orldWay ! 思路对字符串进程分割，得到一个字符串列表，然后再遍历列表，对每个字符串进行处理。同时考虑字符串的长度不同所需的处理方式不同。 答案我的答案123456789101112131415def pig_it(text): t_list = text.split(" ") r_list = [] for i in range(len(t_list)): if len(t_list[i]) == 1: if i!= len(t_list) - 1: r_list.append(t_list[i] + "ay") else: r_list.append(t_list[i]) else: r_list.append(t_list[i][1:] + t_list[i][0] + "ay") result = "" for x in r_list: result += (x + " ") return result.strip() 最佳答案 最佳实践解法123def pig_it(text): lst = text.split() return ' '.join( [word[1:] + word[:1] + 'ay' if word.isalpha() else word for word in lst]) 用了列表推导式，字符串的相关方法。另外，列表切片超出范围时，不会报错，而是返回空。这样就不再需要判断字符串长度的问题。 知识点string.isalpha()()方法检测字符串是否只由字母组成。 语法 1str.isalpha() 返回值如果字符串至少有一个字符并且所有字符都是字母则返回 True,否则返回 False 实例 123456&gt;&gt;&gt; "123".isalpha()False&gt;&gt;&gt; "abc".isalpha()True&gt;&gt;&gt; "abc!".isalpha()False 类似方法 string.isalnum() - 至少有一个字符并且所有字符都是字母或数字 string.isdecimal() - 只包含十进制数字 string.isdigit() - 只包含数字 string.islower() - 包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是小写 string.isnumeric() - 只包含数字字符 string.isspace() - 只包含空格 string.istitle() - 仅包含以大写字母开头、后面都是小写字母的单词。 string.isupper() - 至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是大写 string.split()方法通过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串 语法1str.split(str="", num=string.count(str)) str – 分隔符，默认为所有的空字符，包括空格、换行(\n)、制表符(\t)等。num – 分割次数。 默认情况下字符串按照各种空白字符分割， 诸如空格、 制表符或换行符。 返回值分割后的字符串列表。 实例 12345678910111213141516&gt;&gt;&gt; spam = "I am liu hao"&gt;&gt;&gt; spam.split()['I', 'am', 'liu', 'hao']&gt;&gt;&gt; spam.split(" ")['I', 'am', '', '', 'liu', '', '', 'hao']&gt;&gt;&gt; "Chris_iven+Chris_jack+Chris_lusy".split("+")['Chris_iven', 'Chris_jack', 'Chris_lusy']&gt;&gt;&gt; "Chris_iven+Chris_jack+Chris_lusy".split("-")['Chris_iven+Chris_jack+Chris_lusy']&gt;&gt;&gt; "Chris_iven+Chris_jack+Chris_lusy".split("_")['Chris', 'iven+Chris', 'jack+Chris', 'lusy']&gt;&gt;&gt; "Chris_iven+Chris_jack+Chris_lusy".split("+",2)['Chris_iven', 'Chris_jack', 'Chris_lusy']&gt;&gt;&gt; "Chris_iven+Chris_jack+Chris_lusy".split("+",1)['Chris_iven', 'Chris_jack+Chris_lusy'] string.join()方法用于将序列中的元素以指定的字符连接生成一个新的字符串。 join()方法是针对一个字符串而调用的，并且传入一个列表值（很容易不小心用其他的方式调用它）。split()方法做的事情正好相反：它针对一个字符串调用，返回一个字符串列表。 语法1str.join(sequence) sequence – 要连接的元素序列 返回值返回通过指定字符连接序列中元素后生成的新字符串。 实例 1234567891011121314&gt;&gt;&gt; str = "-"&gt;&gt;&gt; seq = ('a','b','c')# 会为每一个元素添加一个指定字符，不会再最后的地方添加&gt;&gt;&gt; str.join(seq)'a-b-c'&gt;&gt;&gt; str.join(['1','2','3'])'1-2-3'# 当连接字符串时，会自动将字符串分割&gt;&gt;&gt; str.join("abc")'a-b-c'&gt;&gt;&gt; str.join("abc o o")'a-b-c- -o- -o'&gt;&gt;&gt; str.join("123")'1-2-3']]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>codewars</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ansible学习】- 常用文件操作模块之template模块]]></title>
    <url>%2Fansible-files-modules-template.html</url>
    <content type="text"><![CDATA[简介template模块使用了Jinjia2模版语言，进行文档内变量的替换的模块。 template模块用法和copy模块用法基本一致，它主要用于复制配置文件。可以按需求修改配置文件内容来复制模板到被控主机上。 模版中可以使用如下6个变量： ansible_managed - 包含一个字符串，可用于描述模板名称，主机，模板文件的修改时间和所有者的uid template_host - 包含模板机器的节点名称 template_uid - 所有者的uid template_path - 模版路径 template_fullpath - 模版的绝对路径 template_run_date - 模版呈现的时间 模块参数 名称 必选 默认值 可选值 备注 backup no no yes/no 在覆盖之前将原文件备份，备份文件包含时间戳信息 follow no no yes/no 是否遵循目的机器中的文件系统链接 force no yes yes/no 是否强制执行 group no 设置文件/目录的所属组 mode no 设置文件权限，模式实际上是八进制数字（如0644），少了前面的零可能会有意想不到的结果。从版本1.8开始，可以将模式指定为符号模式（例如u+rwx或u=rw,g=r,o=r） newline_sequence(2.4+) no \n \n,\r,\r\n 指定要用于模板文件的换行符 owner no 设置文件/目录的所属用户 src no Jinja2格式化模板的文件位置 trim_blocks no no yes/no 设置为True，则块之后的第一个换行符被移除 unsafe_writes no yes/no 是否以不安全的方式进行，可能导致数据损坏 validate no None 复制前是否检验需要复制目的地的路径 示例template模块的使用方法和copy模块基本相同，相同之处这里就不再赘述，出门左转可以看之前copy模块的讲解，这里举个例子讲一下template的使用方法。 建立模版vim hello_world.txt.j2： 1Hello "&#123;&#123; dynamic_word &#125;&#125;" 由于Ansible是使用Jinja2来编写template模版的，所以需要使用*.j2为文件后缀 上面的&quot;&quot;代表我们在该template里使用了名为dynamic_word的变量 编写playbook，加入变量vim template_demo.yml： 1234567891011121314---- name: Play the template module hosts: test vars: dynamic_word: "World , liuhao ^_^" tasks: - name: generation the hello_world.txt file template: src: hello_world.txt.j2 dest: /tmp/hello_world.txt mode: 0644 owner: liuhao group: liuhao 在第5行，为dynamic_word变量设了一个预设值 在task 里，我们使用template module，并指定了模版的来源src和目的地dest 执行playbook123456789101112[root@centos7 ~]# ansible-playbook template_demo.yml PLAY [Play the template module] *********************************************************************************************************************TASK [Gathering Facts] ******************************************************************************************************************************ok: [172.20.21.121]TASK [generation the hello_world.txt file] **********************************************************************************************************changed: [172.20.21.121]PLAY RECAP ******************************************************************************************************************************************172.20.21.121 : ok=2 changed=1 unreachable=0 failed=0 获取执行结果123[root@centos7 ~]# ansible test -m command -a "cat /tmp/hello_world.txt"172.20.21.121 | SUCCESS | rc=0 &gt;&gt;Hello "World , liuhao ^_^" 可以发现，之前设置的变量dynamic_word已经被替换。 如果配置了重复的变量比如，这里配置了两个dynamic_word，那么ansible会如何处理呢？123456789101112131415---- name: Play the template module hosts: test vars: dynamic_word: "World , liuhao ^_^" dynamic_word: "Problem?" tasks: - name: generation the hello_world.txt file template: src: hello_world.txt.j2 dest: /tmp/hello_world.txt mode: 0644 owner: liuhao group: liuhao 再次运行发现这里会给出一个警告，但是程序会继续运行，当存在重复的字典值时，会使用最后配置的那个变量。从执行结果也可以看出。12345678910111213141516171819[root@centos7 ~]# ansible-playbook template_demo.yml [WARNING]:While constructing a mapping from /root/template_demo.yml, line 5, column 5, found a duplicate dict key (dynamic_word). Using lastdefined value only.PLAY [Play the template module] *********************************************************************************************************************TASK [Gathering Facts] ******************************************************************************************************************************ok: [172.20.21.121]TASK [generation the hello_world.txt file] **********************************************************************************************************changed: [172.20.21.121]PLAY RECAP ******************************************************************************************************************************************172.20.21.121 : ok=2 changed=1 unreachable=0 failed=0 [root@centos7 ~]# ansible test -m command -a "cat /tmp/hello_world.txt"172.20.21.121 | SUCCESS | rc=0 &gt;&gt;Hello "Problem?" 目标文件的父目录不存在与copy模块类似，若目标文件的父目录不存在时，也会报错，如下示例：12345678910111213141516[root@centos7 ~]# ansible-playbook template_demo.yml [WARNING]: While constructing a mapping from /root/template_demo.yml, line 5, column 5, found a duplicate dict key (dynamic_word). Usinglast defined value only.PLAY [Play the template module] **************************************************************************************************************TASK [Gathering Facts] ***********************************************************************************************************************ok: [172.20.21.121]TASK [generation the hello_world.txt file] ***************************************************************************************************fatal: [172.20.21.121]: FAILED! =&gt; &#123;"changed": false, "checksum": "c871758134bd7d3cd7d718ee65ed459b6ca2f0f1", "msg": "Destination directory /tmp/hello does not exist"&#125; to retry, use: --limit @/root/template_demo.retryPLAY RECAP ***********************************************************************************************************************************172.20.21.121 : ok=1 changed=0 unreachable=0 failed=1 这里只是先简单讲述template模块的使用方法，后续讲解playbook编写时还会再接触。]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ansible学习】- 常用文件操作模块之file模块]]></title>
    <url>%2Fansible-files-modules-file.html</url>
    <content type="text"><![CDATA[简介file模块，文件属性模块，主要用于设置已存在文件、符号链接或者目录的属性，或删除文件/符号链接/目录。 模块参数 名称 必选 默认值 可选值 备注 follow no no yes/no 是否遵循目的机器中的文件系统链接 force no yes yes/no 强制执行 group no 设置文件/目录的所属组 mode no 设置文件权限，模式实际上是八进制数字（如0644），少了前面的零可能会有意想不到的结果。从版本1.8开始，可以将模式指定为符号模式（例如u+rwx或u=rw,g=r,o=r） owner no 设置文件/目录的所属用户 path yes 目标文件/目录，也可以用dest,name代替 recurse no no yes/no 是否递归设置属性（仅适用于state=directory） src no 要链接到的文件路径（仅适用于state=link） state no file file/link/directory/hard/touch/absent 若果是directory，所有的子目录将被创建（如果它们不存在）；若是file，文件将不会被创建（如果文件不存在）；link表示符号链接；若是absent，目录或文件会被递归删除；touch代表生成一个空文件；hard代表硬链接； unsafe_writes no yes/no 是否以不安全的方式进行，可能导致数据损坏 示例设置文件权限 - owner\group\mode12345678910111213[root@centos7 ~]# ansible test -m file -a "path=/root/test.sh owner=liuhao group=liuhao mode=0777"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "gid": 1000, "group": "liuhao", "mode": "0777", "owner": "liuhao", "path": "/root/test.sh", "secontext": "unconfined_u:object_r:admin_home_t:s0", "size": 23, "state": "file", "uid": 1000&#125; 创建空文件 - state=touch12345678910111213[root@centos7 ~]# ansible test -m file -a "path=/tmp/liuhao_testfile state=touch mode=0644"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "dest": "/tmp/liuhao_testfile", "gid": 0, "group": "root", "mode": "0644", "owner": "root", "secontext": "unconfined_u:object_r:user_tmp_t:s0", "size": 0, "state": "file", "uid": 0&#125; 创建目录 - state=directory目录是递归创建的12345678910111213[root@centos7 ~]# ansible test -m file -a "path=/tmp/liuhao/test/2018 state=directory mode=0644"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "gid": 0, "group": "root", "mode": "0644", "owner": "root", "path": "/tmp/liuhao/test/2018", "secontext": "unconfined_u:object_r:user_tmp_t:s0", "size": 6, "state": "directory", "uid": 0&#125; 目标文件不存在state=file时会报错，但是state=absent不会报错，执行状态也不会变化。12345678910111213[root@centos7 ~]# ansible test -m file -a "path=/tmp/liuhao/test/2018/1 state=file mode=0644"172.20.21.121 | FAILED! =&gt; &#123; "changed": false, "msg": "file (/tmp/liuhao/test/2018/1) is absent, cannot continue", "path": "/tmp/liuhao/test/2018/1", "state": "absent"&#125;[root@centos7 ~]# ansible test -m file -a "path=/tmp/liuhao/test/2018/1 state=absent mode=0644"172.20.21.121 | SUCCESS =&gt; &#123; "changed": false, "path": "/tmp/liuhao/test/2018/1", "state": "absent"&#125; 删除文件或者目录 - state=absent12345678910111213[root@centos7 ~]# ansible test -m file -a "path=/tmp/liuhao state=absent"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "path": "/tmp/liuhao", "state": "absent"&#125;[root@centos7 ~]# ansible test -m file -a "path=/tmp/liuhao_testfile state=absent"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "path": "/tmp/liuhao_testfile", "state": "absent"&#125;]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible常用模块汇总]]></title>
    <url>%2Fansible-modules.html</url>
    <content type="text"><![CDATA[Ansible命令相关模块之command, shell, raw模块 Ansible命令相关模块之expect, script, telnet模块 Ansible常用文件操作模块之copy模块 Ansible常用文件操作模块之file模块 Ansible常用文件操作模块之template模块 Ansible常用系统模块之service/systemd/ping模块]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ansible学习】- 常用文件操作模块之copy模块]]></title>
    <url>%2Fansible-files-modules-copy.html</url>
    <content type="text"><![CDATA[简介 copy模块用于将本地或远程机器上的文件拷贝到远程主机上。 模块参数 名称 必选 默认值 可选值 备注 backup no no yes/no 在覆盖之前将原文件备份，备份文件包含时间信息 content no 当用content代替src参数的时候，可以把文档的内容设置到特定的值 dest yes 目标绝对路径。如果src是一个目录，dest也必须是一个目录。如果dest是不存在的路径，并且如果dest以/结尾或者src是目录，则dest被创建。如果src和dest是文件，如果dest的父目录不存在，任务将失败 follow no no yes/no 是否遵循目的机器中的文件系统链接 force no yes yes/no 当内容不同于源时，将替换远程文件。设置为no，则只有在目标不存在的情况下才会传输文件 group no 设置文件/目录的所属组，将被馈送到chown local_follow no yes yes/no 是否遵循本地机器中的文件系统链接 mode no 设置文件权限，模式实际上是八进制数字（如0644），少了前面的零可能会有意想不到的结果。从版本1.8开始，可以将模式指定为符号模式（例如u+rwx或u=rw,g=r,o=r） owner no 设置文件/目录的所属用户，将被馈送到chown remote_src(2.0+) no no yes/no 如果yes它会从目标机上搜索src文件 src no 将本地路径复制到远程服务器; 可以是绝对路径或相对的。如果是一个目录，它将被递归地复制。如果路径以/结尾，则只有该目录下内容被复制到目的地，如果没有使用/来结尾，则包含目录在内的整个内容全部复制 unsafe_writes no yes/no 是否以不安全的方式进行，可能导致数据损坏 validate no None 复制前是否检验需要复制目的地的路径 示例拷贝前备份 - backup1234567891011121314151617[root@centos7 ~]# ansible test -m copy -a "src=test.sh backup=yes dest=/root"172.20.21.121 | SUCCESS =&gt; &#123; "backup_file": "/root/test.sh.4315.2018-01-12@13:35:35~", "changed": true, "checksum": "e989084b3f4610a41811c5ea280b14f7c5e855f5", "dest": "/root/test.sh", "gid": 0, "group": "root", "md5sum": "7c211ce4c7941a5bb064e77d69e3d9ff", "mode": "0755", "owner": "root", "secontext": "unconfined_u:object_r:admin_home_t:s0", "size": 23, "src": "/root/.ansible/tmp/ansible-tmp-1515735334.86-21848883747071/source", "state": "file", "uid": 0&#125; src和dest都是文件若dest的文件的父目录不存在将报错12345678910111213141516171819202122[root@centos7 ~]# ansible test -m copy -a "src=test.sh dest=/root/liuhao/test"172.20.21.121 | FAILED! =&gt; &#123; "changed": false, "checksum": "e989084b3f4610a41811c5ea280b14f7c5e855f5", "msg": "Destination directory /root/liuhao does not exist"&#125;[root@centos7 ~]# ansible test -m copy -a "src=test.sh dest=/root/liuhao/"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "checksum": "e989084b3f4610a41811c5ea280b14f7c5e855f5", "dest": "/root/liuhao/test.sh", "gid": 0, "group": "root", "md5sum": "7c211ce4c7941a5bb064e77d69e3d9ff", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:admin_home_t:s0", "size": 23, "src": "/root/.ansible/tmp/ansible-tmp-1515736119.26-238832413210409/source", "state": "file", "uid": 0&#125; 设置文件权限 - owner\group\mode12345678910111213141516[root@centos7 ~]# ansible test -m copy -a "src=test.sh dest=/root dest=/tmp owner=liuhao group=liuhao mode=0644"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "checksum": "e989084b3f4610a41811c5ea280b14f7c5e855f5", "dest": "/tmp/test.sh", "gid": 1000, "group": "liuhao", "md5sum": "7c211ce4c7941a5bb064e77d69e3d9ff", "mode": "0644", "owner": "liuhao", "secontext": "unconfined_u:object_r:admin_home_t:s0", "size": 23, "src": "/root/.ansible/tmp/ansible-tmp-1515735466.22-33633697447932/source", "state": "file", "uid": 1000&#125; content参数12345678910111213141516[root@centos7 ~]# ansible test -m copy -a "content='liuhao \n test\n' dest=/root/liuhaotest"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "checksum": "bd3aa5bf19112271f30c07be425f9a5c08463568", "dest": "/root/liuhaotest", "gid": 0, "group": "root", "md5sum": "7585dc638fd8e219c453c3b1330c7e14", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:admin_home_t:s0", "size": 14, "src": "/root/.ansible/tmp/ansible-tmp-1515735713.37-60072089981042/source", "state": "file", "uid": 0&#125; force参数123456[root@centos7 ~]# ansible test -m copy -a "src=test.sh dest=/root/liuhaotest force=no"172.20.21.121 | SUCCESS =&gt; &#123; "changed": false, "dest": "/root/liuhaotest", "src": "/root/test.sh"&#125; src是目录时源目录以/结尾，只拷贝了目录下的内容：12345678910111213141516[root@centos7 test]# ansible test -m copy -a "src=/root/test/ dest=/tmp/"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "checksum": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "dest": "/tmp/1", "gid": 0, "group": "root", "md5sum": "d41d8cd98f00b204e9800998ecf8427e", "mode": "0644", "owner": "root", "secontext": "unconfined_u:object_r:admin_home_t:s0", "size": 0, "src": "/root/.ansible/tmp/ansible-tmp-1515736521.16-258766767883601/source", "state": "file", "uid": 0&#125; 源目录未以/结尾，直接将src目录本身拷贝到目的地：12345678910111213141516[root@centos7 test]# ansible test -m copy -a "src=/root/test dest=/tmp/"172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "checksum": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "dest": "/tmp/test/1", "gid": 0, "group": "root", "md5sum": "d41d8cd98f00b204e9800998ecf8427e", "mode": "0644", "owner": "root", "secontext": "unconfined_u:object_r:admin_home_t:s0", "size": 0, "src": "/root/.ansible/tmp/ansible-tmp-1515736532.2-82893359525841/source", "state": "file", "uid": 0&#125;]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ansible学习】- 命令相关模块之command, shell, raw模块]]></title>
    <url>%2Fansible-commands-modules-command-shell-raw.html</url>
    <content type="text"><![CDATA[本文主要介绍Ansible的几个命令模块，包括： command - 在远程节点上执行命令 shell - 让远程主机在shell进程下执行命令 raw - 执行低级的和脏的SSH命令 command模块简介 command模块用于在给的的节点上运行系统命令，比如echo hello。 它不会通过shell处理命令，因此不支持像$HOME这样的变量和，以及&lt;, &gt;, |, ;和&amp;等都是无效的。也就是在command模块中无法使用管道符。 模块参数 名称 必选 备注 chdir no 运行command命令前先cd到这个目录 creates no 如果这个参数对应的文件存在，就不运行command free_form yes 需要执行的脚本（没有真正的参数为free_form） executable no 改变用来执行命令的shell，应该是可执行文件的绝对路径。 removes no 如果这个参数对应的文件不存在，就不运行command，与creates参数的作用相反 stdin(2.4后新增) no 将命令的stdin设置为指定的值 示例 列出指定目录下的文件12345678910111213[root@centos7 ~]# ansible test -m command -a "ls /root"172.20.21.120 | SUCCESS | rc=0 &gt;&gt;anaconda-ks.cfgtest.shwhoami.rst[root@centos7 ~]# ansible test -m command -a "ls /root creates=test.sh"172.20.21.120 | SUCCESS | rc=0 &gt;&gt;skipped, since test.sh exists[root@centos7 ~]# ansible test -m command -a "ls /root removes=test.sh1"172.20.21.120 | SUCCESS | rc=0 &gt;&gt;skipped, since test.sh1 does not exist 在这个里面，首先更换目录到root目录中，然后查看test.sh是否存在，如果存在，那么命令不会执行；如果不存在，那么执行命令。 在这里也可以看到，命令是必须存在的，但是没有参数名为free_form参数。 切换目录执行命令 123456789[root@centos7 ~]# ansible test -m command -a "cat test.sh chdir=/root"172.20.21.120 | SUCCESS | rc=0 &gt;&gt;#!/bin/bashi=0echo $((i+1))[root@centos7 ~]# ansible test -m command -a "sh test.sh chdir=/root"172.20.21.120 | SUCCESS | rc=0 &gt;&gt;1 无法使用管道符 12345678[root@centos7 ~]# ansible test -m command -a "ls /root | grep test"172.20.21.120 | FAILED | rc=2 &gt;&gt;/root:anaconda-ks.cfgtest.shwhoami.rstls: 无法访问|: 没有那个文件或目录ls: 无法访问grep: 没有那个文件或目录ls: 无法访问test: 没有那个文件或目录non-zero return code 注意事项 若要通过shell运行一个命令，比如&lt;, &gt;, |等，你实际上需要shell模块。 command模块更安全，因为它不受用户环境的影响 从版本2.4开始，executable参数被删除。如果您需要此参数，请改用shell模块。 对于Windows节点，请改用win_command模块。 shell模块简介让远程主机在shell进程下执行命令，从而支持shell的特性，如管道等。与command模块几乎相同，但在执行命令的时候使用的是/bin/sh。 模块参数 名称 必选 备注 chdir no 运行command命令前先cd到这个目录 creates no 如果这个参数对应的文件存在，就不运行command executable no 改变用来执行命令的shell，应该是可执行文件的绝对路径。 free_form yes 需要执行的脚本（没有真正的参数为free_form） removes no 如果这个参数对应的文件不存在，就不运行command，与creates参数的作用相反 stdin(2.4后新增) no 将命令的stdin设置为指定的值 示例 切换目录，执行命令并保持输出1234567[root@centos7 ~]# ansible test -m shell -a "sh test.sh &gt; result chdir=/root"172.20.21.120 | SUCCESS | rc=0 &gt;&gt;[root@centos7 ~]# ansible test -m shell -a "cat result chdir=/root"172.20.21.120 | SUCCESS | rc=0 &gt;&gt;1 注意事项 如果你想安全可靠的执行命令，请使用command模块，这也是编写playbook的最佳实践。 raw模块简介 raw模块主要用于执行一些低级的，脏的SSH命令，而不是通过command模块。 raw模块只适用于下列两种场景，第一种情况是在较老的（Python 2.4和之前的版本）主机上，另一种情况是对任何没有安装Python的设备（如路由器）。 在任何其他情况下，使用shell或command模块更为合适。 就像script模块一样，raw模块不需要远程系统上的python 模块参数 名称 必选 备注 executable no 改变用来执行命令的shell，应该是可执行文件的绝对路径。 free_form yes 需要执行的脚本（没有真正的参数为free_form） 示例 在远程主机上执行脚本1234[root@centos7 ~]# ansible test -m raw -a "pwd"172.20.21.120 | SUCCESS | rc=0 &gt;&gt;/rootShared connection to 172.20.21.120 closed. 注意事项 如果要安全可靠地执行命令，最好使用shell或command模块来代替。 如果从playbook中使用raw，则可能需要使用gather_facts: no禁用事实收集]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ansible学习】- 命令相关模块之expect, script, telnet模块]]></title>
    <url>%2Fansible-commands-modules-others.html</url>
    <content type="text"><![CDATA[本文主要介绍Ansible的几个命令模块，包括： script - 将本地script传送到远程主机之后执行 expect - 执行命令并响应提示 telnet - 执行低级的和脏的telnet命令 script模块简介 script模块的作用是将本地script传送到远程主机之后执行 给定的脚本将通过远程节点上的shell环境进行处理 script模块在远程系统上不需要python的支持 模块参数 名称 必选 默认值 可选值 备注 chdir(2.4后新增) no 运行command命令前先cd到这个目录 creates no 如果这个参数对应的文件存在，就不运行command decrypt no yes yes/no 此选项控制使用保管库的源文件的自动解密 free_form yes 需要执行脚本的本地文件路径（没有真正的参数为free_form） removes no 如果这个参数对应的文件不存在，就不运行command，与creates参数的作用相反 示例 在远程主机上执行脚本12345678910[root@centos7 ~]# ansible test -m script -a "test.sh chdir=/tmp"172.20.21.120 | SUCCESS =&gt; &#123; "changed": true, "rc": 0, "stderr": "Shared connection to 172.20.21.120 closed.\r\n", "stdout": "/tmp\r\n", "stdout_lines": [ "/tmp" ]&#125; 注意事项 通常来说，使用Ansible模块比推送脚本更好 当脚本执行时，ssh连接插件将通过-tt强制伪tty分配。伪ttys没有stderr通道，所有stderr被发送到标准输出。如果需要标准输出和标准错误分离，请使用到copy模块。 expect模块（预览版）简介 expect模块用于在给的的节点上执行一个命令并响应提示。 它不会通过shell处理命令，因此不支持像$HOME这样的变量和，以及&lt;, &gt;, |, ;和&amp;等都是无效的。也就是在command模块中无法使用管道符。 使用要求（在执行模块的主机上） python &gt;= 2.6 pexpect &gt;= 3.3 模块参数 名称 必选 默认值 备注 chdir no 运行command命令前先cd到这个目录 command yes 命令模块执行命令运行 echo no 是否回显你的回应字符串 responses yes 期望的字符串/正则表达式和字符串的映射来响应。 如果响应是一个列表，则连续的匹配将返回连续的响应。 列表功能是2.1中的新功能。 creates no 如果这个参数对应的文件存在，就不运行command removes no 如果这个参数对应的文件不存在，就不运行command，与creates参数的作用相反 timeout no 30 以秒为单位等待预期时间 示例 在远程主机上执行脚本1234567891011121314- name: Case insensitve password string match expect: command: passwd username responses: (?i)password: "MySekretPa$$word"- name: Generic question with multiple different responses expect: command: /path/to/custom/command responses: Question: - response1 - response2 - response3 注意事项 如果你想通过shell运行一个命令（比如你正在使用&lt;,&gt;,|等），你必须在命令中指定一个shell，比如/bin/bash -c &quot;/path/to/something | grep else&quot;。 在responses下关键是一个python正则表达式匹配，不区分大小写的搜索用前缀?i。 默认情况下，如果多次遇到问题，则会重复其字符串响应。 如果连续问题匹配需要不同的响应，而不是字符串响应，请使用字符串列表作为响应。 expect模块设计用于简单场景，对于更复杂的需求，应该考虑在shell或script模块中使用expect代码 telnet模块（预览版）简介 expect模块用于执行一些低级的和脏telnet命令，不通过模块子系统。 它不会通过shell处理命令，因此不支持像$HOME这样的变量和，以及&lt;, &gt;, |, ;和&amp;等都是无效的。也就是在command模块中无法使用管道符。 模块参数 名称 必选 默认值 备注 command yes 在telnet会话中执行的命令 host no remote_addr 要执行命令的主机/目标 password yes 登录密码 pause no 1 每发出一个命令之间的暂停秒 port no 23 远程端口 prompts no [u&#39;$&#39;] 发送下一个命令之前预期的提示列表 timeout no 30 远程操作超时时间 user no remote_user 登录用户 示例 在远程主机上执行脚本12345678910111213141516171819202122- name: send configuration commands to IOS telnet: user: cisco password: cisco login_prompt: "Username: " prompts: - "[&gt;|#]" command: - terminal length 0 - configure terminal - hostname ios01- name: run show commands telnet: user: cisco password: cisco login_prompt: "Username: " prompts: - "[&gt;|#]" command: - terminal length 0 - show version 注意事项 如果你想通过shell运行一个命令（比如你正在使用&lt;,&gt;,|等），你必须在命令中指定一个shell，比如/bin/bash -c &quot;/path/to/something | grep else&quot;。 在responses下关键是一个python正则表达式匹配，不区分大小写的搜索用前缀?i。 默认情况下，如果多次遇到问题，则会重复其字符串响应。 如果连续问题匹配需要不同的响应，而不是字符串响应，请使用字符串列表作为响应。 expect模块设计用于简单场景，对于更复杂的需求，应该考虑在shell或script模块中使用expect代码]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Codewars每日一题】- Sort the odd]]></title>
    <url>%2FCodewars-Sort-the-odd.html</url>
    <content type="text"><![CDATA[题目题目地址 You have an array of numbers.Your task is to sort ascending odd numbers but even numbers must be on their places. Zero isn’t an odd number and you don’t need to move it. If you have an empty array, you need to return it. Examples1sortArray([5, 3, 2, 8, 1, 4]) == [1, 3, 2, 8, 5, 4] 思路题目的含义是对一个list中的奇数进行排序，而偶数保持顺序不变。 首先想到的思路是将list转换成map，其中key就是list的index，然后筛选出所有value是奇数的，对其排序处理。 或者遍历list，将所有奇数赋值给另外一个列表odd_list，并将原来的位置的数值设置为一个标记。然后对odd_list排序，在放入到原list。 答案我的答案12345678910111213141516def sort_array(source_array): odd_list = [] for i in range(len(source_array)): if source_array[i] % 2 != 0: odd_list.append(source_array[i]) source_array[i] = True list.sort(odd_list) index = 0 for i in range(len(source_array)): if source_array[i] == True: source_array[i] = odd_list[index] index += 1 return source_array 最佳答案 最佳实践解法123def sort_array(arr): odds = sorted((x for x in arr if x%2 != 0), reverse=True) return [x if x%2==0 else odds.pop() for x in arr] 最佳答案的思路跟我的思路是一样的，只是实现方式更加简洁。同样时先筛选出奇数列表，对其排序，然后再遍历原列表，将排过序的数据放置回。 知识点列表推导式列表推导式（list comprehension）是利用其他列表创建新列表（类似于数学术语中的集合推导式）的一种方法。它的工作方式类似于for循环，也很简单。 123456789101112131415161718&gt;&gt;&gt; squares = [x**2 for x in range(10)]&gt;&gt;&gt; squares# 获取可以被3整除的&gt;&gt;&gt; numbers = [x for x in range(20) if x % 3 == 0]&gt;&gt;&gt; numbers[0, 3, 6, 9, 12, 15, 18]# 可以加多个元素判断&gt;&gt;&gt; print([ (x, y) for x in range(10) if x % 2 if x &gt; 3 for y in range(10) if y &gt; 7 if y != 8 ])[(5, 9), (7, 9), (9, 9)]&gt;&gt;&gt; [(x,y) for x in range(3) for y in range(3)][(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)]# 生成dict&gt;&gt;&gt; print(dict([(x,x*10) for x in range(5)]))&#123;0: 0, 1: 10, 2: 20, 3: 30, 4: 40&#125; list.pop()方法pop()函数用于移除列表中的一个元素（默认最后一个元素），并且返回该元素的值。 语法1list.pop(obj=list[-1]) obj – 可选参数，要移除列表元素的对象index。 返回值返回从列表中移除的元素对象。 实例 1234567891011121314&gt;&gt;&gt; list[5, 2, 3, 2, 8, 1, 4, 3, 32]&gt;&gt;&gt; list.pop()32&gt;&gt;&gt; list[5, 2, 3, 2, 8, 1, 4, 3]&gt;&gt;&gt; list.pop(5)1&gt;&gt;&gt; list[5, 2, 3, 2, 8, 4, 3]&gt;&gt;&gt; list.pop(8)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;IndexError: pop index out of range]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>codewars</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ansible学习】- Ad-Hoc命令参数使用说明]]></title>
    <url>%2Fansible-options.html</url>
    <content type="text"><![CDATA[Ad-hoc 命令是一种可以快速输入的命令，而且不需要保存起来的命令。就相当于 bash 中的一句话 shell。本文将介绍一些平时使用 Ad-Hoc 命令时用到较多的参数。 Ansible 常用参数说明使用ansible -h命令就可以列出所有的命令参数，下面列举了常用的一些参数。 option 说明 -v 输出详细信息 -i 指定inventory文件，默认使用/etc/ansible/hosts -f fork的进程个数，默认为5 --list-hosts 列出主机列表，并不会执行其他操作 -private-key=xxx 指定ssh连接使用的文件 -m 指定module，默认为command -a 指定module的参数 -o 精简输出内容 -k 提示输入密码 -K 提示输入sudo密码，与-sudo一起使用 -T 设置连接超时时间 -B 设置后台运行并设置超时时长 使用示例-i示例12345678910111213141516171819202122232425[root@centos7 ~]# cat hosts[apache]172.20.21.121172.20.21.123[nginx]172.20.21.120172.20.21.121[servers:children]apachenginx[servers:vars]ansible_ssh_user='root'ansible_ssh_pass='123456'[root@centos7 ~]# ansible -i hosts apache --list-hosts hosts (2): 172.20.21.121 172.20.21.123[root@centos7 ~]# ansible -i hosts apache -m ping -o172.20.21.123 | SUCCESS =&gt; &#123;"changed": false, "ping": "pong"&#125;172.20.21.121 | SUCCESS =&gt; &#123;"changed": false, "ping": "pong"&#125; -k示例不指定module，默认将使用command。1234[root@centos7 ~]# ansible -i hosts apache -k -o -a "echo hello"SSH password: 172.20.21.123 | SUCCESS | rc=0 | (stdout) hello172.20.21.121 | SUCCESS | rc=0 | (stdout) hello ansible-doc -s取得更详细信息希望知道更加详细的module的信息，最好的方法是使用ansible自带的ansible-doc的-s选项。12345678910111213141516171819202122232425[root@centos7 ~]# ansible-doc -s raw- name: Executes a low-down and dirty SSH command raw: executable: # change the shell used to execute the command. Should be an absolute path to the executable. when using privilege escalation (`become'), a default shell will be assigned if one is not provided as privilege escalation requires a shell. free_form: # (required) the raw module takes a free form command to run. There is no parameter actually named 'free form'; see the examples![root@centos7 ~]# ansible-doc -s expect- name: Executes a command and responds to prompts. expect: chdir: # Change into this directory before running the command. command: # (required) The command module takes command to run. creates: # A filename, when it already exists, this step will *not* be run. echo: # Whether or not to echo out your response strings. removes: # A filename, when it does not exist, this step will *not* be run. responses: # (required) Mapping of expected string/regex and string to respond with. If the response is a list, successive matches return successive responses. List functionality is new in 2.1. timeout: # Amount of time in seconds to wait for the expected strings. 所有命令参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[root@localhost ~]# ansible -hUsage: ansible &lt;host-pattern&gt; [options]Options: -a MODULE_ARGS, --args=MODULE_ARGS 模块的参数,如果执行默认COMMAND的模块，即是命令参数,如：“date”,"pwd"等等 module arguments 模块参数 -k, --ask-pass ask for SSH password 登录密码，提示输入SSH密码而不是假设基于密钥的验证 --ask-su-pass ask for su password su切换密码 -K, --ask-sudo-pass ask for sudo password 提示密码使用sudo,sudo表示提权操作 --ask-vault-pass ask for vault password -B SECONDS, --background=SECONDS 后台运行超时时间 run asynchronously, failing after X seconds (default=N/A) -C, --check don't make any changes; instead, try to predict some 只是测试一下会改变什么内容，不会真正去执行;相反,试图预测一些可能发生的变化 of the changes that may occur -c CONNECTION, --connection=CONNECTION 连接类型使用。可能的选项是paramiko(SSH),SSH和地方。当地主要是用于crontab或启动。 connection type to use (default=smart) -f FORKS, --forks=FORKS 并行任务数。NUM被指定为一个整数,默认是5 specify number of parallel processes to use (default=5) -h, --help show this help message and exit 打开帮助文档API -i INVENTORY, --inventory-file=INVENTORY 指定库存主机文件的路径,默认为/etc/ansible/hosts specify inventory host file (default=/etc/ansible/hosts) -l SUBSET, --limit=SUBSET 进一步限制所选主机/组模式 --limit=192.168.91.135 只对这个ip执行 further limit selected hosts to an additional pattern --list-hosts outputs a list of matching hosts; does not execute anything else -m MODULE_NAME, --module-name=MODULE_NAME 执行模块的名字，默认使用 command 模块，所以如果是只执行单一命令可以不用 -m参数 module name to execute (default=command) -M MODULE_PATH, --module-path=MODULE_PATH 要执行的模块的路径，默认为/usr/share/ansible/ specify path(s) to module library (default=/usr/share/ansible/) -o, --one-line condense output 压缩输出，摘要输出.尝试一切都在一行上输出。 -P POLL_INTERVAL, --poll=POLL_INTERVAL 调查背景工作每隔数秒。需要- b set the poll interval if using -B (default=15) --private-key=PRIVATE_KEY_FILE 私钥路径，使用这个文件来验证连接 use this file to authenticate the connection -S, --su run operations with su 用 su 命令 -R SU_USER, --su-user=SU_USER 指定SU的用户，默认是root用户 run operations with su as this user (default=root) -s, --sudo run operations with sudo (nopasswd) -U SUDO_USER, --sudo-user=SUDO_USER sudo到哪个用户，默认为 root desired sudo user (default=root) -T TIMEOUT, --timeout=TIMEOUT 指定SSH默认超时时间， 默认是10S override the SSH timeout in seconds (default=10) -t TREE, --tree=TREE log output to this directory 将日志内容保存在该输出目录,结果保存在一个文件中在每台主机上。 -u REMOTE_USER, --user=REMOTE_USER 远程用户， 默认是root用户 connect as this user (default=root) --vault-password-file=VAULT_PASSWORD_FILE vault password file -v, --verbose verbose mode (-vvv for more, -vvvv to enable 详细信息 connection debugging) --version show program's version number and exit 输出ansible的版本]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Codewars每日一题】- Rectangle into Squares]]></title>
    <url>%2FCodewars-Rectangle-into-Squares.html</url>
    <content type="text"><![CDATA[题目题目地址 The drawing below gives an idea of how to cut a given “true” rectangle into squares (“true” rectangle meaning that the two dimensions are different). Can you translate this drawing into an algorithm? You will be given two dimensions a positive integer length (parameter named lng) a positive integer width (parameter named wdth) You will return an array with the size of each of the squares. Shell bash returns a string. Examples1234sqInRect(5, 3) should return [3, 2, 1, 1]sqInRect(3, 5) should return [3, 2, 1, 1]sqInRect(20, 14) should return [14, 6, 6, 2, 2, 2]sqInRect(5, 5) should return None #Note: lng == wdth as a starting case would be an entirely different problem and the drawing is planned to be interpreted with lng != wdth. 思路题目的含义是将一个长方形切割成正方形，且正方形尽可能的大。看返回值的规律应该是，将两个数值相减，直至两个数值相等。需要使用递归。 但是初步写完测试后，返现不是这个规律。sqInRect(20, 14) should return [14, 6, 6, 2, 2, 2]这个就不适用。 答案我的答案12345678910111213def sqInRect(lng, wdth): if lng == wdth: return None list = [] list.append(min(lng, wdth)) while lng != wdth: minNum = min(lng, wdth) maxNum = max(lng, wdth) lng = minNum wdth = maxNum - minNum list.append(min(lng, wdth)) return list 最佳答案 最佳实践解法 12345678910111213def sqInRect(lng, wdth): if lng == wdth: return None if lng &lt; wdth: wdth, lng = lng, wdth res = [] while lng != wdth: res.append(wdth) lng = lng - wdth if lng &lt; wdth: wdth, lng = lng, wdth res.append(wdth) return res 递归的解法 1234567# Recursive solutiondef sqInRect(lng, wdth, recur = 0): if lng == wdth: return (None, [lng])[recur] # If this is original function call, return None for equal sides (per kata requirement); # if this is recursion call, we reached the smallest square, so get out of recursion. lesser = min(lng, wdth) return [lesser] + sqInRect(lesser, abs(lng - wdth), recur = 1) 本题的难点在于题目的理解，本人就在题目的理解上花费了较长的时间。可以看出我的解法是和最佳实践解法类似的，看来一般递归解法不属于最佳实践，因为递归的代码相对较为难懂。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>codewars</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ansible学习】- Ansible初探]]></title>
    <url>%2Fabout%20ansible.html</url>
    <content type="text"><![CDATA[本文主要记录本人学习ansible中的一些知识点，对ansible的一些模块进行一些简单的介绍。 安装12yum -y install epel-releaseyum -y install ansible Ansible基础Ansible架构图 Ansible核心组件说明 Ansible：Ansible的核心程序 Host Lnventory：记录了每一个由Ansible管理的主机信息，信息包括ssh端口，root帐号密码，ip地址等等。可以通过file来加载，可以通过CMDB加载 Playbooks：YAML格式文件，多个任务定义在一个文件中，使用时可以统一调用，剧本用来定义那些主机需要调用那些模块来完成的功能 Core Modules：Ansible执行任何管理任务都不是由Ansible自己完成，而是由核心模块完成；Ansible管理主机之前，先调用core Modules中的模块，然后指明管理Host Lnventory中的主机，就可以完成管理主机。 Custom Modules：自定义模块，完成Ansible核心模块无法完成的功能，此模块支持任何语言编写。 Connection Plugins：连接插件，Ansible和Host通信使用 Ansible执行过程暖色调的代表已经模块化 清单文件1234[servers]172.20.21.120172.20.21.121172.20.21.123 默认清单文件是/etc/ansible/hosts。 同时也可以在运行时通过-i参数来指定清单文件。 测试主机连通性1ansible www.baidu.com -m ping 发现执行结果异常，这是因为ansible只纳管定义在清单文件中的主机。 12ansible servers -m pingansible servers -m ping -o 通过-o参数，可以让结果在一行中进行显示。 执行远程指令12ansible servers -m shell -a 'uptime'ansible servers -m command -a 'uptime' 远程主机的yum管理确认软件是否安装12345[root@centos7 ~]# ansible servers -m shell -a 'rpm -qa|grep httpd' [WARNING]: Consider using yum, dnf or zypper module rather than running rpm172.20.21.121 | FAILED | rc=1 &gt;&gt;non-zero return code 安装httpd123456789[root@centos7 ~]# ansible servers -m yum -a 'name=httpd state=latest'172.20.21.121 | SUCCESS =&gt; &#123; "changed": true, "msg": "Repository base is listed more than once in the configuration\nRepository updates is listed more than once in the configuration\nRepository extras is listed more than once in the configuration\nRepository centosplus is listed more than once in the configuration\nThere are unfinished transactions remaining. You might consider running yum-complete-transaction, or \"yum-complete-transaction --cleanup-only\" and \"yum history redo last\", first to finish them. If those don't work you'll have to try removing/installing packages by hand (maybe package-cleanup can help).\nThe program yum-complete-transaction is found in the yum-utils package.\n", "rc": 0, "results": [ ..." ]&#125; 再次安装再次安装时，就会检查客户端已安装的组件是否是最新的，若是最新的就不会再次安装。changed字段会返回false。12345678910[root@centos7 ~]# ansible servers -m yum -a 'name=httpd state=latest'172.20.21.121 | SUCCESS =&gt; &#123; "changed": false, "msg": "", "rc": 0, "results": [ "All packages providing httpd are up to date", "" ]&#125; Ansible组件 - InventoryInventory主机清单inventory文件通常用于定义要管理主机的认证信息，例如ssh登录所需的用户名、密码以及key相关信息。/etc/ansible/hosts文件配置：12345678910111213141516[apache]172.20.21.121172.20.21.123[nginx]172.20.21.[120:121]# 把一个组作为另一个组的子成员[servers:children]apachenginx# 定义组变量[servers:vars]ansible_ssh_user='root'ansible_ssh_pass='123456' 1234567891011121314151617[root@centos7 ~]# ansible apache --list-hosts hosts (2): 172.20.21.121 172.20.21.123[root@centos7 ~]# ansible nginx --list-hosts hosts (2): 172.20.21.120 172.20.21.121[root@centos7 ~]# ansible servers --list-hosts hosts (3): 172.20.21.121 172.20.21.123 172.20.21.120[root@centos7 ~]# ansible all -m shell -a 'hostname' -o172.20.21.123 | SUCCESS | rc=0 | (stdout) centos7172.20.21.121 | SUCCESS | rc=0 | (stdout) centos7172.20.21.120 | SUCCESS | rc=0 | (stdout) centos7 Ansible Inventory 内置参数 参数 用途 例子 ansible_ssh_host 将要连接的远程主机名ssh地址 ansible_ssh_host=192.168.1.100 ansible_ssh_port ssh端口 ansible_ssh_port=3000 ansible_ssh_user ssh 用户名 ansible_ssh_user=user ansible_ssh_pass ssh 密码 ansible_ssh_pass=pass ansible_sudo sudo 用户 ansible_sudo_pass sudo 密码 ansible_sudo_exe sudo 执行路径 ansible_sudo_exe=/usr/bin/sudo ansible_connection hosts 连接方式 ansible_connection=local ansible_ssh_private_key_file hosts 私钥 ansible_ssh_private_key_file=/root/key Ansible组件 - Ad-Hocad hoc，临时的，在ansible中是指需要快速执行，并且不需要报错的命令。对于复杂的命令则需要playbook。 执行命令 -m shell12345678[root@centos7 ~]# ansible servers -m shell -a 'hostname' -o172.20.21.121 | SUCCESS | rc=0 | (stdout) centos7172.20.21.123 | SUCCESS | rc=0 | (stdout) centos7172.20.21.120 | SUCCESS | rc=0 | (stdout) centos7[root@centos7 ~]# ansible servers -m shell -a 'uname -r' -o172.20.21.121 | SUCCESS | rc=0 | (stdout) 3.10.0-514.26.2.el7.x86_64172.20.21.123 | SUCCESS | rc=0 | (stdout) 3.10.0-514.26.2.el7.x86_64172.20.21.120 | SUCCESS | rc=0 | (stdout) 3.10.0-514.26.2.el7.x86_64 复制文件 -m copy1ansible all -m copy -a "src=test.sh dest=/tmp" 软件包管理 -m yum1ansible apache -m yum -a "name=vim state=present" 1ansible apache -m yum -a 'name=httpd state=absent' 服务管理 -m service1ansible apache -m service -a "name=httpd state=restarted enabled=yes" Ansible组件 - Factsfacts组件是Ansible用于采集被管理主机信息的功能，可以使用setup模块查看主机所有的facts信息。可以使用filter参数对结果进行过滤。12ansible apache -m setupansible apache -m setup -a "filter=ansible_default_ipv4" Ansible组件 - playbookplaybook是有一个或者多个play组成的列表。play的主要功能在于将实现归并为一组的主机装扮成实现通过ansible中的task定义好的角色role。 根本上来讲，所谓的task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让他们联合起来按事先编排的机制完成某一任务。 playbook示例yaml剧本1234567891011121314151617- hosts: apache tasks: - name: Install httpd yum: name=httpd state=present - name: copy httpd conf template: src=/etc/httpd/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf owner=root group=root mode=0644 notify: - Restart Apache Service - name: enable httpd is runing service: name=httpd state=started enabled=yes handlers: - name: Restart Apache Service service: name=httpd state=restarted 检查123ansible-playbook apapche.yaml --syntax-checkansible-playbook apapche.yaml --list-taskansible-playbook apapche.yaml --list-hosts 执行playbook1ansible-playbook apapche.yaml]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Codewars每日一题】- Find the unique number]]></title>
    <url>%2FCodewars-Find-the-unique-number.html</url>
    <content type="text"><![CDATA[题目题目地址 There is an array with some numbers. All numbers are equal except for one. Try to find it! Examples12findUniq([ 1, 1, 1, 2, 1, 1 ]) === 2findUniq([ 0, 0, 0.55, 0, 0 ]) === 0.55 It’s guaranteed that array contains more than 3 numbers.The tests contain some very huge arrays, so think about performance. 思路先对list进行排序，对排序后的结果再进行判断。主要是判断首位和末位是否是目标数。 答案我的答案123def find_uniq(arr): arr.sort() return arr[0] if arr[0] != arr[1] else arr[-1] 最佳答案123def find_uniq(arr): a, b = set(arr) return a if arr.count(a) == 1 else b 最佳答案的思路主要有利用set()函数将排除重复数值，将最终的两个数值分离出，然后看原list中哪个数值的数量少，以及使用sort()函数。 关于sort()函数的讲解见【Codewars每日一题】- Invert values，下面主要说下set()函数的用法。 P.S. 这是我有史以来最接近最佳答案的一次 &#x1f604; 知识点set()函数描述set()函数创建一个无序不重复元素集，可进行关系测试，删除重复数据，还可以计算交集、差集、并集等。 语法1class set([iterable]) iterable – 可迭代对象对象；返回值返回新的集合对象。示例 重复元素在set中自动被过滤： 1234&gt;&gt;&gt; a = [ 1, 1, 1, 2, 1, 1 ]&gt;&gt;&gt; s = set(a)&gt;&gt;&gt; sset([1, 2]) 通过add(key)方法可以添加元素到set中，可以重复添加，但不会有效果： 123456&gt;&gt;&gt; s.add(3)&gt;&gt;&gt; sset([1, 2, 3])&gt;&gt;&gt; s.add(2)&gt;&gt;&gt; sset([1, 2, 3]) 通过remove(key)方法可以删除元素： 12345&gt;&gt;&gt; sset([1, 2, 3])&gt;&gt;&gt; s.remove(2)&gt;&gt;&gt; sset([1, 3]) 交集、并集操作set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作： 123456789&gt;&gt;&gt; sset([1, 2, 3])&gt;&gt;&gt; s2 = set([2,3,4])&gt;&gt;&gt; s2set([2, 3, 4])&gt;&gt;&gt; s &amp; s2set([2, 3])&gt;&gt;&gt; s | s2set([1, 2, 3, 4])]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>codewars</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ganglia配置文件gmond.conf详解]]></title>
    <url>%2Fganglia%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6gmond-conf%E8%AF%A6%E8%A7%A3.html</url>
    <content type="text"><![CDATA[Ganglia简介Ganglia是一款为HPC（高性能计算）集群而设计的可扩展的分布式监控系统，它可以监视和显示集群中的节点的各种状态信息，它由运行在各个节点上的gmond守护进程来采集CPU、内存、硬盘利用率、I/O负载、网络流量情况等方面的数据，然后汇总到gmetad守护进程下，使用rrdtool存储数据，最后将历史数据以曲线方式通过PHP页面呈现。 Ganglia的特点如下： 良好的扩展性，分层架构设计能够适应大规模服务器集群的需要 负载开销低，支持高并发 广泛支持各种操作系统（UNIX等）和cpu架构，支持虚拟机 gmond.conf配置文件这里对于ganglia的安装不再赘述，主要讲解gmond.conf配置文件内容。 Ganglia监控客户端gmond安装完成后，配置文件位于Ganglia安装路径的etc目录下，名称为 gmond.conf，使用yum或者RPM包安装的话位于/etc/ganglia/gmond.conf。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172globals &#123; daemonize = yes #是否后台运行，这里表示以后台的方式运行 setuid = yes #是否设置运行用户，在 Windows 中需要设置为 false user = ganglia #设置运行的用户名称，必须是操作系统已经存在的用户，默认是 ganglia debug_level = 0 #调试级别，默认是 0，表示不输出任何日志，数字越大表示输出的日志越多 max_udp_msg_len = 1472 mute = no #字面意思是“哑巴”，是否发送监控数据到其他节点，设置为 yes 表示本节点将不再广播任何自己收集到的数据到网络上 deaf = yes #是否接受其他节点发送过来的监控数据，设置为 yes 表示本节点将不再接收任何其他节点广播的数据包 allow_extra_data = yes #是否发送扩展数据 host_dmax = 400 /*secs. Expires (removes from web interface) hosts in 1 day */ #是否删除一个节点，0 代表永远不删除，0 之外的整数代表节点的不响应时间，超过这个时间后，Ganglia 就会刷新集群节点信息进而删除此节点 host_tmax = 20 /*secs */ cleanup_threshold = 300 /*secs */ #gmond 清理过期数据的时间 gexec = no #是否使用 gexec 来告知主机是否可用，这里不启用 # By default gmond will use reverse DNS resolution when displaying your hostname # Uncommeting following value will override that value. # override_hostname = "mywebserver.domain.com" # If you are not using multicast this value should be set to something other than 0. # Otherwise if you restart aggregator gmond you will get empty graphs. 60 seconds is reasonable send_metadata_interval = 30 /*secs */ #在单播协议中，新添加的节点在多长时间内响应一下以表示自己的存在，0 代表仅在 gmond 启动时通知一次，单位秒 &#125;/* * The cluster attributes specified will be used as part of the &lt;CLUSTER&gt; * tag that will wrap all hosts collected by this instance. */cluster &#123; name = "bcclm1" #集群的名称，是区分此节点属于某个集群的标志，必须和监控服务端 data_source 中的某一项名称匹配 owner = "unspecified" #节点的拥有者，也就是节点的管理员 latlong = "unspecified" #节点的坐标，经度、纬度等，一般无需指定 url = "unspecified" #节点的 URL 地址，一般无需指定&#125;/* The host section describes attributes of the host, like the location */host &#123; location = "unspecified" #节点的物理位置，一般无需指定 &#125;/* Feel free to specify as many udp_send_channels as you like. Gmond used to only support having a single channel */udp_send_channel &#123; #udp 包的发送通道 #bind_hostname = yes # Highly recommended, soon to be default. # This option tells gmond to use a source address # that resolves to the machine's hostname. Without # this, the metrics may appear to come from any # interface and the DNS names associated with # those IPs will be used to create the RRDs.# mcast_join = 239.2.11.71 #指定发送的多播地址，其中 239.2.11.71 是一个 D 类地址。如果使用单播模式，则要写 host = host1，在单播模式下也可以配置多个 udp_send_channel host = 172.16.203.51 port = 8649 #监听端口 # ttl = 1&#125;/* You can specify as many udp_recv_channels as you like as well. */udp_recv_channel &#123; #接收 udp 包配置 #mcast_join = 239.2.11.71 #指定接收的多播地址，同样也是 239.2.11.71 这个 D 类地址 port = 8649 #监听端口 #bind = 239.2.11.71 #绑定地址 retry_bind = true # Size of the UDP buffer. If you are handling lots of metrics you really # should bump it up to e.g. 10MB or even higher. # buffer = 10485760&#125;/* You can specify as many tcp_accept_channels as you like to share an xml description of the state of the cluster */tcp_accept_channel &#123; port = 8649 #通过 tcp 协议监听的端口，在远端可以通过连接到 8649 端口得到监控数据 # If you want to gzip XML output gzip_output = no&#125;]]></content>
      <categories>
        <category>运维监控</category>
      </categories>
      <tags>
        <tag>ganglia</tag>
        <tag>gmond</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Codewars每日一题】- Find The Parity Outlier]]></title>
    <url>%2FCodewars-Find%20The%20Parity%20Outlier.html</url>
    <content type="text"><![CDATA[题目题目地址 You are given an array (which will have a length of at least 3, but could be very large) containing integers. The array is either entirely comprised of odd integers or entirely comprised of even integers except for a single integer N. Write a method that takes the array as an argument and returns this “outlier” N. Examples12345[2, 4, 0, 100, 4, 11, 2602, 36]Should return: 11 (the only odd number)[160, 3, 1719, 19, 11, 13, -21]Should return: 160 (the only even number) 思路最直接的思路就是遍历数组，前提要判断我们要找的目标是一个奇数还是偶数。根据数组中的前三个数字可以判断出目标数是奇还是偶。然后遍历数组，找到目标数。 答案我的答案12345678910111213141516171819202122232425262728293031def find_outlier(integers): if (isOddList(integers)): for i in integers: if not isOdd(i): return i else: for i in integers: if isOdd(i): return i# 判断是否是奇数def isOdd(num): if (num % 2) == 0: return False else: return True# 判读是否是奇数数组，以前三个元素判断即可def isOddList(integers): odd = 0 even = 0 for i in integers[0:3]: if (i % 2) == 0: even += 1 else: odd += 1 if odd &gt; even: return True else: return False 最佳答案1234def find_outlier(int): odds = [x for x in int if x%2!=0] evens= [x for x in int if x%2==0] return odds[0] if len(odds)&lt;len(evens) else evens[0] 最佳答案的思路是分别将奇数和偶数筛选出为单独的list，然后比较最终的list大小可以得出目标数。该方法看着简洁明了。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>codewars</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客Next主题SEO优化方法]]></title>
    <url>%2FHexo%2BNext%20SEO%E4%BC%98%E5%8C%96.html</url>
    <content type="text"><![CDATA[本文主要介绍Hexo博客的优化方法，以Google搜索为例。 添加站点地图安装插件需要安装两个插件来生成 sitemap 文件，前一个是传统的 sitemap，后一个是百度的 sitemap。12npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 修改站点配置文件将sitemap文件添加到站点配置文件_config.yml中，并修改url字段的值，其值默认为http://yoursite.com。123456sitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xmlurl: https://hoxis.github.io 安装完成后执行hexo g即会在站点public目录下生成sitemap.xml和baidusitemap.xml。 添加蜘蛛协议在站点source文件夹下新建robots.txt文件，文件内容如下：123456789101112131415User-agent: *Allow: /Allow: /archives/Allow: /categories/Allow: /tags/ Allow: /resources/ Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: https://hoxis.github.io/sitemap.xmlSitemap: https://hoxis.github.io/baidusitemap.xml Allow字段的值即为允许搜索引擎爬区的内容，可以对应到主题配置文件中的menu目录配置，如果菜单栏还有其他选项都可以按照格式自行添加。 需要将https://hoxis.github.io改成自己的域名。 提交站点到 Google打开Google Search Console，添加博客地址。 站点验证Google给出的推荐方法是上传HTML文件，但是不知道为什么一直验证失败，所以我选择了备用方法中的HTML 标记，将给出的元标记复制到\themes\hexo-theme-next\layout\_partials\head.swig文件中。添加后运行hexo d -g将改动提交。稍后就可以验证成功了。 your-hexo-site\themes\hexo-theme-next\layout\_partials\head.swig123456&lt;meta charset="UTF-8"/&gt;&lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt;&lt;meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/&gt;&lt;meta name="theme-color" content="&#123;&#123; theme.android_chrome_color &#125;&#125;"&gt;&lt;meta name="google-site-verification" content="xxxxxxxxxxxxx" /&gt;&lt;meta name="baidu-site-verification" content="xxxxxxxxx" /&gt; 该方法是通过校验网页中&lt;head&gt;中的属性来进行校验的。 123456789&lt;html&gt; &lt;head&gt; &lt;meta name="google-site-verification" content="S2s6Oge-PuQt56EBO4t90FLwhL0P0faoH08iSNXe8iU" /&gt; &lt;title&gt; 我的标题 &lt;/title&gt; &lt;/head&gt; &lt;body&gt; 网页内容 &lt;/body&gt;&lt;/html&gt; 测试 robots.txt 文件点击左侧的robots.txt测试工具，根据提示提交你的robots.txt。 注意要0错误才可以，如果有错误的话，会有提示，改正确就可以了。 提交站点地图点击右上角添加/测试站点地图输入 sitemap.xml 进行测试，测试无误后再提交文件。 Google抓取方式到了最后一步，如果上方的输入框留空表示抓取首页，抓取方式可以选择桌面，智能手机等等，自行根据需要选择。填好url之后，点击抓取。 抓取完成后可能会有几种状态：完成、部分完成和已重定向等，不过无需担心，这些状态并不会影响提交。此时点击请求编入索引即可，至此博客就成功提交到了 Google，你的博客在google搜索上排名想不靠前都难了，马上上google搜索一下你的关键词和博客title测试一下吧。 Baidu主动提交链接方法该方法可直接推送.github.io结尾的网页的链接给百度而避免百度无法爬取github中链接的问题。该方法需要安装hexo插件，参考官方说明Hexo插件之百度自动提交链接。 安装插件 在Hexo根目录下，安装本插件：1npm install hexo-baidu-url-submit --save 配置 配置博客根目录下的_config.yml文件12345baidu_url_submit: count: 3 ## 比如3，代表提交最新的三个链接 host: https://hoxis.github.io ## 在百度站长平台中注册的域名 token: your_token ## 请注意这是您的秘钥， 请不要发布在公众仓库里! path: baidu_urls.txt ## 文本文档的地址， 新链接会保存在此文本文档里 检查确认_config.yml中的url值与图片中host后的值一致 123# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: https://hoxis.github.io 最后修改deploy添加一段baidu_url_submitter。 12345678910deploy: - type: git repo: https://github.com/hoxis/hoxis.github.io.git branch: master - type: git repo: https://git.coding.net/hoxis/hoxis.git branch: master- type: baidu_url_submitter 推送之后进行部署后该插件将自动进行主动推送至百度，如图所示表示推送成功。 网站结构自身优化出站链接添加nofollow标签网络爬虫会在当前页面搜索所有的链接，然后一个个查看，所以就很有可能跳到别的网站就不回来了。这个时候就需要nofollow起作用了。 nofollow标签是由谷歌领头创新的一个反垃圾链接的标签，并被百度、yahoo等各大搜索引擎广泛支持，引用nofollow标签的目的是：用于指示搜索引擎不要追踪（即抓取）网页上的带有nofollow属性的任何出站链接，以减少垃圾链接的分散网站权重。 修改footer.swig文件路径在your-hexo-site\themes\next\layout\_partials，将下面代码中的a标签加上rel=&quot;external nofollow&quot;属性。1&#123;&#123; __('footer.powered', '&lt;a rel="external nofollow" class="theme-link" target="_blank" href="https://hexo.io"&gt;Hexo&lt;/a&gt;') &#125;&#125; 1&lt;a rel="external nofollow" class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next"&gt; 修改sidebar.swig文件路径在your-hexo-site\themes\next\layout_macro，将下面代码中的a标签加上rel=&quot;external nofollow&quot;属性；1&lt;a href="https://creativecommons.org/&#123;% if theme.creative_commons === 'zero' %&#125;publicdomain/zero/1.0&#123;% else %&#125;licenses/&#123;&#123; theme.creative_commons &#125;&#125;/4.0&#123;% endif %&#125;/" rel="external nofollow" class="cc-opacity" target="_blank"&gt; 1&lt;a href="&#123;&#123; link &#125;&#125;" title="&#123;&#123; name &#125;&#125;" rel="external nofollow" target="_blank"&gt;&#123;&#123; name &#125;&#125;&lt;/a&gt; 1&lt;a rel="external nofollow" href="&#123;&#123; link.split('||')[0] | trim &#125;&#125;" target="_blank" title="&#123;&#123; name &#125;&#125;"&gt; 添加关键字修改模板your-hexo-site\scaffolds\post.md文件，添加keywords和description字段，用于生成的文章中添加关键字和描述。123456title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:keywords:description:--- 修改博文链接HEXO默认的文章链接形式为domain/year/month/day/postname，默认就是一个四级url，并且可能造成url过长，对搜索引擎是十分不友好的，我们可以改成domain/postname 的形式。编辑站点_config.yml文件，修改其中的permalink字段改为permalink: :title.html即可。12#permalink: :year/:month/:day/:title/permalink: :title.html 首页title优化更改index.swig文件your-hexo-site\themes\next\layout 将下面这段代码：1&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; &#123;% endblock %&#125; 改成 1&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; - &#123;&#123; theme.description &#125;&#125; &#123;% endblock %&#125; 这时候你的首页会更符合网站名称-网站描述这习惯。 进阶，做了seo优化，把关键词也显示在title标题里，可改成1&#123;% block title %&#125; &#123;&#123; theme.keywords &#125;&#125; - &#123;&#123; config.title &#125;&#125;&#123;&#123; theme.description &#125;&#125; &#123;% endblock %&#125; 注意：别堆砌关键字，整个标题一般不超过80个字符，可以通过chinaz的seo综合查询检查。]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用代码段]]></title>
    <url>%2F%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E6%AE%B5.html</url>
    <content type="text"><![CDATA[包括 shell、SQL 以及一些常用命令的集合。 shell批量修改文件名12345for file in `/bin/ls | grep .cfg`do newfile=`echo $file | sed 's/\r//g'` mv $file $newfiledone shell判断目录是否存在12345dir="/opt/install/"if [ ! -d "$dir" ]; then echo DIR "'$dir'" is not exist! exit 1fi sql查询表中某字段重复的数据12345678910111213SELECT * FROM vm_info_tabWHERE ip IN ( SELECT ip FROM vm_info_tab GROUP BY ip HAVING COUNT(*) &gt; 1 )AND ip != ''; 抓包1tcpdump -X -nn -i any host 172.20.79.85 and port 8080 -s 0 -w raw.pcap 其中的ip和端口代表目的地址和端口。-w将包重定向到raw.pcap文件中，然后可以通过wireshark进行分析。 shell小数比较shell对于数值的判断都是基于整数的，如果碰到小数就无能为力了。123456789101112131415161718192021222324252627282930#!/usr/bin/env basha=$1b=$2# 此方法需要bc支持，若报错则需要安装bcif [ $(echo "$a &gt; $b" | bc) -eq 1 ];then echo $a is biggerelse echo $b is biggerfi# float number comparison，不需要外部插件支持fcomp() &#123; awk -v n1="$1" -v n2="$2" 'BEGIN &#123;if (n1+0&gt;n2+0) exit 0; exit 1&#125;'&#125;# test and exampleif fcomp "$a" "$b"; then echo "$a&gt;$b"else echo "$a&lt;=$b"fi# 另外，网上流传下面的方法，这种方法是比较的字符串，是不能作为数值比较的方法的！参照测试结果if [ `expr $a \&gt; $b` -eq 1 ];then echo $a is biggerelse echo $b is biggerfi 测试结果，明显第二种方法是有问题的：1234[root@CESHI-CLM-10-254-4-48 liuhao]# source test.sh 19.2 3.319.2 is bigger3.3 is bigger19.1&gt;3.3 根据hosts批量操作123456789101112131415161718192021222324# 批量建立互信for host in $(cat host); do ssh-copy-id -i .ssh/id_rsa.pub deployer@$host; done# 批量测试nrpefor host in $(cat hosts); do ./check_nrpe -H $host -c mycheck_load -a 0.1 1;done# 批量生产配置for host in $(cat hosts); do echo 'define host &#123;' &gt;&gt;hosts.cfg ; echo ' use linux-server' &gt;&gt;hosts.cfg ; echo ' host_name '$host &gt;&gt;hosts.cfg ; echo ' alias '$host &gt;&gt;hosts.cfg ; echo ' address '$host &gt;&gt;hosts.cfg ; echo ' hostgroups 1' &gt;&gt;hosts.cfg ; echo '&#125;' &gt;&gt;hosts.cfg ; echo '' &gt;&gt;hosts.cfg ; done redis使用 登录：redis-cli -h localhost -p 6379 -a 123456 获取所有keys：keys * 获取值：get set_value_test2 设置值：set set_value_test2 2 删除当前数据库中的所有Key：flushdb 删除所有数据库中的key：flushall cp强制覆盖1yes|cp -r /tmp/abc/ . 查看系统状态查看CPU利用1mpstat 查看网络流量sar命令包含在sysstat工具包中，提供系统的众多统计数据。 1sar -n DEV 1 2 命令后面1 2意思是：每一秒钟取1次值，取2次。 DEV显示网络接口信息 另外，-n参数很有用，他有6个不同的开关：DEV | EDEV | NFS | NFSD | SOCK | ALL ，其代表的含义如下： DEV- 显示网络接口信息。 EDEV- 显示关于网络错误的统计数据。 NFS- 统计活动的NFS客户端的信息。 NFSD - 统计NFS服务器的信息 SOCK - 显示套接字信息 ALL - 显示所有5个开关 返回参数说明： IFACE - LAN接口 rxpck/s - 每秒钟接收的数据包 txpck/s - 每秒钟发送的数据包 rxbyt/s - 每秒钟接收的字节数 txbyt/s - 每秒钟发送的字节数 rxcmp/s - 每秒钟接收的压缩数据包 txcmp/s - 每秒钟发送的压缩数据包 rxmcst/s - 每秒钟接收的多播数据包 rxerr/s - 每秒钟接收的坏数据包 txerr/s - 每秒钟发送的坏数据包 coll/s - 每秒冲突数 rxdrop/s - 因为缓冲充满，每秒钟丢弃的已接收数据包数 txdrop/s - 因为缓冲充满，每秒钟丢弃的已发送数据包数 txcarr/s - 发送数据包时，每秒载波错误数 rxfram/s - 每秒接收数据包的帧对齐错误数 rxfifo/s - 接收的数据包每秒FIFO过速的错误数 txfifo/s - 发送的数据包每秒FIFO过速的错误数 压缩相关 .tar 解包：tar xvf FileName.tar 打包：tar cvf FileName.tar DirName 注：tar是打包，不是压缩！ 打包时排除 tomcat/logs 目录tar -zcvf tomcat.tar.gz --exclude=tomcat/logs tomcat 打包时排除logs和libs两个目录及文件xiaoshan.txt：tar -zcvf tomcat.tar.gz --exclude=tomcat/logs --exclude=tomcat/libs --exclude=tomcat/xiaoshan.txt tomcat .gz 解压1 - gunzip FileName.g 解压2 - gzip -d FileName.gz 压缩 - gzip FileName .tar.gz 和 .tgz 解压 - tar zxvf FileName.tar.gz 压缩 - tar zcvf FileName.tar.gz DirName .zip 解压 - unzip FileName.zip 压缩 - zip FileName.zip DirName .rar 解压 - rar x FileName.rar 压缩 - rar a FileName.rar DirName 使用 grep 查找所有包含指定文本的文件 非递归搜索包含指定字符串的文件1grep -s Core /etc/* grep的-s选项会在发现不存在或者不能读取的文件时隐藏报错信息。结果显示除了文件名之外，还会输出包含请求字符串的行。 递归地搜索包含指定字符串的文件-R所谓递归搜索就是指同时搜索所有的子目录。 1grep -R Core /etc/* 搜索所有包含特定单词的文件-w 12grep -sw Core /etc/*grep -Rw Core /etc/* 只输出包含特定单词的文件名-l 1grep -Rwl Core /etc/* 大小写不敏感的搜索-i 1grep -Ri Core /etc/* 搜索时排除某些文件--exclude 1grep -Rl --exclude=*.conf Core /etc/* 搜索时排除某个文件--exclude-dir 1grep -Rl --exclude-dir=/etc/alternatives/ Core /etc/* 搜索结果显示行号-n 1grep -Rnw Core /etc/* 查找不包含指定字符串的文件-v 1grep -Rlv stretch /etc/*]]></content>
      <categories>
        <category>工作学习</category>
      </categories>
      <tags>
        <tag>代码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Codewars每日一题】- Invert values]]></title>
    <url>%2FCodewars-Invert%20values.html</url>
    <content type="text"><![CDATA[题目题目地址 Given a set of numbers, return the additive inverse of each. Each positive becomes negatives, and the negatives become positives. 123invert([1,2,3,4,5]) == [-1,-2,-3,-4,-5]invert([1,-2,3,-4,5]) == [-1,2,-3,4,-5]invert([]) == [] You can assume that all values are integers. 思路遍历列表，分别对每个数字取相反数，再将其放入到新的list里。 答案我的答案12345def invert(lst): result = [] for a in lst: result.append(0-a) return result 最佳答案12def invert(lst): return [-x for x in lst] 12def invert(lst): return [i*-1 for i in lst] 本题还是比较简单的，没有很多技巧。主要在于如何取相反数，一般有两种方法，用-x或者x * -1。另外需要熟悉return [-x for x in lst]这种list的处理方式。 知识点list.append()sort()与sorted()的不同在于，sort()是在原位重新排列列表，而sorted()是产生一个新的列表，也就是说sorted()函数有一个copy的过程，这样多少会带来性能的损耗。另外二者的使用方法也有不同。 描述append()方法用于在列表末尾添加新的对象。 语法list.append(obj) obj – 添加到列表末尾的对象。 返回值该方法无返回值，但是会修改原来的列表。 示例12345678910&gt;&gt;&gt; a = []&gt;&gt;&gt; a.append(1)&gt;&gt;&gt; a[1]&gt;&gt;&gt; a.append([2,3,'a'])&gt;&gt;&gt; a[1, [2, 3, 'a']]&gt;&gt;&gt; a.extend([2,3,'a'])&gt;&gt;&gt; a[1, [2, 3, 'a'], 2, 3, 'a'] 注意append()与extend()的不同。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>codewars</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Codewars每日一题】- Sum without highest and lowest number]]></title>
    <url>%2FCodewars-Sum%20without%20highest%20and%20lowest%20number.html</url>
    <content type="text"><![CDATA[题目题目地址 Sum all the numbers of the array (in F# and Haskell you get a list) except the highest and the lowest element (the value, not the index!).(The highest/lowest element is respectively only one element at each edge, even if there are more than one with the same value!) Example:12&#123; 6, 2, 1, 8, 10 &#125; =&gt; 16&#123; 1, 1, 11, 2, 3 &#125; =&gt; 6 If array is empty, null or None, or if only 1 Element exists, return 0.Note:In C++ instead null an empty vector is used. In C there is no null. ;-) 思路首先想到的就是对list进行排序，然后剔除最大值和最小值，最后求和。另外，可以结合之前在python cookbook中看到的list中分解元素的方法。 答案我的答案123456def sum_array(arr): if None == arr or len(arr)&lt;3: return 0 arr.sort() _,*result,_ = arr return sum(result) 最佳答案1234def sum_array(arr): if arr == None or len(arr) &lt; 3: return 0 return sum(arr) - max(arr) - min(arr) 12def sum_array(arr): return 0 if arr == None else sum(sorted(arr)[1:-1]) 最佳答案中结合使用了list的各种方法，答案一中使用了sum()、min()、max()方法，而无需再进行排序操作，另外第二个答案巧妙地使用了[1:-1]来对排序后的结果进行切片，但是都需要考虑入参是None的情况。 知识点list.sort()和sorted()sort()与sorted()的不同在于，sort()是在原位重新排列列表，而sorted()是产生一个新的列表，也就是说sorted()函数有一个copy的过程，这样多少会带来性能的损耗。另外二者的使用方法也有不同。 描述sort()函数用于对原列表进行排序，如果指定参数，则使用比较函数指定的比较函数。需要注意的是该方法没有返回值，但是会对列表的对象进行排序。因此当直接print(arr.sort())时得到了一个None。123&gt;&gt;&gt; a = [2,334,12,4,6]&gt;&gt;&gt; print(a.sort())None sorted()函数对所有可迭代的对象进行排序操作。会返回重新排序的列表。123&gt;&gt;&gt; a = [2,334,12,4,6]&gt;&gt;&gt; print(sorted(a))[2, 4, 6, 12, 334] 语法list.sort([func]) func – 可选参数, 如果指定了该参数会使用该参数的方法进行排序。 sorted(iterable[, cmp[, key[, reverse]]]) iterable – 可迭代对象。 cmp – 比较的函数，这个具有两个参数，参数的值都是从可迭代对象中取出，此函数必须遵守的规则为，大于则返回1，小于则返回-1，等于则返回0。 key – 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。 reverse – 排序规则，reverse = True降序 ， reverse = False升序（默认）。 示例12345678910&gt;&gt;&gt; a = [2,334,12,4,6]&gt;&gt;&gt; a[2, 334, 12, 4, 6]&gt;&gt;&gt; sorted(a)[2, 4, 6, 12, 334]&gt;&gt;&gt; a[2, 334, 12, 4, 6]&gt;&gt;&gt; a.sort()&gt;&gt;&gt; a[2, 4, 6, 12, 334]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>codewars</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Codewars每日一题】- Sum of Numbers]]></title>
    <url>%2FCodewars-Sum%20of%20Numbers.html</url>
    <content type="text"><![CDATA[题目题目地址 Given two integers a and b, which can be positive or negative, find the sum of all the numbers between including them too and return it. If the two numbers are equal return a or b. Note: a and b are not ordered! Examples123456get_sum(1, 0) == 1 // 1 + 0 = 1get_sum(1, 2) == 3 // 1 + 2 = 3get_sum(0, 1) == 1 // 0 + 1 = 1get_sum(1, 1) == 1 // 1 Since both are sameget_sum(-1, 0) == -1 // -1 + 0 = -1get_sum(-1, 2) == 2 // -1 + 0 + 1 + 2 = 2 答案我的答案123456789101112def get_sum(a,b): sum = 0 #good luck! if a == b: return a elif a &lt; b: for n in range(a, b+1): sum += n else: for n in range(b, a+1): sum += n return sum 最佳答案12def get_sum(a,b): return sum(xrange(min(a,b), max(a,b)+1)) 明显地，我的答案比较直接，没有考虑使用较为“高级”的方法。 知识点sumsum()方法对系列进行求和计算。 语法sum(iterable[, start]) iterable – 可迭代对象，如列表。 start – 指定相加的参数，如果没有设置这个值，默认为0。 示例123456&gt;&gt;&gt; sum([0,1,2])3&gt;&gt;&gt; sum([0,1,2],1)4&gt;&gt;&gt; sum([0,1,2],2)5 range和xrange在最佳答案中还有另外一种：12def get_sum(a,b): return sum(range(min(a, b), max(a, b) + 1)) 与之前的区别在于这里使用了range()函数。 xrange() 函数用法与 range 完全相同，所不同的是生成的不是一个数组，而是一个生成器。 语法range(start, stop[, step]) start: 计数从 start 开始。默认是从 0 开始。例如range(5)等价于range(0, 5); end: 计数到 end 结束，但不包括 end。例如：range(0, 5) 是[0, 1, 2, 3, 4]没有5 step：步长，默认为1。例如：range(0, 5) 等价于 range(0, 5, 1) 示例xrange()和range()这两个基本上都是在循环的时候用。12345for i in range(0, 100):print ifor i in xrange(0, 100):print i 这两个输出的结果都是一样的，实际上有很多不同，range会直接生成一个list对象：12345678910&gt;&gt;&gt; a = range(0,10)&gt;&gt;&gt; print type(a)&lt;type 'list'&gt;&gt;&gt;&gt; print a[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; print a[0], a[1]0 1&gt;&gt;&gt; a = range(0, 10, 2)&gt;&gt;&gt; print a[0, 2, 4, 6, 8] 而xrange则不会直接生成一个list，而是每次调用返回其中的一个值1234567&gt;&gt;&gt; a = xrange(0,10)&gt;&gt;&gt; print type(a)&lt;type 'xrange'&gt;&gt;&gt;&gt; print axrange(10)&gt;&gt;&gt; print a[0], a[1]0 1 所以xrange做循环的性能比range好，尤其是返回很大的时候！尽量用xrange吧，除非你是要返回一个列表。 注意点前提是你使用的是Python2，因为在Python3中range()是像xrange()那样实现以至于一个专门的xrange()函数都不再存在，xrange()会抛出命名异常。1234&gt;&gt;&gt; a = xrange(0,10)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: name 'xrange' is not defined 另外，在Python3中，range()函数也不再返回一个list。12345&gt;&gt;&gt; a = range(0, 10)&gt;&gt;&gt; print(type(a))&lt;class 'range'&gt;&gt;&gt;&gt; print(type(a))&lt;class 'range'&gt;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>codewars</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下大于2TB硬盘格式化及挂载-GPT分区步骤]]></title>
    <url>%2Flinux%E4%B8%8B%E5%A4%A7%E4%BA%8E2TB%E7%A1%AC%E7%9B%98%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%8F%8A%E6%8C%82%E8%BD%BD.html</url>
    <content type="text"><![CDATA[先介绍两种分区表： MBR分区表：（MBR含义：主引导记录） 所支持的最大卷：2T（T: terabytes,1TB=1024GB） 对分区的设限：最多4个主分区或3个主分区加一个扩展分区。 GPT分区表：（GPT含义：GUID分区表） 支持最大卷：18EB（E：exabytes,1EB=1024TB） 每个磁盘最多支持128个分区 明显地，当磁盘超过2TB时需要使用GBT分区。 parted分区步骤 进入parted在命令行键入命令parted 待格式化分区，如下：1parted /dev/sdb 类似fdisk一样，先选择要分区的硬盘，此处为/dev/sdb。 可以输入p打印磁盘信息，查看分区的情况，找到起始和结束位置。 设置分区类型为gpt1mklabel gpt 开始分区1mkpart primary 0% 100% primary指分区类型为主分区，0是分区开始位置，100%是分区结束位置。相同的命令为： 1mkpart primary 0-1 分区时系统会给出提示。 检查分区检查打印当前分区，查看分区设置是否正确完成后用quit命令退出。 磁盘格式化和挂载格式化磁盘1mkfs.ext3 /dev/sdb1 如果支持ext4可选择格式化为ext4，格式化成ext3的时候又出现问题。ext3默认的block size的大小为4k，最大只能支持8T的空间。格式化时指定block size的大小为8K这样最大可以支持16T的空间。相应命令：1mkfs.ext3 -b 8192 /dev/sdb1 挂载挂载到/home目录下1mount /dev/sdb1 /home/ 自动挂载分区配置当在系统里创建了一个新的分区后，因为mount挂载在重启服务后会失效，所以需要将分区信息写到/etc/fstab文件中让其永久挂载，编辑/etc/fstab里加入：1/dev/sdb1 /home ext3 defaults 0 0 保存退出，重启后/dev/sdb1就会自动挂载到/home目录下]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>系统相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python cookbook代码段]]></title>
    <url>%2Fpython-cookbook%E4%BB%A3%E7%A0%81%E6%AE%B5.html</url>
    <content type="text"><![CDATA[数据结构和算法 数据结构和算法将序列的值赋给多个变量123456789101112&gt;&gt;&gt; data = ['ACM', 50, 91.1, (2012, 12, 21)]&gt;&gt;&gt; data['ACM', 50, 91.1, (2012, 12, 21)]&gt;&gt;&gt; name, shares, price, date = data&gt;&gt;&gt; name'ACM'&gt;&gt;&gt; shares50&gt;&gt;&gt; price91.1&gt;&gt;&gt; date(2012, 12, 21) 有时候，你可能只想解压一部分，丢弃其他的值。对于这种情况Python并没有提供特殊的语法。但是你可以使用任意变量名去占位，到时候丢掉这些变量就行了。123456&gt;&gt;&gt; data = ['ACM', 50, 91.1, (2012, 12, 21)]&gt;&gt;&gt; _, shares, price, _ = data&gt;&gt;&gt; shares50&gt;&gt;&gt; price91.1 解析未知个数的可迭代对象：星号表达式123456789101112131415&gt;&gt;&gt; record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212')&gt;&gt;&gt; name, email, *phone = record&gt;&gt;&gt; name'Dave'&gt;&gt;&gt; email'dave@example.com'&gt;&gt;&gt; phone['773-555-1212', '847-555-1212']&gt;&gt;&gt; *trailing, current = [10, 8, 7, 1, 9, 5, 10, 3]&gt;&gt;&gt; trailing[10, 8, 7, 1, 9, 5, 10]&gt;&gt;&gt; current3 值得注意的是上面解压出的phone_numbers变量永远都是列表类型，不管解压的数量是多少(包括0个)。所以，任何使用到phone_numbers变量的代码就不需要做多余的类型检查去确认它是否是列表类型了。 扩展的迭代解压语法是专门为解压不确定个数或任意个数元素的可迭代对象而设计的。通常，这些可迭代对象的元素结构有确定的规则（比如第1个元素后面都是电话号码），星号表达式让开发人员可以很容易的利用这些规则来解压出元素来。而不是通过一些比较复杂的手段去获取这些关联的的元素值。 结合*和_使用123456&gt;&gt;&gt; record = ('ACME', 50, 123.45, (12, 18, 2012))&gt;&gt;&gt; name, *_, (*_, year) = record&gt;&gt;&gt; name'ACME'&gt;&gt;&gt; year2012 双向队列collections.deque的使用使用deque(maxlen=N)构造函数会新建一个固定大小的队列。当新的元素加入并且这个队列已满的时候，最老的元素会自动被移除掉。12345678910111213&gt;&gt;&gt; from collections import deque&gt;&gt;&gt; q = deque(maxlen=3)&gt;&gt;&gt; q.append(1)&gt;&gt;&gt; q.append(2)&gt;&gt;&gt; q.append(3)&gt;&gt;&gt; qdeque([1, 2, 3], maxlen=3)&gt;&gt;&gt; q.append(4)&gt;&gt;&gt; qdeque([2, 3, 4], maxlen=3)&gt;&gt;&gt; q.append(5)&gt;&gt;&gt; qdeque([3, 4, 5], maxlen=3) 如果你不设置最大队列大小，那么就会得到一个无限大小队列，同时可以在队列的两端执行添加和弹出元素的操作。 1234567891011121314151617&gt;&gt;&gt; q = deque()&gt;&gt;&gt; q.append(1)&gt;&gt;&gt; q.append(2)&gt;&gt;&gt; q.append(3)&gt;&gt;&gt; qdeque([1, 2, 3])&gt;&gt;&gt; q.appendleft(4)&gt;&gt;&gt; qdeque([4, 1, 2, 3])&gt;&gt;&gt; q.pop()3&gt;&gt;&gt; qdeque([4, 1, 2])&gt;&gt;&gt; q.popleft()4&gt;&gt;&gt; qdeque([1, 2]) 堆：heapq模块获取队列中最大或最小的N个元素12345678&gt;&gt;&gt; import heapq&gt;&gt;&gt; nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]&gt;&gt;&gt; lar3 = heapq.nlargest(3, nums)&gt;&gt;&gt; lar3[42, 37, 23]&gt;&gt;&gt; sma3 = heapq.nsmallest(3, nums)&gt;&gt;&gt; sma3[-4, 1, 2] 两个函数都能接受一个关键字参数，用于更复杂的数据结构中：1234567891011121314&gt;&gt;&gt; portfolio = [... &#123;'name': 'IBM', 'shares': 100, 'price': 91.1&#125;,... &#123;'name': 'AAPL', 'shares': 50, 'price': 543.22&#125;,... &#123;'name': 'FB', 'shares': 200, 'price': 21.09&#125;,... &#123;'name': 'HPQ', 'shares': 35, 'price': 31.75&#125;,... &#123;'name': 'YHOO', 'shares': 45, 'price': 16.35&#125;,... &#123;'name': 'ACME', 'shares': 75, 'price': 115.65&#125;... ]&gt;&gt;&gt; cheap = heapq.nsmallest(3, portfolio, key=lambda s: s['price'])&gt;&gt;&gt; cheap[&#123;'name': 'YHOO', 'shares': 45, 'price': 16.35&#125;, &#123;'name': 'FB', 'shares': 200, 'price': 21.09&#125;, &#123;'name': 'HPQ', 'shares': 35, 'price': 31.75&#125;]&gt;&gt;&gt; expensive = heapq.nlargest(3, portfolio, key=lambda s: s['price'])&gt;&gt;&gt; expensive[&#123;'name': 'AAPL', 'shares': 50, 'price': 543.22&#125;, &#123;'name': 'ACME', 'shares': 75, 'price': 115.65&#125;, &#123;'name': 'IBM', 'shares': 100, 'price': 91.1&#125;] 上面代码在对每个元素进行对比的时候，会以price的值进行比较。 对序列排序1234&gt;&gt;&gt; nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]&gt;&gt;&gt; heapq.heapify(nums)&gt;&gt;&gt; nums[-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8] 堆数据结构一个重要的特征就是heap[0]永远是最小的元素，并且剩余的元素可以通过heapq.heappop()方法得到，改方法会将第一个元素弹出，并用下一个最小的元素来取代被弹出元素。1234567891011121314&gt;&gt;&gt; nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]&gt;&gt;&gt; heapq.heapify(nums)&gt;&gt;&gt; nums[-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8]&gt;&gt;&gt; nums[0]-4&gt;&gt;&gt; heapq.heappop(nums)-4&gt;&gt;&gt; nums[1, 2, 2, 23, 7, 8, 18, 23, 42, 37]&gt;&gt;&gt; heapq.heappop(nums)1&gt;&gt;&gt; nums[2, 2, 8, 23, 7, 37, 18, 23, 42] 当要查找的元素个数相对比较小的时候，函数nlargest()和nsmallest()是很合适的。如果你仅仅想查找唯一的最小或最大(N=1)的元素的话，那么使用min()和max()函数会更快些。类似的，如果N的大小和集合大小接近的时候，通常先排序这个集合然后再使用切片操作会更快点 (sorted(items)[:N]或者是sorted(items)[-N:])。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS升级python2到python3]]></title>
    <url>%2FCentOS%E5%8D%87%E7%BA%A7python2%E5%88%B0python3.html</url>
    <content type="text"><![CDATA[CentOS 7 中默认安装了 Python，版本比较低（2.7.5），为了使用新版 3.x，需要对旧版本进行升级。 下载新版本python在python官网下载最新的源码包：https://www.python.org/downloads/source/。 可以直接下载然后上传到服务器，也可以通过wget进行下载：1wget https://www.python.org/ftp/python/3.6.3/Python-3.6.3.tgz 安装准备-提前排雷安装gcc相关1yum install make gcc gcc-c++ 因为是源码编译安装，需要gcc相关组件的支持，否则在编译时会报如下错误。 执行./configure时，报错： 说明没有安装合适的编译器。这时，需要安装/升级gcc及其它依赖包。然后重新执行。 安装zlib相关1yum -y install zlib* 在make阶段，需要zlib组件。否则会报zlib not available的异常。 从错误信息分析，就是缺少了zlib的解压缩类库，安装即可。然后重新编译安装python。 安装readline-devel1yum install readline-devel 否则会出现安装完成后Python终端无法使用退格，上下左右。需要安装readline-devel后重新编译安装Python。 安装配置编译 安装12345tar zxvf Python-3.6.3.tgzcd Python-3.6.3./configuremakemake insatll 验证安装成功以后，就可以查看Python的版本： 一个是旧版本 2.x，另外一个是新版本 3.x。注意：在/usr/local/bin/下有一个python3的链接，指向bin目录下的python 3.6。 安装后的配置设置 3.x 为默认版本查看 Python 的路径，在/usr/bin下面。可以看到python软链接的是python 2.7，所以，执行python就相当于执行python 2.7。1234[root@centos7 bin]# ls -al /usr/bin | grep pythonlrwxrwxrwx. 1 root root 7 8月 17 18:01 python -&gt; python2lrwxrwxrwx. 1 root root 9 8月 17 18:01 python2 -&gt; python2.7-rwxr-xr-x. 1 root root 7136 11月 6 2016 python2.7 备份python21mv /usr/bin/python /usr/bin/python2.7.bak 修改软连接1ln -s /usr/local/bin/python3.6 /usr/bin/python 这时再查看Python版本：12[root@centos7 bin]# python -VPython 3.6.3 配置 yum升级Python之后，由于将默认的python指向了python3，yum不能正常使用，需要编辑 yum的配置文件，改为使用python2.7：123456[root@centos7 bin]# vim /usr/bin/yum#!/usr/bin/python2.7import systry: import yum 同时修改/usr/libexec/urlgrabber-ext-down中的配置。12345[root@centos7 bin]# vim /usr/libexec/urlgrabber-ext-down#! /usr/bin/python2.7# A very simple external downloader# Copyright 2011-2012 Zdenek Pavlas 参考：http://blog.csdn.net/liang19890820/article/details/51079633https://www.cnblogs.com/uangyy/p/5980998.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客同时托管到github和coding]]></title>
    <url>%2Fhexo%E5%8D%9A%E5%AE%A2%E5%90%8C%E6%97%B6%E6%89%98%E7%AE%A1%E5%88%B0github%E5%92%8Ccoding.html</url>
    <content type="text"><![CDATA[之前的hexo博客一直托管在GitHub，最近发现也可以托管在国内的Coding上，下面就记录下本次托管到Coding的过程。 注册首先在需要Coding网站注册账号，点这里进行注册。Coding可以免费托管开源代码，同时他让用户免费建立私有库，提供的服务挺好的，是国内的网站。 创建项目 项目名称最好和Coding用户名相同，这样最后直接访问hoxis.coding.me即可。 开启Pages服务因为之前配置是master分支，所以这里Pages部署来源填master分支。 _config.yml文件配置需要按如下配置，可以同时push到GitHub和Coding，需要将其中的代码仓库地址修改为自己的。12345678deploy: - type: git repo: https://github.com/hoxis/hoxis.github.io.git branch: master - type: git repo: https://git.coding.net/hoxis/hoxis.git branch: master 之前网上看的如下这种配置并不行： 12345deploy:type: gitrepo: github: https://github.com/hoxis/hoxis.github.io.git,master coding: https://git.coding.net/hoxis/hoxis.git,master 结果最终，运行hexo g和hexo d后，可以将博客同时部署到了两个服务器上。就可以通过两个地址进行访问了。https://hoxis.github.iohttps://hoxis.coding.me]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Next 添加菜单分类页面]]></title>
    <url>%2FHexo%2BNext%20%E6%96%B0%E5%A2%9E%E8%8F%9C%E5%8D%95%E5%88%86%E7%B1%BB%E9%A1%B5%E9%9D%A2.html</url>
    <content type="text"><![CDATA[在[Hexo+Next]主题下新增一个资源分类页面。 新建一个页面，命名为resources。1hexo new page "resources" 此时会在hexo &gt; source文件夹中会生成一个resources文件夹。 编辑resources文件夹下的md页面将类型设置为resources，主题将自动为这个页面显示所有分类。 1234title: 常用工具date: 2017-12-14 13:05:38type: "resources"--- 注意：如果有启用多说或者Disqus评论，默认页面也会带有评论。需要关闭的话，请添加字段comments并将值设置为false，如： 12345title: 常用工具date: 2017-12-14 13:05:38type: "resources"comments: false--- 在菜单中添加链接编辑主题的_config.yml，在menu中的添加如下: 12menu: resources: /resources || download ||之前的值是目标链接，之后的是分类页面的图标，图标名称来自于FontAwesome icon。若没有配置图标，默认会使用问号图标。 新添加的菜单需要翻译对应的中文打开hexo&gt;theme&gt;next&gt;languages&gt;zh-Hans.yml，在menu下添加： 1234567891011menu: home: 首页 archives: 归档 categories: 分类 tags: 标签 about: 关于 search: 搜索 schedule: 日程表 sitemap: 站点地图 commonweal: 公益404 resources: 资源 参考：https://github.com/iissnan/hexo-theme-next/wiki/%E5%88%9B%E5%BB%BA%E5%88%86%E7%B1%BB%E9%A1%B5%E9%9D%A2]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何查看某个用户组下所有的用户？]]></title>
    <url>%2F%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E6%9F%90%E4%B8%AA%E7%94%A8%E6%88%B7%E7%BB%84%E4%B8%8B%E6%89%80%E6%9C%89%E7%9A%84%E7%94%A8%E6%88%B7%EF%BC%9F.html</url>
    <content type="text"><![CDATA[查看ftp用户组下面的所有用户。 首先，要知道组的id，即gid。使用命令： 12grep 'ftp' /etc/groupawk -F":" '&#123;print $1"\t\t"$4&#125;' /etc/passwd | grep '50']]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七牛云存储批量删除文件]]></title>
    <url>%2F%E4%B8%83%E7%89%9B%E4%BA%91%E5%AD%98%E5%82%A8%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6.html</url>
    <content type="text"><![CDATA[下载命令行工具windows版qshell下载。 用户认证 进入到刚刚下载的qshell目录 设置当前用户的AccessKey和SecretKey 两个参数点此获取 1qshell account &lt;Your AccessKey&gt; &lt;Your SecretKey&gt; 获取待删除文件列表1qshell listbucket &lt;Bucket&gt; &lt;ListBucketResultFile&gt; 最后会在当前目录生成一个名为&lt;ListBucketResultFile&gt;的文件。 编辑该文件，保留需要删除的文件列表。 文件删除1qshell batchdelete [-force] &lt;Bucket&gt; &lt;KeyListFile&gt; 该选项控制工具的默认行为。默认情况下，对于批量操作，工具会要求使用者输入一个验证码，确认下要进行批量文件操作了，避免操作失误的发生。如果不需要这个验证码的提示过程，可以使用-force选项。 输入确认码ejiaid回车后，即开始了文件删除。]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小书匠配置github图床]]></title>
    <url>%2F%E5%B0%8F%E4%B9%A6%E5%8C%A0%E9%85%8D%E7%BD%AEgithub%E5%9B%BE%E5%BA%8A.html</url>
    <content type="text"><![CDATA[好久没有用小书匠了，下载了最新的版本，惊喜的发现有图床功能了，折腾了一下，发现GitHub的还不错，这里记录下如何设置的。 操作流程：绑定–&gt;图床服务–&gt;githubimg 需要在GitHub上预先创建一个仓库，用来存放图片，然后点击下方的token，来设置token。 点击生成token后复制到上图的token中即可。其他选项可以使用默认的，也可以自行填写。]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【我的马拉松】2015苏州太湖国际马拉松]]></title>
    <url>%2F%E3%80%90%E6%88%91%E7%9A%84%E9%A9%AC%E6%8B%89%E6%9D%BE%E3%80%912015%E8%8B%8F%E5%B7%9E%E5%A4%AA%E6%B9%96%E5%9B%BD%E9%99%85%E9%A9%AC%E6%8B%89%E6%9D%BE.html</url>
    <content type="text"><![CDATA[我的第二场半程马拉松时间：2015年12月27日（周日）9:00地点：苏州高新区科技城完赛用时：01:59:32 图记加油助威看这阵势！ People mountain People sea？ 终点 亮个相 奖牌奖牌设计的原型是江南女子的旗袍，不过老婆说是个啤酒起子，囧~ 完赛证书半马第一次跑进了2小时之内，值得纪念！ 总结这次太湖马拉松，总的来说， 当天的环境不太好，气温比较低， 主办者组织的效果也是一般。 完赛后走到接驳车的地方差不多有两公里了，大家路上各种吐槽：走这么多， 差不多成了全马了。 不过这次毕竟是主场作战，能够刷新了自己的PB，已经很满足啦O(∩_∩)O哈哈~ 继续加油！！！]]></content>
      <categories>
        <category>生活杂技</category>
      </categories>
      <tags>
        <tag>马拉松</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL创建用户与授权]]></title>
    <url>%2F%E3%80%90%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%91MySQL%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7%E4%B8%8E%E6%8E%88%E6%9D%83%EF%BC%9F.html</url>
    <content type="text"><![CDATA[本章节主要介绍MySQL下如何创建用户、对用户授权、设置与更改用户密码、撤销用户权限、删除用户。 一. 创建用户命令:1CREATE USER 'username'@'host' IDENTIFIED BY 'password'; 说明： username：你将创建的用户名 host：指定该用户在哪个主机上可以登陆，如果是本地用户可用localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符% password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器 例子：12345CREATE USER 'dog'@'localhost' IDENTIFIED BY '123456';CREATE USER 'pig'@'192.168.1.101_' IDENDIFIED BY '123456';CREATE USER 'pig'@'%' IDENTIFIED BY '123456';CREATE USER 'pig'@'%' IDENTIFIED BY '';CREATE USER 'pig'@'%'; 二. 授权:命令:1GRANT privileges ON databasename.tablename TO 'username'@'host' 说明: privileges：用户的操作权限，如SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALL databasename：数据库名 tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用*表示，如*.* 例子:12GRANT SELECT, INSERT ON test.user TO 'pig'@'%';GRANT ALL ON *.* TO 'pig'@'%'; 注意:用以上命令授权的用户不能给其它用户授权，如果想让该用户可以授权，用以下命令:1GRANT privileges ON databasename.tablename TO 'username'@'host' WITH GRANT OPTION; 三.设置与更改用户密码命令:1SET PASSWORD FOR 'username'@'host' = PASSWORD('newpassword'); 如果是当前登陆用户用:1SET PASSWORD = PASSWORD("newpassword"); 例子:1SET PASSWORD FOR 'pig'@'%' = PASSWORD("123456"); 四. 撤销用户权限命令:1REVOKE privilege ON databasename.tablename FROM 'username'@'host'; 说明:privilege, databasename, tablename：同授权部分 例子:1REVOKE SELECT ON *.* FROM 'pig'@'%'; 注意:假如你在给用户&#39;pig&#39;@&#39;%&#39;授权的时候是这样的（或类似的）：GRANT SELECT ON test.user TO &#39;pig&#39;@&#39;%&#39;，则在使用REVOKE SELECT ON *.* FROM &#39;pig&#39;@&#39;%&#39;;命令并不能撤销该用户对test数据库中user表的SELECT 操作。相反，如果授权使用的是GRANT SELECT ON *.* TO &#39;pig&#39;@&#39;%&#39;;则REVOKE SELECT ON test.user FROM &#39;pig&#39;@&#39;%&#39;;命令也不能撤销该用户对test数据库中user表的Select权限。 具体信息可以用命令SHOW GRANTS FOR &#39;pig&#39;@&#39;%&#39;; 查看。 五.删除用户命令:1DROP USER 'username'@'host';]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设置MySQL允许用户远程登录？]]></title>
    <url>%2F%E3%80%90%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%91%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AEMySQL%E5%85%81%E8%AE%B8%E7%94%A8%E6%88%B7%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95%EF%BC%9F.html</url>
    <content type="text"><![CDATA[项目中需要连接虚拟机上面的MySQL数据库，但是总是出错，怀疑本机是否有连接远程数据库的权限。 执行命令：12mysql&gt; use mysql;mysql&gt; select host,user from user; 查看结果是不是root用户仅允许本地（localhost）登录，下面这个截图就是这种情况： 是的话，就要修改它的host为%，表示任意IP地址都可以登录。 1mysql&gt; update user set host = '%' where user = 'root'; 执行完后可能提示error。再mysql&gt; select host,user from user;查看下吧。 root对应的host成了%，表示可以任意IP地址登录了。 1mysql&gt; flush privileges; 把缓存flush掉，在使用update语句修改用户记录后，需要FLUSH语句告诉服务器重载授权表。 之后就可以在远程使用当前的数据库连接了。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设置ibatis 后台打印完整的sql语句？]]></title>
    <url>%2F%E3%80%90%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7%E3%80%91%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AEibatis%20%E5%90%8E%E5%8F%B0%E6%89%93%E5%8D%B0%E5%AE%8C%E6%95%B4%E7%9A%84sql%E8%AF%AD%E5%8F%A5%EF%BC%9F.html</url>
    <content type="text"><![CDATA[在项目开发时都大家都希望将SQL在后台打印出来，以帮助开发以及后续的bug修改。如果用JDBC那么可以方便的打印，可使用ibatis就不知道怎么办了，最近在网上找了一段log4j的配置可以很保姆的处理这个问题。这里贴出来给大家参考一下。 建立一个log4j.properties文件，放到工程源文件夹下，如果是eclipse那么放到src下，eclipse会自动将这个文件加载到class目录下。如下图 如果是JB，那么要设置，这类型的文件也加载到目标项目中。 将log4j.jar和commons-logging.jar（我这次就是落下了这个jar！）放到项目的类路径中，如果是web项目就是lib下。 配置的log4j.properties文件的例子。证明可用！ 123456789101112log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n log4j.logger.com.ibatis=debug log4j.logger.com.ibatis.common.jdbc.SimpleDataSource=debug log4j.logger.com.ibatis.common.jdbc.ScriptRunner=debug log4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=debug log4j.logger.java.sql.Connection=debug log4j.logger.java.sql.Statement=debug log4j.logger.java.sql.PreparedStatement=debug,stdout 在项目试运行需要维护得阶段可以把debug改为error，这样服务器后台只打印报错信息，这样既可以看清错误又可以减轻服务器负担（后台不断打印数据很消耗服务器资源的。。）]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新版38.0.5火狐如何安装 pocket 插件？]]></title>
    <url>%2F%E3%80%90%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7%E3%80%91%E6%96%B0%E7%89%8838.0.5%E7%81%AB%E7%8B%90%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85%20pocket%20%E6%8F%92%E4%BB%B6%EF%BC%9F.html</url>
    <content type="text"><![CDATA[在新版的Firefox 38.0.5中，原生集成了pocket收藏的功能，但是用起来体验太烂了，和之前的插件版pocket没法比啊。 保存到 Pocket 按钮被放置到了工具栏上，而进入 Pocket 则与书签在一起，但是，点击View Pocket List 后，是直接打开 Pocket 网站，这里并没有整合进 Firefox，总之用起来十分之不爽！ 还好我大天朝人才济济，我们还可以通过从文件安装附加组件的方式来安装pocket。 安装步骤 pocket插件下载地址： http://hoxis-github-io.qiniudn.com/pocket-3.0.6-fx.xpi 下载完成后，在附件组件管理界面，选择从文件安装附加组件： 选中下载好的插件后，确认安装即可： 至此，就可以继续使用pocket插件啦~ O(∩_∩)O~~ 另外，在下面可以找到一些其他的插件下载： http://sourceforge.net/projects/lightfirefox/files/Addons%20modified%20for%20Light/ http://pan.baidu.com/wap/shareview?&amp;shareid=2744799423&amp;uk=1580071060&amp;dir=%2F%E7%81%AB%E7%8B%90%E5%88%86%E4%BA%AB&amp;page=1&amp;num=20&amp;fsid=717724874162443&amp;third=0&amp;]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10下安装 迅雷精简版，提示阻止此应用]]></title>
    <url>%2F%E3%80%90%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7%E3%80%91win10%E4%B8%8B%E5%AE%89%E8%A3%85%20%E8%BF%85%E9%9B%B7%E7%B2%BE%E7%AE%80%E7%89%88%EF%BC%8C%E6%8F%90%E7%A4%BA%E9%98%BB%E6%AD%A2%E6%AD%A4%E5%BA%94%E7%94%A8.html</url>
    <content type="text"><![CDATA[管理员cmd打开安装程序，输入程序地址enter。 升级win10后，win10的系统安全性提升了许多，这样就导致一些软件不能随意安装，比如迅雷精简版。迅雷精简版本来是一个神器啊，没有广告，没有乱七八糟的插件，但是安装时却被系统阻止了，比如这样： 网上找了各种办法，什么修改权限啊、修改系统过滤条件啊等等等灯。 还是这个方法靠谱： 管理员cmd打开安装程序，输入程序地址，回车Enter！ win + s，输入cmd，在命令提示符上右击，选择以管理员身份运行，输入程序地址，如D:\download\ThunderMini_dl1.5.3.288.exe，回车，这样就出来了程序安装页面，之后就可以就行正常的安装步骤了，如图。]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【我的马拉松】2015南京国际马拉松]]></title>
    <url>%2F%E3%80%90%E6%88%91%E7%9A%84%E9%A9%AC%E6%8B%89%E6%9D%BE%E3%80%912015%E5%8D%97%E4%BA%AC%E5%9B%BD%E9%99%85%E9%A9%AC%E6%8B%89%E6%9D%BE.html</url>
    <content type="text"><![CDATA[我的第一场正式马拉松时间：2015年11月29日（星期日）8:30地点：南京奥体中心完赛用时：02:06:01 图记起点当天天气还是不错的 看那个招手的doubi，对！那不是我~ 中途传说中的仪凤门，是南京明城墙十三座内城门之一。 终点前的一个桥 终点 奖牌南京马拉松的奖牌设计的还是蛮好看的，在本人伟岸的身影衬托下，显得更加精致了~ 再来个背面： 完赛证书第一次完成正式马拉松的成绩，自己还是很满意的。 总结第一次正式马拉松，还是在这个自己学习生活了三年的地方，值得纪念。 继续加油！！！]]></content>
      <categories>
        <category>生活杂技</category>
      </categories>
      <tags>
        <tag>马拉松</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义 input type="file" 文件上传样式]]></title>
    <url>%2F%E8%87%AA%E5%AE%9A%E4%B9%89input%20type%3Dfile%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%A0%B7%E5%BC%8F.html</url>
    <content type="text"><![CDATA[本文主要介绍如何修改原生的&lt;input type=&quot;file&quot;&gt;标签的显示效果，自定义实现文件上传的样式。 原生的&lt;input type=&quot;file&quot;&gt;标签在Firefox下显示是这样的：而在chrome显示是这样的： 其中的选择文件的按钮和后面文字是一体的，点击后面的文字同样可以进行文件选择，这是原生&lt;input type=&quot;file&quot;&gt;标签显示的结果。 有些人想自定义显示按钮上的文字（各个浏览器下面显示还不一样，坑啊），或者 自定义 后面显示的文字，又或者不想让用户点击文字就可以上传文件，等等。 自定义样式实现思路隐藏&lt;input type=&quot;file&quot;&gt;，自己写一个按钮，加上onclick事件，触发file文件域。具体做法如下： 页面上放个隐藏的&lt;input type=&quot;file&quot;&gt;; 然后加上一个文本&lt;a id=&quot;filename&quot;&gt;请选择文件&lt;/a&gt;用于显示文件名和一个按钮input（type=”button”） 点按钮的时候调用&lt;input type=&quot;file&quot;&gt;的click选择文件 在&lt;input type=&quot;file&quot;&gt;的onchange事件中把其值显示在文本&lt;a&gt;中 实现代码页面显示部分12345&lt;form id='mainForm' action="xxx.action" method="post" name="mainForm"&gt; &lt;input type="button" value="选择文件" onclick="document.mainForm.excel.click()"&gt; &lt;a id="filename"&gt;请选择文件&lt;/a&gt; &lt;input type="file" name="excel" id="excel" accept="application/vnd.ms-excel" style="display:none" onChange="changeText(this)"&gt;&lt;/form&gt; js代码处理123456789101112function changeText(th)&#123; var filename = document.getElementById("filename"); var exist = th.value.lastIndexOf("\\"); // 火狐浏览器直接可以获取到文件名 if(exist == -1)&#123; filename.textContent = th.value; &#125; //chrome可以获取到绝对路径 else&#123; filename.textContent = th.value.substring(exist + 1); &#125;&#125; 注意事项刚开始考虑如何在选择文件后将文件名显示在按钮后面时，考虑的是使用innerText方法，将读取的文件名塞到&lt;a&gt;标签内。但是发现innerText方法在Firefox下不起作用。在网上查了相关资料后发现innerText方法并非W3C标准属性，因此我们无法在FireFox中使用它，一般情况下我们可以使用textContent来代替。具体的区别可以参考文章：被玩坏的innerHTML、innerText、textContent和value属性]]></content>
      <categories>
        <category>前端相关</category>
      </categories>
      <tags>
        <tag>文件上传</tag>
        <tag>样式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CXF WebService 客户端设置超时时间]]></title>
    <url>%2FCXF%20WebService%20%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%AE%BE%E7%BD%AE%E8%B6%85%E6%97%B6%E6%97%B6%E9%97%B4.html</url>
    <content type="text"><![CDATA[本文主要介绍CXF WebService 客户端如何设置超时时间，以及相关参数的介绍。 在使用WebService时，出现了超时的异常，如下。1234567891011121314151617181920警告: Interceptor for &#123;http://www.idc.com/idc/idc.wsdl&#125;SouthBaseService#&#123;http://www.idc.com/idc/idc.wsdl&#125;SyncVmInfo has thrown exception, unwinding noworg.apache.cxf.interceptor.Fault: Could not send Message....Caused by: java.net.SocketTimeoutException: SocketTimeoutException invoking http://127.0.0.1:8081/njrs/SouthBaseWS: Read timed out...Caused by: java.net.SocketTimeoutException: Read timed out at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.read(SocketInputStream.java:152) at java.net.SocketInputStream.read(SocketInputStream.java:122) at java.io.BufferedInputStream.fill(BufferedInputStream.java:235) at java.io.BufferedInputStream.read1(BufferedInputStream.java:275) at java.io.BufferedInputStream.read(BufferedInputStream.java:334) at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:689) at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:633) at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1324) at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468) at org.apache.cxf.transport.http.HTTPConduit$WrappedOutputStream.handleResponseInternal(HTTPConduit.java:2165) at org.apache.cxf.transport.http.HTTPConduit$WrappedOutputStream.handleResponse(HTTPConduit.java:2134) at org.apache.cxf.transport.http.HTTPConduit$WrappedOutputStream.close(HTTPConduit.java:1988) ... 105 more 最初的想法是觉得肯定有地方是可以设置这么一个超时时间的，但是却苦苦找不到设置的地方，最终经过各种折腾，Google之百度之，找到了解决办法。 Using WebService, we usually set in the client request timeout limit in order to avoid long time to connect to the server is unavailable. CXF environment, the client can be configured through two properties timeout limit: 在使用网络服务时，通常需要为客户端设置请求超时时间，以避免长时间的去连接不可用的服务器。在CXF环境中，客户端可以通过两个参数配置超时限制： The ConnectionTimeout: WebService based TCP connection, this property can be understood as TCP handshake time settings, exceeds the time that it is the connection timeout in milliseconds, the default is 30000 milliseconds, or 30 seconds. ConnectionTimeout: WebService是基于TCP连接的，因此这个属性可以理解为设置TCP握手时间，若超出这个时间就认为连接超时。默认的时间单位是毫秒，默认设置是30000毫秒，即30秒。 ReceiveTimeout: this property WebService request is sent to wait for a response time exceeds the length of time that it is the response timeout in milliseconds, the default is 60000 milliseconds, or 60 seconds. ReceiveTimeout: 这个属性表示发送WebService请求后所等待响应的时间，若超过设置的时间则认为超时。默认的时间单位是毫秒，默认设置是60000毫秒，即60秒。 Here are two ways to configure the client:下面有两种方法可以在客户端进行配置： In the spring configuration file settings. 在spring配置文件中进行配置。 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:jaxws="http://cxf.apache.org/jaxws" xmlns:http-conf="http://cxf.apache.org/transports/http/configuration" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-2.0.xsd http://cxf.apache.org/jaxws http://cxf.apache.org/schemas/jaxws.xsd http://cxf.apache.org/transports/http/configuration http://cxf.apache.org/schemas/configuration/http-conf.xsd "&gt; &lt;http-conf:conduit name="&#123;WSDL Namespace&#125;portName.http-conduit"&gt; &lt;http-conf:client ConnectionTimeout="10000" ReceiveTimeout="20000"/&gt; &lt;/http-conf:conduit&gt; &lt;/beans&gt; It should be noted there are several places:1, we need to specify the http-conf namespace: xmlns: http-conf =2, the location of the specified pattern:Http-conf: Conduit name attribute to specify service settings to take effect. by the service namespace in the WSDL port name. “http-conduit”, the name attribute, such as the {} HelloWorld.http in-conduit. If the name attribute is set to “http-conduit”, will be effective for all services. 如下几点需要注意： 需要指定http-conf的命名空间：xmlns:http-conf=&quot;http://cxf.apache.org/transports/http/configuration&quot; 指定模式位置: http://cxf.apache.org/transports/http/configuration http://cxf.apache.org/schemas/configuration/http-conf.xsd http-conf:conduit中的name属性,指定设置生效的服务。name属性由service的namespace、WSDL中的 port name和”.http-conduit”组成，如{http://apache.org/hello_world}HelloWorld.http- conduit。如果将name属性设置为“*.http-conduit”，则会对所有服务生效。 Java code to be set. 使用Java代码设置：1234567Client client = ClientProxy.getClient (port);HTTPConduit http = (HTTPConduit) client.getConduit();To = new HTTPClientPolicy (HTTPClientPolicy httpClientPolicy);httpClientPolicy.setConnectionTimeout (36000);httpClientPolicy.setAllowChunking (false);httpClientPolicy.setReceiveTimeout (32000);http.setClient (httpClientPolicy); Server-side set spring code is as follows: 服务器端的spring代码配置如下： 1234&lt;! - On the server side to set the response timeout limit, now is the default value of 30 seconds -&gt;&lt;http-conf:destination name="*.http-conduit"&gt;&lt;http-conf:server ReceiveTimeout="30000" /&gt;&lt;/ Http-conf: destination&gt; 参考：http://www.javawebdevelop.com/3314355/]]></content>
      <categories>
        <category>工作学习</category>
      </categories>
      <tags>
        <tag>WebService</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CMDBuild安装及其webservice接口的获取]]></title>
    <url>%2FCMDBuild%E5%AE%89%E8%A3%85%E5%8F%8Awebservice%E6%8E%A5%E5%8F%A3%E7%9A%84%E8%8E%B7%E5%8F%96.html</url>
    <content type="text"><![CDATA[最近项目组之前一直使用的OneCMDB出现了问题，在增删改数据时异常的慢，于是考虑是否可以优化OneCMDB，由于本人水平有限，对OneCMDB进行代码级别的优化暂时还有点难度。于是就对现有的其他开源CMDB进行调研，首先是CMDBuild（官方网站）。 对于CMDBuild，先上结论。 优缺点优点 完全自主的系统配置 界面炫酷美观，AJAX让人操作十分便捷 数据格式自由定制（在GLPI中，资产的数据格式都已经定义好了，用户很难修改） 有专门的团队在进行不断的维护，目前最新的版本是2015年6月发布的2.3.2 内置工作流引擎，可以创建工作流 报表系统：支持JasperReports、Alfresco 提供基于SOAP和REST的webservice接口缺点 网上资料少，极其少！差不多只有安装的介绍！ 官方提供的代码示例几乎没有，这让开发者自己摸索么？还是我没找到？ 提供的webservice接口是wsdl和wadl形式的，不能给个jar包什么的吗？ 安装参考：http://www.cnblogs.com/supakito/p/cmdbuild_install.htmlhttp://20988902.blog.51cto.com/805922/1541289 安装要求 硬件： server-class computer (modern architecture) 4GB of RAM 80 GB of available hard disk space 软件： 任何支持以下应用的OS (推荐linux) PostgreSQL 9.0 or higher (PostgreSQL 9.3 recommended) Apache Tomcat 6.0 or higher（好像7.0不支持） JDK 1.6 安装步骤 安装jdk，tomcat（不再赘述） 安装PostgreSQL并配置 将下载好的cmdbuild-2.3.2.zip解压，文件目录如下图所示， 将其中的cmdbuild-2.3.2.war拷贝到Tomcat的webapps文件夹下，将其重命名为cmdbuild.war 将cmdbuild-2.3.2\extras\tomcat-libs\6.0下的postgresql-9.1-901.jdbc4.jar拷贝到Tomcat的lib文件夹下 启动tomcat，开始解析cmdbuild.war tomcat启动成功后，在地址栏输入localhost:8080/cmdbuild，可以进入如下界面： 点击next，进入下一个界面 按照如图所示进行配置，可以测试下数据库连接是否可以。如果没有错误出现，那么就可以进入到主界面了，炫酷！ 至此，CMDBuild的安装就完成了。 webservice接口的获取在找CMDBuild的接口时可是费了很大劲，最后在一个角落里找到了一点痕迹，http://hostname:port/cmdbuild/services/rest/v1，于是按照这个地址拼接了自己的获取地址：http://localhost:8080/cmdbuild/services，就这样终于找到了所谓的webservice接口。但其中SOAP是WSDL形式的，REST是WADL形式的。于是乎，又想着如何将wsdl的接口变成java的。 WSDL2Java利用jdk自带的工具wsimport.exe就可以实现： 1wsimport http://127.0.0.1/TicketMobile/services/Cococ?wsdl -keep -p com.llg.ws2 -s g:/ws 参数说明 wsimport 这个是必须的 该工具的名称 http://127.0.0.1/TicketMobile/services/Cococ?wsdl wsdl文件链接 -keep 是否生成源文件 -p com.llg.ws2 生成后的java包名 -s g:/ws 生成后放哪个目录 于是，就可以将wsdl的接口变成java的，于是按照文档上的例子兴高采烈的开始敲代码。。。 官方文档上只有这么一点代码： 123456789101112131415161718192021222324252627// 1. Create an instance in the ConfigurationContext class and indicate in it where the repository directory is. In the repository directory there are 2 directories: the modules directory which contains the rampart.mar file, and the conf directory which contains the file to define the safety policy which should be adopted.ConfigurationContext configContext = ConfigurationContextFactory .createConfigurationContextFromFileSystem("/path/to/repository",// null);//// 2. Instance the WebservicesStub class moving in it the ConfigurationContext just created WebServicesStub stub = new WebServicesStub(configContext);// 3.Set the authentication credentialsStAXOMBuilder builder = new StAXOMBuilder( "/path/to/repository/conf/policy.xml");//Options options = stub._getServiceClient().getOptions();options.setUserName("username");options.setPassword("password");options.setProperty(// RampartMessageData.KEY_RAMPART_POLICY,// PolicyEngine.getPolicy(builder.getDocumentElement()// ));// 4.Instance a GetCardList object and call the serverGetCardList list = new GetCardList();list.setClassName("Computer");GetCardListResponse response = stub.getCardList(list);Card[] card = response.get_return();// 5.At this point you can iterate on the array card content and extract the most interesting values. For example, if you want to recover the description of every Computer, the following method will be enough:System.out.println(card[i].getDescription()); 至此，官方代码提供完毕，可是WebServicesStub哪来的？其他的类还可以通过Google找到相关的jar包，可是WebServicesStub哪来的？ WebServicesStub的来头最后，网上各种找啊，凡是相关的资料都试了，终于在stub调用WebService这里找到了管用的方法。 使用Axis2提供的wsdl2java.bat命令可以根据WSDL文件产生调用WebService的代码 具体操作，下载安装Axis2不说了。 进入到%AXIS2_HOME%\bin\，执行1wsdl2java -uri http://localhost:8080/cmdbuild/services/soap/Webservices?wsdl -p client -s -o stub 其中-url参数指定了wsdl文件的路径，可以是本地路径，也可以是网络路径。-p参数指定了生成的Java类的包名，-o参数指定了生成的一系列文件保存的根目录。 在执行完上面的命令后，读者就会发现在当前目录下多了个stub 目录，在stub/src/client目录可以找到一个$Proxy146ServiceStub.java文件（奇怪的名字，因为提供的wsdl文件里就是这个名字），该文件复杂调用WebService，读者可以在程序中直接使用这个类。 最后的最后，终于可以用WebServicesStub了，可是问题还是有，等我先折腾折腾吧。有什么问题可以直接留言一起讨论。 ##总结 CMDBuild是由意大利的公司所开发的一款开源CMDB产品，网上相关的资料很少，中文的资料就更少，只有一些简单的安装介绍的文章，而关于其如何使用的资料几乎没有，只有官方所提供的手册。然而其只是给出了SOAP的WSDL格式的接口，并没有其他的jar文件，并且在其官方使用手册中只有简单的使用示例代码，对于其中一些类的来源也没有给出，没有一个完善的api开发文档，因此若要真正的使用起来尚有一定的困难，暂时还不能进行代码级别的测试。]]></content>
      <categories>
        <category>工作学习</category>
      </categories>
      <tags>
        <tag>CMDBuild</tag>
        <tag>CMDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书笔记-《JavaScript DOM编程艺术》]]></title>
    <url>%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8AJavaScript%20DOM%E7%BC%96%E7%A8%8B%E8%89%BA%E6%9C%AF%E3%80%8B.html</url>
    <content type="text"><![CDATA[第1章第2章1.最好的方法是将&lt;script&gt;标签放在HTML文档的最后，&lt;/body&gt;之前，这样可以使得浏览器更快的加载页面。 2.解释型语言 3.注释：建议用 123456//单行注释/* 多行注释 多行注释*/ 4.变量区分大小写 5.弱类型语言，不需要类型声明。 6.支持字符串.数值.浮点数.布尔值. 7.数组Array，数组中的元素可以是不同类型的数据，或者变量 如：12345var arr = Array(4);var arr = Array();arr[2]="test";var arr = [1,2,3,"test"]; 关联数组 8.对象声明对象：1234var lennon = Object();lennon.name = "John";lennon.year = 1940;lennon.isLiving = false; 或者：1var lennon = &#123;name:"John", year:1940, isLiving:false&#125;;//这不是JSON吗？ 9.条件语句 if(){}else{}同Java一样 10.=，==，==== 赋值== 比较值，不严格，””==false，成立！=== 严格比较，不仅比较值，还会比较变量的类型 11.用户自定义对象1var liuhao = new Person;//和java相比，没有括号 12.内建对象:Array.Math.Date数组，12var persons = new Array();persons.length; 13.宿主对象：由运行环境（Web浏览器）提供的，包括Form.Image.Element等，用来获取网页上的表单.表单元素等信息 第3章14.DOM：Document.Object.Model。加载到当前窗口的网页，可以使用js去读取其中的内容。 15.window对象，对应浏览器本身，其属性和方法通常称为BOM（浏览器对象模型）。window.open.window.blur等方法。各种弹出广告的实现 16.HTML DOM 树形结构: 17.CSS的简单使用123selector&#123; property:value;&#125; 如：1234p&#123; color:yellow; font-size:1.2em;&#125; 18.CSS属性的继承：节点树上的各个元素将继承其父元素的样式属性，如：1234body&#123; color:white; background-color:black;&#125; 将作用于嵌套在body元素内部的所有元素。 19.class属性：可以在所有的元素上添加class属性：12&lt;p class="special"&gt;This is a special p.&lt;p/&gt;&lt;h2 class="special"&gt;This is a special p.&lt;/h2&gt; 可以通过如下的方式设置上面两个元素的属性：123.special&#123; font-style:italic;&#125; 也可以单独设置某种元素的class属性：123p.special&#123; font-style:italic;&#125; 20.id属性：网页元素的唯一标示符，对于&lt;ul id=&quot;abc&quot;&gt;，可以这样设置它的属性：123#abc&#123; color:black&#125; 也可以利用id属性为包含在该元素中的其他元素设置样式：123#abc li&#123; font-style:italic;&#125; 21.获取元素对象：通过ID.标签名（如p.li等标签）.类名 document.getElementById(&quot;demo&quot;)：返回一个对象 element.getElementsByTagName(&quot;li&quot;)：返回一个对象数组，其中每个对象对应着文档中有着给定标签的一个元素。该方法允许使用通配符， getElementsByClassName()：返回一个对象数组，可以查找带有多个类名的元素。 22.获取 设置元素属性 object.getAttribute(attribute)，attribute：待查询元素的属性的名字，如&lt;p title=&quot;提醒&quot;&gt;不要忘了买这些！&lt;/p&gt;里的title属性 object.setAttribute(attribute,value)，将属性attribute的值设置为value 23.DOM工作模式：先加载文档的静态内容，再动态刷新，动态刷新不影响文档的静态内容。 第4章24.事件函数的处理机制：在给某个元素添加了事件处理函数（如onclick）后，一旦事件发生，就会执行相应的JavaScript代码，被调用的JavaScript代码可以返回一个值，这个值将会传递给那个事件处理函数（onclick）。例如，给一个链接添加一个onclick函数，并让该函数返回一个布尔类型的值。这样一来，当这个链接被点击时，如果那段代码返回了true，那么onclick函数就认为这个“链接被点击了”；如果返回了false，那么就会认为这个链接“没有被点击”。如：1&lt;a href="http://www.baidu.com" onclick="return false;"&gt;点我&lt;/a&gt; 点击后，将不会触发链接默认的行为（跳转）。 25.想在页面加载时运行函数count，可以这样设置1window.onload = count; 26.childNodes属性：可以用来获取任何一个元素的所有子元素，是一个包含其全部子元素的数组，包含的不仅仅是元素节点（ul、img等），甚至连空格和换行符都被当作节点。 27.nodeType属性：node.nodeType获取节点的nodeType属性，返回的是一个数字，共有12种取值，常用的有： 元素节点：1 属性节点：2 文本节点：3 28.nodeValue属性：node.nodeValue获取/设定一个节点的值。1&lt;p id="description"&gt;选个图吧&lt;/p&gt; &lt;p&gt;的nodeValue属性将是一个空值null，包含在&lt;p&gt;元素中的文本是另外一个节点，是&lt;p&gt;元素的一个子节点。 29.firstChild和lastChild属性：node.firstChild等价于node.childNodes[0]，node.lastChild等价于node.childNodes[node.childNodes.length-1] 待更新。。。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YiYi]]></title>
    <url>%2FYiYi-A-One-and-a-Two.html</url>
    <content type="text"><![CDATA[“我好想你。尤其是当我看到那个，还没有名字的小表弟，就会想起你常跟我说：你老了。我很想跟他说我觉得……我也老了。” 婆婆，对不起，不是我不喜欢跟你讲话，只是我觉得我能跟你讲的你一定老早就知道了。不然，你就不会每次都叫我“听话”。就像他们都说你走了，你也没有告诉我你去了哪里，所以，我觉得，那一定是我们都知道的地方。婆婆，我不知道的事情太多了，所以，你知道我以后想做什么吗？我要去告诉别人他们不知道的事情，给别人看他们看不到的东西。我想，这样一定天天都很好玩。说不定，有一天，我会发现你到底去了哪里。到时候，我可不可以跟大家讲，找大家一起过来看你呢？婆婆，我好想你，尤其是我看到那个还没有名字的小表弟，就会想起，你常跟我说：你老了。我很想跟他说，我觉得，我也老了…… 有一幅很著名的画：太阳在海平面之上，阳光洒下整片海，沙滩上有几个人正朝着太阳的方向仰望，你认为是日出还是日落？据说看到日出的人充满朝气，是乐观主义者；看到日落的人暮气沉沉，是悲观主义者。某天有人问我，你看到的是日出还是日落？虽然我知道这个寓意，却不想掩饰什么，我说我看到的是日落，他说你真的老了。也是在那天我看了《一一》，本来很淡然的我却在片尾曲响起的时候，呆坐在那里，掩面而泣，好像活了一辈子那么长，好像又只有三个小时那么短，我想起电影里的一句台词：电影的发明使我们的人生延长了三倍。这部电影让我从十岁活到了六十岁，最后由婆婆的去世到舅舅的孩子出生经历了轮回。 十岁的我是洋洋 我有个知识丰富的爸比，一个神经质的妈妈，一个温柔的姐姐，一个总叫我“听话”的婆婆。我总是被女生欺负，我不喜欢学校的“小老婆”。有一天，我听见隔壁的人在吵架。第二天，在电梯口遇见了那个阿姨，我想转过去看她。爸比说：“洋洋，不能这么看人家。这样很不礼貌，人家会生气的。” 我说：“可是我想知道她在难过什么。我从后面看不到啊。”我跟爸比说：“爸比，你看到的我看不到，我看到的你也看不到。我怎么知道你在看什么呢？”于是爸比就教我拍照。我每天都给周围的人拍背影，因为他们看不到我就拍给他们看。我用我的眼睛看到的世界讲给大人们听，他们听不懂，他们不相信，于是我就拍下来。后来，我发现“小老婆”也并不是很坏，婆婆死了，我跟他说对不起。就这样，拍着拍着，我就二十岁。 二十岁的我是婷婷 我有个很疼我的爸爸，一个老被女生欺负的弟弟，一个有气质的婆婆。我跟隔壁家的莉莉是朋友，我喜欢她的男朋友胖子。这些我都不敢跟别人说，可是堵在心里很难受，于是我就跟婆婆说。我不明白为什么舅舅不娶云云阿姨。我问爸爸：“如果阿弟舅舅不是坏人，那小燕阿姨一定有问题了咯？”我以为爱情有好坏对错之分，好人就应该得到爱情，坏人就不应该得到爱情。我开始跟胖子约会，后来他们还是重新在一起了，我觉得不公平，我没有做什么坏事情，为什么胖子就不喜欢我。再后来，经历了很多事，胖子为了莉莉杀死了与她妈妈有染的人，我的爱情也在他的咆哮中流失了，婆婆也死了。突然间我就明白了关于爱情的很多事。就这样，想着想着，我就三十岁了。 三十岁的我是舅舅 我有个很老实的姐夫，一个很关心我的姐姐，一个很凶的老婆，一个善解人意的前女友云云。我很相信算命，每天都在想如何捞钱，却总是郁郁不得志。我以为我很能说，但是当我和妈妈说话的时候却什么也说不出来。我很害怕我的老婆，我不知道是为了肚子里的孩子还是真的爱她。当孩子满月的那天，云云来了，老婆很不爽，结果同学和她吵了起来，我不知道怎么办，我痛恨自己的懦弱。那天我失魂落魄的回家，第二天，老婆在浴室看到昏倒的我，我想有那么一刹那我真的想死掉。后来，我的妈妈去世了，我的生意也开始转好。就这样，混着混着，我就四十岁了。 四十岁的我是敏敏或者NJ 我有个很木讷的丈夫，一个读书用功的女儿，一个很自闭的儿子，一个不成器的弟弟，一个关系很好的公司同事南希。一切看上去并不坏。有一天，妈妈陷入昏迷，我必须每天都去跟她说话，说着说着我就崩溃了，怎么只有这么少。我觉得我好像白活了。我每天像个傻子一样，我每天在干什么啊？我大哭起来，我找不到人生的意义，活了这么久到底在活些什么？南希劝说我去山上呆一段时间，回来的时候，我说，其实山上也没什么。后来，我依然不知道自己在做什么，迷茫着迷茫着，我就六十岁了。 我有个并没有太多交流的老婆，一个很可爱的女儿，一个很像我的儿子，一个一事无成的小舅子，一个相识很多年的老同学兼同事。其实我心里还住着一个人，我的初恋女友阿瑞。常常觉得与周围格格不入，我自有一套行为方式。我讨厌生意里的尔虞我诈，我厌恶事事谈到钱的恶俗，可是我却不得不深陷其中。直到遇到大田，我觉得自己交了一个真心的朋友，跟他谈音乐艺术，跟他谈人生哲理，从未如此推心置腹。我还遇见了阿瑞，想起初恋的过往，我心里从来就没有爱过另一个人，只有她。可是我却拒绝了她，因为我觉得真没有再活一次的必要了，过去了就是过去了，已经回不来了。冲突着冲突着，我就六十岁了。 六十岁的我是婆婆 我从来没说过一句话，但是我一直都知道。知道他们的困惑彷徨，知道他们的脆弱悲伤，知道他们的快乐欣喜，这些我全都知道，而且我也知道该怎么做，可是我不想说，我也不能说。因为就像植物一样，过度照顾反而让他失去了进化的本能，他们总会和我一样明白，因为他们总会有自己的六十岁，而我却要死了。 或许你现在是过去的洋洋，现在的婷婷，将来的舅舅，敏敏，NJ，不管怎么样，你最后都是婆婆，一开始都是舅舅的儿子。周围亦有现在的洋洋，现在的婷婷，现在的舅舅，敏敏，NJ，婆婆。一个你便组成了一个世界。 看完电影，我就开始极力给他解释我为什么看到的是日落，我说日落后是长长的黑暗却总会有黎明的到来，总怀揣着希望。今天早上当我去跑步的时候，看到街角的早餐店，里面供应着花卷，馒头，烧卖，酸菜包，肉包，白菜包，饺子，一共七种。我想我每天买一种，就是七天，一共有四家店，就是二十八天，将近一个月。于是我可以跟婆婆说，我每天都有不一样。 @来自豆瓣]]></content>
      <categories>
        <category>生活杂技</category>
      </categories>
      <tags>
        <tag>电影</tag>
      </tags>
  </entry>
</search>
